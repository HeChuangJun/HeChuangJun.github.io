<?xml version="1.0" encoding="utf-8"?><?xml-stylesheet type="text/xsl" href="https://javaguide.cn/rss.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/">
  <channel>
    <atom:link href="https://javaguide.cn/rss.xml" rel="self" type="application/rss+xml"/>
    <title>JavaGuide</title>
    <link>https://javaguide.cn/</link>
    <description>「Java学习指北 + Java面试指南」一份涵盖大部分 Java 程序员所需要掌握的核心知识。准备 Java 面试，复习 Java 知识点，首选 JavaGuide！  </description>
    <language>zh-CN</language>
    <pubDate>Mon, 04 Aug 2025 13:34:28 GMT</pubDate>
    <lastBuildDate>Mon, 04 Aug 2025 13:34:28 GMT</lastBuildDate>
    <generator>@vuepress/plugin-feed</generator>
    <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
    <category>前端</category>
    <category>面试</category>
    <category>网址收藏</category>
    <category>后端</category>
    <category>运维</category>
    <category>理论</category>
    <category>算法</category>
    <category>数据库</category>
    <category>源码</category>
    <category>架构设计</category>
    <item>
      <title>CSS</title>
      <link>https://javaguide.cn/frontend/css.html</link>
      <guid>https://javaguide.cn/frontend/css.html</guid>
      <source url="https://javaguide.cn/rss.xml">CSS</source>
      <description>css 1. css(cascacing style sheet)层叠样式表 2. css语法 3. 块元素和行内元素 4. 选择器:CSS寻找实现效果的目标元素的工具（核心） 5. CSS的样式、属性：属性值 6. 盒子模型 7. 获取元素的绝对位置 8. 使用div+css的步骤构建页面的步骤（个人看法） 9. 浮动 1. css(cascacin...</description>
      <category>前端</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>css</p>
<!--more-->
<!-- TOC -->
<ul>
<li><a href="#1-csscascacing-style-sheet%E5%B1%82%E5%8F%A0%E6%A0%B7%E5%BC%8F%E8%A1%A8">1. css(cascacing style sheet)层叠样式表</a></li>
<li><a href="#2-css%E8%AF%AD%E6%B3%95">2. css语法</a></li>
<li><a href="#3-%E5%9D%97%E5%85%83%E7%B4%A0%E5%92%8C%E8%A1%8C%E5%86%85%E5%85%83%E7%B4%A0">3. 块元素和行内元素</a></li>
<li><a href="#4-%E9%80%89%E6%8B%A9%E5%99%A8css%E5%AF%BB%E6%89%BE%E5%AE%9E%E7%8E%B0%E6%95%88%E6%9E%9C%E7%9A%84%E7%9B%AE%E6%A0%87%E5%85%83%E7%B4%A0%E7%9A%84%E5%B7%A5%E5%85%B7%E6%A0%B8%E5%BF%83">4. 选择器:CSS寻找实现效果的目标元素的工具（核心）</a></li>
<li><a href="#5-css%E7%9A%84%E6%A0%B7%E5%BC%8F%E5%B1%9E%E6%80%A7%E5%B1%9E%E6%80%A7%E5%80%BC">5. CSS的样式、属性：属性值</a></li>
<li><a href="#6-%E7%9B%92%E5%AD%90%E6%A8%A1%E5%9E%8B">6. 盒子模型</a></li>
<li><a href="#7-%E8%8E%B7%E5%8F%96%E5%85%83%E7%B4%A0%E7%9A%84%E7%BB%9D%E5%AF%B9%E4%BD%8D%E7%BD%AE">7. 获取元素的绝对位置</a></li>
<li><a href="#8-%E4%BD%BF%E7%94%A8divcss%E7%9A%84%E6%AD%A5%E9%AA%A4%E6%9E%84%E5%BB%BA%E9%A1%B5%E9%9D%A2%E7%9A%84%E6%AD%A5%E9%AA%A4%E4%B8%AA%E4%BA%BA%E7%9C%8B%E6%B3%95">8. 使用div+css的步骤构建页面的步骤（个人看法）</a></li>
<li><a href="#9-%E6%B5%AE%E5%8A%A8">9. 浮动</a></li>
</ul>
<!-- /TOC -->
<h1>1. css(cascacing style sheet)层叠样式表</h1>
<ul>
<li>它是用于控制网页样式并允许将样式信息与网页内容分离的一种标记性语言</li>
<li>用于设置HTML页面中的文本内容（字体、大小、对齐方式等）、图片的外形（高度、边框样式、边距等）以及版面的布局等外观显示样式，就是使html页面更好看。</li>
<li>样式：给HTML标签添加需要显示的效果，通常存储在样式表中</li>
<li>层叠：使用不同的添加方式給同一个HTML标签添加样式，最后所有的样式叠在一起共同作用于该标签</li>
</ul>
<h1>2. css语法</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>选择器{//选择器区分大小写
	属性1：属性值;//属性和属性值不区分大小写，
	属性2：属性值;//如果属性值中间由多个单词组成且中间包含空格，则必须为这个属性值加上英文双引号
	/*css注释*/快捷键ctrl+/
	..
}
</code></pre></div><h1>3. 块元素和行内元素</h1>
<table>
<thead>
<tr>
<th style="text-align:center">分类</th>
<th style="text-align:center">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">div</td>
<td style="text-align:center">html块级标签，进行区域划分，独自占一行，后来加上的东西只能拎起一行</td>
</tr>
<tr>
<td style="text-align:center">span</td>
<td style="text-align:center">html标签行内元素，默认所有的在一行，span后面加的东西可以和它同一行，无高度宽度</td>
</tr>
</tbody>
</table>
<h1>4. 选择器:CSS寻找实现效果的目标元素的工具（核心）</h1>
<table>
<thead>
<tr>
<th style="text-align:center">选择器分类</th>
<th style="text-align:center">语法</th>
<th style="text-align:center">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">id选择器</td>
<td style="text-align:center">#id{}</td>
<td style="text-align:center">对一个元素单独设置样式一个 id 只可以作用于一个标签上面，一个标签也只有一个 id 名。</td>
</tr>
<tr>
<td style="text-align:center">类选择器</td>
<td style="text-align:center">.class{}</td>
<td style="text-align:center">对一个元素定义单独样式或对多个元素设置相同的样式</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">类选择器与id选择器在命名只能是英文字母、数字、连接符(-)、下划线(_)，</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">数字不能打头。(连接符、下划线打头后面需要跟字母)</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">一个类名可作用于多个标签上面，一个标签也可有多个类名(多个类名用空格隔开)</td>
</tr>
<tr>
<td style="text-align:center">元素选择器</td>
<td style="text-align:center">html标签名{}</td>
<td style="text-align:center">对同类型的html标签设置相同样式</td>
</tr>
<tr>
<td style="text-align:center">层级（包含）选择器</td>
<td style="text-align:center">父元素 子元素</td>
<td style="text-align:center">如：div p</td>
</tr>
<tr>
<td style="text-align:center">属性选择器</td>
<td style="text-align:center">基本选择器[属性=‘属性值’]</td>
<td style="text-align:center">如：input[type='text']</td>
</tr>
</tbody>
</table>
<h1>5. CSS的样式、属性：属性值</h1>
<table>
<thead>
<tr>
<th style="text-align:center">CSS常见样式</th>
<th style="text-align:center">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">border</td>
<td style="text-align:center">边界 1px solid black;  solid实线、none无边、double双线</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">border-top-style、border-right-style、border-bottom-style、border-left-style</td>
</tr>
<tr>
<td style="text-align:center">width</td>
<td style="text-align:center">宽度 10px</td>
</tr>
<tr>
<td style="text-align:center">height</td>
<td style="text-align:center">高度 10px</td>
</tr>
<tr>
<td style="text-align:center">float</td>
<td style="text-align:center">浮动 left/right/none;</td>
</tr>
<tr>
<td style="text-align:center">clear</td>
<td style="text-align:center">清除浮动 left/right/both 浮动不再占用原文档流的位置</td>
</tr>
<tr>
<td style="text-align:center">display</td>
<td style="text-align:center">block块标签，以区域的方式出现，每个标签独自占据一整行或多整行。a,span</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">inline行内元素，不必再新的一行开始，不强迫其他元素在新一行显示hn,div,ul,ol，无高度宽度</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">inline-block将对象呈递为内联对象，但是对象的内容作为块对象呈递</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">none,不显示不占用页面空间</td>
</tr>
<tr>
<td style="text-align:center">margin</td>
<td style="text-align:center">外边距auto;页面居中</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">margin-top、margin-right、margin-bottom、margin-left</td>
</tr>
<tr>
<td style="text-align:center">padding</td>
<td style="text-align:center">内边距 padding:10px 0.25em 2ex 20%;按上右下左的顺序设置各边的内边距，可为像素百分比等不同单位</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">padding-top、padding-right、padding-bottom、padding-left</td>
</tr>
<tr>
<td style="text-align:center">font-style</td>
<td style="text-align:center">italic(斜体)、normal(正常的);</td>
</tr>
<tr>
<td style="text-align:center">font-size</td>
<td style="text-align:center">30px;</td>
</tr>
<tr>
<td style="text-align:center">font-family</td>
<td style="text-align:center">"楷体";</td>
</tr>
<tr>
<td style="text-align:center">color</td>
<td style="text-align:center">字体颜色没有font-color属性！！！！</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">(1)(英文单词)red;(2)十六进制数字， color：#FF00FF</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">(3)rgb 表示rgb(0,0,0)，三个值红、绿、蓝，每个取值都是 0-255 或者百分比</td>
</tr>
<tr>
<td style="text-align:center">font-weight</td>
<td style="text-align:center">数字(100-900 的整百数值)、bold加粗，bolder 比加粗更粗，lighter 细线)</td>
</tr>
<tr>
<td style="text-align:center">text-align</td>
<td style="text-align:center">center 内容（包括图片文字）居中</td>
</tr>
<tr>
<td style="text-align:center">text-decoration</td>
<td style="text-align:center">none 超链接的下划线去掉</td>
</tr>
<tr>
<td style="text-align:center">background-color</td>
<td style="text-align:center">背景颜色 red</td>
</tr>
<tr>
<td style="text-align:center">background-image</td>
<td style="text-align:center">背景图片 url(../aaa/bbb/love.jpg);</td>
</tr>
<tr>
<td style="text-align:center">Background-repeat</td>
<td style="text-align:center">是否平铺 repeat-X:在水平方向进行平铺</td>
</tr>
<tr>
<td style="text-align:center">Background-position</td>
<td style="text-align:center">center</td>
</tr>
<tr>
<td style="text-align:center">transform</td>
<td style="text-align:center">translateX(10px);translateX(100%/-100%);将整个div移到当前位置的最右/左</td>
</tr>
<tr>
<td style="text-align:center">opacity</td>
<td style="text-align:center">不透明度opacity:1;//默认1，不透明,透明0，看不见</td>
</tr>
<tr>
<td style="text-align:center">overflow</td>
<td style="text-align:center">overflow-x:hidden;超出大小是否显示滚动条</td>
</tr>
<tr>
<td style="text-align:center">transition</td>
<td style="text-align:center">ll 0.8s ease;//渐变</td>
</tr>
<tr>
<td style="text-align:center">position:absolute;</td>
<td style="text-align:center">生成绝对定位的元素，相对于static 定位以外的第一个父元素进行定位</td>
</tr>
</tbody>
</table>
<br>
<table>
<thead>
<tr>
<th style="text-align:center">引入CSS样式方法</th>
<th style="text-align:center">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">行内引入</td>
<td style="text-align:center">&lt;div style="font-size: 20px;"&gt; 没有做到结构与显示分离，耦合性大，少用</td>
</tr>
<tr>
<td style="text-align:center">内部引入</td>
<td style="text-align:center">&lt;style type="text/css"&gt;&lt;/style&gt;//在head标签之间,无法重用于其他页面</td>
</tr>
<tr>
<td style="text-align:center">外部引入</td>
<td style="text-align:center">&lt;link rel="stylesheet" href="" type="text/css"/&gt;//在head标签之间,结构与显示分离</td>
</tr>
<tr>
<td style="text-align:center">优先级</td>
<td style="text-align:center">理论上：行内&gt;内嵌&gt;链接 + 就近原则</td>
</tr>
</tbody>
</table>
<br>
<h1>6. 盒子模型</h1>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/b6fb687624b49e601d278.png" alt="f6.png" tabindex="0"><figcaption>f6.png</figcaption></figure>
<ul>
<li>padding和margin修改注意总尺寸变化<br>
|定位分类|说明|<br>
|:-😐 :-: |<br>
|相对定位|position: relative;left: 30px;top: 20px;调整元素出现在原位置的相对位置，占据空间|<br>
|绝对定位|position: absolute;left: 30px;top: 20px;与文档流无关，不占据空间，相对于祖先元素定位|<br>
|浮动|向左或向右移动，直到外边缘碰到包含框或另一个浮动框的边框为止,不在文档的普通流|</li>
</ul>
<h1>7. 获取元素的绝对位置</h1>
<ul>
<li>const Position=document.getElement.getBoundingClientRect();返回的是一个包含绝对位置的像素值Position.left,top,right,bottom</li>
</ul>
<h1>8. 使用div+css的步骤构建页面的步骤（个人看法）</h1>
<ul>
<li>1、先分析网页由多少个div组成</li>
<li>2、根据具体div设置相应选择器及样式width、height、border必写，根据F12的开发人员工具来完成以上问题的设置</li>
<li>3、最后慢慢调整间隙，注意浮动的妙用。</li>
</ul>
<h1>9. 浮动</h1>
<ul>
<li>由于浮动框不在文档的普通流中，文档的普通流中的块框就像浮动框不存在一样</li>
<li>浮动的框可能覆盖不浮动（文档流）框，<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/d2bc4784b896cf8e15c64.png" alt="f1.png"><br>
浮动框碰到浮动框按顺序排列，<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/b2cf0aa2a3c78765d1be9.png" alt="f2.png"><br>
如果包含框太窄，无法容纳水平排列的三个浮动元素，那么其它浮动块向下移动，直到有足够的空间。<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/48be5f3730a140a0f9d7c.png" alt="f3.png"><br>
如果浮动元素的高度不同，那么当它们向下移动时可能被其它浮动元素“卡住”：<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/796254cdc35b55416d035.png" alt="f4.png"><br>
清除浮动<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/dd3750454853e58bb7222.png" alt="f5.png"></li>
</ul>
]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/b6fb687624b49e601d278.png" type="image/png"/>
    </item>
    <item>
      <title>Html</title>
      <link>https://javaguide.cn/frontend/html.html</link>
      <guid>https://javaguide.cn/frontend/html.html</guid>
      <source url="https://javaguide.cn/rss.xml">Html</source>
      <description>Html 1. Html介绍 超文本标记语言（HyperText Markup Language）不是编程语言 超文本指页面可以包含图片、链接等非文字内容，比普通文本更强大 标记就是使用标签的方法将需要的内容包起来。使用一组标签对内容进行描述的语言 标签不区分大小写，建议小写，扩展名html或htm HTML：它是整个网站的骨架。 CSS：它是对整个网...</description>
      <category>前端</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>Html</p>
<!--more-->
<h1>1. Html介绍</h1>
<ul>
<li>超文本标记语言（HyperText Markup Language）不是编程语言</li>
<li>超文本指页面可以包含图片、链接等非文字内容，比普通文本更强大</li>
<li>标记就是使用标签的方法将需要的内容包起来。使用一组标签对内容进行描述的语言</li>
<li>标签不区分大小写，建议小写，扩展名html或htm</li>
<li>HTML：它是整个网站的骨架。</li>
<li>CSS：它是对整个网站骨架的内容进行美化(修饰)</li>
<li>Javascript：它能够让整个页面具有动态效果。</li>
</ul>
<h1>2. Html文档结构</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>&lt;!DOCTYPE html&gt;&lt;!--html5的头,比html4.01的文件头简洁--&gt;
&lt;html lang="zh"&gt;&lt;!--根标签，由头和体组成 , lang语言--&gt;
&lt;head&gt;&lt;!--头标签，用于引入脚本、导入样式、提供元信息等，浏览器端不显示--&gt;
	&lt;meta charset="UTF-8"&gt;&lt;!--设置html页面编码--&gt;
	&lt;title&gt;显示浏览器标题&lt;/title&gt;
&lt;/head&gt;
	&lt;body&gt;体标签，网页主体&lt;/body&gt;
&lt;/html&gt;

vscode 的 "!" 快捷键
</code></pre></div><h1>3. Html语法</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>注释:&lt;!--注释内容--&gt;  快捷键ctrl+/，源码可见，不能嵌套

超链接：&lt;a href="目标地址url" target="_blank(新开)/_self(替换)/frame的name属性" title="提示文本"&gt;超链接&lt;/a&gt; 目标地址 "2.html" 、"http://www.baidu.com" "#p1" 锚点 &lt;p id="p1"&gt;下面内容&lt;/p&gt;
&lt;a href="#"&gt;回到顶部&lt;/a&gt;

&lt;b&gt;粗体&lt;/b&gt;

&lt;br/&gt;插入单个换行

&lt;div&gt;11&lt;/div&gt;

&lt;!--frameset（了解） --&gt;
&lt;!--多个窗口页面整合在一起的一个集合（框架集），每个页面都是单独文档，--&gt;
&lt;!--需要用子标签&lt;frame&gt;来确定页面的位置。多个frameset可以嵌套使用，frameset和body不能共存--&gt;
&lt;a href="right.html" target="right"&gt;&lt;/a&gt;
&lt;frameset rows="20%,*/？px，*(表示上边占？%/？像素，下边100-？%)"&gt;
	&lt;frameset cols="20%,*/？px，*(左边占20%/？像素，右边占80%)"&gt;
	&lt;frame src="url用于指向html页面" nonresize=”true”noresize框架分割线不能移动/&gt;
	&lt;frame name="right(frame中的name 属性必须是超链接的的target属性值)" /&gt;
&lt;/frameset&gt;

&lt;!--表单标签（重要）
action属性，请求路径，确定表单提交到服务器的地址（路径）
method属性，请求方式，默认get，提交的数据追加在请求路径上。不安全。
如/1.html?username=jack&amp;password=1234.数据格式k/v，追加使用？拦截，
之后每一对数据使用&amp;连接，url限制提交长度
post属性值，提交的数据不在请求路径上，不显示在地址栏上，安全，长度无限制
表单标签，无显示，要提交的数据必须放在表单标签内
enctype 在 post 请求时，指定请求体的数据格式
o application/x-www-form-urlencoded(默认)
o multipart/form-data
其中表单项提供多种收集数据的方式
。 有 name 属性的表单项数据，才会被发送给服务器
--&gt;
&lt;form action="#/${pageContext.request.contextPath}/虚拟路径" method="get/post" entype=”multipart/form-data(包含上传控件) name="regist"“”&gt;
	输入框:
	&lt;input type="text" disabled name="a" readonly="readonly(只读)" value="a" maxlength="5"  placeholder="用户提示" /&gt;
	&lt;input type="password" name="password" required="required（必填）"/&gt;
	生日 &lt;input type="date"name="birthday"&gt; java用LocalDate birthday接收@DateTimeFormat(pattern ="yyyy-MM-dd")
	单选按钮 java用String sex接收
	&lt;input type="radio" name="sex" value="男"/&gt;男
	&lt;input type="radio" name="sex" value="女" checked="checked（默选）"/&gt;女
	复选按钮 java用List接收
	&lt;input type="checkbox" name="hobby" value="钓鱼"/&gt;钓鱼
	&lt;input type="checkbox" name="hobby" value="a" checked="checked"/&gt;a
	提交按钮：&lt;input type="submit" value="注册（显示文本）"/&gt;
	普通按钮：&lt;input type="button" value="zhuce"/&gt;
	重置按钮：（将表单恢复到默认值）&lt;input type="reset" /&gt;
	&lt;!--图形提交按钮通过src给按钮设置图片image--&gt;
	隐藏字段:&lt;input type="hidden" name="id" value="（暗中传输一些参数）" /&gt;
	上传文件&lt;input type="file(上传)" name="avatar"/&gt; 后端用MultipartFile avatar接收
	&lt;!--name属性（必写）服务器通过name属性值获得表单提交的数据、见闻起义
	value属性:设置input默认值,submit和reset为按钮显示数据,发给服务器的值--&gt;
	下拉框：
	&lt;select name="province" multiple=”multiple（多选）”size=“3（可见选项数）”&gt;
	&lt;option&gt;--请选择--&lt;/option&gt;
	&lt;option value="北京"&gt;北京&lt;/option&gt;
	&lt;option value="上海" selected="selected（默认勾选）"&gt;上海&lt;/option&gt;
	&lt;/select&gt;
	文本域：
	&lt;textarea name="zwjs" cos=”?（列数）” rows=”?（行数）”&gt;&lt;/textarea&gt;
&lt;/form&gt;

&lt;font size="7"(1-7，默认3，大于7的按7显示)color="#FF0000(blue)" face=“楷体”&gt;&lt;/font&gt;

&lt;h2&gt;标题标签hn 1-6，n越大，字体越小，大于6则按6算&lt;/h2&gt;加粗加黑显示，单独占用一行，与其他行有一定的间距

&lt;hr size=”5”（水平线的高度，单位像素） noshade=”noshade(水平线标签:noshade表示没阴影、纯色)”/&gt;

&lt;i&gt;斜体&lt;/i&gt;

&lt;img src="图片路径url/#（不跳转）"  width="？px/？%" height="？px" alt="加载失败信息"/&gt;
&lt;!--width和height设置百分数用于填充满整个表格或该像素
src:指的是图片显示的路径(位置)
绝对路径：E:\Users\Desktop\WEB01_HTML\资料\WEB01\image
相对路径：
①同一级：直接写文件名称或者./文件名称
②上一级：../文件名称③下一级：目录名称/文件名称--&gt;
文件地址
data URL
data:媒体类型;base64,数据
object URL

&lt;video src="文件路径" controls&gt;&lt;/video&gt;
&lt;audio src="文件路径" controls&gt;&lt;/audio&gt;

&lt;ol start="4" reversed="reversed(有序列表降序排列)" type="a/A/i/I/1"&gt;
	&lt;li&gt;CSDN&lt;/li&gt;
	&lt;li&gt;百度&lt;/li&gt;
&lt;/ol&gt;

&lt;p title="I'm a tooltip"&gt;段落标签，自动在其前后创建一些空白 title将鼠标悬停在元素上时，title 属性的值将显示为工具提示&lt;/p&gt;

table(加载太慢，了解)
方式1
&lt;table align="center/right/center" border="2px" cellspacing="0px" cellpadding="0px" align="center"
	width="500px" height="400px" bgcolor="blue"&gt;			
	&lt;tr&gt;
		&lt;td colspan="2"&gt;2&lt;/td&gt;//列
		&lt;td rowspan="2"&gt;3&lt;/td&gt;
	&lt;/tr&gt;
	&lt;tr&gt;
		&lt;td &gt;4&lt;/td&gt;
		&lt;td &gt;5&lt;/td&gt;
	&lt;/tr&gt;
&lt;/table&gt;	
方式2
tbodies，所有的tbody，tbodies[i]，表示第几个tbody，rows多少行，rows[i],第几行。length，长度
&lt;table border="1px" width="500px" height="50px" align="center" id="tbl"&gt;
	&lt;thead&gt;
		&lt;tr&gt;
		&lt;th&gt;编号&lt;/th&gt;//表头，该内容默认居中、加粗
		&lt;th&gt;姓名&lt;/th&gt;
		&lt;th&gt;年龄&lt;/th&gt;
		&lt;/tr&gt;
	&lt;/thead&gt;
	&lt;tbody&gt;
		&lt;tr &gt;
		&lt;td&gt;1&lt;/td&gt;
		&lt;td&gt;张三&lt;/td&gt;
		&lt;td&gt;22&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr &gt;
		&lt;td&gt;2&lt;/td&gt;
		&lt;td&gt;李四&lt;/td&gt;
		&lt;td&gt;25&lt;/td&gt;
		&lt;/tr&gt;
	&lt;/tbody&gt;
&lt;/table&gt;

&lt;ul type="square/circle/disc(无序列表方块/空心圆/实心圆)"&gt;
	&lt;li&gt;CSDN&lt;/li&gt;
	&lt;li&gt;百度&lt;/li&gt;
&lt;/ul&gt;

&amp;nbsp；&amp;lt;
</code></pre></div>]]></content:encoded>
    </item>
    <item>
      <title>javascript</title>
      <link>https://javaguide.cn/frontend/javascript.html</link>
      <guid>https://javaguide.cn/frontend/javascript.html</guid>
      <source url="https://javaguide.cn/rss.xml">javascript</source>
      <description>javaScript 1. 概念&amp;作用 2. javascript引入方式 3. 数据类型 4. typeof、instanceof、=== 5. javaScript语法 6. BOM浏览器对象模型（整个HTML页面内容） 7. javascript正则匹配 8. 转换成jq对象 9. 全局属性和函数可用于所有内建的JavaScript对象 10. ...</description>
      <category>前端</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>javaScript</p>
<!--more-->
<!-- TOC -->
<ul>
<li><a href="#1-%E6%A6%82%E5%BF%B5%E4%BD%9C%E7%94%A8">1. 概念&amp;作用</a></li>
<li><a href="#2-javascript%E5%BC%95%E5%85%A5%E6%96%B9%E5%BC%8F">2. javascript引入方式</a></li>
<li><a href="#3-%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B">3. 数据类型</a></li>
<li><a href="#4-typeofinstanceof">4. typeof、instanceof、===</a></li>
<li><a href="#5-javascript%E8%AF%AD%E6%B3%95">5. javaScript语法</a></li>
<li><a href="#6-bom%E6%B5%8F%E8%A7%88%E5%99%A8%E5%AF%B9%E8%B1%A1%E6%A8%A1%E5%9E%8B%E6%95%B4%E4%B8%AAhtml%E9%A1%B5%E9%9D%A2%E5%86%85%E5%AE%B9">6. BOM浏览器对象模型（整个HTML页面内容）</a></li>
<li><a href="#7-javascript%E6%AD%A3%E5%88%99%E5%8C%B9%E9%85%8D">7. javascript正则匹配</a></li>
<li><a href="#8-%E8%BD%AC%E6%8D%A2%E6%88%90jq%E5%AF%B9%E8%B1%A1">8. 转换成jq对象</a></li>
<li><a href="#9-%E5%85%A8%E5%B1%80%E5%B1%9E%E6%80%A7%E5%92%8C%E5%87%BD%E6%95%B0%E5%8F%AF%E7%94%A8%E4%BA%8E%E6%89%80%E6%9C%89%E5%86%85%E5%BB%BA%E7%9A%84javascript%E5%AF%B9%E8%B1%A1">9. 全局属性和函数可用于所有内建的JavaScript对象</a></li>
<li><a href="#10-%E4%B8%BA%E4%BB%80%E4%B9%88js%E6%98%AF%E5%8D%95%E7%BA%BF%E7%A8%8B%E7%9A%84">10. 为什么JS是单线程的？</a></li>
</ul>
<!-- /TOC -->
<h1>1. 概念&amp;作用</h1>
<ul>
<li>编程语言 用于开发交互式web页面（向HTML页面添加交互行为）</li>
<li>脚本语言（轻量级编程语言）</li>
<li>不需编译（解释性语言）直接嵌入HTML页面中，由浏览器执行</li>
<li>HTML页面中嵌入动态文本、对浏览器事件响应，读写HTML元素，</li>
<li>验证提交数据，检测访客数及访客的浏览信息等。使页面具有动态效果</li>
</ul>
<h1>2. javascript引入方式</h1>
<table>
<thead>
<tr>
<th style="text-align:center">javascript引入方式</th>
<th style="text-align:center">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">内嵌式</td>
<td style="text-align:center">&lt;script type="text/javascript(默认，可省略)"&gt;javascript代码&lt;/script&gt;</td>
</tr>
<tr>
<td style="text-align:center">外联式</td>
<td style="text-align:center">&lt;script type="text/javascript" src=“1.js” charset=“utf-8”&gt;&lt;/script&gt;</td>
</tr>
</tbody>
</table>
<h1>3. 数据类型</h1>
<p>|基本（值）数据类型|说明|举例|<br>
|:-😐:-😐<br>
|String|使用双引号 " 或单引号 ' 括起来的一个或多个字符|"<a href="http://caibaojian.com" target="_blank" rel="noopener noreferrer">http://caibaojian.com</a>"、'字符串'|<br>
|Number|包括整数和浮点数（包含小数点的数或科学记数法的数）|30、-10、11.2、2.35e10|<br>
|Boolean|表示 true 或 false 这两种状态|5 == 2 其运算结果为 false|<br>
|Null|变量或内容值为空（null），可以通过给一个变量赋 null 值来清除变量的内容|str = null|<br>
|Undefined|变量被创建后，未给该变量赋值，|var str|<br>
|对象（引用）类型|说明|举例|<br>
|Array|var cars=new Array();|var cars=["Audi","BMW","Volvo"];|<br>
|Object|JavaScript 操作的对象|var person={firstname:"Bill", lastname:"Gates", id:5566};|<br>
|Function|JavaScript 操作的对象|可以执行的一种特别对象|<br>
<br></p>
<h1>4. typeof、instanceof、===</h1>
<ul>
<li>typeof返回类型字符串
<ul>
<li>可以判断undefined、Number、string、boolean、function</li>
<li>不能判断：null与object</li>
</ul>
</li>
<li>instanceof 判断对象具体类型</li>
<li>=== 可以判断null undefined<br>
严格相等运算符，用作逻辑判等</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>1 == 1 // 返回 true
1 === '1'// 返回 true，会先将右侧的字符串转为数字，再做比较
1 === 1 // 返回 false，类型不等，直接返回 fa1se
</code></pre></div><p>typeof 查看某个值的类型</p>
<p>||<br>
需求，如果参数n没有传递，给它一个【男】</p>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>推荐做法
function test(n='男'){conso1e.1og(n);}
你可能的做法
function test(n){
	if(n === undefined){
		n='男';
	}
	conso1e.1og(n);
}
还可能是这样
function test(n){
	n=(n=== undefined)?'男’:n;
	console.1og(n);
}
一些老旧代码中可能的做法
function test(n){
	n = n ||'男'
	console.1og(n);
}
它的语法是
值1 || 值2
如果值1 是 Truthy，返回值1，如果值1 是 Falsy 返回值 2

3)??与?.
需求，如果参数 n没有传递或是 null，给它一个【男】
如果用传统办法
function test(n){
	if(n == undefined || n=== nu11){
		n='男'
    }
	console.1og(n);
}
用??
function test(n){
	n = n ?? '男';
	console.1og(n);
}

需求，函数参数是一个对象，可能包含有子属性
例如，参数可能是
let stul={
	name :"张三”，
	address:{
		city:'北京
	};
}
let stu2 ={
	name:"李四”
}
let stu3={
name:"李四"
address:nu11
}
现在要访问子属性(有问题)
function test(stu){
console.1og(stu.address.city)
}
现在希望当某个属性是 nulish 时，短路并返回 undefined
function test(stu){
	console.1og(stu.address?.city)
}
用传统办法
function test(stu){
	if(stu.address ===undefined ll stu.address === nu11){
		console.1og(undefined);
		return;
    }
	console.1og(stu.address.city)
}

...
展开运算符
作用1:打散数组传递给多个参数
let arr = [1, 2, 3];
function test(a,b,c){
	console.1og(a,b,c);
}
test(arr[0],arr[1],arr[2]);// 输出 1,2,3
展开运算符写法
test(...arr);// 输出 1,2,3
打散可以理解为【去掉了】数组外侧的中括号，只剩下数组元素
作用2:复制数组或对象
数组
let arr1 = [1,2,3];
let arr2= [...arrl]; // 复制数组

注意:展开运算符复制属于浅拷贝，例如
let ol = {name:'张三',address: {city:【北京'}}
let o2 = {...01};

对象
let objl = {name:'张三',age: 18};
Tet obj2 = {...obj1}; //复制对象
作用3:合并数组或对象
let a1 = [1,2];
let a2 = [3,4];
let b1= [...al,...a2];// 结果[1,2,3,4]
let b2 = [...a2,5,...al]// 结果[3,4,5,1,2]

合并对象
let ol= {name:'张三'};
Tet o2 = {age:18};
let o3 ={name:'李四'};
let nl={...ol,...02};
let n2 = {...03,...o2,..o1}:
同名后面覆盖前面

5)[] {}
解构赋值
[]
用在声明变量时
let arr = [1,2,3];
let [a,b，c]= arr;//结果 a=1，b=2，c=3

用在声明参数时
let arr =[1,2,3];
function test([a,b,c]){
	consofe.1og(a,b,c)
}
test(arr) // 结果 a=1，b=2，c=3

{}
用在声明变量时
let obj = {name:"张三",age:18};
let {name,age} = obj;
用在声明参数时
let obj = {name:"张三", age:18};
function test({name, age]) {console.1og(name，age);}
test(obj)
</code></pre></div><h2>控制语句</h2>
<p>if ...else<br>
switch<br>
while<br>
do...while<br>
for<br>
for ... in ☆</p>
<p>for ... of ☆</p>
<p>try ... catch☆</p>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>1) for in
主要用来遍历对象
let father = {name:'张三', age:18, study:function(){}};
for(const n in father){
console.1og(n);
}
其中 const n代表遍历出来的属性名
注意1:方法名也能被遍历出来(它其实也算一种特殊属性)
注意2:遍历子对象时，父对象的属性会跟着遍历出来
Tet son =object.create(father);
son.sex =“男"

for(const n in son){
	console.1og(n);
}

注意3:在 for in 内获取属性值，要使用[]语法，而不能用.语法
for(const n in son){
	console.log(n, son[n]);
}

2) for of
主要用来遍历数组，也可以是其它可迭代对象，如 Map，set 等
let al =[1,2,3];

for(const i of al){
console.1og(i);
}
let a2 =[
{name:'张三', age:18},
{name:'李四'，age:20}
{name:'王五'，age:22}
];

for(const obj of a2){
console.1og(obj.name， obj.age);
}
for(const {name,age} of a2){
console.1og(name, age);
}

3) try catch
let stu1 = {name:'张三',age:18, address: {city:'北京'}};
1et stu2 ={name:'张三',age:18};

function test(stu){
	try {
		console.1og(stu.address.city)
    } catch(e){
		console.1og('出现了异常'，e.message)
    } finally {
    	console.1og('fina11y');
    }
}
</code></pre></div><h1>5. javaScript语法</h1>
<table>
<thead>
<tr>
<th style="text-align:center">javaScript组成</th>
<th style="text-align:center">基本语法</th>
<th style="text-align:center">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">ECMAScript（核心）</td>
<td style="text-align:center">变量定义</td>
<td style="text-align:center">var 变量名[=值];(可以不声明，直接使用，默认值undefined、变量存在但没赋值)</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">（变量弱类型：同一个变量可以存放不同类型的数据）</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">如果在函数的内容用var定义，那么它是一个局部变量，</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">如果没有使用var它是一个全局的</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">严格区分大小写，注释与java相同</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">运算符</td>
<td style="text-align:center">js比较===全等，值和类型，相比java没有equals，null写成""</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">== 它在做比较的时候会进行自动转换。</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">=== 它在做比较的时候不会进行自动转换。</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">基本数据类型</td>
<td style="text-align:center">number（任何数字）、bigint<br>number 类型标识的是双精度浮动小数，例如<br>10 /3;// 结果 3.3333333333333335<br>既然是浮点小数，那么可以除零<br>10 /0;// 结果 Infinity 正无穷大-10/0;//结果 -Infinity 负无穷大<br>浮点小数都有运算精度问题，例如<br>2.0-1.1;//结果 0.8999999999999999<br>字符串转数字<br>parseInt("10");// 结果是数字 10<br>parseInt("10.5")//结果是数字 10，去除了小数部分;<br>parseInt("10")/3;//结果仍视为 number 浮点数，因此结果为3.3333333333333335<br>parseInt("abc");<br>//转换失败，结果是特殊值 NaN(Not a Number)</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">string（“”‘’）<br>let s1 ='超链接'<br>let s2 ='超链接';<br>Tet name=;//zhang li...<br>Tet age =;// 18 20<br>let uri2=<code>/test?name=$iname}&amp;age=${age}</code> ;</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">boolean Truthy、Falsy<br>在js 中，并不是 boolean 才能用于条件判断，你可以在if语句中使用【数字】【字符串】.. 作为判断条件<br>这时就有一个规则，当需要条件判断时，这个值被当作 true 还是false，当作 true的值归类为 truthy，当作 false 的值归类为 falsy<br>false<br>Nullish (null, undefined)<br>0, 0n, NaN<br>"",",``</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">null（对象的默认值）和undefined(变量无初始化时的默认值))<br>执行表达式或函数，没有返回结果，出现 undefined<br>访问数组不存在的元素，访问对象不存在的属性，出现 undefined<br>定义变量，没有初始化，出现 undefined<br>二者共同点<br>都没有属性、方法<br>二者区别<br>undefined 由js产生，null 由程序员提供<br>Nullish</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">引用数据类型</td>
<td style="text-align:center">Number</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">String match()找到一个或多个正则表达式的匹配.substr(a,b)从起始索引号提取字符串中指定数目的字符.substring(a,b)提取字符串中两个指定的索引号之间的字符。</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">Boolean new Boolean(value)value不写默认false</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">Array</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">Boolean</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">DateDate.getTime()返回1970年1月1日至今的毫秒数、解决浏览器缓存问题</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">Math</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">ReqExp对象正则表达式对象 ReqExp.test(要测的对象)</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">普通函数</td>
<td style="text-align:center">[window/element.onload/var 变量名=]function 函数名(参数[=默认值],参数){函数体,return 返回值}</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">匿名函数</td>
<td style="text-align:center"><code>[window/element.onload/var 变量名=]</code>(function(参数,参数){函数体，return 返回值})<br>(function(a,b){return a + b;})<br>(function(a,b){return a+ b;})(1,2)<br></td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">箭头函数</td>
<td style="text-align:center">(参数)=&gt;{函数体 return结果}<br>如果只有一个参数，()可以省略<br>如果函数体内只有一行代码，{}可以省略document.getElementById("p1").onclick=()=&gt;<br>console.1og(“鼠标单击了...箭头函数");<br></td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">调用函数</td>
<td style="text-align:center">函数名(参数，参数)</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">事件(调用函数)</td>
<td style="text-align:center">事件=“[return] 函数名([参数，参数])”</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">onload 只能写一次并且放到body标签中</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">onsubmit   写在form标签中，必须有返回值。return false不提交</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">onclick、ondbclick</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">onblur 表单校验，text离焦</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">onfocus 表单校验，text获得焦点</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">onchange 二级联动、onkeydown搜索引擎</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">onkeypress 搜索引擎</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">onkeyup、onmousdown</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">onmouseup、onmouseover鼠标悬空高亮问题</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">onmouseout鼠标离开、onmousemove</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">让按钮点击失效：onclick=”javascript:volid(0)”</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">event对象</td>
<td style="text-align:center">clientX,鼠标指针水平坐标</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">clientY鼠标指针垂直坐标</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">keyCode返回键盘输入的ASCII码</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">preventDefault()阻止浏览器默认行为</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">stopPropagation()阻止事件传播</td>
</tr>
<tr>
<td style="text-align:center">BOM浏览器对象</td>
<td style="text-align:center">window对象</td>
<td style="text-align:center">表示浏览器中打开的窗口,都是全局函数，window可省略</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">alert(“提示框提示信息”);confirm("确认提示信息");prompt("提示信息框");</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">var xx=setInterval(function(),millisec)</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">setInterval（“function()”,毫秒值)</td>
</tr>
</tbody>
</table>
]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/7046ecfecabe6d05a7142.png" type="image/png"/>
    </item>
    <item>
      <title>jQuery</title>
      <link>https://javaguide.cn/frontend/jquery.html</link>
      <guid>https://javaguide.cn/frontend/jquery.html</guid>
      <source url="https://javaguide.cn/rss.xml">jQuery</source>
      <description>jQuery 1. jquery(重点) 2. jsdom与jq对象互换 3. 函数 4. 选择器：获取元素 5. jquery的Dom操作 6. apache POI技术 1. jquery(重点) 2. jsdom与jq对象互换 3. 函数 4. 选择器：获取元素 5. jquery的Dom操作 6. apache POI技术</description>
      <category>前端</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>jQuery</p>
<!--more-->
<!-- TOC -->
<ul>
<li><a href="#1-jquery%E9%87%8D%E7%82%B9">1. jquery(重点)</a></li>
<li><a href="#2-jsdom%E4%B8%8Ejq%E5%AF%B9%E8%B1%A1%E4%BA%92%E6%8D%A2">2. jsdom与jq对象互换</a></li>
<li><a href="#3-%E5%87%BD%E6%95%B0">3. 函数</a></li>
<li><a href="#4-%E9%80%89%E6%8B%A9%E5%99%A8%E8%8E%B7%E5%8F%96%E5%85%83%E7%B4%A0">4. 选择器：获取元素</a></li>
<li><a href="#5-jquery%E7%9A%84dom%E6%93%8D%E4%BD%9C">5. jquery的Dom操作</a></li>
<li><a href="#6-apache-poi%E6%8A%80%E6%9C%AF">6. apache POI技术</a></li>
</ul>
<!-- /TOC -->
<h1>1. jquery(重点)</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>javascript的一个轻量级框架，对javascript进行封装，提供简便选择器和方法。
①Jquery它是一个库(框架)，要想使用它，必须先引入！
&lt;script type="text/javascript" src="../../js/jquery-1.8.3.js" &gt;
&lt;/script&gt;
②在&lt;scrpit&gt;&lt;/script&gt;之间写jquery代码,用法jQuery(选择器)==$(选择器)
变量尽量$开头，//单行注释   /*多行注释*/
</code></pre></div><h1>2. jsdom与jq对象互换</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>jsdom对象→jquery对象：$(dom对象)或jQuery(dom对象)
jquery对象→jsdom对象：jquery对象[索引]、
jquery对象.get(索引)其中索引为匹配到的jq对象，一般为0
js和jq对象的api不能相互调用 
</code></pre></div><h1>3. 函数</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>js：window.onload=function(){}只赋值一次，覆盖，加载慢(整个页面加载完毕时执行&lt;包括图片&gt;)
jq:$(document).ready(function(){});多次赋值，依次执行快！
(整个dom树结构绘制完毕&lt;dom树图片可能没加载完&gt;加载)简写$(function(){});

jq选择器对象.事件=function(){});
jq选择器对象.事件(function(){})
可以用this代表当前的jq对象
</code></pre></div><h1>4. 选择器：获取元素</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>基本选择器
id选择器$("#id")
类选择器$(".class")
元素选择器$("元素")
$("*")
$("元素，元素") 选择两个样式都有的元素

层级选择器
$("父元素选择器   子元素选择器")选择父元素中所有的子元素
$("父元素选择器&gt;子元素选择器")选择父元素中的所有第一级子元素
$("父元素选择器+子元素选择器")选择父元素后面的所有子元素
$("父元素选择器~子元素选择器")选择父元素的所有同级兄弟元素

属性选择器
基本选择器[属性名=‘属性值’]
基本选择器[属性名]
基本选择器[属性名!='属性值']
基本选择器[属性名^='属性值']开头
基本选择器[属性名$='属性值']结尾
基本选择器[属性名*='属性值']

表单属性过滤选择器
$("select option:selected")
$("input:checked")
$(":text")

基本过滤选择器（常用）
:first
妙用</code></pre></div>]]></content:encoded>
    </item>
    <item>
      <title>计算机网络</title>
      <link>https://javaguide.cn/interview/computernetwork.html</link>
      <guid>https://javaguide.cn/interview/computernetwork.html</guid>
      <source url="https://javaguide.cn/rss.xml">计算机网络</source>
      <description>1. TCP三次握手原因 [TCP](计算机网络.md/#53-传输控制协议tcptransmission-control-protocol)</description>
      <category>面试</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<!-- more -->
<h1>1. TCP三次握手原因</h1>
<p><code>[TCP](计算机网络.md/#53-传输控制协议tcptransmission-control-protocol)</code></p>
]]></content:encoded>
    </item>
    <item>
      <title>分库分表</title>
      <link>https://javaguide.cn/interview/databasesharding.html</link>
      <guid>https://javaguide.cn/interview/databasesharding.html</guid>
      <source url="https://javaguide.cn/rss.xml">分库分表</source>
      <description>1. 为什么要分库？为什么要分表？ 业务量剧增，磁盘容量不足，并发连接数不足，所以要分库 &amp;lt;&amp;lt;阿里开发手册&amp;gt;&amp;gt;单表行数超过500万行或者单表容量超过2GB。存储和查询的性能就会遇到瓶颈了 2. 什么是分库分表？ 数据分片，指按照某个维度将存放在单一数据库中的数据分散地存放至多个数据库或表中以达到提升性能瓶颈以及可用性的效果。数据分片的有效手段是对关系型...</description>
      <category>面试</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<!-- more -->
<h1>1. 为什么要分库？为什么要分表？</h1>
<ul>
<li>业务量剧增，磁盘容量不足，并发连接数不足，所以要分库</li>
<li>&lt;&lt;阿里开发手册&gt;&gt;单表行数超过500万行或者单表容量超过2GB。存储和查询的性能就会遇到瓶颈了</li>
</ul>
<h1>2. 什么是分库分表？</h1>
<ul>
<li>数据分片，指按照某个维度将存放在单一数据库中的数据分散地存放至多个数据库或表中以达到提升性能瓶颈以及可用性的效果。数据分片的有效手段是对关系型数据库进行分库和分表</li>
</ul>
<h1>3. 如何选择分表键？</h1>
<ul>
<li>需要先找到业务的主题。比如你的数据库表是一张企业客户信息表，就可以考虑用了客户号做为分表键。</li>
<li>信息表，使用 id 进行分片。例如说，文章、商品信息等等。</li>
<li>业务表，使用 user_id 进行分片。例如说，订单表、支付表等等。</li>
<li>日志表，使用 create_time 进行分片。例如说，访问日志、登陆日志等等。</li>
</ul>
<h1>4. 非分表键如何查询？</h1>
<ul>
<li>假设一张用户表，根据userId做分表键，来分库分表。但是用户登录时，需要根据用户手机号来登陆。这时候，就需要通过手机号查询用户信息。而手机号是非分表键。</li>
<li>非分表键查询，一般有这几种方案：
<ul>
<li>将用户信息冗余同步到ES，同步发送到ES，然后通过ES来查询（推荐）</li>
<li>基因法：比如非分表键可以解析出分表键出来，比如常见的，订单号生成时，可以包含客户号进去，通过订单号查询，就可以解析出客户号。但是这个场景除外，手机号似乎不适合冗余userId。</li>
<li>映射关系：创建映射表，只有分表键、非分表键两列字段。使用非分表键查询时，先从映射表获得非分表键对应的分表键，然后再使用非分表键+分表键去查询对应的表。映射表可以改成缓存到Redis等缓存中。当然，需要考虑如果 Redis 持久化的情况。将映射表缓存到内存中，减少一次到映射表的查询。</li>
</ul>
</li>
</ul>
<h1>5. 分表策略如何选择？水平分表有哪几种路由方式？</h1>
<ul>
<li>
<p>路由：数据应该分到哪一张表。</p>
</li>
<li>
<p>根据范围：选取有序的数据列（例如，主键id、时间戳等）作为路由的条件，不同分段分散到不同的数据库表中。支付系统只能查一年范围内的支付记录可能就是按照时间进行了分表</p>
<ul>
<li>范围路由设计的复杂点主要体现在分段大小的选取上，分段太小会导致切分后子表数量过多，增加维护复杂度；分段太大可能会导致单表依然存在性能问题，一般建议分段大小在100万至2000万之间，具体需要根据业务选取合适的分段大小。</li>
<li>优点是有利于扩容。只需要增加新的表就可以了，原有的数据不需要动。</li>
<li>缺点分布不均匀和热点问题。假如按照1000万来进行分表，有可能某个分段实际存储的数据量只有1000条，而另外一个分段实际存储的数据量有900万条。最近一个月的订单都在300万~600万之间，平时用户一般都查最近一个月的订单比较多，请求都打到同一张表</li>
</ul>
</li>
<li>
<p>根据Hash取模：选取某个列（或者某几个列组合也可以）的值进行Hash运算，然后根据Hash结果取余分散到不同的数据库表中。同样以订单id为例，假如我们一开始就规划了4个数据库表，路由算法可以简单地用id%4的值来表示数据所属的数据库表编号，id为12的订单放到编号为50的子表中，id为13的订单放到编号为61的字表中。</p>
<ul>
<li>Hash路由设计的复杂点主要体现在初始表数量的选取上，表数量太多维护比较麻烦，表数量太少又可能导致单表性能存在问题</li>
<li>优点：表分布比较均匀，不会存在明显的热点问题。可以平均分配每个库的数据量和请求压力。</li>
<li>缺点：前期规划不好，需要扩容二次分表，表的数量需要增加，所以hash值需要重新计算，这时候需要迁移数据了。比如我们开始分了10张表，之后业务扩展需要，增加到20张表。那问题就来了，之前根据orderId取模10后的数据分散在了各个表中，现在需要重新对所有数据重新取模20来分配数据。</li>
</ul>
</li>
<li>
<p>一致性Hash</p>
<ul>
<li>如果用hash方式分表，为了解决这个扩容迁移问题，可以使用一致性hash思想来解决。</li>
<li>一致性哈希：在移除或者添加一个服务器时，能够尽可能小地改变已存在的服务请求与处理请求服务器之间的映射关系。一致性哈希解决了简单哈希算法在分布式哈希表存在的动态伸缩等问题</li>
<li>首先，选择一个足够大的Hash空间（一般是 0 ~ 2^32）构成一个哈希环。</li>
<li>然后，对于缓存集群内的每个存储服务器节点计算 Hash 值，可以用服务器的 IP 或 主机名计算得到哈希值，计算得到的哈希值就是服务节点在 Hash 环上的位置。</li>
<li>最后，对每个需要存储的数据 key 同样也计算一次哈希值，计算之后的哈希也映射到环上，数据存储的位置是沿顺时针的方向找到的环上的第一个节点。</li>
<li>扩容服务器时只需替移动重复的hash对应的资源</li>
<li>可以使用Guava // bucket 的范围在 0 ~ buckets 之间 int bucket = Hashing.consistentHash(id, buckets)</li>
</ul>
</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class Main {
    //真实节点
    private static String[] serverIpArray = new String[]{"192.168.1.100", "47.100.61.70", "172.87.2.10", "1.1.1.1", "34.125.90.32"};
    //虚拟节点
    private static TreeMap&lt;Integer, String&gt; virtualNodeMap;
 
    static {
        virtualNodeMap = new TreeMap&lt;&gt;();
        //默认为每个真实节点生成3个虚拟节点
        for (String realIp : serverIpArray) {
            for (int i = 0; i &lt; 3; i++) {
                //这边加上随机数,只是为了使得虚拟节点的hash值更加分散
                //但是在实际情况中，虚拟节点的hash值需要固定
                String virtualIp = new Random().nextInt(10000) + "#" + realIp;
                virtualNodeMap.put(getHash(virtualIp), realIp);
            }
        }
    }
 
    //获取ip的哈希值,可以有多种算法实现,这里只用hashCode()演示
    //当然也有其他的实现,避免ip相近,hash相近的情况
    private static int getHash(String ip) {
        int hashCode = Math.abs(ip.hashCode());
        System.out.println(ip + ":" + hashCode);
        return hashCode;
    }
 
    //由客户端获取最近的虚拟节点,最后返回虚拟节点对应的真实节点
    private static String getRealServerIp(String client) {
        int clientHash = getHash(client);
        Integer higherKey = virtualNodeMap.higherKey(clientHash);
        if (higherKey == null) {
            //返回hash环中的第一个虚拟ip
            return virtualNodeMap.get(virtualNodeMap.firstKey());
        }
        //返回比客户端的哈希值稍微大一点的虚拟ip
        return virtualNodeMap.get(higherKey);
    }
 
    public static void main(String[] args) {
        String[] clientIpArray = new String[]{"小明家的电脑", "小红的平板", "小华的手机"};
        for (String client : clientIpArray) {
            String realIp = getRealServerIp(client);
            System.out.println(client + "连接到了" + realIp);
        }
    }
}
</code></pre></div><h1>6. 分库分表带来的问题</h1>
<ul>
<li>从分库的角度
<ul>
<li>跨库事务问题：需要分布式事务来解决</li>
<li>跨库无法使用JOIN问题：
<ul>
<li>业务代码中进行关联，先把一个表的数据查出来，然后通过得到的结果再去查另一张表，然后利用代码来关联得到最终的结果</li>
<li>适当的冗余一些字段。比如以前的表就存储一个关联ID，但是业务时常要求返回对应的Name或者其他字段。这时候就可以把这些字段冗余到当前表中，来去除需要关联的操作。</li>
<li>数据异构，通过binlog同步等方式，把需要跨库join的数据异构到ES等存储结构中，通过ES进行查询。</li>
</ul>
</li>
</ul>
</li>
<li>从分表的角度
<ul>
<li>跨节点的count,orderby,groupby以及聚合函数问题:只能由业务代码来实现或者用中间件将各表中的数据汇总、排序、分页然后返回。</li>
<li>数据迁移，容量规划，扩容等问题:数据的迁移，容量如何规划，未来是否可能再次需要扩容等</li>
<li>ID问题:数据库表被切分后，不能再依赖数据库自身的主键生成机制，所以需要一些手段来保证全局主键唯一。
<ul>
<li>自增但设置不同自增步长。比如现在有三张表，步长设置为3，三张表ID初始值分别是1、2、3。这样第一张表的ID增长是1、4、7。第二张表是2、5、8。第三张表是3、6、9，这样就不会重复了</li>
<li>UUID，简单，但是不连续的主键插入会导致严重的页分裂，性能差</li>
<li>分布式ID，Twitter开源的sonwflake雪花算法</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1>7. 如果查询条件不带分片键，怎么办？</h1>
<ul>
<li>当查询不带分片键时，则中间件一般会扫描所有库表，然后聚合结果，然后进行返回。</li>
</ul>
<h1>8. 如何避免热点问题数据倾斜（热点数据）</h1>
<ul>
<li>如果我们根据时间范围分片，某电商公司11月搞营销活动，那么大部分的数据都落在11月份的表里面了，其他分片表可能很少被查询，即数据倾斜了，有热点数据问题了。</li>
<li>可以使用range范围+ hash哈希取模结合的分表策略，在拆分库的时候，可以先用range范围方案，比如订单id在0~4000万的区间，划分为订单库1;id在4000万~8000万的数据，划分到订单库2,将来要扩容时，id在8000万~1.2亿的数据，划分到订单库3。然后订单库内，再用hash取模的策略，把不同订单划分到不同的表。</li>
</ul>
<h1>9. 分库跨节点Join关联问题</h1>
<ul>
<li>字段冗余：把需要关联的字段放入主表中，避免关联操作；比如订单表保存了卖家ID（sellerId），你把卖家名字sellerName也保存到订单表，这就不用去关联卖家表了。这是一种空间换时间的思想。</li>
<li>全局表：比如系统中所有模块都可能会依赖到的一些基础表（即全局表），在每个数据库中均保存一份。</li>
<li>数据抽象同步：比如A库中的a表和B库中的b表有关联，可以定时将指定的表做同步，将数据汇合聚集，生成新的表。一般可以借助ETL工具。</li>
<li>应用层代码组装：分开多次查询，调用不同模块服务，获取到数据后，代码层进行字段计算拼装。</li>
</ul>
<h1>10. 跨节点的count,order by,group by等聚合函数问题</h1>
<ul>
<li>一般都需要基于全部数据集合进行计算。可以分别在各个节点上得到结果后，再在应用程序端进行合并。</li>
</ul>
<h1>11. 分库分表后的分页问题</h1>
<ul>
<li>全局视野法：在各个数据库节点查到对应结果后，在代码端汇聚再分页。这样优点是业务无损，精准返回所需数据；缺点则是会返回过多数据，增大网络传输比如分库分表前，你是根据创建时间排序，然后获取第2页数据。如果你是分了两个库，那你就可以每个库都根据时间排序，然后都返回2页数据，然后把两个数据库查询回来的数据汇总，再根据创建时间进行内存排序，最后再取第2页的数据。</li>
<li>业务折衷法-禁止跳页查询：不允许跳页查询了只有上一页和下一页，。查询第一页时，是跟全局视野法一样的。但是下一页时，需要把当前最大的创建时间传过来，然后每个节点，都查询大于创建时间的一页数据，接着汇总，内存排序返回</li>
</ul>
<h1>12. 分库分表实现方式：</h1>
<ul>
<li>Client 模式</li>
<li>Proxy 模式</li>
</ul>
<h1>13. 分库分表选择哪种中间件？如何选择</h1>
<ul>
<li><strong>Sharding-JDBC</strong> 当当开源 jdbc层面操作  client 层方案</li>
<li>cobar 阿里 Proxy方式 必须将拆分后的表分别放入不同的库实现分布式</li>
<li><strong>Mycat</strong> 国内开源  Proxy 方式</li>
<li>Atlas 360 Proxy方式 不能实现分布式分表 所有表都在同一个库</li>
<li>TDDL（淘宝）阿里 Client方式 功能强大 过于复杂部分开源</li>
<li>vitess 谷歌 集群基于Zookeeper管理，通过RPC方式进行数据处理，可支撑高流量</li>
<li>Sharding Sphere可能是目前最好的开源的分库分表解决方案，目前已经进入 Apache 孵化，提供三种模式
<ul>
<li>Sharding-JDBC</li>
<li>Sharding-Proxy</li>
<li>Sharding-Sidecar 计划开发中。</li>
</ul>
</li>
<li>Sharding Sphere ，这个可以满足我们的诉求。Sharding-JDBC 方案，这种 Client 层方案的优点在于不用部署，运维成本低，不需要代理层的二次转发请求，性能很高，但是如果遇到升级啥的需要各个系统都重新升级版本再发布，各个系统都需要耦合 sharding-jdbc 的依赖。例如阿里、美团内部，更多使用的是 Client 模式。</li>
<li>Sharding Sphere 的 Sharding-Proxy 方案，这种 Proxy 层方案，可以解决我们平时查询数据库的需求。我们只需要连接一个 Sharding-Proxy ，就可以查询分库分表中的数据。另外，如果我们有跨语言的需求，例如 PHP、GO 等，也可以使用它。</li>
</ul>
<h1>14. 如何迁移到分库分表？</h1>
<ul>
<li>1、停止部署法。凌晨停机，写迁移程序读旧数据库数据，通过中间件写入到新分库分表中，结束后校验迁移前后一致性，没问题就迁移业务到新库</li>
<li>2、双写部署法，基于业务层。
<ul>
<li>根据主键或者创建时间大小将表test数据区分为历史数据和增量数据</li>
<li>将与test表有关的写业务sql写入到消息队列中</li>
<li>系统上线，写迁移程序(1.查出最大id2.每次抓取id&gt;? adn id &lt;?+step步长的数据，写入到新库中&gt;)将test表历史数据迁移到新数据库中，历史数据迁移完成后再迁移消息队列里面的数据</li>
<li>将迁移程序下线，写一段订阅程序订阅消息队列中的数据。订阅程序将订阅到到数据，通过中间件写入新库</li>
<li>新老库一致性验证，去除代码中的双写代码，将涉及到 test_tb 表的读写操作，指向新库。</li>
</ul>
</li>
<li>3、双写部署法，基于 binlog 。
<ul>
<li>根据主键或者创建时间大小将表test数据区分为历史数据和增量数据</li>
<li>打开binlog日志，系统正常上线。写迁移程序将test表历史数据迁移到新数据库中，历史数据迁移完成后再迁移增量数据</li>
<li>写一个订阅程序，订阅binlog(mysql中有canal 。至于oracle中，大家就随缘自己写吧)。然后将订阅到到数据通过中间件，写入新库。</li>
<li>检验一致性，没问题就切库</li>
</ul>
</li>
<li>怎么验数据一致性
<ul>
<li>先验数量是否一致，因为验数量比较快。</li>
<li>验关键性的几个字段是否一致。</li>
<li>一次取50条(不一定50条，具体自己定，我只是举例),然后像拼字符串一样，拼在一起。用md5进行加密，得到一串数值。新库一样如法炮制，也得到一串数值，比较两串数值是否一致。如果一致，继续比较下50条数据。如果发现不一致，用二分法确定不一致的数据在0-25条，还是26条-50条。以此类推，找出不一致的数据，进行记录即可。</li>
</ul>
</li>
</ul>
<h1>15. 如何评估分库数量</h1>
<ul>
<li>MySQL一般单库超过5千万记录压力就非常大了。如果分库数量少，达不到分散存储和减轻DB性能压力的目的；如果分库的数量多，对于跨多个库的访问，应用程序需要访问多个库。建议分4~10个库</li>
</ul>
<h1>16. 垂直分库、水平分库、垂直分表、水平分表的区别？怎么分库分表？√</h1>
<ul>
<li>水平分库：以字段为依据，按照一定策略（hash、range等），将一个库中的数据拆分到多个库中。每个库的结构都一样，数据不一样，没有交集 id 1-1000</li>
<li>水平分表：以字段为依据，按照一定策略（hash、range等），将一个表中的数据拆分到多个表中。每个表的结构都一样，数据不一样，没有交集 id 1-1000</li>
<li>垂直分库：以表为依据，按照业务归属不同，将不同的表拆分到不同的库中。每个库的结构都不一样，数据也不一样，没有交集。按照用户、商品、订单分到不同的库中。</li>
<li>垂直分表：以字段为依据，按照字段的活跃性，将表中字段拆到不同的表（主表和扩展表）中。每个表的结构不一样。数据也不一样，一般来说，每个表的字段至少有一列交集，一般是主键，用于关联数据</li>
</ul>
<h1>18. 不停机扩容怎么实现？</h1>
<ul>
<li>
<p>在线双写，查询走老库</p>
<ul>
<li>建立好新的库表结构，数据写入久库的同时，也写入拆分的新库</li>
<li>数据迁移，使用数据迁移程序，将旧库中的历史数据迁移到新库</li>
<li>使用定时任务，新旧库的数据对比，把差异补齐<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/539f395d31202ddb73744.png" alt="databaseexpand1.jpg"></li>
</ul>
</li>
<li>
<p>在线双写，查询走新库</p>
<ul>
<li>完成了历史数据的同步和校验</li>
<li>把对数据的读切换到新库<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/da218b19c04ecca511246.png" alt="databaseexpand2.jpg"></li>
</ul>
</li>
<li>
<p>旧库下线</p>
<ul>
<li>旧库不再写入新的数据</li>
<li>经过一段时间，确定旧库没有请求之后，就可以下线老库<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/a9383293a12f5db0fe72b.png" alt="databaseexpand3.jpg"></li>
</ul>
</li>
</ul>
<h1>19. 如何解决分布式事务？</h1>
<ul>
<li>数据在分库分表时，需要保证一个逻辑中，能够形成本地事务。举个例子，创建订单时，我们会插入订单表和订单明细表，那么：如果我们基于这两个表的 id 进行分库分表，将会导致插入的记录被分到不同的库表中，因为创建下单可以购买 n 个商品，那么就会有 1 条订单记录和 n 条 订单明细记录。而这 n 条订单明细记录无法和 1 条订单记录分到一个库表中。如果我们基于这两个表的 user_id 进行分库分表，那么插入的记录被分到相同的库表中。这也是为什么业务表一般使用 user_id 进行分库分表的原因之一。</li>
<li>为什么一定要形成本地事务？在有了本地事务的基础上，通过使用分布式事务的解决方案，协调多个本地事务，形成最终一致性。另外，😈 本地事务在这个过程中，能够保证万一执行失败，再重试时，不会产生脏数据。</li>
</ul>
]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/539f395d31202ddb73744.png" type="image/png"/>
    </item>
    <item>
      <title>设计模式</title>
      <link>https://javaguide.cn/interview/designpattern.html</link>
      <guid>https://javaguide.cn/interview/designpattern.html</guid>
      <source url="https://javaguide.cn/rss.xml">设计模式</source>
      <description>设计模式</description>
      <category>面试</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>设计模式</p>
<!-- more -->
<h1>1. 为什么要使用设计模式?</h1>
<ul>
<li>代码重用性 (相同功能的代码，不用多次编写)</li>
<li>可读性 (编程规范性, 便于其他程序员的阅读和理解)</li>
<li>可扩展性 (当需要增加新的功能时，非常的方便，称为可维护)</li>
<li>可靠性 (当我们增加新的功能后，对原来的功能没有影响)</li>
<li>使程序呈现高内聚，低耦合的特性</li>
</ul>
<h1>2. 设计模式七大原则</h1>
<ul>
<li>单一职责原则SRP(Single Responsibility Principle):一个类或者一个方法应该只负责一项职责</li>
<li>接口隔离原则ISP(the Interface Segregation Principle ISP):客户端不应该依赖它不需要的接口(接口有A、B方法，只用到A的话，把接口拆成两个)</li>
<li>依赖倒转(倒置)原则DIP(the Dependency Inversion Principle DIP):面向接口编程，私有属性依赖接口或抽象类，继承时遵循里氏替换原则</li>
<li>里氏替换原则(the Liskov Substitution Principle LSP):继承时，子类的尽量不要重写父类方法，父类的通用方法尽量不要改，避免发生未知错误，可用聚合、组合、依赖解决</li>
<li>开闭原则ocp(Open－Close Principle):模块和函数应该对扩展开放(对提供方)，对修改关闭(对使用方)。(通过增加代码而不是修改代码完成)用抽象构建框架，用实现扩展细节</li>
<li>迪米特法则:一个对象尽量降低对其他类的依赖，无关的类不要以局部变量出现在类的内部</li>
<li>合成复用原则:使用合成/聚合的方式，而不是使用继承;依赖：方法传参传给他 聚合：声明属性和set的方法，组合 直接属性new一个</li>
</ul>
<h1>3. 设计模式及其类型（23种）</h1>
<h2>3.1. 创建型模式</h2>
<h3>3.1.1. 单例模式</h3>
<ul>
<li>单例模式：保证在系统中，对某个类只能存在一个对象实例，并且该类只提供一个取得其对象实例的方法(静态方法)</li>
<li>使用场景：频繁的创建和销毁的对象、创建对象时耗时过多或耗费资源过多(重量级对象)，但又常用的工具类对象、频繁访问数据库或文件的对象(数据库连接池、多线程池、SessionFactory等)</li>
<li>步骤：1. 构造器私有化, 外部不能new 2.本类内部创建对象实例  3. 提供一个公有的静态方法，返回实例对象</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>//饿汉式：线程安全、无延时加载、内存浪费(在类装载的时候就完成实例，避免了多线程的同步问题)
class Singleton {
    private Singleton() {}
    private final static Singleton instance = new Singleton();
    public static Singleton getInstance() { return instance; }
}

//懒汉式：线程安全，同步方法,但效率太低
class Singleton {
    private Singleton() {}
    private static Singleton instance;
    public static synchronized Singleton getInstance() {
        if(instance == null) { 
            instance = new Singleton();
        }
        return instance;
    }
}

//双重检查：线程安全；延迟加载；效率较高√
class Singleton {
    private Singleton() {}
    private static volatile Singleton instance;//将线程中的东西更新到主存
    //需要加volatile关键字，否则会出现错误，因为JVM指令的重排优化
    //创建对象包括三个指令
    //    1.new #2 &lt;T&gt; ：分配内存地址，属性初始化并赋予默认值
    //    2.invokespecial #3 &lt;T.&lt;init&gt;&gt; 调用构造方法并完成对象初始化
    //    3.astore_1 将对象指针指向对象 如果以上三个指令顺序错误，将导致程序出错
    public static Singleton getInstance() {
        if(instance == null) {
            synchronized (Singleton.class) {
                if(instance == null) {
                    instance = new Singleton();
                }
            }
        }
        return instance;
    }
}

//静态内部类：延时加载，效率高；类的静态属性只会在第一次加载类的时候初始化，在类进行初始化时，别的线程是无法进入的。保证了线程的安全性√
class Singleton {
    private Singleton() {}
    private static class SingletonInstance {
        private static final Singleton INSTANCE = new Singleton(); //写一个静态内部类,该类中有一个静态属性 Singleton
    }
    public static Singleton getInstance() {
        return SingletonInstance.INSTANCE;
    }
}

//枚举：枚举线程安全，而且还能防止反序列化重新创建新的对象。
public class Cilent {
    public static void main(String[] args) {
        Singleton instance = Singleton.INSTANCE;            
        instance.sayOK();
    }
}
enum Singleton {
    INSTANCE;
    public void sayOK() { System.out.println("ok~"); }
}
</code></pre></div><h3>3.1.2. 工厂模式</h3>
<ul>
<li>工厂模式:大量的创建某种、某类或者某批对象，定义创建对象的抽象方法，由子类决定要实例化的类。工厂方法模式将对象的实例化推迟到子类。</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>class Client{
    public static void main(String[] args) {
        new ProductFactoryB().useProduct("ProductC");
    }
}

interface Product{void createProduct();}

class ProductA implements Product{public void createProduct(){System.out.println("ProductA");}}
class ProductB implements Product{public void createProduct(){System.out.println("ProductB");}}
class ProductC implements Product{public void createProduct(){System.out.println("ProductC");}}
class ProductD implements Product{public void createProduct(){System.out.println("ProductD");}}

//抽象工厂：描述具体工厂的公共接口 核心，只需传入名字
abstract class ProductFactory {
    private Product product = null;
    void useProduct(String name){product = getProduct(name);product.createProduct();}
    abstract Product getProduct(String name);
}

//具体工厂：描述具体工厂，创建产品的实例，供外界调用
class ProductFactoryA extends ProductFactory{
    public Product getProduct(String name){
        if(name.equals("ProductA")){ return new ProductA(); }else{ return new ProductB(); }
    }
}

class ProductFactoryB extends ProductFactory{
    public Product getProduct(String name){
        if(name.equals("ProductC")){ return new ProductC(); }else{ return new ProductD(); }
    }
}
</code></pre></div><h3>3.1.3. 抽象工厂模式</h3>
<ul>
<li>抽象工厂模式：定义了一个interface用于创建相关或有依赖关系的对象簇，而无需指明具体的类</li>
<li>将工厂抽象成两层，AbsFactory(抽象工厂) 和 具体实现的工厂子类。程序员可以根据创建对象类型使用对应的工厂子类。这样将单个的简单工厂类变成了工厂簇，更利于代码的维护和扩展</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>class Client{
    public static void main(String[] args) {
        new FoodFactory(new ProductFactoryB()).getProduct("ProductC");
    }
}

interface Product{void createProduct();}

class ProductA implements Product{public void createProduct(){System.out.println("ProductA");}}
class ProductB implements Product{public void createProduct(){System.out.println("ProductB");}}
class ProductC implements Product{public void createProduct(){System.out.println("ProductC");}}
class ProductD implements Product{public void createProduct(){System.out.println("ProductD");}}

//抽象工厂：描述具体工厂的公共接口
interface AbsProductFactory {public Product getProduct(String name);}

//具体工厂：描述具体工厂，创建产品的实例，供外界调用
class ProductFactoryA implements AbsProductFactory{
    public Product getProduct(String name){
        if(name.equals("ProductA")){ return new ProductA(); }else{ return new ProductB(); }
    }
}

class ProductFactoryB implements AbsProductFactory{
    public Product getProduct(String name){
        if(name.equals("ProductC")){ return new ProductC(); }else{ return new ProductD(); }
    }
}

//抽象产品族：描述抽象产品的公共接口 核心。传入工厂和名字 增加了这个类可以指定工厂生产
class FoodFactory {
    AbsProductFactory factory;
    public FoodFactory(AbsProductFactory factory) {
        this.factory = factory;
    }
    public void getProduct(String name) {
        this.factory.getProduct(name).createProduct();
    }
}
</code></pre></div><h3>3.1.4. 原型模式</h3>
<ul>
<li>原型模式(Prototype模式):拷贝对象实例（不是同一个对象）违背了ocp原则；逃避构造函数的约束</li>
<li>资源优化场景:类初始化需要消化非常多的资源，这个资源包括数据、硬件资源等。</li>
<li>性能和安全要求的场景:通过new产生一个对象需要非常繁琐的数据准备或访问权限时</li>
<li>一个对象多个修改者的场景:一个对象需要提供给其他对象访问，而且各个调用者可能都需要修改其值时，可以使用原型模式拷贝多个对象供调用者使用</li>
<li>创建新的对象比较复杂时，可以利用原型模式简化对象的创建过程，同时也能够提高效率</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>//浅拷贝仅仅复制所考虑的对象，而不复制它所引用的对象(基本数据类型直接复制，引用数据类型引用传递)
//1.实现Cloneable接口，2.重写clone()方法：
public class Client {
    public static void main(String[] args) {
        Sheep sheep = new Sheep("tom");
        Sheep firend = new Sheep("jack");
        sheep.setFriend(firend);
        Sheep sheep2 = (Sheep)sheep.clone(); //克隆
        System.out.println("firend=" + firend + ",sheep2.friend=" + sheep2.getFriend());
    }
}

class Sheep implements Cloneable {
    private String name;//基本数据类型直接复制
    private Sheep friend; //引用数据类型引用传递
    public Sheep(String name) {this.name = name;}

    public String getName() { return name; }
    public Sheep getFriend() { return friend; }
    public void setFriend(Sheep friend) { this.friend = friend; }

    @Override
    protected Object clone()  {//克隆该实例，使用默认的clone方法来完成
        Sheep sheep = null;
        try {
            sheep = (Sheep)super.clone();
        } catch (Exception e) {}
        return sheep;
    }
}

//深拷贝把要复制的对象所引用的对象都复制了一遍
//1.重写clone方法来实现深拷贝，然后对所有引用属性进行拷贝
//2.通过对象序列化实现深拷贝(推荐)
public class Client {
    public static void main(String[] args) throws Exception {
        Sheep sheep = new Sheep("tom");
        Sheep firend = new Sheep("jack");
        sheep.setFriend(firend);
        //方式1 完成深拷贝
//      Sheep sheep2 = (Sheep)sheep.clone();
//      System.out.println("firend=" + firend + ",sheep2.friend=" + sheep2.getFriend());
        //方式2 完成深拷贝
        Sheep sheep2 = (Sheep)sheep.deepClone();
        System.out.println("firend=" + firend + ",sheep2.friend=" + sheep2.getFriend());
    }
}

class Sheep implements Cloneable,Serializable {
    private String name;//基本数据类型直接复制
    private Sheep friend; //引用数据类型引用传递
    public Sheep(String name) { this.name = name; }

    public String getName() { return name; }
    public Sheep getFriend() { return friend; }
    public void setFriend(Sheep friend) { this.friend = friend; }

    @Override
    protected Object clone()  {//克隆该实例，使用默认的clone方法来完成
        Sheep sheep = null;
        try {
            sheep = (Sheep)super.clone();
            sheep.setFriend((Sheep) friend.clone());
        } catch (Exception e) {}
        return sheep;
    }

    //深拷贝 - 方式2 通过对象的序列化实现 (推荐)
    public Object deepClone() {
        ByteArrayOutputStream bos = null;
        ObjectOutputStream oos = null;
        ByteArrayInputStream bis = null;
        ObjectInputStream ois = null;
        try {
            //序列化
            bos = new ByteArrayOutputStream();
            oos = new ObjectOutputStream(bos);
            oos.writeObject(this); //当前这个对象以对象流的方式输出
            //反序列化
            bis = new ByteArrayInputStream(bos.toByteArray());
            ois = new ObjectInputStream(bis);
            Sheep copyObj = (Sheep) ois.readObject();
            return copyObj;
        } catch (Exception e) {
            e.printStackTrace();
            return null;
        } finally {//关闭流
            try {
                bos.close();
                oos.close();
                bis.close();
                ois.close();
            } catch (Exception e2) {
                System.out.println(e2.getMessage());
            }
        }
    }
}
</code></pre></div><h3>3.1.5. 建造者模式</h3>
<ul>
<li>建造者模式，将<strong>组成部分相似</strong>的复杂对象的建造过程抽象出来（抽象类别），使这个抽象过程的不同实现方法可以构造出不同表现（属性）的对象。</li>
<li>建造者模式是一步一步创建一个复杂的对象，它允许用户只通过指定复杂对象的类型和内容就可以构建它们，用户不需要知道内部的具体构建细节</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class Client{
    public static void main(String[] args) {
        System.out.println(new ProductDricter().build(new ProductBuilder()));
    }
}

//Product（产品角色）： 一个具体的产品对象。
class Product{
    private String name;
    private String price;
    public String getName() { return name; }
    public void setName(String name) { this.name = name; }
    public String getPrice() { return price; }
    public void setPrice(String price) { this.price = price; }

    public String toString() { return "Product{name=" + name + ", price=" + price + "}"; }
}

//抽象建造者： 创建一个Product对象的各个部件指定的 接口/抽象类
abstract class Builder{
    protected Product product = new Product();
    abstract void buildName();
    abstract void bulidPrice();
    public Product getProduct(){return product;}
}

//多个具体建造者
class ProductBuilder extends Builder{
    public void buildName(){this.product.setName("炸鸡");}
    public void bulidPrice(){this.product.setPrice("10元");}
    public Product getProduct(){return product;}
}

//指挥者 传入不同的制造者
class ProductDricter {
    public Product build(Builder builder){
        builder.buildName();
        builder.bulidPrice();
        return builder.getProduct();
    }
}
</code></pre></div><h2>3.2. 结构型模式</h2>
<h3>3.2.1. 适配器模式</h3>
<ul>
<li>适配器模式(Adapter Pattern)将一个类的接口转换成另一种接口.让原本接口不兼容的类可以兼容</li>
<li>用户调用适配器转化处理的目标接口方法，适配器在调用被适配者的相关接口方法</li>
<li><strong>C根据接口要求将不合适的类A转成接口要的类B，只不过传入不合适类A的方式不一样</strong></li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class Client {
    public static void main(String[] args) {
        new ClassAdapter().request();
        new ObjectAdapter(new Adaptee()).request();
    }
}

//目标接口
interface Target{public void request();}

//被适配类（不符合要求的类）
class Adaptee{public void specialRequest(){System.out.println("适配者中的业务代码被调用!");}}


//类适配器模式-适配器类实现目标接口并继承被适配类完成目标接口转换
class ClassAdapter extends Adaptee implements Target{
    @Override
    public void request(){
        specialRequest();
    };
}

//对象适配模式-对象适配类
class ObjectAdapter implements Target{
    private Adaptee adaptee;//继承改成实现 关联关系-聚合
    public ObjectAdapter(Adaptee adaptee) {
        this.adaptee = adaptee;
    }
    @Override
    public void request(){
        adaptee.specialRequest();
    }
}

//接口适配器模式-接口适配类
abstract class InterfaceAdapter implements Target{public void request(){}}

public class Client {
    public static void main(String[] args) {
        InterfaceAdapter interfaceAdapter = new InterfaceAdapter() {
            @Override
            public void request() {
                System.out.println("使用了m1的方法");
            }
        };
        interfaceAdapter.request();
    }
}

</code></pre></div><h3>3.2.2. 桥接模式</h3>
<ul>
<li>桥接模式(Bridge模式)：将实现与抽象放在两个不同的类层次中，使两个层次可以独立改变。</li>
<li>桥接模式要求正确识别出系统中<strong>两个独立变化的维度</strong>，因此其使用范围有一定的局限性，即需要有这样的应用场景。</li>
<li>对于那些不希望使用继承或因为多层次继承导致系统类的个数急剧增加的系统，桥接模式尤为适用.</li>
<li>常见的应用场景: -JDBC驱动程序</li>
<li>银行转账系统
<ul>
<li>转账分类: 网上转账，柜台转账，AMT转账</li>
<li>转账用户类型：普通用户，银卡用户，金卡用户..</li>
</ul>
</li>
<li>消息管理
<ul>
<li>消息类型：即时消息，延时消息</li>
<li>消息分类：手机短信，邮件消息，QQ消息...</li>
</ul>
</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>//桥接模式:将C的功能抽象为接口A，将A的功能桥接回到C上，调用C的方法相当于调用A的实现方法
public class Client{
    public static void main(String[] args) {
        RefinedAbstraction refinedAbstraction = new RefinedAbstraction();
        refinedAbstraction.setImplementor(new ConcreteImplementorA());
        refinedAbstraction.do1();
    }
}

//实现化角色
interface Implementor{public void do1();}

//具体实现化角色
class ConcreteImplementorA implements Implementor{public void do1(){}}

//抽象化角色
abstract class Abstraction {//桥接类
    protected Implementor implementor;
    public void setImplementor(Implementor implementor){this.implementor = implementor;}
    protected abstract void do1();
}

//扩展抽象化角色
class RefinedAbstraction extends Abstraction{
    public void do1(){this.implementor.do1();System.out.println("子类自己的功能");}
}
</code></pre></div><h3>3.2.3. 装饰者模式</h3>
<ul>
<li>装饰者模式：动态的将新功能附加到对象上。在对象功能扩展方面，它比继承更有弹性</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class Client {
    public static void main(String[] args) {
        D d = new D();
        d.setA(new B());
        System.out.println(d.fun());
    }
}

//抽象构件角色
interface A{int fun();}

//具体构件角色
class B implements A{public int fun(){return 1;}}

//抽象装饰角色
abstract class C implements A{
    private A a;
    public void setA(A a){this.a = a;}
    public int fun(){return a.fun();};
}

//具体装饰角色
class D extends C{
    public int fun(){
        return super.fun() + decorate();
    }
    private int decorate(){System.out.println("为具体构件角色增加额外的功能");return 1;}//装饰
}
</code></pre></div><h3>3.2.4. 组合模式</h3>
<ul>
<li>组合模式（Composite Pattern），又叫部分整体模式，它创建了对象组的树形结构，将对象组合成树状结构以表示“整体-部分”的层次关系</li>
<li>组合模式让客户以一致的方式处理个别对象以及组合对象</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class Client{
    public static void main(String[] args) {
        B b = new B();
        C c = new C();
        D d = new D();
        b.addA(c);
        c.addA(d);
        b.print();
    }
}

//BCD实现继承一个抽象类达到嵌套组合的目的，层层包含的关系
abstract class A{protected void addA(A a){} protected abstract void print();}

class B extends A{
    private List&lt;A&gt; list = new ArrayList&lt;A&gt;();
    public void addA(A a){list.add(a);}
    public void print(){for(A a:list){a.print();}}
}

class C extends A{
    private List&lt;A&gt; list = new ArrayList&lt;A&gt;();
    public void addA(A a){list.add(a);}
    public void print(){for(A a:list){a.print();}}
}

class D extends A{
    private List&lt;A&gt; list = new ArrayList&lt;A&gt;();
    public void addA(A a){list.add(a);}
    public void print(){System.out.print("D");};
}
</code></pre></div><h3>3.2.5. 外观者模式</h3>
<ul>
<li>外观模式（Facade）为子系统中的一组接口提供一个一致的界面，此模式定义了一个高层接口，这个接口使得这一子系统更加容易使用</li>
<li>外观模式通过定义一个一致的接口，用以屏蔽内部子系统的细节，使得调用端只需跟这个接口发生调用，而无需关心这个子系统的内部细节</li>
<li>当系统需要分层次设计时，可以使用</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>//对Facade操作实现对A和B操作
public class Client{
    public static void main(String[] args) {
        Facade f = new Facade();
        f.setA(new A());
        f.setB(new B());
        f.fun();
        f.fun2();
    }
}

class Facade{
    private A a;
    private B b;
    public void setA(A a){this.a=a;}
    public void setB(B b){this.b=b;}
    public void fun(){
        a.fun1();b.fun4();//分两个层次了
    }
    public void fun2(){
        b.fun3();a.fun2();
    }
}

class A {public void fun1(){System.out.println("fun1");} public void fun2(){System.out.println("fun2");}}
class B {public void fun3(){System.out.println("fun3");} public void fun4(){System.out.println("fun4");}}
</code></pre></div><h3>3.2.6. 享元模式(池技术)</h3>
<ul>
<li>享元模式（Flyweight Pattern）: 运用共享技术有效地支持大量细粒度的对象，减少对象的创建</li>
<li>常用于系统底层开发，解决系统的性能问题。像数据库连接池，里面都是创建好的连接对象，在这些连接对象中有我们需要的则直接拿来用，避免重新创建，如果没有我们需要的，则创建一个</li>
<li>享元模式能够解决重复对象的内存浪费的问题，当系统中有大量相似对象，需要缓冲池时。不需总是创建新对象，可以从缓冲池里拿。这样可以降低系统内存，同时提高效率</li>
<li>享元模式经典的应用场景就是池技术了，String常量池、数据库连接池、缓冲池等等都是享元模式的应用，享元模式是池技术的重要实现方式</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class Client{
    public static void main(String[] args) {
        B b = new B();
        ((A) b.getA("test")).fun();
        ((A) b.getA("test")).fun();
    }
}
class A{public void fun(){System.out.println(this);}}

class B{
    private Map&lt;String,A&gt; map = new HashMap&lt;String,A&gt;();
    public A getA(String name){
        A a = map.get(name);
        if(a == null){
            A nA = new A();
            map.put(name,nA);
            return nA;
        }
        return a;
    }
}
</code></pre></div><h3>3.2.7. 代理模式(JDK与cglib)</h3>
<ul>
<li>代理模式：为一个对象提供一个替身，以控制对这个对象的访问。即通过代理对象访问目标对象.这样做的好处是:可以在目标对象实现的基础上,增强额外的功能操作,即扩展目标对象的功能。</li>
<li>被代理的对象可以是远程对象、创建开销大的对象或需要安全控制的对象</li>
<li>代理模式有不同的形式, 主要有三种 静态代理、动态代理 (JDK代理、接口代理)和 Cglib代理 (可以在内存动态的创建对象，而不需要实现接口， 他是属于动态代理的范畴) 。</li>
<li>代理模式(Proxy)的变体
<ul>
<li>防火墙代理:内网通过代理穿透防火墙，实现对公网的访问。</li>
<li>缓存代理:比如：当请求图片文件等资源时，先到缓存代理取，如果取到资源则ok,如果取不到资源，再到公网或者数据库取，然后缓存。</li>
<li>远程代理:远程对象的本地代表，通过它可以把远程对象当本地对象来调用。远程代理通过网络和真正的远程对象沟通信息</li>
<li>同步代理:主要使用在多线程编程中，完成多线程间同步工作</li>
</ul>
</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>- 静态代理：需要定义接口或者父类,被代理对象(即目标对象)与代理对象一起实现相同的接口或者是继承相同父类；一旦接口增加方法，目标对象和代理对象都要维护，因为代理对象和目标对象实现一样的接口，所以会有很多代理类
public class Client{
    public static void main(String[] args) {
        B b = new B();
        C c = new C();
        c.setA(b);
        c.fun();
    }
}
interface A{void fun();}

class B implements A{public void fun(){System.out.println("目标对象...");}}//被代理对象/目标对象

class C implements A{//代理对象
    private B b;
    private A a;
    public void setA(A a){this.a = a;}
    public void fun(){
        System.out.println("前处理....");
        this.a.fun();
        System.out.println("后处理....");
    }
}

动态代理模式的(JDK代理、接口代理)
- 代理对象不需要实现接口，但是目标对象要实现接口
- 代理类所在包:java.lang.reflect.Proxy
- JDK实现代理只需要使用newProxyInstance方法,但是该方法需要接收三个参数,完整的写法是: 
    - static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces,InvocationHandler h )
    - ClassLoader 指定当前目标对象使用的类加载器，获取加载器的方法固定
    - Class&lt;?&gt;[] interfaces 目标对象实现的接口类型，使用泛型方法确认类型
    - InvocationHandler h 执行目标对象的方法时，会触发该方法，会把当前执行的对象方法当参数传入

public class Client {
    public static void main(String[] args) {
        A proxyInstance = (A)new ProxyFactory(new B()).getProxyInstance();
        proxyInstance.a();
    }
}

interface A {void a();}

class B implements A{ public void a() {System.out.println("代理对象");} }//被代理对象/目标对象

class ProxyFactory {
    private Object target;
    public ProxyFactory(Object target) {this.target = target;}
    public Object getProxyInstance() {//代理对象
        return Proxy.newProxyInstance(target.getClass().getClassLoader(), target.getClass().getInterfaces(),
                new InvocationHandler() {
                    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
                        System.out.println("前处理....");
                        Object object = method.invoke(target, args);
                        System.out.println("后处理....");
                        return object;
                    }
                });
    }
}

Cglib代理/子类代理
- Cglib代理是在内存中构建一个子类对象从而实现对目标对象功能扩展。
- Cglib是一个强大的高性能的代码生成包,它可以在运行期扩展java类与实现java接 口.它广泛的被许多AOP的框架使用,例如Spring AOP，实现方法拦截
- 在AOP编程中如何选择代理模式：目标对象需要实现接口，用JDK代理、目标对象不需要实现接口，用Cglib代理
- Cglib包的底层是通过使用字节码处理框架ASM来转换字节码并生成新的类
public class Client {
    public static void main(String[] args) {
        A target = new A();
        ((A)new ProxyFactory(target).getProxyInstance()).fun();
    }
}

class A{public void fun(){System.out.println("代理对象...");}}

class ProxyFactory implements MethodInterceptor {
    private Object target;
    public ProxyFactory(Object target) {this.target = target;}
    public Object getProxyInstance() {
        Enhancer enhancer = new Enhancer();
        enhancer.setSuperclass(target.getClass());
        enhancer.setCallback(this);
        return enhancer.create();
    }
    @Override
    public Object intercept(Object arg0, Method method, Object[] args, MethodProxy proxy) throws Throwable {
        System.out.println("前处理....");
        Object object = method.invoke(target, args);
        System.out.println("后处理....");
        return object;
    }
}
</code></pre></div><h2>3.3. 行为型模式</h2>
<h3>3.3.1. 模板方法模式</h3>
<ul>
<li>模板方法模式（Template Method Pattern），在一个抽象类公开定义了执行它的方法的模板。它的子类可以按需要重写方法实现，但调用将以抽象类中定义的方式进行。</li>
<li>模板方法模式 定义一个操作中的算法的骨架，而将一些步骤延迟到子类中，使得子类可以不改变一个算法的结构，就可以重定义该算法的某些特定步骤</li>
<li>一般模板方法加上final关键字，防止子类重新模板方法</li>
<li>当要完成某个过程。该过程要执行一系列步骤，这一系列的步骤基本相同，但其个别步骤在实现可能不同，考虑使用模板方法模式来处理</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class Client {
    public static void main(String[] args) {
        A a = new B(); a.make();
    }
}

abstract class A {
    //模板方法, make , 模板方法可以做成final , 不让子类去覆盖.
    final void make() {if(gouzi()){B();}C();}
    abstract void B();
    abstract void C();
    boolean gouzi(){return false;}//默认不做任何事，子类可以视情况要不要覆盖它，该方法称为“钩子”。
}

class B extends A{
    void B(){System.out.println("B实现了模板方法B");};
    void C(){System.out.println("B实现了模板方法C");};
    boolean gouzi(){return true;}
}
</code></pre></div><h3>3.3.2. 命令模式</h3>
<ul>
<li>命令模式：我们经常需要向某些对象发送请求，但是并不知道请求的接收者是谁，也不知道被请求的操作是哪个，只需在程序运行时指定具体的请求接收者即可</li>
<li>命名模式通过命令对象使得请求发送者与请求接收者消除彼此之间的耦合，让对象之间的调用关系更加灵活，实现解耦。</li>
<li>在命名模式中，会将一个请求封装为一个对象，以便使用不同参数来表示不同的请求(即命名)，同时命令模式也支持可撤销的操作。</li>
<li>容易设计一个命令队列。只要把命令对象放到列队，就可以多线程的执行命令；容易实现对请求的撤销和重做</li>
<li>命令模式可能导致某些系统有过多的具体命令类，增加了系统的复杂度，这点在使用的时候要注意</li>
<li>命令模式经典使用场景：界面的一个按钮都是一条命令、模拟CMD、订单的撤销/恢复、触发-反馈机制</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>//命令调用者集合了所有的命令，调用命令时实际调用接收者的方法，而命令可以选择调用不同的接受者方法
public class Client {
    public static void main(String[] args) {
        Receiver receiver = new Receiver();
        ConcreteCommand concreteCommand = new ConcreteCommand(receiver);
        Invoker invoker = new Invoker();
        invoker.takeCommand(concreteCommand);
        invoker.placeCommands();
    }
}

//命令模式 命令接口命令角色Command
interface Command {void execute();}

//请求实现类 命令实现类 依赖接收者 将一个接受者对象与一个动作绑定，调用接受者相应的动作，实现execute
class ConcreteCommand implements Command {
    private Receiver receiver;
    public ConcreteCommand(Receiver receiver){this.receiver = receiver;}
    public void execute() {receiver.buy();}
}

//请求类 接受者Receiver
class Receiver {
    public void buy(){}
}

//命令调用类：调用者角色
class Invoker {
    private List&lt;Command&gt; commandList = new ArrayList&lt;Command&gt;();
    public void takeCommand(Command command){commandList.add(command);}
    public void placeCommands(){
        for (Command command : commandList) {
            command.execute();
        }
    }
}
</code></pre></div><h3>3.3.3. 访问者模式</h3>
<ul>
<li>访问者模式（Visitor Pattern），封装一些作用于某种数据结构的各元素的操作，它可以在不改变数据结构的前提下定义作用于这些元素的新的操作。</li>
<li>主要将数据结构与数据操作分离，解决 数据结构和操作耦合性问题</li>
<li>访问者模式的基本工作原理是：在被访问的类里面加一个对外提供接待访问者的接口</li>
<li>访问者模式主要应用场景是：需要对一个对象结构中的对象进行很多不同操作(这些操作彼此没有关联)，同时需要避免让这些操作"污染"这些对象的类，可以选用访问者模式解决</li>
<li>重载是静态绑定，重写是动态绑定，双分派把重写放在重载之前，以实现在运行时动态判断执行那个子类的方法。</li>
<li>访问者模式可以对功能进行统一，可以做报表、UI、拦截器与过滤器，适用于数据结构相对稳定的系统</li>
<li>因此，如果一个系统有比较稳定的数据结构，又有经常变化的功能需求，那么访问者模式就是比较合适的.</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class Client {
    public static void main(String[] args) {
        ObjectStructure objectStructure = new ObjectStructure();
        objectStructure.attach(new Man());
        objectStructure.attach(new Woman());

        //成功
        Success success = new Success();
        objectStructure.display(success);

        Fail fail = new Fail();
        objectStructure.display(fail);
    }
}

//抽象访问者 Visitor抽象访问者
abstract class Action {
    public abstract void getManResult(Man man);
    public abstract void getWomanResult(Woman woman);
}

//实际访问者  ConcreteVisitor具体访问者
class Success extends Action {
    public void getManResult(Man man) {System.out.println(" 男人给的评价该歌手很成功 !");}
    public void getWomanResult(Woman woman) {System.out.println(" 女人给的评价该歌手很成功 !");}
}

class Fail extends Action {
    public void getManResult(Man man) {System.out.println(" 男人给的评价该歌手失败 !");}
    public void getWomanResult(Woman woman) {System.out.println(" 女人给的评价该歌手失败 !");}
}

//抽象元素 接收一个访问者对象
abstract class Person {
    public abstract void accept(Action action);
}

//实际元素
//使用了双分派, 即
//首先在客户端程序中，将具体状态作为参数传递Woman中(第一次分派)
// 然后Woman 类调用作为参数的 "具体方法" 中方法getWomanResult, 同时将自己(this)作为参数传入，完成第二次的分派
//双分派是指不管类怎么变化，我们都能找到期望的方法运行。
//双分派意味着得到执行的操作取决于请求的种类和两个接收者的类型 -
//假设我们要添加一个Wait的状态类，只需增加一个Action子类即可在客户端调用即可，不需要改动任何其他类的代码
class Woman extends Person{
    public void accept(Action action) {action.getWomanResult(this);}
}

class Man extends Person {
    public void accept(Action action) {action.getManResult(this);}
}

//数据结构，管理很多人（Man , Woman）ObjectStructure
class ObjectStructure {
    private List&lt;Person&gt; persons = new LinkedList&lt;&gt;();
    public void attach(Person p) {persons.add(p);}
    public void detach(Person p) {persons.remove(p);}
    public void display(Action action) {
        for(Person p: persons) {
            p.accept(action);
        }
    }
}
</code></pre></div><h3>3.3.4. 迭代器模式</h3>
<ul>
<li>如果我们的集合元素是用不同的方式实现的，有数组，还有java的集合类，或者还有其他方式，当客户端要遍历这些集合元素的时候就要使用多种遍历方式，而且还会暴露元素的内部结构，可以考虑使用迭代器模式解决。</li>
<li>迭代器模式，提供一种遍历集合元素的统一接口，用一致的方法遍历集合元素，不需要知道集合对象的底层表示，即：不暴露其内部的结构。</li>
<li>提供了一种设计思想，就是一个类应该只有一个引起变化的原因（叫做单一责任原则）。在聚合类中，我们把迭代器分开，就是要把管理对象集合和遍历对象集合的责任分开，这样一来集合改变的话，只影响到聚合对象。而如果遍历方式改变的话，只影响到了迭代器。</li>
<li>当要展示一组相似对象，或者遍历一组相同对象时使用, 适合使用迭代器模式<br>
-每个聚合对象都要一个迭代器，会生成多个迭代器不好管理类</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class Client {
    public static void main(String[] args) {
        ConcreteAggregate aggregate = new ConcreteAggregate();
        Iterator iterator = aggregate.createIterator();
        while(iterator.hasNext()) {
            Element e = (Element)iterator.next();
            System.out.println(e.getName());
        }
    }
}

//需要被迭代的对象
class Element {
    private String name;//set/get
    public Element(String name) {this.name = name;}
    public String getName() { return name; }
}
//aggregate接口
interface Aggregate {
    Iterator createIterator();
}

//aggregate接口实现
class ConcreteAggregate implements Aggregate {
    Element[] elements;
    public ConcreteAggregate() {elements = new Element[]{new Element("test1"),new Element("test2")};}
    @Override
    public Iterator createIterator() {return new ConcreteIterator(elements);}
}

//迭代器实现
class ConcreteIterator implements Iterator {
    Element[] elements;
    int position = 0; //遍历的位置
    public ConcreteIterator(Element[] elements) {this.elements = elements;}
    //判断是否还有下一个元素
    @Override
    public boolean hasNext() {
        if(position &gt;= elements.length || elements[position] == null) {
            return false;
        }else {
            return true;
        }
    }
    @Override
    public Object next() {
        Element element = elements[position];
        position += 1;
        return element;
    }
}
</code></pre></div><h3>3.3.5. 观察者模式</h3>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class Client {
    public static void main(String[] args) {
        Subject subject = new Subject();
        new BinaryObserver(subject);
        subject.setState(15);
    }
}

//通知者
class Subject {
    private List&lt;Observer&gt; observers = new ArrayList&lt;Observer&gt;();
    private int state;
    public int getState() {return state;}
    //通知核心
    public void setState(int state) {
        this.state = state;
        notifyAllObservers();
    }
    public void attach(Observer observer){observers.add(observer);}
    public void notifyAllObservers(){
        for (Observer observer : observers) {
            observer.update();
        }
    }
}

//观察者抽象
abstract class Observer {
    protected Subject subject;
    public abstract void update();
}

//观察者
class BinaryObserver extends Observer{
    public BinaryObserver(Subject subject){
        this.subject = subject;
        this.subject.attach(this);
    }
    @Override
    public void update() {
        System.out.println( "Binary String: " + Integer.toBinaryString( subject.getState() ) );
    }
}
</code></pre></div><h3>3.3.6. 中介者模式</h3>
<ul>
<li>中介者模式（Mediator Pattern），用一个中介对象来封装一系列的对象交互。中介者使各个对象不需要显式地相互引用，从而使其耦合松散，而且可以独立地改变它们之间的交互</li>
<li>比如MVC模式，C（Controller控制器）是M（Model模型）和V（View视图）的中介者，在前后端交互时起到了中间人的作用</li>
<li>多个类相互耦合，会形成网状结构, 使用中介者模式将网状结构分离为星型结构，进行解耦</li>
<li>中介者承担了较多的责任，一旦中介者出现了问题，整个系统就会受到影响</li>
<li>如果设计不当，中介者对象本身变得过于复杂，这点在实际使用时，要特别注意</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class Client {
    public static void main(String[] args) {
        Mediator mediator = new ConcreteMediator();
        ConcreteColleague concreteColleague = new ConcreteColleague(mediator, "alarm");
        concreteColleague.SendMessage(0);
    }
}

//同事抽象类
abstract class Colleague {
    private Mediator mediator;
    public String name;
    public Colleague(Mediator mediator, String name) {this.mediator = mediator;this.name = name;mediator.Register(name, this);}
    public Mediator GetMediator() {return this.mediator;}
    public abstract void SendMessage(int stateChange);
    public Colleague(){}

}

//具体同事类
class ConcreteColleague extends Colleague {
    public ConcreteColleague(Mediator mediator, String alarm) {
        super(mediator,alarm);
    }
    @Override
    public void SendMessage(int stateChange) {this.GetMediator().GetMessage(stateChange, this.name);}
    public void StartCoffee() {System.out.println("It's time to startcoffee!");}
}

//抽象中介者
abstract class Mediator {
    public abstract void Register(String colleagueName, Colleague colleague);//将给中介者对象，加入到集合中
    public abstract void GetMessage(int stateChange, String colleagueName);//接收消息, 具体的同事对象发出
}

//具体的中介者类
class ConcreteMediator extends Mediator {
    private HashMap&lt;String, Colleague&gt; colleagueMap = new HashMap&lt;String, Colleague&gt;();//集合，放入所有的同事对象
    private HashMap&lt;String, String&gt; interMap = new HashMap&lt;String, String&gt;();
    public ConcreteMediator() {}

    @Override
    public void Register(String colleagueName, Colleague colleague) {
        colleagueMap.put(colleagueName, colleague);
        if (colleague instanceof ConcreteColleague) {interMap.put("ConcreteColleague", colleagueName);}
    }

    //具体中介者的核心方法
    //1. 根据得到消息，完成对应任务
    //2. 中介者在这个方法，协调各个具体的同事对象，完成任务
    @Override
    public void GetMessage(int stateChange, String colleagueName) {
        if (colleagueMap.get(colleagueName) instanceof ConcreteColleague) {
            if (stateChange == 0) {((ConcreteColleague) (colleagueMap.get(interMap.get("ConcreteColleague")))).StartCoffee();}
        }
    }
}
</code></pre></div><h3>3.3.7. 解释器模式</h3>
<ul>
<li>在编译原理中，一个算术表达式通过词法分析器形成词法单元，而后这些词法单元再通过语法分析器构建语法分析树，最终形成一颗抽象的语法分析树。这里的词法分析器和语法分析器都可以看做是解释器</li>
<li>解释器模式（Interpreter Pattern）：是指给定一个语言(表达式)，定义它的文法的一种表示，并定义一个解释器，使用该解释器来解释语言中的句子(表达式)</li>
<li>应用场景:可以将一个需要解释执行的语言中的句子表示为一个抽象语法树 ;一些重复出现的问题可以用一种简单的语言来表达 一个简单语法需要解释的场景;这样的例子还有，比如编译器、运算表达式计算、正则表达式、机器人等</li>
<li>当有一个语言需要解释执行，可将该语言中的句子表示为一个抽象语法树，就可以考虑使用解释器模式，让程序具有良好的扩展性</li>
<li>使用解释器可能带来的问题：解释器模式会引起类膨胀、解释器模式采用递归调用方法，将会导致调试非常复杂、效率可能降低.</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>//表达式接口
public interface Expression {
    public boolean interpret(String context);
}

//表达式实现
public class TerminalExpression implements Expression {
    private String data;
    public TerminalExpression(String data){this.data = data; }
    @Override
    public boolean interpret(String context) {
        if(context.contains(data)){return true;}
        return false;
    }
}

public class OrExpression implements Expression {
    private Expression expr1 = null;
    private Expression expr2 = null;
    public OrExpression(Expression expr1, Expression expr2) { 
        this.expr1 = expr1;
        this.expr2 = expr2;
    }
    @Override
    public boolean interpret(String context) {      
        return expr1.interpret(context) || expr2.interpret(context);
    }
}

public class AndExpression implements Expression {
    private Expression expr1 = null;
    private Expression expr2 = null;
    public AndExpression(Expression expr1, Expression expr2) { 
        this.expr1 = expr1;
        this.expr2 = expr2;
    }
    @Override
    public boolean interpret(String context) {      
        return expr1.interpret(context) &amp;&amp; expr2.interpret(context);
    }
}

public class client {
    //规则：Robert 和 John 是男性
    public static Expression getMaleExpression(){
        Expression robert = new TerminalExpression("Robert");
        Expression john = new TerminalExpression("John");
        return new OrExpression(robert, john);    
    }
    //规则：Julie 是一个已婚的女性
    public static Expression getMarriedWomanExpression(){
        Expression julie = new TerminalExpression("Julie");
        Expression married = new TerminalExpression("Married");
        return new AndExpression(julie, married);    
    }
    public static void main(String[] args) {
        Expression isMale = getMaleExpression();
        Expression isMarriedWoman = getMarriedWomanExpression();
        System.out.println("John is male? " + isMale.interpret("John"));
        System.out.println("Julie is a married women? " + isMarriedWoman.interpret("Married Julie"));
    }
}
</code></pre></div><h3>3.3.8. 备忘录模式</h3>
<ul>
<li>备忘录模式（Memento Pattern）在不破坏封装性的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态。这样以后就可将该对象恢复到原先保存的状态</li>
<li>备忘录对象主要用来记录一个对象的某种状态，或者某些数据，当要做回退时，可以从备忘录对象里获取原来的数据进行恢复操作</li>
<li>给用户提供了一种可以恢复状态的机制，可以使用户能够比较方便地回到某个历史的状态</li>
<li>如果类的成员变量过多，势必会占用比较大的资源，而且每一次保存都会消耗一定的内存, 这个需要注意</li>
<li>适用的应用场景：1、后悔药。 2、打游戏时的存档。 3、Windows 里的 ctri + z。 4、IE 中的后退。 4、数据库的事务管理</li>
<li>为了节约内存，备忘录模式可以和原型模式配合使用</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class Client {
    public static void main(String[] args) {
        Originator originator = new Originator();
        Caretaker caretaker = new Caretaker();
        originator.setState(" 状态#1 攻击力 100 ");
        //保存了当前的状态
        caretaker.add(originator.saveStateMemento());
        originator.setState(" 状态#2 攻击力 80 ");
        caretaker.add(originator.saveStateMemento());
        originator.setState(" 状态#3 攻击力 50 ");
        caretaker.add(originator.saveStateMemento());
        System.out.println("当前的状态是 =" + originator.getState());
        //希望得到状态 1, 将 originator 恢复到状态1
        originator.getStateFromMemento(caretaker.get(0));
        System.out.println("恢复到状态1 , 当前的状态是");
        System.out.println("当前的状态是 =" + originator.getState());
    }
}

//备忘录对象
class Memento {
    private String state;
    public Memento(String state) {this.state = state;}
    public String getState() {return state;}
}

//守护者对象,负责保存多个备忘录对象
class Caretaker {
    //在List 集合中会有很多的备忘录对象
    private List&lt;Memento&gt; mementoList = new ArrayList&lt;Memento&gt;();
    public void add(Memento memento) {mementoList.add(memento);}
    //获取到第index个Originator 的 备忘录对象(即保存状态)
    public Memento get(int index) {return mementoList.get(index);}
}

//originator : 对象(需要保存状态的对象)
class Originator {
    private String state;//状态信息
    public String getState() {return state;}
    public void setState(String state) {this.state = state;}
    //编写一个方法，可以保存一个状态对象 Memento
    //因此编写一个方法，返回 Memento
    public Memento saveStateMemento() {return new Memento(state);}
    //通过备忘录对象，恢复状态(将自己的属性转成传入来的属性)
    public void getStateFromMemento(Memento memento) {state = memento.getState();}
}
</code></pre></div><h3>3.3.9. 状态模式</h3>
<ul>
<li>状态模式（State Pattern）：它主要用来解决对象在多种状态转换时，需要对外输出不同的行为的问题。状态和行为是一一对应的，状态之间可以相互转换</li>
<li>当一个对象的内在状态改变时，允许改变其行为，这个对象看起来像是改变了其类</li>
<li>方便维护。将容易产生问题的if-else语句删除了，如果把每个状态的行为都放到一个类中，每次调用方法时都要判断当前是什么状态，不但会产出很多if-else语句，而且容易出错,容易增删状态</li>
<li>会产生很多类。每个状态都要一个对应的类，当状态过多时会产生很多类，加大维护难度</li>
<li>应用场景：当一个事件或者对象有很多种状态，状态之间会相互转换，对不同的状态要求有不同的行为的时候，可以考虑使用状态模式</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class Client {
    public static void main(String[] args) {
        Context context = new Context();
        StartState startState = new StartState();
        startState.doAction(context);
        System.out.println(context.getState().toString());
        StopState stopState = new StopState();
        stopState.doAction(context);
        System.out.println(context.getState().toString());
    }
}

//状态接口
interface State {
    void doAction(Context context);
}

//状态实现
class StartState implements State {
    public void doAction(Context context) {
        System.out.println("Player is in start state");
        context.setState(this);
    }
    public String toString(){return "Start State";}
}

class StopState implements State {
    public void doAction(Context context) {
        System.out.println("Player is in stop state");
        context.setState(this);
    }
    public String toString(){return "Stop State";}
}

//context
class Context {
    private State state;
    public void setState(State state){
        this.state = state;
    }
    public State getState(){
        return state;
    }
}
//将接口实现类放入到传入参数context的接口属性中，调用传入参数context可获得接口实现类及调用其方法
</code></pre></div><h3>3.3.10. 策略模式</h3>
<ul>
<li>策略模式（Strategy Pattern）中定义算法族，分别封装起来，让他们之间可以互相替换，此模式让算法的变化独立于使用算法的客户分别封装行为接口，实现算法族，超类里放行为接口对象，在子类里具体设定行为对象。原则就是：分离变化部分，封装接口，基于接口编程各种功能。此模式让行为的变化独立于算法的使用者</li>
<li>策略模式的关键是：分析项目中变化部分与不变部分</li>
<li>策略模式的核心思想是：多用组合/聚合 少用继承；用行为类组合，而不是行为的继承。更有弹性</li>
<li>提供了可以替换继承关系的办法： 策略模式将算法封装在独立的Strategy类中使得你可以独立于其Context改变它，使它易于切换、易于理解、易于扩展</li>
<li>需要注意的是：每添加一个策略就要增加一个类，当策略过多是会导致类数目庞大</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class Client {
    public static void main(String[] args) {
        Context context = new Context(new OperationAdd());    
        System.out.println("10 + 5 = " + context.executeStrategy(10, 5));
        context = new Context(new OperationSubstract());      
        System.out.println("10 - 5 = " + context.executeStrategy(10, 5));
    }
}
//策略接口
interface Strategy {
    public int doOperation(int num1, int num2);
}
//策略实现
class OperationAdd implements Strategy{
    @Override
    public int doOperation(int num1, int num2) {
        return num1 + num2;
    }
}
class OperationSubstract implements Strategy{
    @Override
    public int doOperation(int num1, int num2) {
        return num1 - num2;
    }
}
//context
class Context {
    private Strategy strategy;
    public Context(Strategy strategy){
        this.strategy = strategy;
    }
    public int executeStrategy(int num1, int num2){
        return strategy.doOperation(num1, num2);
    }
}
</code></pre></div><h3>3.3.11. 职责链模式</h3>
<ul>
<li>职责链模式Chain of Responsibility Pattern责任链模式，为请求创建了一个接收者对象的链对请求的发送者和接收者进行解耦。</li>
<li>职责链模式通常每个接收者都包含对另一个接收者的引用。如果一个对象不能处理该请求，那么它会把相同的请求传给下一个接收者，依此类推。</li>
<li>性能会受到影响，特别是在链比较长的时候，因此需控制链中最大节点数量，一般通过在Handler中设置一个最大节点数量，在setNext()方法中判断是否已经超过阀值，超过则不允许该链建立，避免出现超长链无意识地破坏系统性能</li>
<li>最佳应用场景：有多个对象可以处理同一个请求时，比如：多级请求、请假/加薪等审批流程、Java Web中Tomcat对Encoding的处理、拦截器</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class Client {
    public static void main(String[] args) {

        DepartmentApprover departmentApprover = new DepartmentApprover("张主任");//创建相关的审批人
        CollegeApprover collegeApprover = new CollegeApprover("李院长");
        SchoolMasterApprover schoolMasterApprover = new SchoolMasterApprover("佟校长");

        departmentApprover.setApprover(collegeApprover);//需要将各个审批级别的下一个设置好 (处理人构成环形: )
        collegeApprover.setApprover(schoolMasterApprover);
        schoolMasterApprover.setApprover(departmentApprover);

        departmentApprover.processRequest(new PurchaseRequest(31000, 1));
        collegeApprover.processRequest(new PurchaseRequest(200, 2));
    }
}

//处理者抽象
abstract class Approver {
    Approver approver;  //下一个处理者
    String name; // 名字
    public Approver(String name) {this.name = name;}
    public void setApprover(Approver approver) {this.approver = approver;}
    //处理审批请求的方法，得到一个请求, 处理是子类完成，因此该方法做成抽象
    public abstract void processRequest(PurchaseRequest purchaseRequest);
}

//具体处理者
class CollegeApprover extends Approver {
    public CollegeApprover(String name) {super(name);}
    @Override
    public void processRequest(PurchaseRequest purchaseRequest) {
        if(purchaseRequest.getPrice() &gt; 5000 &amp;&amp; purchaseRequest.getPrice() &lt;= 10000) {
            System.out.println(" 请求编号 id= " + purchaseRequest.getId() + " 被 " + this.name + " 处理");
        }else {
            approver.processRequest(purchaseRequest);
        }
    }
}

class DepartmentApprover extends Approver {
    public DepartmentApprover(String name) {super(name);}
    @Override
    public void processRequest(PurchaseRequest purchaseRequest) {
        if(purchaseRequest.getPrice() &lt;= 5000) {
            System.out.println(" 请求编号 id= " + purchaseRequest.getId() + " 被 " + this.name + " 处理");
        }else {
            approver.processRequest(purchaseRequest);
        }
    }
}

class SchoolMasterApprover extends Approver {
    public SchoolMasterApprover(String name) {super(name);}
    @Override
    public void processRequest(PurchaseRequest purchaseRequest) {
        if(purchaseRequest.getPrice() &gt; 10000) {
            System.out.println(" 请求编号 id= " + purchaseRequest.getId() + " 被 " + this.name + " 处理");
        }else {
            approver.processRequest(purchaseRequest);
        }
    }
}

//请求类
class PurchaseRequest {
    private float price = 0.0f; //请求金额
    private int id = 0;
    public PurchaseRequest(float price, int id) {
        this.price = price;
        this.id = id;
    }
    public float getPrice() {
        return price;
    }
    public int getId() {
        return id;
    }
}
</code></pre></div>]]></content:encoded>
    </item>
    <item>
      <title>分布式</title>
      <link>https://javaguide.cn/interview/distributed.html</link>
      <guid>https://javaguide.cn/interview/distributed.html</guid>
      <source url="https://javaguide.cn/rss.xml">分布式</source>
      <description>1. 什么是CAP定理？ CAP定理是指分布式系统中， CAP三者不可兼得 一致性（Consistency）：在分布式系统中的所有数据备份，在同一时刻是否同样的值。（等同于所有节点访问同一份最新的数据副本） 可用性（Availability）：保证每个请求不管成功或者失败都有响应。 分区容忍性（Partition tolerance）：分布式系统在遇到...</description>
      <category>面试</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<!-- more -->
<h1>1. 什么是CAP定理？</h1>
<ul>
<li>CAP定理是指分布式系统中， CAP三者不可兼得
<ul>
<li>一致性（Consistency）：在分布式系统中的所有数据备份，在同一时刻是否同样的值。（等同于所有节点访问同一份最新的数据副本）</li>
<li>可用性（Availability）：保证每个请求不管成功或者失败都有响应。</li>
<li>分区容忍性（Partition tolerance）：分布式系统在遇到某节点或网络分区故障的时候，仍然能够对外提供满足一致性或可用性的服务。</li>
</ul>
</li>
</ul>
<h1>2. 为什么CAP不可兼得呢？</h1>
<ul>
<li>分布式系统，分区是必然存在的，所谓分区指的是分布式系统可能出现的字区域网络不通，成为孤立区域的的情况。</li>
<li>保证一致性。则可用性保证不了，因为要等一致</li>
<li>保证可用性。则一致性保证不了，达到一致要时间</li>
</ul>
<h1>3. CAP对应的模型和应用，Zookeeper，Eureka，Nacos，consoul分别属于什么架构？√</h1>
<ul>
<li>CA(单机):放弃分区容错性，加强一致性和可用性，集群数据库、xFS文件系统</li>
<li>AP:放弃一致性，分区容错性和可用性，一旦分区发生，节点之间可能会失去联系，为了高可用，每个节点只能用本地数据提供服务，而这样会导致全局数据的不一致性。系统不保证改变提交以后立即改变集群的状态，但是随着时间的推移最终状态是一致的。-&gt;Web缓存、DNS、GOSSIP.MySQL主从异步复制\Redis \Eureka</li>
<li>CP:放弃可用性，追求一致性和分区容错性，P（分区）会导致同步时间无限延长，网络问题会直接让整个系统不可用.保证系统改变提交以后立即改变集群的状态。-&gt;分布式数据库、分布式锁，paxo，raft，zab.MySQL主从半同步复制\Zookeeper</li>
<li>业界主要采用了 XA 协议的强一致规范以及柔性事务的最终一致规范。</li>
</ul>
<h1>4. BASE理论</h1>
<ul>
<li>BASE理论是对CAP中AP的一个扩展，业务系统牺牲一致性来换取系统的可用性和分区容错性。BASE是下面三个短语的缩写
<ul>
<li>Basically Available 基本可用：通过支持局部故障而不是系统全局故障来实现的。如将用户分区在 5 个数据库服务器上，一个用户数据库的故障只影响这台特定主机那 20% 的用户，其他用户不受影响。</li>
<li>Soft State 软状态，允许系统中存在中间状态，这个状态不影响系统可用性，这里指的是 CAP 中的不一致。</li>
<li>Eventually Consistent 最终一致是指经过一段时间后，所有节点数据都将会达到一致。这个时间取决于网络延时、系统负载、数据复制方案设计等等因素。</li>
</ul>
</li>
</ul>
<h1>5. 为什么需要一致性算法？</h1>
<ul>
<li>数据不能存在单个节点（主机）上，否则可能出现单点故障；多个节点（主机）需要保证具有相同的数据</li>
</ul>
<h1>6. 常用的一致性算法分类？</h1>
<ul>
<li>Paxos算法：能够在存在故障节点的情况下保证系统的一致性。</li>
<li>Raft算法：比Paxos算法更易于理解和实现的一致性算法，它将分布式一致性问题分解成多个易于处理的子问题。</li>
<li>ZAB协议：Zookeeper中使用的一种一致性协议，它通过选举一个leader来协调多个follower之间的数据更新。</li>
<li>2PC协议：分布式系统中常用的一致性协议，它通过预提交和提交两个阶段来保证系统的一致性。</li>
<li>3PC协议：3在2PC协议的基础上增加了超时机制和准备阶段的“可以提交”状态，以提高系统的性能和可靠性。</li>
<li>Gossip协议：一种基于随机化的分布式一致性协议，它通过节点之间的随机通讯来传播数据和状态信息，从而达到一致性的目的。</li>
</ul>
<h1>7. Paxos算法</h1>
<ul>
<li>Paxos算法是基于消息传递且具有高效容错特性的一致性算法</li>
<li>在Paxos中有这么几个角色,一个节点可以同时充当不同角色。
<ul>
<li>Proposer（提议者）:提议者提出提案，用于投票表决。提案=编号+value，可以表示为[M,V]，每个提案都有唯一编号，而且编号的大小是趋势递增的</li>
<li>Accecptor（接受者）:对提案进行投票，并接受达成共识的提案。</li>
<li>Learner（学习者）:被告知投票的结果，接受达成共识的提案。</li>
<li>Proposal(提议)</li>
</ul>
</li>
<li>算法流程:
<ul>
<li>1.准备阶段(Prepare Phase)
<ul>
<li>提议者Proposer提议一个编号为N（N必须大于之前本提议者所有Proposal提案的编号）的Proposal提案，然后向接受者Accecptor的某个超过半数的子集成员发送包含Proposal提案的prepare请求，由接受者Accecptor决定哪个请求占大多数</li>
<li>如果一个接受者Accecptor收到包含编号为N的Proposal的prepare请求，并且编号N大于它已经接收的所有prepare请求的编号，然后接受者会返回promise承诺，忽略任何编号小于N的Proposal提案。同时包括已经accept过的最大编号的Proposal提案作为响应反馈给提议者</li>
<li>接受者在收到提案后，会给与提议者两个承诺与一个应答：
<ul>
<li>两个承诺：承诺忽略提案号小于或等于N的Prepare请求；承诺忽略提案号小于N的Accept请求</li>
<li>一个应答：回复已经accept的提案中提案号最大的那个提案所设定的值NmaxValue和提案号Nmax，如果这个值从来没有被任何提案设定过，则返回空值。如果不满足已经做出的承诺，即收到的提案号并不是决策节点收到过的最大的，那允许直接对此 Prepare 请求不予理会</li>
</ul>
</li>
</ul>
</li>
<li>2.Accept(接受)阶段
<ul>
<li>如果提议者Proposer收到来自半数以上的接受者对于它发出的编号为N的prepare请求的响应，然后给Proposal提案设置值value，value就是从Accecptor接收者中收到的响应中编号最大的提案的值，如果响应中不包含任何提案，那么它可以随意选定一个值。此时，提议者Proposer会向接受者Accecptor的某个超过半数的子集成员发出已经设置值的Accept Request Message</li>
<li>如果接受者Accecptor收到这个编号为N的Proposal提案的Accept Request Message，如果这个编号N大于接受者Accecptor之前所有返回promise承诺，则接受者Accecptor就会Accept，同时向提议者Proposer和所有学习者Learner发送Accepted Message，其他情况则接受者Accecptor忽略Accept Request Message</li>
<li>注意:接受者Accecptor可以Accept多个Proposal提案，在某些失败情况下，Proposal提案可能有不同的值，但是Paxos算法保证值最终达到一致；当多个提议者Proposer发送冲突的Prepare请求，或者提议者Proposer没有接收到超过半数Promise承诺或者Accepted Message，以上这些情况都会使新一轮提议者发起编号更大的proposal; 当接收者Accecptor接收acceptAccept Requeset Message时，也会选出在提议者Proposer的leader，因此，Paxos算法也适合在集群中选出leader</li>
</ul>
</li>
</ul>
</li>
<li>Paxos算法有什么缺点吗？怎么优化？
<ul>
<li>上述为Basic Paxos 算法，在单提议者的前提下是没有问题的，但是假如有多个提议者互不相让，那么就可能导致整个提议的过程进入了死循环。</li>
<li>Lamport 提出了 Multi Paxos 的算法思想。在多个提议者的情况下，选出一个Leader（领导者），由领导者作为唯一的提议者，这样就可以解决提议者冲突的问题。<br>
![paxos.png)</li>
</ul>
</li>
</ul>
<h2>7.1. Raft算法</h2>
<ul>
<li>Raft算法的角色
<ul>
<li>Leader（领导者）</li>
<li>Follower（跟随者）</li>
<li>Candidate（候选人）</li>
</ul>
</li>
<li>领导者由跟随者投票选出。刚开始没有 领导者，所有集群中的 参与者 都是 跟随者。所有跟随者 都能参与竞选，这时所有跟随者的角色就变成了 候选人，民主投票选出领袖后就开始了这届领袖的任期Term，然后选举结束，所有除 领导者 的 候选人 又变回 跟随者 服从领导者领导。</li>
<li>Leader选举过程
<ul>
<li>Raft 使用心跳（heartbeat）触发Leader选举。当Server启动时，初始化为Follower。Leader向所有Followers周期性发送heartbeat。如果Follower在选举超时时间内没有收到Leader的heartbeat，就会等待一段随机的时间后发起一次Leader选举。Follower将其当前term加一然后转换为Candidate。它首先给自己投票并且给集群中的其他服务器发送 RequestVote RPC 。结果有以下三种情况：</li>
<li>赢得了多数（超过1/2）的选票，成功选举为Leader；</li>
<li>收到了Leader的消息，表示有其它服务器已经抢先当选了Leader；</li>
<li>没有Server赢得多数的选票，Leader选举失败，等待选举时间超时（Election Timeout）后发起下一次选举。</li>
<li>选出 Leader 后，Leader 通过 定期 向所有 Follower 发送 心跳信息 维持其统治。若 Follower 一段时间未收到 Leader 的 心跳，则认为 Leader 可能已经挂了，然后再次发起 选举 过程。</li>
</ul>
</li>
</ul>
<h1>8. 分布式id需要满足什么条件？常见生成方法有哪些？√</h1>
<ul>
<li>
<p>全局唯一</p>
</li>
<li>
<p>高性能：高可用低延时，ID生成响应要块，否则反倒会成为业务瓶颈</p>
</li>
<li>
<p>高可用：100%的可用性是骗人的，但是也要无限接近于100%的可用性</p>
</li>
<li>
<p>好接入：要秉着拿来即用的设计原则，在系统设计和实现上要尽可能的简单</p>
</li>
<li>
<p>趋势递增：最好趋势递增，这个要求就得看具体业务场景了，一般不严格要求</p>
</li>
<li>
<p>Redis是单线程的并且reids中的incr命令是原子自增的。redis是第三方的组件，如果本身系统中就没有使用redis，这时使用redis就会增加系统的负担，因为一旦使用就是集群，而且至少得三个哨兵集群。<br>
redis如果使用RBD作为持久化，那在一个快照时间内宕机了，此时还未进行吃就会，恢复后会出现ID重复.使用AOF进行持久化，恢复较慢。（至少丢失1s得数据）</p>
</li>
<li>
<p>UUID</p>
</li>
<li>
<p>雪花算法:twitter开源得分布式id生成方案。其核心思想就是：使用一个64bit得long型数字作为全局唯一id。</p>
</li>
<li>
<p>第一部分1个bit：0，二进制的最高位为符号位。0表示整数，1表示负数。</p>
</li>
<li>
<p>第二部分是41bit的时间戳。单位是毫秒。41bit可以表示的数字多达241-1,也就是可以标识241-1毫秒，约等于69年(从1970年开始)。</p>
</li>
<li>
<p>第三部分5个bit：表示机房id，最多表示2^5个机房</p>
</li>
<li>
<p>第四部分为5个bit：表示的是机器id。每个房间里可以有2^5个机器。</p>
</li>
<li>
<p>第五部分12个bit：表示序号，就是某个机房某台机器上一毫秒内同时生成的id的序号。12bit可以代表的最大正整数是2^12-1,一共4096个数，也就是说一毫秒内可以生成4096个唯一id。如果在同一毫秒内，则将序列号递增1，使用掩码（最低12位为1，高位都为0）进行位与运行后如果值为0，则自增后的序列号超过了4095</p>
</li>
<li>
<p>高性能高可用，生成时不依赖于数据库，完全在内存中生成。容量大：每秒能生成百万的自增id。id自增:时间时自增的，所以生成的id也是自增的。</p>
</li>
<li>
<p>缺点：依赖与系统时间的一致性，如果系统时间被回调，或者改变，可能造成重复的id。算法中可通过记录最后一个生成 id 时的时间戳来解决，每次生成 id 之前比较当前服务器时钟是否被回拨，避免生成重复 id</p>
</li>
<li>
<p>redis集群的incr方法</p>
</li>
</ul>
<h1>9. 如何设计分布式锁？分布式锁怎么实现？√</h1>
<ul>
<li>具备原子性、可重入性；具备锁失效机制，防止死锁；具备非阻塞锁特性，即没获取到锁返回获取锁失败，而不是一直等待</li>
<li>高性能、高可用的获取与释放锁</li>
<li>分布式锁的实现方式：
<ul>
<li>基于数据库：
<ul>
<li>用数据库的排他锁实现select * from xxx for update</li>
<li>创建一张锁表，数据库对字段作唯一性约束。加锁的时候，在锁表中增加一条记录即可；释放锁的时候删除记录就行。如果有并发请求同时提交到数据库，数据库会保证只有一个请求能够得到锁。属于数据库 IO 操作，效率不高，而且频繁操作会增大数据库的开销，因此这种方式在高并发、高性能的场景中用的不多。</li>
</ul>
</li>
<li>基于redis：利用redis的set key value NX EX 30000；也可以用redis的第三方库比如Redisson</li>
<li>基于zookeeper：利用zookeeper的临时顺序节点实现；每个线程都是先创建临时顺序节点，然后获取当前目录下最小的节点(序号)，判断最小节点是不是当前节点，如果是那么获取锁成功，如果不是那么获取锁失败。获取锁失败的线程获取当前节点上一个临时顺序节点，并对对此节点进行监听，当该节点删除的时候(上一个线程执行结束删除或者是掉线zk删除临时节点)这个线程会获取到通知，代表获取到了锁。公平锁使用临时节点实现，非公平锁使用临时顺序节点实现.也可以用zookeeper的第三方库比如Curator</li>
</ul>
</li>
</ul>
<h1>10. 分布式事务</h1>
<ul>
<li>分布式事务是指事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于不同的分布式系统的不同节点之上。布式事务需要保证这些分支事务要么全部成功，要么全部失败</li>
</ul>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/93416270ed2d740c33a9d.png" alt="distributedtransaction.png" tabindex="0"><figcaption>distributedtransaction.png</figcaption></figure>
<ul>
<li>
<p>XA方案/2PC二阶段提交</p>
<ul>
<li>XA分布式事务的规范，由X/Open组织提出，定义了(全局)事务管理器(TM)和(局部)资源管理器(RM)之间的接口。主流的数据库基本都支持XA事务，包括mysql、oracle、sqlserver</li>
<li>XA事务由一个或多个资源管理器（RM）(数据库)、一个事务管理器（TM）和一个应用程序（ApplicationProgram）组成。</li>
<li>XA一共分为两阶段：
<ul>
<li>第一阶段（prepare）所有的参与者RM准备执行事务并锁住需要的资源。参与者ready时，向TM报告已准备就绪。</li>
<li>第二阶段 (commit/rollback)：当事务管理者(TM)确认所有参与者(RM)都ready后，向所有参与者发送commit命令。有任何一个参与者(RM)ready失败，向所有参与者发送rollback命令，若在commit过程中出现宕机等异常时，则在节点服务重启后，可根据 XA recover 再次进行 commit 补偿，以保证数据的一致性。</li>
</ul>
</li>
</ul>
</li>
<li>
<p>问题</p>
<ul>
<li>单点问题：单机事务管理器宕机导致资源管理器阻塞，数据库无法使用.</li>
<li>性能问题：准备就绪后资源一直处于阻塞状态，直到提交完成，释放资源.并发度低</li>
<li>数据一致性问题，因为网络问题部分资源管理器执行了提交，但其他资源管理器没有执行。数据不一致</li>
</ul>
</li>
<li>
<p>java语言可参考seata、Sharding Sphere、Spring JTA + Atomikos</p>
</li>
<li>
<p>应用场景：适合单块应用里，跨多个库的分布式事务，而且因为严重依赖于数据库层面来搞定复杂的事务，效率很低，绝对不适合高并发的场景。微服务规定和规范，是要求每个服务只能操作自己对应的一个数据库。如果你要操作别人的服务的库，你必须是通过调用别的服务的接口来实现，绝对不允许交叉访问别人的数据库<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/ca34bd75f2c04b1738005.png" alt="xatransaction.png"></p>
</li>
<li>
<p>3PC（三阶段提交）</p>
<ul>
<li>为解决两阶段提交协议的单点故障和同步阻塞问题。</li>
<li>三阶段提交有这么三个阶段：CanCommit，PreCommit，DoCommit三个阶段
<ul>
<li>CanCommit：准备阶段。协调者向参与者发送commit请求，参与者如果可以提交就返回Yes响应，否则返回No响应。</li>
<li>PreCommit：预提交阶段。协调者根据参与者在准备阶段的响应判断是否执行事务还是中断事务，参与者执行完操作之后返回ACK响应，同时开始等待最终指令。</li>
<li>DoCommit：提交阶段。协调者根据参与者在准备阶段的响应判断是否执行事务还是中断事务：
<ul>
<li>如果所有参与者都返回正确的ACK响应，则提交事务</li>
<li>如果参与者有一个或多个参与者收到错误的ACK响应或者超时，则中断事务</li>
<li>如果参与者无法及时接收到来自协调者的提交或者中断事务请求时，在等待超时之后，会继续进行事务提交</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>解决的只是两阶段提交中单体故障和同步阻塞的问题，因为加入了超时机制，这里的超时的机制作用于 预提交阶段 和 提交阶段。如果等待 预提交请求 超时，参与者直接回到准备阶段之前。如果等到提交请求超时，那参与者就会提交事务了。</p>
</li>
<li>
<p>无论是2PC还是3PC都不能保证分布式系统中的数据100%一致。</p>
</li>
<li>
<p>TCC（Try-Confirm-Cancel） 方案（补偿机制）</p>
<ul>
<li>TCC模型针对每个操作，都需要有一个其对应的确认和取消操作，当操作成功时调用确认操作，当操作失败时调用取消操作，把锁的粒度完全交给业务处理，它需要每个子事务业务都实现Try-Confirm/Cancel接口。TCC模式本质也是2PC ，只是TCC在应用层控制。</li>
<li>TCC分为3个阶段
<ul>
<li>Try阶段：尝试执行，完成所有业务检查（一致性）, 预留必须业务资源（准隔离性）对各个服务的资源做检测以及对资源进行锁定或者预留。</li>
<li>Confirm阶段：确认执行真正执行业务，不作任何业务检查，只使用Try阶段预留的业务资源，Confirm操作要求具备幂等设计，Confirm失败后需要进行重试。</li>
<li>Cancel阶段：取消执行，释放Try阶段预留的业务资源。Cancel阶段满足幂等设计。如果任何一个服务的业务方法执行出错，那么这里就需要进行补偿，就是执行已经执行成功的业务逻辑的回滚操作。（把那些执行成功的回滚）</li>
</ul>
</li>
<li>通常会在Try里面冻结金额，但不扣款，Confirm里面扣款，Cancel里面解冻金额，一个成功完成的TCC事务时序图如下：</li>
</ul>
</li>
<li>
<p>优缺点</p>
<ul>
<li>规避了数据库的2PC性能低下问题。并发度较高，无长期资源锁定。</li>
<li>一致性较好，不会发生SAGA已扣款最后又转账失败的情况</li>
<li>应用侵入性强，开发量较大，try、confirm、cancel三个阶段都需要业务逻辑实现。需要根据网络、系统故障等不同失败原因实现不同的回滚策略，实现难度大</li>
<li>适用于订单类业务，对中间状态有约束的业务</li>
<li>在需要前置资源锁定的场景，不得不使用 XA 或 TCC 的方式。如下单场景，在订单创建之前，需要扣除优惠券、钱包余额、积分等不得不进行前置多资源锁定，无非是使用 XA 的强锁，还是 TCC 的弱锁。当然，如果能不用 TCC 的情况下，尽量不要用 TCC 。因为，编写回滚逻辑的代码，可能会比较恶心。</li>
<li>ByteTCC，TCC-transaction，Himly。java语言可参考seata<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/2276c860cf983b0edff09.png" alt="tcctransaction.png"></li>
</ul>
</li>
<li>
<p>SAGA方案</p>
<ul>
<li>Saga是将长事务拆分为多个本地短事务，由Saga事务协调器协调，如果正常结束那就正常完成，如果某个步骤失败，则根据相反顺序一次调用补偿操作。</li>
<li>Saga组成如下：
<ul>
<li>每个Saga由一系列sub-transaction Ti 组成</li>
<li>每个Ti都有对应的补偿动作Ci ，补偿动作用于撤销Ti造成的结果。每个T都是一个本地事务。</li>
<li>和TCC相比，Saga没有try动作 ，它的Ti就是直接提交到库</li>
</ul>
</li>
<li>Saga的执行顺序有两种：
<ul>
<li>子事务序列 T1, T2, …, Tn得以完成 (最佳情况)。</li>
<li>或者序列 T1, T2, …, Tj, Cj, …, C2, C1, 0 &lt; j &lt; n, 得以完成。</li>
</ul>
</li>
<li>Saga 定义了两种恢复策略：
<ul>
<li>向后恢复：补偿所有已完成的事务，如果任一子事务失败。（第二种执行顺序）</li>
<li>向前恢复：重试失败的事务，假设每个子事务最终都会成功。向前恢复没有必要提供补偿事务，如果你的业务中，子事务（最终）总会成功，或补偿事务难以定义或不可能，向前恢复更符合你的需求。理论上补偿事务永不失败，然而，在分布式世界中，服务器可能会宕机、网络可能会失败，甚至数据中心也可能会停电，这时需要提供故障恢复后回退的机制，比如人工干预。</li>
</ul>
</li>
<li>如何解决没有 Prepare阶段可能带来的问题？由于 Saga 模型中没有 Prepare 阶段，因此事务间不能保证隔离性，当多个 Saga 事务操作同一资源时，就会产生更新丢失、脏数据读取等问题，这时需要在业务层控制并发。例如：在应用层面加锁。应用层面预先冻结资源。</li>
<li>并发度高，不用像XA事务那样长期锁定资源</li>
<li>需要定义正常操作以及补偿操作，开发量比XA大</li>
<li>一致性较弱，对于转账，可能发生A用户已扣款，最后转账又失败的情况</li>
<li>适用于长事务，对中间结果不敏感的业务场景适用</li>
<li>go语言可参考DTM，java语言可参考seata、Apache Service Comb 的 Saga 事务引擎、Sharding Sphere 的 Saga 支持<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/a62fef45ab701a92cfb2f.png" alt="sagatransaction.png"></li>
</ul>
</li>
<li>
<p>本地消息表ebay</p>
<ul>
<li>在消息发送方的同一个业务数据库中添加一个记录着消息状态相关信息的消息表，保证业务表与消息表在同一个事务，使用定时任务轮询查询状态为未同步的消息表，发送到MQ，如果发送失败，就重试发送</li>
<li>消息消费方处理消息队列中的消息，完成自己的业务逻辑。同时保证不会处理重复消息。如果本地事务处理失败，那么就会重试执行。如果是业务上面的失败，给消息生产方发送一个业务补偿消息，通知进行回滚等操作。使用定时任务轮询查询状态为未同步的消息表，发送到MQ，如果发送失败，就重试发送</li>
<li>优点&amp;缺点：
<ul>
<li>很好地解决了分布式事务问题，实现了最终一致性。长事务仅需要分拆成多个任务，使用简单</li>
<li>缺点是消息表会耦合到业务系统中。最终一致性的间隔主要有定时任务的间隔时间决定。生产者需要额外的创建消息表。每个本地消息表都需要进行轮询。消费者的逻辑如果无法通过重试成功，那么还需要更多的机制，来回滚操作</li>
</ul>
</li>
<li>适用于可异步执行的业务，且后续操作无需回滚的业务</li>
</ul>
</li>
<li>
<p>可靠消息最终一致性方案</p>
<ul>
<li>阿里开源的RocketMQ4.3之后的版本正式支持事务消息</li>
<li>消息发送方先发送一个prepared消息到mq，如果这个prepared消息发送失败那么就直接取消操作别执行了；如果这个消息发送成功过了，那么接着执行本地事务，如果成功就告诉mq发送确认消息，如果失败就告诉mq回滚消息</li>
<li>如果发送了确认消息，那么此时消息接收方会接收到确认消息，然后执行本地的事务；</li>
<li>mq会自动定时轮询所有 prepared 消息回调你的接口，接口里面可以查下数据库看之前本地事务已经提交/回滚/异常，回复确认/回滚/重试。避免本地事务执行成功了，而确认消息却发送失败了。</li>
<li>如果系统B的事务失败了这自动不断重试直到成功，如果实在是不行，要么就是针对重要的资金类业务进行回滚，比如B系统本地回滚后，想办法通知系统A也回滚；或者是发送报警由人工来手工回滚和补偿。</li>
<li>长事务仅需要分拆成多个任务，并提供一个反查接口，使用简单、消费者的逻辑如果无法通过重试成功，那么还需要更多的机制，来回滚操作</li>
<li>适用于可异步执行的业务，且后续操作无需回滚的业务</li>
<li>不需要再建消息表，对性能的损耗和业务的入侵更小</li>
<li>可参考rocketmq，DTM也提供了简单实现，《RabbitMQ 之消息确认机制（事务+Confirm）》</li>
</ul>
</li>
<li>
<p>最大努力通知方案</p>
<ul>
<li>适用于一些对最终一致性实时性要求没那么高的业务，比如支付通知，短信通知。</li>
<li>发送方提供接口，让接受通知方能够通过接口查询业务处理结果</li>
<li>发送方消息队列ACK机制，消息队列按照间隔1min、5min、10min、30min、1h、2h、5h、10h的方式，逐步拉大通知间隔 ，直到达到通知要求的时间窗口上限。之后不再通知</li>
<li>最大努力通知适用于业务通知类型，例如微信交易的结果，就是通过最大努力通知方式通知各个商户，既有回调通知，也有交易查询接口</li>
<li>以支付通知为例，业务系统调用支付平台进行支付，支付平台进行支付，进行操作支付之后支付平台会去同步通知业务系统支付操作是否成功，如果不成功，会一直异步重试，但是会有一个最大通知次数，如果超过这个次数后还是通知失败，就不再通知，业务系统自行调用支付平台提供一个查询接口，供业务系统进行查询支付操作是否成功。</li>
</ul>
</li>
<li>
<p>本地消息表和事务消息都属于可靠消息与最大努力通知区别?</p>
<ul>
<li>可靠消息一致性，发起通知方需要保证将消息发出去，并且将消息发到接收通知方，消息的可靠性关键由发起通知方来保证。</li>
<li>最大努力通知，发起通知方尽最大的努力将业务处理结果通知为接收通知方，但是可能消息接收不到，此时需要接收通知方主动调用发起通知方的接口查询业务处理结果，通知的可靠性关键在接收通知方。</li>
</ul>
</li>
</ul>
<h1>11. seata实现</h1>
<ul>
<li>
<p>Seata是从业务无侵入的两阶段提交（全局事务）着手，在传统的两阶段上进行改进，把一个分布式事务理解成一个包含了若干分支事务的全局事务。而全局事务的职责是协调它管理的分支事务达成一致性，要么一起成功提交，要么一起失败回滚</p>
</li>
<li>
<p>Seata中存在这么几种重要角色：</p>
<ul>
<li>TC（Transaction Coordinator）：事务协调者。管理全局的分支事务的状态，用于全局性事务的提交和回滚。</li>
<li>TM（Transaction Manager）：事务管理者。用于开启、提交或回滚事务。</li>
<li>RM（Resource Manager）：资源管理器。用于分支事务上的资源管理，向TC注册分支事务，上报分支事务的状态，接收TC的命令来提交或者回滚分支事务。</li>
</ul>
</li>
<li>
<p>Seata整体执行流程</p>
<ul>
<li>服务A中的TM向TC申请开启一个全局事务，TC就会创建一个全局事务并返回一个唯一的XID</li>
<li>服务A中的RM向TC注册分支事务，然后将这个分支事务纳入 XID 对应的全局事务管辖中</li>
<li>服务A开始执行分支事务</li>
<li>服务A开始远程调用B服务，此时 XID 会根据调用链传播</li>
<li>服务B中的 RM 也向 TC 注册分支事务，然后将这个分支事务纳入 XID 对应的全局事务管辖中</li>
<li>服务B开始执行分支事务</li>
<li>全局事务调用处理结束后，TM 会根据有误异常情况，向 TC 发起全局事务的提交或回滚</li>
<li>TC 协调其管辖之下的所有分支事务，决定是提交还是回滚<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/60852f1b024765c3a8189.png" alt="seata.png"></li>
</ul>
</li>
<li>
<p>你们公司是如何处理分布式事务的？</p>
<ul>
<li>我们某某特别严格的场景，用的是 TCC 来保证强一致性。</li>
<li>其他场基于阿里的 RocketMQ 来实现了分布式事务。如果是一般的分布式事务场景，订单插入之后要调用库存服务更新库存，库存数据没有资金那么的敏感，可以用可靠消息最终一致性方案。</li>
</ul>
</li>
</ul>
<h1>12. 分布式限流算法</h1>
<h2>12.1. 计数器</h2>
<ul>
<li>比如我们要限制1s能够通过的请求数，实现的思路就是从第一个请求进来开始计时，在接下来的1s内，每个请求进来请求数就+1，超过最大请求数的请求会被拒绝，等到1s结束后计数清零，重新开始计数。弊端：比如前10ms已经通过了最大的请求数，那么后面的990ms的请求只能拒绝，这种现象叫做“突刺现象”</li>
</ul>
<h2>12.2. 漏桶算法</h2>
<ul>
<li>桶底出水的速度恒定，进水的速度可能快慢不一，但是当进水量大于出水量的时候，水会被装在桶里，不会直接被丢弃；但是桶也是有容量限制的，当桶装满水后溢出的部分还是会被丢弃的。可以准备一个队列来保存暂时处理不了的请求，然后通过一个线程池定期从队列中获取请求来执行</li>
</ul>
<h2>12.3. 令牌桶算法</h2>
<ul>
<li>令牌桶就是生产访问令牌的一个地方，生产的速度恒定，用户访问的时候当桶中有令牌时就可以访问，否则将触发限流。Guava RateLimiter是一个谷歌提供的限流，其基于令牌桶算法，比较适用于单实例的系统</li>
</ul>
]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/93416270ed2d740c33a9d.png" type="image/png"/>
    </item>
    <item>
      <title>dubbo</title>
      <link>https://javaguide.cn/interview/dubbo.html</link>
      <guid>https://javaguide.cn/interview/dubbo.html</guid>
      <source url="https://javaguide.cn/rss.xml">dubbo</source>
      <description>Dubbo</description>
      <category>面试</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>Dubbo</p>
<!-- more -->
<h1>1. Dubbo组件</h1>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/74cce94dc95c242560901.png" alt="dubboarchitecture.png" tabindex="0"><figcaption>dubboarchitecture.png</figcaption></figure>
<ul>
<li>Provider: 暴露服务的服务提供方。在启动时，向注册中心注册自己提供的服务。</li>
<li>Consumer: 调用远程服务的服务消费方。在启动时，向注册中心订阅自己所需的服务。</li>
<li>Registry: 服务注册与发现的注册中心。返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。服务消费者从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。</li>
<li>Monitor: 统计服务的调用次调和调用时间的监控中心。服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。</li>
<li>Container: 服务运行容器。负责启动，加载，运行服务提供者。</li>
</ul>
]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/74cce94dc95c242560901.png" type="image/png"/>
    </item>
    <item>
      <title>面试</title>
      <link>https://javaguide.cn/interview/interview.html</link>
      <guid>https://javaguide.cn/interview/interview.html</guid>
      <source url="https://javaguide.cn/rss.xml">面试</source>
      <description>自我介绍 面试官早上好，我是xxx，来自广东清远，2018年从广东药科大学制药工程专业毕业，目前有5年java开发经验，做过传统医疗项目和互联网社交项目，在项目里面使用过springboot、mybatis框架、redis分布式缓存组件，rabbitmq消息队列，mysql数据库等，在上一份工作中负责核心模块开发，参与过需求评审和数据库设计，有在lin...</description>
      <category>面试</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<!-- TOC -->
<h1>自我介绍</h1>
<ul>
<li>
<p>面试官早上好，我是xxx，来自广东清远，2018年从广东药科大学制药工程专业毕业，目前有5年java开发经验，做过传统医疗项目和互联网社交项目，在项目里面使用过springboot、mybatis框架、redis分布式缓存组件，rabbitmq消息队列，mysql数据库等，在上一份工作中负责核心模块开发，参与过需求评审和数据库设计，有在linux上排查线上问题的经验。希望能加入贵公司担任java开发工程师，谢谢</p>
</li>
<li>
<p>Good morning, interviewer, My name is xxx,I come from Qingyuan,a city in Guangdong Province. I was graduated from Guangdong Pharmaceutical University in 2018, majoring in pharmaceutical engineering. l have been working as a java development engineer for 5 years, and have done traditional medical projects and Internet social projects, in which I have used springboot, mybatis framework and redis distributed cache component. rabbitmq message queue, mysql database, etc. In my last job, I was responsible for core module development, participated in requirement review and database design, and had experience in troubleshooting online problems on linux. I hope I can make a good performance today. That’s  all. Thank you for giving me the chance.</p>
</li>
<li>
<p>面试官早上好，我是xxx，广东清远人，18年广东药科大学毕业，制药工程专业，目前住在天河梅花园，是一个i人，平时喜欢看书跑步，与陌生人熟悉后就会变成e人，乐观开朗</p>
</li>
</ul>
<h1>场景设计</h1>
<ul>
<li>先完成再完美：我想了一下可以这么做，时间有限，可能有些不合理地方，然后说方案</li>
<li>想到多少说多少，部分也没关系</li>
<li>不会就坦诚说还有xx部分，因为xx地方没有想到，可不可以给点提示</li>
<li>不知道选什么方案就提出选择困难原因</li>
</ul>
<h1>遇到不懂的地方</h1>
<ul>
<li>没听清，不好意思你是指xxx内容还是xxx内容，把范围缩小，不会就不要说</li>
<li>不懂，这个我不大了解，我猜是这样的或者我没怎么了解，但我知道xxxx和它差不多，也能做到zzz目的</li>
</ul>
<h1>项目</h1>
<ul>
<li>项目难点或者亮点？</li>
<li>项目为什么用？而不用？为什么这么设计？</li>
<li>项目描述
<ul>
<li>1.项目的背景(这个项目解决什么问题)，1分钟以内要描述完</li>
<li>2.项目包含的功能/模块，简单说明每个功能的作用</li>
<li>3.你参与并负责的横块</li>
<li>4.项目采用的技术架构</li>
<li>5.项目中的难点、亮点和个人的成长
<ul>
<li>1.体现你解决问题的能力</li>
<li>2.体现你的学习能力</li>
<li>3.体现你的架构思维</li>
<li>4.体现你的团队协作能力</li>
<li>5.体现你的管理能偶</li>
<li>6.体现你的技术能力</li>
<li>也就是只要能够体现上述这些能力的，都可以去总结出来，不一定是高并发/高性能的一些事情比如独立从0到1搭建微服务架构、第一次参与线上问题的诊断和解决</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1>你有没有什么想问的？</h1>
<ul>
<li>如果职位描述没有写部门或者业务，可以问具体做什么业务，团队规模多少</li>
<li>就刚才的面试，你觉得我还有哪些地方需要加强的地方</li>
<li>您当初选择这家公司的原因是什么呢?</li>
<li>团队氛围如何，平时几点下班</li>
</ul>
<h1>面试复盘</h1>
<ul>
<li>遇到不懂或者回答不好的问题，面试结束后要弄懂</li>
</ul>
<h1>hr面</h1>
<ul>
<li>
<p>人生、对方公司情况和谈薪资，卡涨幅30%</p>
</li>
<li>
<p>压工资，可以说有一个offer，对方给了xxx，但自己更希望来贵公司+理由，希望薪资可以给到</p>
</li>
<li>
<p>谈薪资：</p>
<ul>
<li>1薪资结构&amp;发放时间。
<ul>
<li>薪资结构一般包括无责底薪+绩效+提成+奖金+各种补贴+年终奖+其他福利</li>
<li>发放时间：最好15号前</li>
<li>年终奖13、14薪</li>
<li>税前税后</li>
<li>调薪制度，一年一般10%</li>
</ul>
</li>
<li>2劳动合同&amp;试用期：
<ul>
<li>注意:劳动法规定劳动合同期限在6个月到一年的，试用期最长不超过30天;</li>
<li>劳动合同期限在一年以上三年以下的，试用期最长不得超过 60天;</li>
<li>劳动合同期限在三年以上的，试用期不得超过6个月。试用期最长不得超过六个月，</li>
<li>试用期工资折扣不得低于正式工资的 80%(一般面试的时候问好)</li>
</ul>
</li>
<li>3福利待遇 福利待遇一般包括房补、话补、交通补贴、餐补等福利</li>
<li>4五险一金：
<ul>
<li>注意:五险一金包括:养老保险+医疗保险+失业保险+工伤保险+生育保险+住房公积金，缴纳基数和比例</li>
<li>六险一金：在五险一金的基础上增加、收起.业保险，即大病保险，是一种补充医疗保，缴纳基数和比例</li>
</ul>
</li>
<li>工作时间，双休单休</li>
<li>年假：已满1年不满10年的，年休假5天;已满10年不满20年的，年休假10天;已满20年的，年休假15天;国家法定休假日、休息日不计入年休假的假期。年假应享与正常工作期间相同的工资收入</li>
<li>年终</li>
<li>加班费</li>
<li>晋升渠道，升职</li>
<li>打卡</li>
<li>补贴</li>
</ul>
</li>
<li>
<p>工作内容</p>
</li>
<li>
<p>优点</p>
<ul>
<li>学习方面:学习能力强，能够较快的攻克一些比较难的任务</li>
<li>生活方面:积极乐观:行动力强;喜欢复盘，对自己有长期规划和短期规划:定好目标就会坚持不懈的走下去，有韧性;比较活泼外向一些，喜欢与人交际，也有很多好朋友。</li>
</ul>
</li>
<li>
<p>缺点(从另一个角度看就是优点，切记不能说纯缺点)</p>
<ul>
<li>有点强迫症，会对任务的细节核对多遍，比如发送重要的邮件，就会把收信人还有邮件内容检查两遍但其他人可能不会检查，我这样子就有点浪费时间了。</li>
<li>有点钻牛角尖，尤其在学习新的知识时，我有个点不懂就会去找资料，必须把他搞懂，或者至少理解个大概才会放手，这个过程很花时间，但我不这样子做的话就难受。之后我的朋友给我说他们的方法就是把不懂的先放着，等学了别的知识，再返回来看这个知识点就触类旁通了，我目前也在慢慢地对情况进行分类讨论，有的用我之前方法，有的用我朋友给我说的方法，效果也不错。</li>
</ul>
</li>
<li>
<p>兴趣爱好</p>
<ul>
<li>喜欢爬山、徒步这些户外活动。不仅可以亲近大自然，而且可以不断挑战自己体能的极限，我很喜欢这种突破自我带给我的成就感。</li>
<li>喜欢运动，尤其是一些球类运动，比如羽毛球、乒乓球，我一般周末会叫上好朋友一起，这种竞技活动不仅可以增加朋友间的感情，而且可以释放大量多巴胺，缓解一周的工作压力;</li>
<li>喜欢阅读，在工作学习之余，喜欢读一些人物传记、散文之类的文学书籍，也喜欢看一些能拓宽视野的纪录片。</li>
</ul>
</li>
</ul>
<h1>其他问题</h1>
<ul>
<li>
<p>你有什么缺点?由于我习惯自学，导致有时候很容易陷入误区走不出来。陷入误区的原因一般是这个部分的自身基础不牢靠,或者是公司内部的文档资料不齐全我可能需要花费比较多的时间在自我纠结上。不过我目前也在改善这个问题，以后会好好利用新人多问不会被骂的权利</p>
</li>
<li>
<p>职业规划是什么？希望能够在这个岗位上做到独当一面，负责一些大的、跨组的大事项。当然如果伴随着能力的提升，能够有带人或者带团队的机会我也会去提升其他相关的技能，提升自己的管理能力。</p>
</li>
<li>
<p>对加班怎么看?刚进去公司加班很正常，因为一切都不熟悉，我会为了快速上手业务、迅速融入团队而加班。随着工作熟练度的提升，单位时间内的产出会相对有所增加，在产出符合预期的情况下，预计工作时间应该是有些缩短的。这时候如果遇到紧急的业务需求或者是业务扩张而人手不足的情况，我是能接受加班的直至人手扩充。但如果说加班并不是因为个人产出或者紧急的需求，而是因为一些流程之类的问题，我觉得加班并不是能根本解决问题的方式。</p>
</li>
<li>
<p>怎么处理上级冲突?和上级发生冲突的时候，我首先做的是积极和上级沟通自己的想法，同时列出自己的论据，然后也会去了解上级的想法。最终会保证在以公司利益为前提下达成一致，这个过程中可能会引入其他同事。团队内达成一致才能为一个共同目标去努力。我认为意见冲突是没法避免的，合理的讨论才能聚集团队的智慧，提升团队纠错能力</p>
</li>
</ul>
<h1>离职原因</h1>
<p>在原公司所负责的工作内容比较单一且重复性比较高，无法满足我个人的职业发展需求。我想找一个更有挑战性并且有更大成长空间的工作。而贵公司的情况非常符合我的预期:<br>
首先，我很认可贵公司所推崇的人性化管理，非常符合我对工作环境的预期，我也相信在这样的环境中，我能发挥更大的主观能动性。<br>
并且我非常看好贵公司所处的行业和所做的事，如果我能有幸加入贵公司，相信一定能和贵公司一起发展、共同进步。</p>
<h1>1. What Do You Know About Us?</h1>
<p>Sir Thomas Sunderland founded HSBC in <a href="http://1865.lt" target="_blank" rel="noopener noreferrer">1865.lt</a> standsfor Hongkong Shanghai Business Corporation and iscurrently the seventh-largest bank worldwide in terms ofassets.With over 48 million customers in 66 countries.HSBC qualifies as one of the largest banking and financialservices <a href="http://organizations.lt" target="_blank" rel="noopener noreferrer">organizations.lt</a> is listed on the London StockExchange as the Hong Kong Stock Exchange.<br>
托马斯•桑德兰爵士(Sir Thomas Sunderland)于1865年创立了汇丰银行。它代表香港上海商业公司，目前是全球第七大资产银行。在66个国家拥有超过4800万客户。汇丰银行是世界上最大的银行和金融服务机构之一。它在伦敦证券交易所作为香港证券交易所上市。</p>
<h1>2.Tell Us About Yourself</h1>
<p>I am an accountant with seven years of experience.l haveworked in several departments, with the recent one beingcredit and loans.l have vast experience with differentaccounting software that will benefit me in this job. Being indifferent teams also means that l can fit well in teamsettings and deliver in collaborative work. l believe that allthe skills l have gathered over time have prepared me forthis job.<br>
我是一名有七年经验的会计。我在好几个部门工作过，最近的一次是信贷部门。我对各种会计软件有丰富的经验，这对我做这份工作很有帮助。作为冷漠的团队也意味着我可以很好地适应团队环境，并在协作工作中交付成果。我相信这些年来我所学到的技能已经为这份工作做好了准备。</p>
<h1>Why Do You Want to Work Of Us?</h1>
<p>I want a career in banking and feel that this is the bestplace to grow my career and be better at what l do. l havealso had the chance to talk to some of your former andcurrent employees, and they all agree that this is the bestworkplace for anybody who wants to advance. AdditionallyI would be proud to work in a company that has beenfeatured in the Times repeatedly.l will use all my skills,expertise and experiences to succeed in this job<br>
我想在银行工作，我觉得这是我事业发展的最好的地方，也是我做得更好的地方。我也有机会与贵公司的一些前任和现任员工交谈过，他们都认为对于任何想要晋升的人来说，这是最好的工作场所。此外，我很自豪能在一家多次登上《纽约时报》专题报道的公司工作。我将运用我所有的技能、专业知识和经验来做好这份工作</p>
<h1>Why Should We Hire You?</h1>
<p>I am a customer service executive with over ten years nfexperience.lhave strong communication skills that will help me efficiently manage inbound and outbound callsand resolve customer queries. l am also a quick learnerand can work well under pressure.l can electronicallyprocess data and respond to any customer queriestouching on banking transactions across the world<br>
我是一名有十多年经验的客户服务主管。我有很强的沟通技巧，这将帮助我有效地管理呼入和呼出电话，并解决客户的疑问。我学东西很快，能在压力下很好地工作。我可以用电子方式处理数据，并对任何涉及全球银行交易的客户查询作出回应</p>
<h1>5.Some of Our Positions Have RoutineTasks.What Do You Think about Such?</h1>
<p>I believe that i handle routine work quite well from my previous experience.lusually stay in the moment ancremain focused all through, which allows me to satisfycustomer needs.l also maintain high levels of accuracyand timeliness regardless of how repetitive thie jobs are<br>
根据我以前的经验，我相信我能很好地处理日常工作。我通常专注于当下，始终保持专注，这使我能够满足客户的需求。我也要保持高水平的准确性和及时性，不管工作有多重复</p>
<h2>15.5. 例子16</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>package c_019_m;

import java.util.ArrayList;
import java.util.List;
import java.util.concurrent.TimeUnit;

/**
 * 面试（淘宝？）
 * 实现一个容器，提供两个方法，add，size
 * 写两个线程，线程1添加10个元素到容器中，线程2实现监控元素的个数，当个数到达5时，线程2给出提示并结束
 */
public class MyContainer3 {

    private List&lt;Object&gt; list = new ArrayList&lt;&gt;();

    public void add(Object ele) {
        list.add(ele);
    }

    public int size() {
        return list.size();
    }

    public static void main(String[] args) {

        MyContainer3 container = new MyContainer3();

        final Object lock = new Object();

        new Thread(() -&gt; {
            synchronized (lock) {
                System.out.println("t2 启动");
                if (container.size() != 5) {
                    try {
                        lock.wait();
                    } catch (InterruptedException e) {
                        e.printStackTrace();
                    }
                }
                System.out.println("监测到容器长度为5，线程2立即退出");
                lock.notify();
            }
        }, "t2").start();

        // 先启动t2线程，让t2线程进入等待状态
        try {
            TimeUnit.SECONDS.sleep(2);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        
        new Thread(() -&gt; {
            synchronized (lock) {
                for (int i = 0; i &lt; 10; i++) {
                    container.add(new Object());
                    System.out.println("add " + i);
                    // 当长度为5时，通知 t2 进行退出
                    if (container.size() == 5) {
                        lock.notify(); // notify 不会释放锁，即便通知t2，t2也获取不到锁
                        // 可以在wait一下，将锁释放，再让t2通知t1继续执行
						//notify不能唤醒特定线程，由cpu决定的
						//notify会让线程从上次的wait的地方继续执行
                        try {
                            lock.wait();
                        } catch (InterruptedException e) {
                            e.printStackTrace();
                        }
                    }
                    try {
                        TimeUnit.SECONDS.sleep(1);
                    } catch (InterruptedException e) {
                        e.printStackTrace();
                    }
                }
            }
        }, "t1").start();
    }

}

/*
使用wait和notify
wait()与notify() 方法的调用必须在同步代码块中
wait会释放锁，notify不会释放锁，一般不要用
锁定对象a，调用a.wait() 方法，当前线程就会进入等待状态，然后释放锁。
当某线程调用 a.notify() / a.notifyAll()， 叫醒在a对象等待的所有线程
 */
</code></pre></div><h2>15.6. 例子17</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>package c_019_m;

import java.sql.Time;
import java.util.ArrayList;
import java.util.List;
import java.util.concurrent.CountDownLatch;
import java.util.concurrent.TimeUnit;

/**
 * 面试（淘宝？）
 * 实现一个容器，提供两个方法，add，size
 * 写两个线程，线程1添加10个元素到容器中，线程2实现监控元素的个数，当个数到达5时，线程2给出提示并结束
 */
public class MyContainer5 {

    private volatile List&lt;Object&gt; list = new ArrayList&lt;&gt;();

    public void add(Object ele) {
        list.add(ele);
    }

    public int size() {
        return list.size();
    }

    public static void main(String[] args) {

        MyContainer5 container = new MyContainer5();

        // Count down 往下数  Latch 门闩
        // 门闩不能保证可见性，不是一种同步方式，只是一种线程通信方式，保证不了可见性
        // 门闩的等待，不会持有任何锁
        CountDownLatch latch = new CountDownLatch(1);

        new Thread(() -&gt; {
            System.out.println("t2 启动");
            if (container.size() != 5) {
                try {
                    latch.await();
                    // 指定等待时间
                    //latch.await(5000, TimeUnit.MILLISECONDS);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }
            System.out.println("监测到容器长度为5，线程2立即退出");
        }, "t2").start();

        try {
            TimeUnit.SECONDS.sleep(1);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }

        new Thread(() -&gt; {
            System.out.println("t1 启动");
            for (int i = 0; i &lt; 10; i++) {
                container.add(new Object());
                System.out.println("add " + i);
                // 当长度为5时，撤掉一个门闩，此时门闩为0，门会打开，即t2会继续执行
                if (container.size() == 5) {
                    latch.countDown();
                }
                try {
                    TimeUnit.SECONDS.sleep(1);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }
        }, "t1").start();
    }

}

/*

使用CountDownLatch实现（最简单的方式）

Latch：门闩


使用Latch替代 wait notify来进行通信
好处是，通信简单，同时也可以指定等待时间
使用await和countDown 方法替代 wait 和 notify
CountDownLatch不涉及锁定，当count值为0时，当前线程继续运行
当不涉及同步，只涉及线程通信的时候，用synchronized + wait + notify 就显得太重了
 */
</code></pre></div><h2>15.7. 例子6</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>package c_021_m;

import java.util.LinkedList;

/**
 * 经典面试：写一个固定容量的容器，拥有put和get方法，以及getCount方法
 * 能够支持2个生产者线程以及10个消费者线程的阻塞调用
 * 
 * 点：生产者消费者模式
 * 
 * 如果调用 get方法时，容器为空，get方法就需要阻塞等待
 * 如果调用 put方法时，容器满了，put方法就需要阻塞等待
 * 
 * 实现方式：
 * 1. wait/notify
 * 2. Condition
 */
public class MyContainer1&lt;T&gt; {
    
    private final LinkedList&lt;T&gt; list = new LinkedList&lt;&gt;();
    private final int MAX = 10;
    private int count = 0;

    public synchronized void put(T t) {
        while (MAX == count) { // 如果容量最大，释放锁等待    ///【这里为什么使用while，而不是使用if？？？】
            try {
                this.wait();
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }
        // 否则 put 
        list.add(t);
        ++count;
        this.notifyAll(); // 通知消费者线程，可以消费了
        // 【这里为什么调用 notifyAll 而不是 notify ？】
    }

    public synchronized T get() {
        while (list.size() == 0) { // 如果容量为空，释放锁等待  
            try {
                this.wait();
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }
        // 否则获取
        T t = list.removeFirst();
        count--;
        this.notifyAll(); // 通知生产者线程生产
        return t;
    }
}

/*

为什么使用while 而不是使用 if ？？？
在与wait()的配合中，百分之99的程序都是与while而不是if结合使用。
上述代码中，在容器已满的情况下，put方法会wait等待，当容器中的元素被消费者消费了一部分，就会唤醒所有put方法，
put方法会继续向下执行，直接执行list.add(t)，那么多个生产者线程执行list.add() 就有可能出现数据一致性的问题。
如果使用while则会循环判断，就避免了这些问题。

不是有锁吗？为什么会需要循环判断？
wait之后，锁就会失去，再次被唤醒时，并且得到锁之后，**是从list.add()开始执行的**，会无判断直接加入到容器中。


为什么调用 notifyAll 而不是 notify ？
因为notify有可能再次叫醒一个生产者线程


 */
</code></pre></div><h2>15.8. 例子7</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>package c_021_m;

import java.util.LinkedList;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.locks.Condition;
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReentrantLock;

/**
 * 经典面试：写一个固定容量的容器，拥有put和get方法，以及getCount方法
 * 能够支持2个生产者线程以及10个消费者线程的阻塞调用
 * &lt;p&gt;
 * 点：生产者消费者模式
 * &lt;p&gt;
 * 如果调用 get方法时，容器为空，get方法就需要阻塞等待
 * 如果调用 put方法时，容器满了，put方法就需要阻塞等待
 * &lt;p&gt;
 * 实现方式：
 * 1. wait/notify
 * 2. Condition
 * &lt;p&gt;
 * &lt;p&gt;
 * 使用Lock和Condition实现，可以精确唤醒某些线程
 */
public class MyContainer2&lt;T&gt; {

    private final LinkedList&lt;T&gt; list = new LinkedList&lt;&gt;();
    private final int MAX = 10;
    private int count = 0;

    private Lock lock = new ReentrantLock();
    private Condition producer = lock.newCondition();
    private Condition consumer = lock.newCondition();


    public synchronized void put(T t) {
        lock.lock();
        try {
            while (MAX == count) {
                producer.await();
            }
            list.add(t);
            ++count;
            consumer.signalAll();
        } catch (InterruptedException e) {
            e.printStackTrace();
        } finally {
            lock.unlock();
        }
    }

    public synchronized T get() {
        lock.lock();
        try {
            while (list.size() == 0) {
                consumer.await();
            }
        } catch (InterruptedException e) {
            e.printStackTrace();
        } finally {
            lock.unlock();
        }
        T t = list.removeFirst();
        count--;
        producer.signalAll();
        return t;
    }

    public static void main(String[] args) {
        MyContainer2&lt;String&gt; c = new MyContainer2&lt;&gt;();
        // 启动消费者线程
        for (int i = 0; i &lt; 10; i++) {
            new Thread(() -&gt; {
                for (int j = 0; j &lt; 5; j++) {
                    System.out.println(c.get());
                }
            }, "c_" + i ).start();
        }

        try {
            TimeUnit.SECONDS.sleep(1);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }

        for (int i = 0; i &lt; 2; i++) {
            new Thread(()-&gt;{
                for (int j = 0; j &lt; 2; j++) {
                    c.put(Thread.currentThread().getName() + " " + j);
                }
            }, "p_" + i).start();
        }
    }
}

</code></pre></div><h1>21. vue是如何实现数据双向绑定的</h1>
<h1>22. vue怎么实现对象和数组监听</h1>
<h1>23. mybatis执行流程顺序排序</h1>
<p>(1)读取 MyBatis 配置文件 mybatis-config.xml。mybatis-config.xml作为MyBatis 的全局配置文件，配置了 MyBatis的运行环境等信息，其中主要内容是获取数据库连接。<br>
(2)加载映射文件 Mapper.xml。Mapper.xml 文件即 SQL 映射文件，该文件中配置了操作数据库的 SQL 语句，需要在 mybatis-config.xml 中加载才能执行。mybatis-config.xml可以加载多个配置文件，每个配置文件对应数据库中的一张表。<br>
(3)构建会话工厂。通过 MyBatis 的环境等配置信息构建会话工厂SqlSessionFactory。<br>
(4)创建SqlSession 对象。由会话工厂创建 SqlSession 对象，该对象中包含了执行 SQL 的所有方法。<br>
(5)在 Executor 接口的执行方法中，包含一个 MappedStatement 类型的参数，该参数是对映射信息的封装，用于存储要映射的 SQL语句的id、参数等。<br>
Mapper.xml文件中一个 SQL 对应一个 MappedStatement对象，SQL的id即是 MappedStatement 的 id。<br>
(6)MyBatis底层定义了一个Executor接口来操作数据库,它会根据SqlSession传递的参数动态地生成需要执行的 SQL 语句，同时负责查询缓存的维护。<br>
(7)输入参数映射。在执行方法时，MappedStatement 对象会对用户执行 SQL语句的输入参数进行定义(可以定义为 Map、List类型、基本类型和 POJO类型)，Executor 执行器会通过 MappedStatement 对象在执行 SQL 前，将输入的Java 对象映射到 SQL 语句中。这里对输入参数的映射过程就类似于 JDBC编程中对 preparedStatement 对象设置参数的过程。<br>
(8)输出结果映射。在数据库中执行完 SQL 语句后，MappedStatement 对象会对 SQL 执行输出的结果进行定义(可以定义为 Map 和 List类型、基本类型、POJO类型)，Executor 执行器会通过 MappedStatement 对象在执行 SQL 语句后，将输出结果映射至 Java 对象中。这种将输出结果映射到 Java 对象的过程就类似于 JDBC编程中对结果的解析处理过程。</p>
<p>2、关于 mybatis，请找出错误的描述。<br>
1、Configuration:用于描述 JDBC 主配置文件信息，MyBatis 框架在启动完成以后会加载主配置文件，将配置信息转换为 Configuration 对象。<br>
2、SqlSession:面向用户的 API，是 JDBC 与数据库交互的接口。<br>
3、Executor:SQL 执行器,用于和数据库交互.SqlSession 可以理解为 Executor组件的外观，真正执行 SQL 的是 SqlSession 组件。<br>
4、MappedStatement:用于描述SQL配置信息，MyBatis 框架启动时，XML文件或者注解配置的SQL信息会被转换为MappedStatement对象注册到Configuration 组件中。<br>
5、StatementHandler:封装了对JDBC中Statement 对象的操作，包括为Statement 参数占位符设置值，通过 Statement 对象执行 SQL语句<br>
6、TypeHandler:类型处理器，用于Java类型与基础类型之间的转换。<br>
7、ParameterHandler:用于处理 SQL中的参数占位符，为参数占位符设置值。<br>
8、ResultSetHandler:封装了对Set对象的处理逻辑，将结果集转换为Java实体对象</p>
<p>3、关于 mybatis 流程，请排好下列顺序?<br>
1、加载 mybatis 全局配置文件(数据源、mapper映射文件等)<br>
2、解析配置文件<br>
3、SqlSessionFactoryBuilder 通 过Configuration对象生成SqlSessionFactory<br>
4、MyBatis 基于 XML 配置文件生成 Configuration<br>
5、和一个个 MappedStatement(包括了参数映射配置、动态 SQL 语句、<br>
结果映射配置)，其对应着<code>&lt;select|update|delete|insert&gt;</code>标签项。</p>
<p>4、Mybatis 中的 SQLSession 流程请排好下列顺序<br>
a、用户程序调用 mybatis 接口层 api(即 Mapper 接口中的方法)<br>
b、通过 Executor(负责动态 SQL的生成和查询缓存的维护)将MappedStatement 对象进行解析<br>
c、使用 Paramterhandler 填充参数，使用 statementHandler绑定参数<br>
d、sql 参数转化、动态 sql 拼接，生成 jdbc Statement 对象<br>
e、SqlSession 通过调用 api的StatementID 找到对应的 MappedStatement 对象<br>
f、JDBC 执行 sql也行数<br>
g、使用 ResultSetHandler 将返回结果转化成 HashMap、JavaBean等存储结构并返回<br>
h、借助 MappedStatement中的结果映射关系<br>
i、关闭 sqlsession 会话</p>
<p>5、判断关于 springcloud config 配置中心下列说法对错<br>
1、配置服务器:为配置客户端提供其对应的配置信息，配置信息的来源为配置仓库，启动时即拉取配置仓库的信息，缓存到本地仓库中。<br>
2、配置客户端:除了配置服务器之外的应用服务，启动时从配置服务器拉取其对应的配置信息。<br>
3、配置仓库:为配置服务器提供配置源信息，配置仓库的实现可以支持多种方式。</p>
<p>6、关于 Spring Cloud Config 构建判断下列操作是否正确，如果是错误的，请说明理由<br>
构建 Spring cloud config 配置中心<br>
1、创建一个普通的 Spring Boot 项目<br>
2、在 pom.xml 文件中添加 config-server 依赖<br>
3、在入口类，也就是 main 方法的类上添加注解 @EnableConfigServer<br>
4、在 application.properties 中配置一下 git 仓库信息，此处我们使用<br>
GitHub( 也可以使用码云 gitee)。<br>
接口 URL:/{application}/{profile}/{label}<br>
构建 Springcloud config 配置中心仓库<br>
接下来我们需要在 github 上设置好配置中心，首先在本地创建一个文件夹叫wkcto，然后在里面创建一个文件夹叫 config-center，然后在 config-center 中创建四个配置文件。<br>
经过对 wkcto 目录下的文件进行操作后，最终使用 git push 推送到远程仓库，然后启动我们的配置中心，通过/{application}/{profile}/{label}就能访问到我们的配置文件了。</p>
<p>构建 Spring cloud config 配置中心客户端<br>
1、创建一个普通的 Spring Boot 工程 08-springcloud-config-client，并添加<br>
starter-conifd 依赖.<br>
2、创建 bootstrap.properties 文件，用于获取配置信息。<br>
name 对应配置文件中的 application 部分，profile 对应了 profile 部分，label<br>
对应了 label 部分，uri 表示配置中心的地址。<br>
然后使用@RefreshScope 进行对配置文件的刷新，接下来就是用 Spring 自带<br>
注解可以获取配置内容。例如@value</p>
<p>7、关于配置中心执行流程，判断下图的是否正确，如果不正确，请说明理由。<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/f4fe8a438b4fca2f17b6b.png" alt="配置中心执行流程.jpg"></p>
<p>8、为下列 Eureka 工作流程排序<br>
1、Eureka Server 启动成功，等待服务端注册。在启动过程中如果配置了集群，集群之间定时通过 Replicate 同步注册表,每个 Eureka Server 都存在独立完整的服务注册表信息<br>
2、Eureka Client 启动时根据配置的 Eureka Server 地址去注册中心注册服务<br>
3、Eureka Client 会每 30s 向 Eureka Server 发送一次心跳请求，证明客户端服务正常<br>
4、当 Eureka Server 90s 内没有收到 Eureka Client 的心跳，注册中心则认为该节点失效，会注销该实例<br>
5、单位时间内 Eureka Server 统计到有大量的 Eureka Client 没有上送心跳，则认为可能为网络异常，进入自我保护机制，不再剔除没有上送心跳的客户端流移<br>
6、当 Eureka Client 心跳请求恢复正常之后，Eureka Server 自动退出自我保护模式<br>
7、Eureka Client 定时全量或者增量从注册中心获取服务注册表，并且将获取到的信息缓存到本地<br>
8、服务调用时，Eureka Client 会先从本地缓存找寻调取的服务。如果获取不到，先从注册中心刷新注册表，再同步到本地缓存<br>
9、Eureka Client 获取到目标服务器信息，发起服务调用<br>
10、Eureka Client 程序关闭时向 Eureka Server 发送取消请求，Eureka Server 将实例从注册表中删除</p>
<p>9、springGateway 的执行流程排序<br>
1、接受请求<br>
2、寻找路由规则<br>
3、WEB 过滤器链<br>
4、请求转发<br>
5、核心过滤器链执行<br>
6、响应回写</p>
<p>10、补充或者删除 Redis 的基本数据结构类型<br>
1、String<br>
2、Hash<br>
3、ArrayList<br>
4、HashSet<br>
5、zset</p>
<p>11、关于 redis 使用，判断下列措施是否正确<br>
MySQL 里有 2000w 数据，redis 中只存 20w 的数据，如何保证 redis中的数据都是热点数据<br>
位<br>
措施:redis 内存数据集大小上升到一定大小的时候，就施行数据淘汰策略。</p>
<p>12、Redis 适合的场景正确的有哪些，错误的有哪些<br>
(1)会话缓存V<br>
(2)队列 V<br>
(3)排行榜/计数器V<br>
(4)发布/订阅</p>
<p>13、MongoDB 是否支持数据类型，如果不对请标记出来<br>
1、String<br>
2、Integer<br>
3、Double<br>
4、Boolean<br>
5、Object<br>
6、Object ID<br>
7、Arrays<br>
8、Min/Max Keys<br>
9、Datetime<br>
10、Code<br>
11、Regular Expression 等</p>
<p>14、请为下列 rabbitmq 生产者发送消息的流程排序 )，<br>
1、生产者连接 RabbitMQ，建立TCP 连接(Connection)，开启信道(Channel)<br>
2、生产者声明一个 Exchange(交换器)，并设置相关属性，比如交换器类型、是否持久化等<br>
3、生产者声明一个队列井设置相关属性，比如是否排他、是否持久化、是否自动删除等<br>
4、生产者通过 bindingKey(绑定 Key)将交换器和队列绑定(binding)起来<br>
5、生产者发送消息至 RabbitMQBroker，其中包含routingKey(路由键)、交换器等信息<br>
6、相应的交换器根据接收到的 routingKey 查找相匹配的队列。<br>
7、如果找到，则将从生产者发送过来的消息存入相应的队列中。<br>
8、如果没有找到，则根据生产者配置的属性选择丢弃还是回退给生产者<br>
9、关闭信道。<br>
10、关闭连接。</p>
<p>15、请为下列 rabbitmq 消费者接收消息的流程排序<br>
1、消费者连接到 RabbitMQ Broker ，建立一个连接(Connection)，开启一个信道(Channel)。<br>
2、消费者向 RabbitMQ Broker 请求消费相应队列中的消息,可能会设置相应的回调函数，以<br>
及做一些准备工作<br>
3、等待 RabbitMQ Broker 回应并投递相应队列中的消息， 消费者接收消息。<br>
4、消费者确认(ack) 接收到的消息。<br>
5、RabbitMQ 从队列中删除相应己经被确认的消息。<br>
6、关闭信道。<br>
7、关闭连接。</p>
<h1>17. 逻辑题</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>P先生、Q先生具有足够的推理能力。他们知道桌子的抽屉里有16张扑克牌：
红桃 A Q 4
黑桃 J 8 4 2 7 3
草花 K Q 5 4 6
方块 A 5
约瀚教授从这16张牌中挑出一张牌来，并把这张牌的点数告诉P先生，把这张牌的花色告诉Q先生。约翰教授问P先生和Q先生：你们能从已知的点数或花色中推知这张牌是什么牌吗？
P先生："我不知道这张牌。"
Q先生："我知道你不知道这张牌。"
P先生："现在我知道这张牌了。"
Q先生："我也知道了。"

请问这张牌是什么牌？
答案：方块5

第一句话表明点数有重复
第二句话表明对应花色中全部都是有重复的点数，所以是红桃或者方块
第三句话，首先排除了A，剩下Q, 4，5
第四句话既然知道花色就能确定只能是方块5了
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>有甲、乙、丙三个学生，一个出生在北京，一个出生在上海，一个出生在武汉；他们中一个学国际金融专业，一个学工商管理专业，一个学外语。其中：I.甲不是学国际金融的，乙不是学外语的。II．学国际金融的不出生在上海。III．学外语的出生在北京。IV．乙不出生在武汉。请根据上述条件，判断甲的专业；（） A．国际金融B．工商管理C．外语D．三种专业都可能

答案： C
</code></pre></div><h2>16.4. 计算n的阶乘的末尾有几个0√</h2>
<p>在线计算阶乘的地址<a href="http://www.99cankao.com/statistics/factorial-calculator.php" target="_blank" rel="noopener noreferrer">http://www.99cankao.com/statistics/factorial-calculator.php</a><br>
尾部的0一共有多少个，就要看这个数包含多少个5的因子</p>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public static int SelectZero(int n){
    int count=0;
    while(n!=0){
        count+=n/5;
        n=n/5;
    }
    return count;
}
</code></pre></div><h2>16.3. 1亿个int类型数字，如何找出重复数字？√</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class Test{
    public static void main(String[] args){
        long time=new Date().getTime();
        int[] arr=new int[100000000];//1亿长度
        for(int i=0;i&lt;arr.length;i++){
            arr[i]=i+1;
        }
        arr[99999999]=2020;
        int min=arr[0];
        int max=arr[0];
        for(int i=0;i&lt;arr.length;i++){
            if(arr[i]&lt;min)
                min=arr[i];
            if(arr[i]&gt;max)
                max=arr[i];
        }
        byte[] bucket=new byte[(max-min)/8+1];
        for(int i=0;i&lt;arr.length;i++){
            int num=arr[i];
            int j=(num-min)/8;
            int k=(num-min)%8;
            if(((bucket[j]&gt;&gt;k)&amp;1)&gt;0){//重复了
                System.out.println("Number of repeats："+num);
                break;
            }else{
               bucket[j]|=(1&lt;&lt;k);
            }
        }
        long time2=new Date().getTime();
        System.out.println("millisecond:"+(time2-time));
    }
}
</code></pre></div><h2>13.7. 求以下表达式1-2+3-4+...+m的值，写出您想到的一种或几种实现方法</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public int fun(int m){
	int sum=0;
	for(int i=1;i&lt;m+1;i++){
		if(i%2==0){
			sum=sum-i;
		}else{
			sum=sum+i;
		}
	}
	return sum;
}
</code></pre></div><h1>查看反编译代码</h1>
<ul>
<li>C:\Java\jdk-11.0.8\bin\server放入hsdis-amd64.dll</li>
<li>idea运行添加vm参数</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>-server
-Xcomp
-XX:+UnlockDiagnosticVMOptions
-XX:+PrintAssembly
-XX:CompileCommand=compileonly,*MyTest.fun
</code></pre></div><p>cd /opt/banzhutest &amp;&amp; sh <a href="http://stop.sh" target="_blank" rel="noopener noreferrer">stop.sh</a> &amp;&amp; cd admin &amp;&amp; sh <a href="http://stop.sh" target="_blank" rel="noopener noreferrer">stop.sh</a> &amp;&amp; cd &amp;&amp; cd code/banzhunewserver &amp;&amp; git pull &amp;&amp; mvn clean package -Ptest &amp;&amp; cp banzhu-api/target/testbanzhu.jar /opt/banzhutest/testbanzhu.jar &amp;&amp; cp banzhu-admin/target/admintestbanzhu.jar /opt/banzhutest/admin/admintestbanzhu.jar &amp;&amp; cd /opt/banzhutest &amp;&amp; sh <a href="http://start.sh" target="_blank" rel="noopener noreferrer">start.sh</a> &amp;&amp; cd admin &amp;&amp; sh <a href="http://start.sh" target="_blank" rel="noopener noreferrer">start.sh</a> &amp;</p>
]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/f4fe8a438b4fca2f17b6b.png" type="image/png"/>
    </item>
    <item>
      <title>java基础</title>
      <link>https://javaguide.cn/interview/javabasics.html</link>
      <guid>https://javaguide.cn/interview/javabasics.html</guid>
      <source url="https://javaguide.cn/rss.xml">java基础</source>
      <description>java基础 1. 什么是 Java？特点？ Java 是一门面向对象的编程语言 面向对象（封装，继承，多态），跨平台(一次编写，到处运行) 2. JVM、JDK、JRE区别 JVM：Java Virtual Machine，Java 虚拟机，Java 程序运行在 Java 虚拟机上。针对不同系统的实现（Windows，Linux，macOS）不同的 ...</description>
      <category>面试</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>java基础</p>
<!--more-->
<h1>1. 什么是 Java？特点？</h1>
<ul>
<li>Java 是一门面向对象的编程语言</li>
<li>面向对象（封装，继承，多态），跨平台(一次编写，到处运行)</li>
</ul>
<h1>2. JVM、JDK、JRE区别</h1>
<ul>
<li>JVM：Java Virtual Machine，Java 虚拟机，Java 程序运行在 Java 虚拟机上。针对不同系统的实现（Windows，Linux，macOS）不同的 JVM，因此 Java 语言可以实现跨平台。</li>
<li>JRE： Java 运⾏时环境。包括 Java 虚拟机（JVM）和Java 类库</li>
<li>JDK: Java Development Kit，它是功能⻬全的 Java SDK（软件开发工具包）。包括了 JRE 以及编译器（javac）、Java 文档生成工具（Javadoc）、Java 调试器等开发工具。为开发者提供了开发、编译、调试 Java 程序的一整套环境。</li>
<li>JDK 包含 JRE，JRE 包含 JVM。</li>
</ul>
<h1>3. java跨平台实现原理</h1>
<ul>
<li>跨平台性，是指Java语言编写的程序，一次编译后，可以在多个系统平台上运行。</li>
<li>实现原理：Java程序是通过Java虚拟机在系统平台上运行的，只要该系统可以安装相应的 Java 虚拟机就可以运行 java 程序</li>
</ul>
<h1>4. java数据类型有哪些?</h1>
<table>
<thead>
<tr>
<th style="text-align:center">基本数据类型</th>
<th style="text-align:center">八种</th>
<th style="text-align:center">字节数</th>
<th style="text-align:center">数据表示范围</th>
<th style="text-align:center">默认值</th>
<th style="text-align:center">包装类</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">整型</td>
<td style="text-align:center">byte</td>
<td style="text-align:center">1</td>
<td style="text-align:center">-2^7^-1,2^7^-1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">Byte</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">short</td>
<td style="text-align:center">2</td>
<td style="text-align:center">-2^15^,2^15^-1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">Short</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">int</td>
<td style="text-align:center">4</td>
<td style="text-align:center">-2^31,2^31-1 <strong>默认是int</strong></td>
<td style="text-align:center">0</td>
<td style="text-align:center">Integer</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">long</td>
<td style="text-align:center">8</td>
<td style="text-align:center">-2^63^,2^63^-1 +L</td>
<td style="text-align:center">0</td>
<td style="text-align:center">Long</td>
</tr>
<tr>
<td style="text-align:center">浮点型</td>
<td style="text-align:center">float</td>
<td style="text-align:center">4</td>
<td style="text-align:center">-3.403E38～3.403E38 E科学计数10^38 128-127次方+F 1位符号位，8位指数位(偏移量127，实际值应该减去127)，23位尾数位，7位有效数字</td>
<td style="text-align:center">0.0f</td>
<td style="text-align:center">Float</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">double</td>
<td style="text-align:center">8</td>
<td style="text-align:center">-1.798E308～1.798E308 E科学计数10^308 1024-1023次方+D 1位符号位，11位指数位，52位尾数位，16位有效数字，<strong>默认是双精度</strong></td>
<td style="text-align:center">0.0d</td>
<td style="text-align:center">Double</td>
</tr>
<tr>
<td style="text-align:center">布尔型</td>
<td style="text-align:center">boolean</td>
<td style="text-align:center">1</td>
<td style="text-align:center">true、false</td>
<td style="text-align:center">false</td>
<td style="text-align:center">Boolean</td>
</tr>
<tr>
<td style="text-align:center">字符型</td>
<td style="text-align:center">char</td>
<td style="text-align:center">2</td>
<td style="text-align:center">''包裹，只包含一字符，运算按ASCII码对应的整数运算</td>
<td style="text-align:center">''</td>
<td style="text-align:center">Character</td>
</tr>
<tr>
<td style="text-align:center">引用数据类型</td>
<td style="text-align:center">数组、类、接口</td>
<td style="text-align:center"></td>
<td style="text-align:center">String是对象</td>
<td style="text-align:center">null</td>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
<h1>5. char能不能存一个中文汉字?</h1>
<ul>
<li>Java中无论汉字还是英文字母都用Unicode编码（2字节）表示。char类型占2个字节。所以可以存储一个中文汉字</li>
</ul>
<h1>6. 存在数字i加1小于i或者i减1小于i?√</h1>
<ul>
<li>整型类型是有范围的，如果发生越界，那么将出现该情况</li>
</ul>
<h1>7. 什么是自动类型转换与强制类型转换?</h1>
<ul>
<li>Java所有的数值型变量可以相互转换，当把一个表数范围小的数值或变量直接赋给另一个表数范围大的变量时，可以进行自动类型转换；反之，需要强制转换。</li>
<li>数据类型数据范围从小到大：byte -&gt; short -&gt; int -&gt; long -&gt; float -&gt; double</li>
<li>float f=3.4（×）3.4 是双精度数。需要强制类型转换float f =(float)3.4;或者写成float f =3.4F</li>
<li>short s1 = 1; s1 = s1 + 1; 编译出错，由于1是int类型，因此s1+1运算结果也是int型，需要强制转换类型才能赋值给short</li>
<li>short s1 = 1; s1 += 1;编译正确，因为s1+= 1相当于s1 = short(s1 + 1);有隐含强制类型转换。</li>
</ul>
<h1>8. 自动装拆箱和设计理由？</h1>
<ul>
<li>自动装箱是Java编译器在基本数据类型和对应的包装类之间做转化。比如：把int转化成Integer。反之就是自动拆箱。</li>
<li>为了简化代码，因为jdk1.5需要手写代码才能完成基本数据类型转成包装类放入集合中</li>
</ul>
<h1>9. &amp;&amp;运算符和&amp;运算符区别？</h1>
<ul>
<li>都是表示与的逻辑运算符and，当两边的表达式都为true，结果才为true</li>
<li>&amp;&amp;：有短路功能，当第一个表达式的值为false的时候，则不再计算第二个表达式；</li>
<li>&amp;：2个表达式都会执行。当两边的表达式不是Boolean类型则表示按位操作</li>
</ul>
<h1>10. switch表达式的值？</h1>
<ul>
<li>byte、short、int、char、enum枚举、String</li>
</ul>
<h1>11. break,continue,return区别及作用？</h1>
<ul>
<li>break跳出整个循环，不再执行循环</li>
<li>continue跳出本次循环，继续执行下次循环</li>
<li>return结束当前的方法 直接返回</li>
</ul>
<h1>12. 用最有效率的方法计算2乘以8？</h1>
<ul>
<li>2&lt;&lt;3。位运算，二进制位左移三位相当于乘以2的三次方。</li>
</ul>
<h1>13. 自增自减运算相关问题</h1>
<ul>
<li>当运算符放在变量之前时(前缀)，先自增/减，再赋值；当运算符放在变量之后时(后缀)，先赋值，再自增/减。</li>
<li>i=i++结果i不变，因为JVM对自增运算会定义一个临时变量来接收i值，然后进行自增，等价于int temp = i;i++;i = temp;</li>
</ul>
<h1>14. Java 中的 Math.round(-1.5) 等于多少？</h1>
<ul>
<li>round表示'四舍五入'，算法为Math.floor(x+0.5)即加0.5后再向下取整，所以Math.round(1.5)=2，Math.round(-1.5)=-1</li>
</ul>
<h1>15. 面向对象OOP和面向过程OPP区别？</h1>
<ul>
<li>面向对象，它将现实世界中的事物抽象成对象，并通过类和对象的概念来模拟真实世界中的各种关系和操作。</li>
<li>面向过程，分析出解决问题所需要的步骤，然后用函数把这些步骤一步一步实现，使用的时候再一个一个的一次调用就可以</li>
<li>区别
<ul>
<li>关注点不同:面向对象关注现实世界中的对象及其关系，而面向过程关注解决问题的步骤和过程。</li>
<li>数据和函数的关系不同:在面向对象中，数据和操作数据的方法被封装在对象中，而在面向过程中，数据和函数是分离的</li>
<li>代码组织方式不同:面向对象通过类和对象来组织代码，具有更好的模块化和可重用性;而面向过程通常按照功能或步骤来组织代码，可能导致代码结构混乱</li>
<li>扩展性和可维护性不同:面向对象通过封装、继承和多态等特性提高了代码的扩展性和可维护性;而面向过程在这方面表现相对较差</li>
</ul>
</li>
</ul>
<h1>16. 面向对象有哪些特性？</h1>
<ul>
<li>封装：把对象的属性私有化，同时提供可以被外界访问的属性的方法.代码复用、安全性高</li>
<li>继承: 以已存在的类的定义作为基础建立新类。新类的定义可以增加新的属性或新的方法，也可以继承父类的属性和方法。通过继承可以很方便地进行代码复用，扩展性强，但耦合度增强
<ul>
<li>一个类只能继承一个类，所有的类都直接或者间接的继承了Object类</li>
<li>子类自动拥有父类所有有属性和方法,但只能访问父类非私有属性和方法</li>
<li>默认访问子类的[同名]成员变量/方法，不存在则访问父类非私有[同名]成员变量/方法。即使在父类构造方法中调用也能自动调子类方法</li>
</ul>
</li>
<li>多态：指程序中定义的引⽤变量所指向的具体类型和通过该引⽤变量调用的⽅法在编程时并不确定，⽽是在程序运⾏期间才确定，即⼀个引⽤变量到底会指向哪个类的实例对象，该引⽤变量发出的⽅法调⽤到底是哪个类中实现的⽅法，必须在由程序运⾏期间才能决定。实现方式：子类继承父类、子类重写父类的方法、父类引用指向子类的对象或者类实现接口、类实现接口的方法，类引用指向接口</li>
</ul>
<h1>17. 重载和重写区别？√</h1>
<ul>
<li>方法重载overload:<strong>同一个类</strong>中多个名称相同、参数类型或个数或顺序不同的方法</li>
<li>方法重写override:<strong>父子类</strong>中方法名、参数列表、返回值相同、但方法体不同的方法
<ul>
<li>返回值、异常小于等于，少于等于父类</li>
<li>访问修饰符大于等于父类</li>
<li>static方法，final方法，private方法，构造器Constructor不能被继承，因此不能重写Override</li>
</ul>
</li>
</ul>
<h1>18. private，default，protected，public访问控制符范围</h1>
<ul>
<li>private本类，default同包、protected同包及其子类，public所有</li>
</ul>
<h1>19. this关键字有什么作用？</h1>
<ul>
<li>this代表对象本身</li>
<li>作用：
<ul>
<li>对象本身的引用</li>
<li>区分重名的形参和成员变量</li>
<li>引用本类构造函数</li>
</ul>
</li>
</ul>
<h1>20. 抽象类和接口有什么区别？如何选用？√</h1>
<ul>
<li>相同点
<ul>
<li>都可以包含抽象方法</li>
<li>都不能直接实例化对象;直到抽象方法都覆盖完了才可以创建对象</li>
</ul>
</li>
<li>不同点
<ul>
<li>一个类只能继承一个直接父类(可能是抽象类),却可以实现多个接口;(接口弥补了单继承)</li>
<li>抽象类可以定义构造函数;接口不能</li>
<li>抽象类可以包含具体方法;接口在jdk8才有默认方法</li>
<li>抽象类可以包含私有方法，接口在jdk9才有</li>
</ul>
</li>
<li>二者的选用
<ul>
<li>优先选用接口,尽量少用抽象类</li>
<li>需要定义子类的行为,又要为子类提供共性功能时才选用抽象类</li>
</ul>
</li>
</ul>
<h1>21. 成员变量与局部变量的区别有哪些？</h1>
<ul>
<li>从语法形式上看：成员变量是属于类的，⽽局部变量是在⽅法中定义的变量或是⽅法的参数；成员变量可以被 public , private , static 等修饰符所修饰，⽽局部变量不能被访问控制修饰符及 static 所修饰；但是，成员变量和局部变量都能被 final 所修饰。</li>
<li>从变量在内存中的存储⽅式来看：如果成员变量是使⽤ static 修饰的，那么这个成员变量是属于类的，如果没有使⽤ static 修饰，这个成员变量是属于实例的。对象存于堆内存，如果局部变量类型为基本数据类型，那么存储在栈内存，如果为引⽤数据类型，那存放的是指向堆内存对象的引⽤或者是指向常量池中的地址。</li>
<li>从变量在内存中的⽣存时间上看：成员变量是对象的⼀部分，它随着对象的创建⽽存在，⽽局部变量随着⽅法的调⽤⽽⾃动消失。</li>
<li>成员变量如果没有被赋初值：则会⾃动以类型的默认值⽽赋值（⼀种情况例外:被 final 修饰的成员变量也必须显式地赋值），⽽局部变量则不会⾃动赋值。</li>
</ul>
<h1>22. 静态变量和实例变量的区别？静态方法和实例方法的区别？</h1>
<ul>
<li>静态变量: 被static修饰符修饰的变量，属于类，一个类不管创建多少个对象，静态变量在内存中有且仅有一个副本。</li>
<li>实例变量: 属于某一对象，需要先创建对象然后通过对象才能访问到它。</li>
<li>类/静态方法不能访问非静态方法和变量，实例方法可以访问类的所有成员变量和方法</li>
</ul>
<h1>23. final、finally、finalize区别？</h1>
<ul>
<li>final是修饰符，修饰类不能被继承，修饰方法不能被重写，修饰变量不能被修改且必须在声明时初始化值。不可变指的是变量的引用不可变，不是引用指向的内容的不可变。</li>
<li>finally只能在try/catch语句中，无论try块中的代码是否抛出异常，finally块中的代码一定会执行。常用于释放资源(I/O)。不会被执行的情况：在finally语句块中发生了异常；在代码中用了System.exit()退出程序；</li>
<li>finalize:在Object类中的方法，在垃圾收集器删除对象之前对这个对象调用一次。finalize被调用不一定会立即回收该对象，所以有可能调用finalize后，该对象又不需要被回收了，然后到了真正要被回收的时候，因为前面调用过一次，所以不会再次调用finalize了，进而产生问题，因此不推荐使用。</li>
</ul>
<h1>24. ==和equals区别？</h1>
<ul>
<li>==：如果比较的对象是基本数据类型，则比较的是数值是否相等；如果比较的对象是引用数据类型，则比较的是对象的地址值是否相等</li>
<li>equals方法：没有重写相当于==，重写后比较两个对象的内容是否相等。String、Integer重写了</li>
</ul>
<h1>25. hashcode方法作用？两个对象的hashCode方法相同，则equals方法也一定为true吗？</h1>
<ul>
<li>hashCode 方法主要用来获取对象的哈希码，哈希码是由对象的内存地址或者对象的属性计算出来的，它是⼀个int类型的整数，通常是不会重复的，因此可以用来作为键值对的键，以提高查询效率。</li>
<li>不一定。因为存在哈希碰撞，在散列表中，hashCode()相等即两个键值对的哈希值相等，然而哈希值相等，并不一定能得出键值对相等</li>
<li>为了解决哈希冲突的问题，哈希表在处理键时，不仅会比较键对象的哈希码，还会使用 equals 方法来检查键对象是否真正相等。如果两个对象的哈希码相同，但通过 equals 方法比较结果为 false，那么这两个对象就不被视为相等。</li>
</ul>
<h1>26. 为什么重写equals方法就一定要重写hashCode方法？</h1>
<ul>
<li>保证在equals相同的情况下hashcode值必定相同：如果只重写equals方法，那么被认为相等的对象可能会有不同的哈希码（默认是对象的地址，因此所有对象都是不同的哈希码），存储在集合不同的位置，导致集合出现重复元素或者无法找到对应元素（因为equals是根据对象的特征进行重写）</li>
<li>提升性能：hashCode能提高hashmap等集合去重的性能，如果没有重写hashCode()方法,那么集合每次添加元素都要遍历已有元素调用equals方法，性能太差，重写hashcode能减少equals方法调用次数</li>
</ul>
<h1>27. Java中的参数传递时传值呢还是传引用？</h1>
<ul>
<li>java基本类型作为参数被传递时是值传递；引用类型作为参数被传递时也是值传递，参数值是对象的引用。</li>
</ul>
<h1>28. 深拷贝和浅拷贝？</h1>
<ul>
<li>浅拷贝仅拷贝被拷贝对象的基本数据类型变量的值和引用数据类型变量的地址值，而对于引用类型变量指向的堆中的对象不会拷贝</li>
<li>深拷贝完全拷贝一个对象，拷贝被拷贝对象的成员变量的值，堆中的对象也会拷贝一份。</li>
<li>浅拷贝实现Cloneable接口并重写Object类中的clone()方法;</li>
<li>深拷贝实现Serializable接口，通过对象的序列化和反序列化，或者使所有引用类型属性实现Cloneable接口</li>
</ul>
<h1>29. Java中创建对象的几种方式？</h1>
<ul>
<li>使用new关键字</li>
<li>使用Class类的newInstance方法，Class.forName.newInstance()</li>
<li>使用clone方法</li>
<li>反序列化，比如调用ObjectInputStream类的readObject()方法</li>
</ul>
<h1>30. Java对象初始化过程√</h1>
<ul>
<li>父类静态属性</li>
<li>父类静态代码块</li>
<li>子类静态属性</li>
<li>子类静态代码块</li>
<li>父类非静态属性</li>
<li>父类构造代码块</li>
<li>父类构造方法</li>
<li>子类非静态属性</li>
<li>子类构造代码块</li>
<li>子类构造方法</li>
</ul>
<h1>31. 怎么精确表示任意精度的整数和任何精度的定点数或者货币？√</h1>
<ul>
<li>BigInteger任意精度的整数</li>
<li>BigDecimal任何精度的定点数-&gt;货币</li>
<li>转成分用int运算</li>
</ul>
<h1>32. String是Java基本数据类型吗？可以被继承吗？</h1>
<ul>
<li>引用类型，String被final修饰不能被继承</li>
</ul>
<h1>33. String是不可变类吗？字符串拼接是如何实现的？</h1>
<ul>
<li>String是不可变的，1.8以前+的拼接操作，如果字符串在常量池中不存在，则会生成新的对象。1.8时被优化为基于StringBuilder的append方法进行处理</li>
</ul>
<h1>34. 不同String创建方法分别创建了几个对象？√</h1>
<ul>
<li>1.String str1 = "abc";2.String str2 = new String("abc")</li>
<li>1在内存的字符串常量池中存储abc字符串对象</li>
<li>2在内存的字符串常量池中找abc字符串对象，没有则创建；在堆中创建str2对象，引用指向abc字符串对象</li>
</ul>
<h1>35. String为什么是不可变的？设计原因？√</h1>
<ul>
<li>不可变：一旦String对象被创建，它所包含的字符串内容是不可改变的。</li>
<li>不可变是因为引用的char数组(jdk1.9后改为byte数组)被final修饰。字符串的值本身不能改变，但引用字符串的变量中记录的地址值是可以改变的。每次修改操作（如拼接、替换等）都会产生新对象。</li>
<li>避免内存浪费：当创建一个String对象时，如果字符串值在常量池中已经存在则不会创建，只是引用已经存在的对象</li>
<li>性能优化：字符串不变性保证了hash码的唯一性，允许String对象缓存频繁使用的HashCode（如HashMap），不必每次都去计算新的哈希码</li>
<li>安全性：String被许多的Java类用来当做参数，例如：网络连接地址URL、文件路径path、反射机制的String参数等, 如果String不是固定不变的，将会引起各种安全隐患。</li>
</ul>
<h1>36. String、StringBuilder、StringBuffer 的区别？√</h1>
<ul>
<li>String：类的对象是不可变的；适用于字符串内容不经常改变的场景。在使用字符串常量或进行少量的字符串操作时使用。每次对String对象进行修改操作（如拼接、替换等）实际上都会生成一个新的String对象，而不是修改原有对象。大量字符串连接情况下，产生太多对象浪费内存。线程安全</li>
<li>StringBuilder：适用于单线程环境下需要频繁修改字符串内容的场景，比如在循环中拼接或修改字符串，使用字符数组char[]保存字符串,可变类，每次对String对象进行修改操作（如拼接、替换等）都是直接在原有字符串对象的底层数组上进行，不产生新对象，线程不安全；效率高</li>
<li>StringBuffer：适用于多线程环境下需要频繁修改字符串内容的场景，使用字符数组char[]保存字符串,可变类，方法加同步锁synchronized，线程安全；效率低</li>
<li>多线程强制使用StringBuilder()</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class StringBuilderHolder {
    private final StringBuilder sb;
    
    public StringBuilderHolder(int capacity) {
        sb = new StringBuidler(capacity);
    }
    //3.避免重复构造String，重用StringBuilder
    public StringBuilder resetAndGetStringBuilder() {
        sb.setLength(0);
        return sb;
    }
}
//2.ThreadLocal避免多线程冲突
private static final ThreadLocal&lt;StringBuilderHolder&gt; threadLocalStringBuilderHolder = new ThreadLocal&lt;StringBuilderHolder&gt;() {
    protected StringBuilderHolder initialValue() {
        //1.设置好初始长度，超过char[]默认16调用System.arraycopy成倍复制扩容太浪费资源
        return new StringBuilderHolder(256);
    }
}

StringBuilder sb = threadLocalStringBuilderHolder.get().resetAndGetStringBuilder();
</code></pre></div><h1>37. intern 方法有什么作用？</h1>
<ul>
<li>如果当前字符串内容存在于字符串常量池，直接返回字符串常量池中的字符串；否则，将此String对象添加到池中，并返回String对象的引用</li>
</ul>
<h1>38. int和Integer有什么区别？√</h1>
<ul>
<li>integer是int的包装类，属于引用数据类型，而int是Java的基本数据类型</li>
<li>Integer默认值是null，int的默认值是0</li>
<li>Integer是对象的引用，当new一个Integer时，实际上是生成一个指针指向此对象；而int则是直接存储数据值</li>
<li>Integer变量必须实例化后才可以使用，而int不需要。</li>
</ul>
<h1>39. ==比较Integer、new Integer、int的值√</h1>
<p>除以下情况外,==比较都是true</p>
<ul>
<li>new Integer(100) != new Integer(100) 因为new生成的两个integer指向堆中的地址，而引用数据类型比较时实际是比较地址是否相同。</li>
<li>new Integer(100) != Integer i=100 因为非new生成的Integer变量指向的是java常量池中的对象，而new Integer()生成的变量指向堆中新建的对象</li>
<li>Integer i = 128 != Integer j=128(Integer缓存-128-127的Integer对象，自动装箱时不会new新的Integer对象，而是直接引用缓存池中的Integer对象)</li>
</ul>
<h1>40. String转成Integer原理？</h1>
<ul>
<li>String转成Integer：Integer.parseInt(String s)Integer.valueOf(String s)</li>
<li>最终调用Integer类中的parseInt(String s, int radix)方法，字符串遍历计算负的值累减，1314=-1 * (-1+-3<em>10+-1</em>100)</li>
</ul>
<h1>41. Error和Exception的区别？</h1>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/e35afb80114c9ff59b1db.jpg" alt="Exception.jpg" tabindex="0"><figcaption>Exception.jpg</figcaption></figure>
<ul>
<li>受检异常：编译器会检查并要求必须处理的异常。</li>
<li>非受检异常：编译器不会检查也不要求必须处理的异常.</li>
<li>Throwable：所有错误或异常的超类，表示程序中可能会产生的异常
<ul>
<li>Error(非受检异常)系统级的错误;运行环境中的内部错误或者硬件问题,会导致应用程序中断.如：系统崩溃、虚拟机错误、内存空间不足、方法调用栈溢出等</li>
<li>Exception：程序可以处理的异常
<ul>
<li>编译期异常Checked Exception(<strong>受检异常</strong>)Exception中除RuntimeException及其子类之外的异常。通常不会自定义该类异常，而是直接使用系统提供的异常类。</li>
<li>运行时期异常RuntimeException及其子类异常(非受检异常)，出现原因大多因为代码本身有问题应该从逻辑上去解决并改进代码</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1>42. 异常的处理方式?</h1>
<ul>
<li>throw，throws抛出，自己不处理，抛给调用者处理(throws异常类用在方法上，可以跟多个异常类；throw异常对象用在方法内)</li>
<li>try catch捕获异常;可选择加上finally语句块，finally 语句块不管程序是否正常执行，最终它都会必然执行。</li>
</ul>
<h1>43. 异常处理经典题?</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>//tryreturn准备-&gt;catch-&gt;finally-&gt;tryreturn
public class TryDemo {
    public static void main(String[] args) {
        System.out.println(test1());//执行结果31。在return前会先执行finally，所以是先输出3，再输出1
        System.out.println(test2());//执行结果3。try返回前先执行finally，结果finally直接return了，就走不到try里面的return了
        System.out.println(test3());//执行结果2.执行finally之前将i的结果暂存，finally执行完毕后返回之前暂存的结果，而不是返回3
    }
    public static int test1() {
        try {
            return 1;
        } catch (Exception e) {
            return 2;
        } finally {
            System.out.print("3");
        }
    }
    public static int test2() {
        try {
            return 2;
        } finally {
            return 3;
        }
    }
    public static int test3() {
        int i = 0;
        try {
            i = 2;
            return i;
        } finally {
            i = 3;
        }
    }
}

</code></pre></div><h1>44. 什么是java IO?</h1>
<ul>
<li>Java IO流的40多个类都是从如下4个抽象类基类中派生出来的。</li>
<li>InputStream/Reader: 所有输入流的基类，前者是字节输入流，后者是字符输入流。</li>
<li>OutputStream/Writer: 所有输出流的基类，前者是字节输出流，后者是字符输出流。<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/6e44bc67911b299c3cb3c.jpg" alt="IO.jpg"></li>
</ul>
<h1>45. InputStream为什么不能重复读取？如何实现重复读取？√</h1>
<ul>
<li>因为inputStream设计就是这样的</li>
<li>使用ByteArrayOutputStream</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class InputStreamCacher {  
    private ByteArrayOutputStream byteArrayOutputStream = null;
    public InputStreamCacher(InputStream inputStream) {
        byteArrayOutputStream = new ByteArrayOutputStream();  
        byte[] buffer = new byte[1024];    
        int len;    
        try {  
            while ((len = inputStream.read(buffer)) &gt; -1 ) {    
                byteArrayOutputStream.write(buffer, 0, len);    
            }  
            byteArrayOutputStream.flush();  
        } catch (IOException e) {  
            logger.error(e.getMessage(), e);  
        }    
    }
    public InputStream getInputStream() { 
        return new ByteArrayInputStream(byteArrayOutputStream.toByteArray());  
    }  
}  
InputStreamCacher  cacher = new InputStreamCacher(inputStream);  
InputStream stream = cacher.getInputStream();
</code></pre></div><h1>46. 字节流和字符流区别？</h1>
<ul>
<li>Java用Unicode编码存储字符</li>
<li>其实字符流是由 Java 虚拟机将字节转换得到的，为了方便在不知道编码的情况下操作字符，提高读写效率</li>
<li>字节流按8位传输(操作字节和字节数组、数字_)以字节为单位输入输出数据</li>
<li>字符流按16位传输(由Java虚拟机将字节转化为2个字节的Unicode字符为单位的字符而成的)对多国语言支持性比较好</li>
<li>音频文件、图片、歌曲使用用字节流，中文文本的，使用字符流</li>
<li>不管文件读写还是网络发送接收，信息的最小存储单元都是字节</li>
</ul>
<h1>47. BIO,NIO,AIO 区别</h1>
<ul>
<li>BIO(Block IO):同步阻塞。服务器实现模式为一个连接一个线程，即客户端有连接请求时服务器端就需要启动一个线程进行处理，如果这个连接不做任何事情会造成不必要的线程开销，可以通过线程池机制改善.适用于连接数较少的场景。基于 Socket 和 ServerSocket 进行网络通信。</li>
<li>NIO(non-blocking IO)同步非阻塞。服务器实现模式为一个IO请求一个线程，即客户端发送的连接请求都会注册到多路复用器上，多路复用器轮询到连接有I/O请求时才启动一个线程进行处理.适用于连接数多但连接时间短的场景。基于 SocketChannel 和 ServerSocketChannel 进行网络通信。服务器可以用一个线程处理多个客户端连接，通过 Selector 监听多个 Channel 来实现多路复用，极大地提高了网络编程的性能。</li>
<li>AIO(Asynchronous I/O)异步不阻塞。服务器实现模式为一个有效请求一个线程，客户端的I/O请求都是由OS先完成了再通知服务器应用去启动线程进行处理.适用于连接数较多且连接时间较长的应用,适用于连接数多且连接时间长的场景。</li>
</ul>
<h1>48. 什么是序列化和反序列化？</h1>
<ul>
<li>序列化 (Serialization)把Java对象转为二进制流，方便存储和传输.反序列化就是把二进制流恢复成对象。</li>
<li>场景:将内存中的对象状态保存到一个文件中或者数据库中;套接字在网络上传送对象;通过RMI传输对象</li>
<li>Serializable接口作用:只是一个标记，无作用，但是如果不实现这个接口，在有些序列化场景会报错,推荐实现</li>
<li>serialVersionUID作用:用来验证序列化的对象和反序列化对应的对象ID是否一致。如果没有显示指定serialVersionUID，则编译器会根据类的相关信息自动生成一个。如果你没有定义serialVersionUID， 结果序列化对象之后，在反序列化之前把对象的类的结构改了，比如增加了一个成员变量，则此时的反序列化会失败。</li>
<li>序列化不包含transient修饰变量和静态变量。transient只能修饰变量，不能修饰类和方法。</li>
<li>序列化方法：
<ul>
<li>Java对象序列化:通过对象输出流ObjectOutputStream和对象输入流ObjectInputStream。</li>
<li>Json序列化:使用jackson包，通过ObjectMapper类操作，比如将对象转化为byte数组或者将json串转化为对象。</li>
<li>ProtoBuff序列化:ProtocolBuffer是一种轻便高效的结构化数据存储格式，ProtoBuff序列化对象可以很大程度上将其压缩，可以大大减少数据传输大小，提高系统性能。</li>
</ul>
</li>
</ul>
<h1>49. 什么是零拷贝？</h1>
<ul>
<li>
<p>DMA：直接内存访问（Direct Memory Access）是一种硬件设备(网卡、显卡等)绕开CPU独立直接访问内存的机制。提高了CPU效率。DMA和硬件交互并且将数据从磁盘缓冲区拷贝到内核缓冲区</p>
</li>
<li>
<p>传统数据交互模式</p>
<ul>
<li>读数据过程：涉及2次空间切换(内核态&lt;=&gt;用户态)、1次DMA拷贝(磁盘=&gt;内核缓冲区)、1次CPU拷贝(内核缓冲区=&gt;用户缓冲区)；
<ul>
<li>应用程序要读取磁盘数据，调用read()函数实现用户态切换内核态，这是第1次状态切换；</li>
<li>DMA控制器将数据从磁盘拷贝到内核缓冲区，这是第1次DMA拷贝；向CPU发起I/O中断，报告CPU数据已经Ready了；</li>
<li>CPU收DMA的I/O中断之后，CPU将数据从内核缓冲区复制到用户缓冲区，这是第1次CPU拷贝；</li>
<li>CPU完成拷贝之后，read()函数返回实现内核态切换用户态，这是第2次状态切换；</li>
</ul>
</li>
<li>写数据过程：涉及2次空间切换(内核态&lt;=&gt;用户态)、1次DMA拷贝(内核缓冲区=&gt;socket缓冲区)、1次CPU拷贝(用户缓冲区=&gt;内核缓冲区)；
<ul>
<li>应用程序要向网卡写数据，调用write()函数实现用户态切换内核态，这是第1次切换；</li>
<li>CPU将用户缓冲区数据拷贝到内核缓冲区，这是第1次CPU拷贝；</li>
<li>DMA控制器将数据从内核缓冲区复制到socket缓冲区，这是第1次DMA拷贝；</li>
<li>完成拷贝之后，write()函数返回实现内核态切换用户态，这是第2次切换；<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/3d46750277356c44306b4.jpg" alt="basicsmodel.jpg"></li>
</ul>
</li>
</ul>
</li>
<li>
<p>零拷贝技术：在应用程序不对数据做修改前提下，减少从内核缓冲区到用户缓冲区，再从用户缓冲区到内核缓冲区两次数据拷贝（需要CPU参与）和用户态与内核态的两次切换，直接在内核态完成数据拷贝</p>
</li>
<li>
<p>实现拷贝方法：mmap+write(RocketMQ)，sendfile(Kafa)，sendfile+DMA收集，splice方式</p>
</li>
<li>
<p>mmap是Linux提供的一种内存映射文件的机制，将内核中读缓冲区地址与用户空间缓冲区地址进行映射，实现内核缓冲区与用户缓冲区的共享。效果是将读写2个CPU拷贝改为1个内核缓冲区到socket缓冲区的CPU拷贝，mmap对大文件传输有优势，而小文件可能出现碎片；当你的程序map了一个文件，然后被另一个进程截断(truncate)时, write系统调用会因为访问非法地址而被SIGBUS信号终止。SIGBUS信号默认会杀死你的进程并产生一个coredump并中止服务；不可靠，写到mmap中的数据并没有被真正的写到硬盘，操作系统会在程序主动调用flush的时候才把数据真正的写到硬盘<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/d537052894e30f887dfb5.jpg" alt="mmapandwritemodel.jpg"></p>
</li>
<li>
<p>sendfile方式，建立了两个文件之间的传输通道。效果是少了(读数据时内核到用户和写数据时用户到内核)2次状态切换和将读写2个CPU拷贝改为1个内核缓冲区到socket缓冲区的CPU拷贝，由于数据不经过用户缓冲区，因此该数据无法被修改。只有2次状态切换、1次CPU拷贝、2次DMA拷贝。但是sendfile在内核缓冲区和socket缓冲区仍然存在一次CPU拷贝<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/19b55697111330ca1a1b2.jpg" alt="sendfileandwritemodel.jpg"></p>
</li>
<li>
<p>sendfile+DMA收集，需要硬件DMA控制器的配合。升级后的sendfile将内核空间缓冲区中对应的数据描述信息（文件描述符、地址偏移量等信息）记录到socket缓冲区中。DMA控制器根据socket缓冲区中的地址和偏移量将数据从内核缓冲区拷贝到网卡中，只有2次状态切换、0次CPU拷贝、2次DMA拷贝，但是仍然无法对数据进行修改，并且需要硬件层面DMA的支持，并且sendfile只能将文件数据拷贝到socket描述符上，有局限性<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/0460e61b4ca24d6b947cb.jpg" alt="sendfileanddmamodel.jpg"></p>
</li>
<li>
<p>splice无需硬件支持，并且不再限定于socket上，实现两个普通文件之间的数据零拷贝。splice系统调用可以在内核缓冲区和socket缓冲区之间建立管道来传输数据，避免了两者之间的CPU拷贝操作。splice的两个文件描述符参数中有一个必须是管道设备<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/0c7eec840e083b88c0e99.jpg" alt="splicemodel.jpg"></p>
</li>
</ul>
<h1>50. 泛型和类型擦除原理?</h1>
<ul>
<li>泛型（generics）提供了编译时类型安全检测机制，本质是参数化类型，所操作的数据类型被指定为一个参数。</li>
<li>好处是编译时检查类型安全，并且所有的强制转换都是自动和隐式的，不需要使用显式转换和instanceOf操作符，提高代码重用率</li>
<li>泛型擦除是指编译器在编译时擦擦除了所有类型相关的信息，所以在运行时不存在任何类型相关的信息</li>
<li>为什么需要泛型擦除？为了向下兼容</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>//泛型类
//在实例化泛型类时，必须指定T的具体类型Generic&lt;Integer&gt; genericInteger = new Generic&lt;Integer&gt;(123456);
public class Generic&lt;T&gt;{
    private T key;
    public Generic(T key) {this.key = key;}
    public T getKey(){return key;}
}
//泛型接口
public interface Generator&lt;T&gt; {
    public T method(T key);
}
//实现泛型接口，指定类型：
class GeneratorImpl&lt;T&gt; implements Generator&lt;String&gt;{
    @Override
    public String method() {
        return "hello";
    }
}
//泛型方法
public static &lt;E&gt; void printArray(E[] inputArray)
{
  for (E element:inputArray){
    System.out.printf("%s", element);
  }
  System.out.println();
}
// 创建不同类型数组： Integer, Double 和 Character
Integer[] intArray = { 1, 2, 3 };
String[] stringArray = { "Hello", "World" };
printArray( intArray  );
printArray( stringArray  );
</code></pre></div><h1>51. List中泛型的区别?</h1>
<ul>
<li>List&lt;? extends T&gt;接受任何继承自T的类型的List</li>
<li>List&lt;? super T&gt;接受任何T的父类构成的List</li>
</ul>
<h1>52. 说一下你对注解的理解？</h1>
<ul>
<li>注解本质上是一个标记，注解可以标记在类上、方法上、属性上等，标记自身也可以设置一些值</li>
<li>注解生命周期有三大类，分别是：
<ul>
<li>RetentionPolicy.SOURCE：给编译器用的，不会写入class文件@Override,lombok注解</li>
<li>RetentionPolicy.CLASS：会写入class文件，在类加载阶段丢弃，也就是运行的时候就没这个信息了</li>
<li>RetentionPolicy.RUNTIME：会写入class文件，永久保存，可以通过反射获取注解信息@Autowired.AOP注解</li>
</ul>
</li>
</ul>
<h1>53. 什么是反射？优缺点？应用场景？</h1>
<ul>
<li>在程序的运行状态中，可以构造任意一个类的对象，了解任意一个对象所属的类，了解任意一个类的成员变量和方法，调用任意一个对象的属性和方法。这种动态获取程序信息以及动态调用对象的功能称为反射机制</li>
<li>优点：运行期类型的判断，动态加载类，提高代码灵活度</li>
<li>缺点：反射相当于解释操作，性能比直接的java代码要慢很多</li>
<li>功能：
<ul>
<li>在运行时构造一个类的对象</li>
<li>判断一个类所具有的成员变量和方法</li>
<li>调用一个对象的方法</li>
<li>生成动态代理</li>
</ul>
</li>
<li>应用场景
<ul>
<li>JDBC连接数据库时使用Class.forName()通过反射加载数据库的驱动程序</li>
<li>Spring通过XML配置反射装载Bean的过程</li>
<li>Java类里面解析xml或properties里面的内容，得到对应实体类的字节码字符串以及相关的属性信息</li>
<li>使用反射机制，根据这个字符串获得某个类的Class实例，注解等信息</li>
<li>动态配置实例的属性</li>
<li>工厂模式，使用反射机制，根据全限定类名获得某个类的Class实例</li>
</ul>
</li>
<li>原理：Java程序执行分为编译和运行两步，编译之后会生成字节码(.class)文件，JVM类加载的时候，会加载字节码文件，将类型相关的所有信息加载进方法区，反射就是去获取这些信息，然后进行各种操作<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/c196cc46ea032f3e55685.png" alt="javareflect.png"></li>
</ul>
<h1>54. 反射中，Class.forName和ClassLoader区别？</h1>
<ul>
<li>都可用来对类进行加载</li>
<li>Class.forName(...)方法会将类的.class文件加载到JVM并对类进行解释并执行类中的static块</li>
<li>ClassLoader只会将.class文件加载到JVM中，在newInstance才执行类中的static块</li>
<li>Class.forName(name, initialize, loader) 方法也可控制是否加载static块，并且只有调用了newInstance方法采用调用构造函数，创建类的对象。</li>
</ul>
<h1>55. jdk1.8新特性</h1>
<ul>
<li>接口默认方法：允许给接口添加一个非抽象的方法实现，使用default关键字修饰</li>
<li>Lambda表达式和函数式接口：Lambda表达式本质上是一段匿名内部类，允许把函数作为一个方法的参数（函数作为参数传递到方法中），使代码更加简洁，但最好不要超过3行</li>
<li>Stream API：用函数式编程方式在集合类上进行复杂操作的工具，配合Lambda表达式可以方便的对集合进行处理</li>
<li>日期时间API：Java 8 引入了新的日期时间 API 改进了日期时间的管理。</li>
<li>Optional类：用来解决空指针异常的问题。</li>
</ul>
<h1>56. Lambda表达式</h1>
<ul>
<li>Lambda 表达式本质上是一段匿名内部类，也可以是一段可以传递的代码。</li>
<li>函数式接口（Functional Interface） 被@FunctionalInterface 注解修饰的能缩写成Lambda表示式，如Runnable，Comparator，Callable、Predicate、Function、Supplier、Consumer等等</li>
<li>Lambda举例：new Thread( () -&gt; System.out.println("Thread is running since Java8!") ).start();</li>
</ul>
<h1>57. Optional使用</h1>
<ul>
<li>Optional是用于防范NullPointerException。包装对象（可能是 null, 也有可能非 null）的容器</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>Optional&lt;String&gt; optional = Optional.of("bam");

optional.isPresent();           // true
optional.get();                 // "bam"
optional.orElse("fallback");    // "bam"

optional.ifPresent((s) -&gt; System.out.println(s.charAt(0)));     // "b"
</code></pre></div><h1>58. Stream流用过吗？</h1>
<ul>
<li>Stream对一个包含一个或多个元素的集合做中间操作或终端操作。终端操作会返回一个结果，而中间操作会返回一个Stream流</li>
</ul>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/84dcdbd58d40d05030439.png" alt="javasteam.png" tabindex="0"><figcaption>javasteam.png</figcaption></figure>
<h1>59. maven常用命令</h1>
<ul>
<li>mvn package打包到target</li>
<li>mvn install打包到本地</li>
<li>mvn deploy发送到私服</li>
</ul>
]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/e35afb80114c9ff59b1db.jpg" type="image/jpeg"/>
    </item>
    <item>
      <title>java集合</title>
      <link>https://javaguide.cn/interview/javacollections.html</link>
      <guid>https://javaguide.cn/interview/javacollections.html</guid>
      <source url="https://javaguide.cn/rss.xml">java集合</source>
      <description>1. 集合继承结构 Collection，主要由 List、Set、Queue 组成 List：存储的元素有序，可重复。动态数组的 ArrayList 和封装了链表的 LinkedList； Set：存储的元素无序，不可重复。HashSet 和 TreeSet； Queue：队列。双端队列 ArrayDeque，以及优先级队列 PriorityQueu...</description>
      <category>面试</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<!-- more -->
<!--TOC-->
<h1>1. 集合继承结构</h1>
<ul>
<li>Collection，主要由 List、Set、Queue 组成
<ul>
<li>List：存储的元素有序，可重复。动态数组的 ArrayList 和封装了链表的 LinkedList；</li>
<li>Set：存储的元素无序，不可重复。HashSet 和 TreeSet；</li>
<li>Queue：队列。双端队列 ArrayDeque，以及优先级队列 PriorityQueue。</li>
</ul>
</li>
<li>Map，键值对集合。HashMap。键不能重复，每个键只能对应一个值。HashMap、LinkedHashMap、TreeMap</li>
</ul>
<p><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/9d9065dbe4e0a916ac96f.jpg" alt="collection.png"><br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/bfd03cc15ac4e7881d444.jpg" alt="map.png"></p>
<h1>2. 简单介绍一下队列 Queue</h1>
<ul>
<li>Java队列主要通过 java.util.Queue 接口和 java.util.concurrent.BlockingQueue 两个接口来实现。</li>
<li>PriorityQueue 是一个基于优先级堆的无界队列，它的元素按照自然顺序排序或者 Comparator 进行排序。</li>
<li>ArrayDeque 是一个基于数组的双端队列，可以在两端插入和删除元素。</li>
<li>LinkedList既可以当作 List 使用，也可以当作 Queue 使用。</li>
<li>BlockingQueue 线程安全的队列，还添加了等待/通知机制，以便在队列为空时阻塞获取元素的线程，直到队列变得可用，或者在队列满时阻塞插入元素的线程，直到队列变得可用。被广泛用于“生产者-消费者”问题中，其原因是 BlockingQueue 提供了可阻塞的插入和移除方法。当队列容器已满，生产者线程会被阻塞，直到队列未满；当队列容器为空时，消费者线程会被阻塞，直至队列非空时为止。</li>
<li>BlockingQueue 接口的实现类有 ArrayBlockingQueue、DelayQueue、LinkedBlockingDeque、LinkedBlockingQueue、LinkedTransferQueue、PriorityBlockingQueue、SynchronousQueue 等。</li>
<li>阻塞指的是一种程序执行状态，其中某个线程在等待某个条件满足时暂停其执行（即阻塞），直到条件满足时恢复其执行。</li>
</ul>
<h1>3. 阻塞队列是如何实现的？</h1>
<ul>
<li>ArrayBlockingQueue是一个基于数组的有界阻塞队列，采用 ReentrantLock 锁来实现线程的互斥，而 ReentrantLock 底层采用的是 AQS 实现的队列同步，线程的阻塞调用 LockSupport.park 实现，唤醒调用 LockSupport.unpark 实现。</li>
</ul>
<h1>4. 队列和栈的区别</h1>
<ul>
<li>队列是一种先进先出（FIFO, First-In-First-Out）的数据结构。在队列中，第一个加入队列的元素会是第一个被移除的。队列常用于处理按顺序来的任务。</li>
<li>栈是一种后进先出（LIFO, Last-In-First-Out）的数据结构。在这种结构中，最后一个加入栈的元素会是第一个被移除的。这种特性使得栈非常适合于那些需要访问最新添加的数据元素的场合。</li>
</ul>
<h1>5. ArrayList和LinkedList区别？√</h1>
<ul>
<li>ArrayList基于数组实现，LinkedList基于双向链表实现</li>
<li>ArrayList查找快(数组下标查找)，增删慢(需要复制数组和移动元素)，适合顺序添加、随机访问场景；LinkedList查找慢(移动指针从前往后依次查找)、增删快(改变前后驱节点指向)适合多次增加删除修改场景</li>
<li>ArrayList支持随机访问，可通过下标直接获取元素，实现了RandmoAccess接口，LinkedList不支持，没有实现RandmoAccess接口</li>
<li>ArrayList基于数组，是一块连续的内存空间，扩容后空间是原来的1.5倍，可能会有空的内存空间，存在一定空间浪费，LinkedList基于链表，内存空间不连续，每个节点需要存储前驱和后继，所以会占用更多的空间</li>
</ul>
<h1>6. ArrayList扩容机制？</h1>
<ul>
<li>ArrayList基于数组实现，数组的容量是在定义的时候确定的，在插入时候，会先检查是否需要扩容，如果当前容量+1超过数组长度，就会进行扩容</li>
<li>扩容是创建一个1.5倍的新数组，然后把原数组的值拷贝过去</li>
<li>初始容量10，初始化指定容量会提升性能</li>
</ul>
<h1>7. ArrayList怎么序列化?为什么用transient修饰数组?</h1>
<ul>
<li>ArrayList通过两个流ObjectOutputStream和ObjectInputStream的两个方法readObject、writeObject进行序列化和反序列化。json序列化也可以</li>
<li>因为ArrayList的数组中有部分数据是null存在内存浪费，同时减少不必要序列化和反序列化，ArrayList使用transient修饰存储元素的elementData的数组，使之不被序列化。</li>
</ul>
<h1>8. 并发修改异常和集合的快速失败(fail-fast)?</h1>
<ul>
<li>快速失败(fail—fast)：Java 集合的一种错误检测机制，在用迭代器遍历一个集合对象时，如果线程A遍历过程中，线程B对集合对象的内容进行了修改（增加、删除、修改），则会抛出ConcurrentModificationException</li>
<li>原理：迭代器在遍历时使用一个modCount变量。遍历开始时赋值给expectedmodCount，集合在被遍历期间如果内容发生变化，就会改变modCount的值。每当迭代器使用 hashNext()/next()遍历下一个元素之前，都会检测modCount变量是否为 expectedmodCount值，是的话就返回遍历；否则抛出异常，终止遍历。</li>
<li>场景：java.util包下的集合类都是快速失败的，不能在多线程下发生并发修改（迭代过程中被修改），如ArrayList</li>
<li>解决方法：多线程下所有涉及到改变modCount值得地方全部加上synchronized。使用CopyOnWriteArrayList来替换ArrayList</li>
<li>如何删除元素
<ul>
<li>使用Iterator，顺序向下，如果找到元素使用remove方法移除</li>
<li>倒序遍历List，如果找到元素使用remove方法移除</li>
</ul>
</li>
</ul>
<h1>9. 安全失败(fail-safe)?</h1>
<ul>
<li>采用安全失败机制的集合容器，在遍历时不是直接在集合内容上访问的，而是先复制原有集合内容，在拷贝的集合上进行遍历</li>
<li>原理：由于迭代时是对原集合的拷贝进行遍历，所以在遍历过程中对原集合所作的修改并不能被迭代器检测到，所以不会触发ConcurrentModificationException</li>
<li>缺点：基于拷贝内容的优点是避免了ConcurrentModificationException，但迭代器并不能访问到修改后的内容</li>
<li>场景：java.util.concurrent包下的容器都是安全失败，可以在多线程下并发修改，如CopyOnWriteArrayList</li>
</ul>
<h1>10. 如何保证ArrayList线程安全?</h1>
<ul>
<li>使用Collections.synchronizedList包装ArrayList，然后操作包装后的list。</li>
<li>使用CopyOnWriteArrayList代替ArrayList。</li>
<li>使用ArrayList时通过同步机制去控制ArrayList读写。</li>
</ul>
<h1>11. CopyOnWriteArrayList？</h1>
<ul>
<li>线程安全版本的 ArrayList。采用读写分离的并发策略。允许并发读，读操作是无锁的，性能高。写操作首先将当前容器复制一份，然后在新副本上执行写操作，结束之后再将原容器的引用指向新容器。</li>
</ul>
<h1>12. hashMap的实现原理/底层数据结构?</h1>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/c204ae8e1025043161cad.png" alt="hashmapstructure.png" tabindex="0"><figcaption>hashmapstructure.png</figcaption></figure>
<ul>
<li>jdk1.8的数据结构是Node数组+链表+红黑树，</li>
<li>HashMap的Node数组用于存储键值对,当向 HashMap 中添加一个键值对时，会使用哈希函数计算键的哈希码，确定其在数组中的位置，当多个键经哈希处理后得到相同的索引时，会发生哈希冲突，如果键已经存在，其对应的值将被新值覆盖。否则新元素将被添加到链表的末尾。为了提升查询性能。当链表上的元素个数超过8个且数组大小&gt;=64时，链表转化成红黑树，节点变成树节点，红黑树的查询效率是 O(logN)，比链表的 O(n) 要快。数组的查询效率是 O(1)。但是当红黑树节点个数小于6时转为链表；当从 HashMap 中获取元素时，也会使用哈希函数计算键的位置，然后根据位置在数组、链表或者红黑树中查找元素。</li>
<li>HashMap 的初始容量是 16，随着元素的不断添加，HashMap 的容量（数组大小）可能不足，需要进行扩容，阈值是capacity * loadFactor，capacity 为容量，loadFactor 为负载因子，默认为 0.75。扩容后的数组大小是原来的 2 倍，然后把原来的元素重新计算哈希值，放到新的数组中</li>
</ul>
<h1>13. 为什么使用红黑树而不使用二叉树或者平衡树呢？</h1>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/7b404a96dad386d65dbd5.png" alt="mangrove.png" tabindex="0"><figcaption>mangrove.png</figcaption></figure>
<ul>
<li>红黑树一种自平衡的二叉查找树：
<ul>
<li>每个节点要么是红色，要么是黑色；</li>
<li>根节点永远是黑色的；</li>
<li>所有的叶子节点都是是黑色的（注意这里说叶子节点其实是图中的 NULL 节点）；</li>
<li>每个红色节点的两个子节点一定都是黑色；</li>
<li>从任一节点到其子树中每个叶子节点的路径都包含相同数量的黑色节点；</li>
</ul>
</li>
<li>不用二叉树原因：二叉树容易出现极端情况，比如插入的数据是有序的，那么二叉树就会退化成链表，查询效率就会变成 O(n)。</li>
<li>不用平衡二叉树原因：平衡二叉树插入和删除数据时，为了保持保持平衡需要旋转的次数更多，保持平衡效率比红黑树低</li>
</ul>
<h1>14. 红黑树怎么保持平衡？</h1>
<ul>
<li>红黑树有两种方式保持平衡：旋转(分为左旋和右旋)和染色。<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/8a63028a99dc3e0be747e.png" alt="levorotation.png"><br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/c0088556697b01d568da0.png" alt="dextrorotation.png"><br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/1211584c77b4609a91bd5.png" alt="dye.png"></li>
</ul>
<h1>15. hashMap的put方法执行过程?</h1>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/f96cde9b8f5122da3d674.jpg" alt="put.jpg" tabindex="0"><figcaption>put.jpg</figcaption></figure>
<ul>
<li>1.通过 hash 方法计算 key 的哈希值</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>static final int hash(Object key) {
    int h;
    return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);
}
</code></pre></div><ul>
<li>2.判断tab是否为空或者长度为0，如果是则进行扩容操作。</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>if ((tab = table) == null || (n = tab.length) == 0) 
  n = (tab = resize()).length;
</code></pre></div><ul>
<li>3.根据哈希值计算下标，如果数组对应下标正好没有存放数据，则直接插入，</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>if ((p = tab[i = (n - 1) &amp; hash]) == null)
    tab[i] = newNode(hash, key, value, null);
</code></pre></div><ul>
<li>4.如果对应下标已经有数据了，就需要判断是否为相同的key，是则覆盖 value，否则需要判断是否为树节点，是则向树中插入节点，否则向链表中插入数据。在链表中插入节点的时候，如果链表长度大于等于 8或者数组长度&gt;=64，则需要把链表转换为红黑树。</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>else {
    Node&lt;K,V&gt; e; K k;
    //
    if (p.hash == hash &amp;&amp;
        ((k = p.key) == key || (key != null &amp;&amp; key.equals(k))))
        e = p;
    else if (p instanceof TreeNode)
        e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value);
    else {
        for (int binCount = 0; ; ++binCount) {
            if ((e = p.next) == null) {
                p.next = newNode(hash, key, value, null);
                if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st 转链表
                    treeifyBin(tab, hash);
                break;
            }
            if (e.hash == hash &amp;&amp;
                ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))
                break;
            p = e;
        }
    }
}
</code></pre></div><ul>
<li>5.最后所有元素处理完成后，判断是否超过阈值；threshold，超过则扩容。然后rehash原数组</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>if (++size &gt; threshold)
    resize();
</code></pre></div><h1>16. 只重写 equals 没重写 hashcode，map put 的时候会发生什么?</h1>
<ul>
<li>会导致 equals 相等的两个对象，hashcode 不相等，这样的话，这两个对象会被放到不同的桶中，这样就会导致 get 的时候，找不到对应的值。</li>
</ul>
<h1>17. HashMap的get方法执行过程?</h1>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/ffa2d69b3051e98ee501c.png" alt="get.png" tabindex="0"><figcaption>get.png</figcaption></figure>
<ul>
<li>使用扰动函数，获取新的哈希值</li>
<li>计算数组下标，获取节点</li>
<li>当前节点和 key 匹配，直接返回</li>
<li>否则，当前节点是否为树节点，查找红黑树</li>
<li>否则，遍历链表查找</li>
</ul>
<h1>18. hashMap计算hash的方法？为什么这么设计？</h1>
<ul>
<li>hash = (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16) key的hashCode低16位与高16位异或</li>
<li>降低降低hash碰撞的概率，让hashCode取值出的高位参与运算，使得数据分布更平均的操作</li>
<li>高频操作采用位运算，算法高效</li>
</ul>
<h1>19. 为什么哈希函数能降低hash碰撞？</h1>
<ul>
<li>因为高16位与低16位亦或能增加低位的随机性，减少碰撞。（在计算元素位置时把散列值和数组长度-1做与操作。同时因为数组长度为2的整数幂，数组长度-1相当于低位掩码。与操作的结果就是散列值的高位全部归零，只保留低位值，用来做数组下标访问。以初始长度16为例，16-1=15。2进制表示是0000 0000 0000 0000 0000 0000 0000 1111。和某个散列值做与操作结果就是截取了最低的四位值。就算散列值分布再松散，要是只取最后几位的话，碰撞也会很严重。如果散列本身做得不好，分布上成等差数列的漏洞，如果正好让最后几个低位呈现规律性重复，那就容易碰撞了。右移16位，32bit的一半，自己的高半区和低半区做异或，就是为了混合原始哈希码的高位和低位，以此来加大低位的随机性。而且混合后的低位掺杂了高位的部分特征，高位的信息也被变相保留下来）<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/67d6ae212618b6636f2b2.jpg" alt="hash.jpg"></li>
</ul>
<h1>20. hashMap计算数组的位置？为什么不直接使用hashCode()处理后的哈希值直接作为table的下标？</h1>
<ul>
<li>i = (length - 1) &amp; hash 求出hash与数组长度-1进行与(&amp;)操作（结果就是散列值的高位全部归零，只保留低位值）</li>
<li>原因1当数组长度为2的幂次方时，h&amp;(length-1)等价于h%length取模,比取余操作更加有效率</li>
<li>原因2通过取模操作解决了“哈希值与数组大小范围不匹配”的问题；key.hashCode()返回int类型范围-(2 ^ 31)~(2 ^ 31 - 1)，约40亿。而HashMap的容量范围是在16（默认初始值）~2 ^ 30，内存放不下</li>
</ul>
<h1>21. HashMap的size为什么必须是2的整数次方？</h1>
<ul>
<li>充分利用数组空间，让数据更均匀分布，减少hash冲突，如果length不是2的次幂，比如15，则length–1=14，二进制为 1110，再与h与操作，最后一位都为0，而 0001，0011，0101，1001，1011，0111，1101这几个位置不能存放元素了，此时数组可用位置比数组长度少，增加了碰撞的几率，减慢了查询的效率。</li>
<li>当size为2的n次方时，h &amp; (length – 1) 等价于h%length取模，位运算速度快</li>
<li>在扩容迁移的时候不需要再重新通过哈希定位新的位置了。因为每次扩容都是翻倍，与 (n-1)&amp;hash原位置相比，只是多了一个bit位。使得扩容后的位置=原位置 or 原位置 + 旧容量</li>
</ul>
<h1>22. 如果初始化HashMap传17作为初始容量会怎么处理？</h1>
<ul>
<li>初始化时不是2的倍数时，HashMap会将值转化为大于该值的最小的2次幂，所以传入17时HashMap的实际容量是32。</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>//MAXIMUM_CAPACITY = 1 &lt;&lt; 30这个是临界范围，即最⼤的Map集合
//或运算主要是为了把⼆进制的各个位置都填上1，当⼆进制的各个位置都是1以后，就是标准的2的倍数减1了，最后把结果加1再返回即可
static final int tableSizeFor(int cap) {
 int n = cap - 1;
 n |= n &gt;&gt;&gt; 1;
 n |= n &gt;&gt;&gt; 2;
 n |= n &gt;&gt;&gt; 4;
 n |= n &gt;&gt;&gt; 8;
 n |= n &gt;&gt;&gt; 16;
 return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1; }
</code></pre></div><figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/662c58176e0ac38a0a26f.png" alt="hashmaptablesize.png" tabindex="0"><figcaption>hashmaptablesize.png</figcaption></figure>
<h1>23. 初始化 HashMap 的时候需要传入容量值吗？</h1>
<ul>
<li>在创建 HashMap 时可以指定初始容量值。这个容量是指 Map 内部用于存储数据的数组大小。</li>
<li>如果预先知道 Map 将存储大量键值对，提前指定一个足够大的初始容量可以减少因扩容导致的重哈希（rehashing）操作，从而提高性能。因为每次扩容时，HashMap 需要新分配一个更大的数组并重新将现有的元素插入到这个新数组中，这个过程相对耗时，尤其是当 Map 中已有大量数据时。</li>
<li>过大的初始容量会浪费内存，特别是当实际存储的元素远少于初始容量时。如果不指定初始容量，则默认的初始容量 16。</li>
</ul>
<h1>24. 有什么哈希函数的构造方法呢？</h1>
<ul>
<li>HashMap里哈希构造函数的方法叫除留取余法：H(key)=key%p(p&lt;=N)，关键字除以一个不大于哈希表长度的正整数p，所得余数为地址</li>
<li>直接定址法：直接根据key来映射到对应的数组位置，例如 1232 放到下标 1232 的位置。</li>
<li>数字分析法：取key的某些数字（例如十位和百位）作为映射的位置</li>
<li>平方取中法：取key平方的中间几位作为映射的位置</li>
<li>折叠法：将key分割成位数相同的几段，然后把它们的叠加和作为映射的位置</li>
</ul>
<h1>25. hashMap使用了什么方法解决Hash冲突？</h1>
<ul>
<li>链地址法（使用散列表）链接相同hash值的数据</li>
<li>使用2次扰动函数（hash函数）来降低哈希冲突的概率，使得数据分布更平均</li>
<li>引入红黑树进一步降低遍历的时间复杂度，使得遍历更快；</li>
</ul>
<h1>26. 解决哈希冲突有哪些方法？</h1>
<ul>
<li>再哈希法：两套哈希算法，当发生哈希冲突的时候，使用另外一种哈希算法，直到找到空槽为止。设计要求高</li>
<li>开放地址法：遇到哈希冲突的时候，就去寻找下一个空的槽。有 3 种方法：
<ul>
<li>线性探测：从冲突的位置开始，依次往后找，直到找到空槽。</li>
<li>二次探测：从冲突的位置 x 开始，第一次增加 1^2个位置，第二次增加 2^2，直到找到空槽。</li>
<li>双重哈希：准备多个哈希函数，发生冲突的时候，使用另外一个哈希函数。</li>
</ul>
</li>
<li>链地址法，当发生哈希冲突的时候，使用链表将冲突的元素串起来。HashMap 采用的正是拉链法。</li>
</ul>
<h1>27. 怎么判断key相等呢？</h1>
<ul>
<li>依赖于key的equals()方法和hashCode()方法，以及 == 运算符。
<ul>
<li>hashCode()：计算key的哈希码。由于不同的key可能有相同的哈希码，hashCode()只是第一步筛选。</li>
<li>equals()：当两个key的哈希码相同时，再用key的equals()方法精确比较。只有返回true时，两个key才完全相同</li>
<li>==：如果两个key的引用指向同一个对象，那么hashCode()和equals()方法都会返回true，所以equals判断前使用==运算符判断</li>
</ul>
</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>if (e.hash == hash &amp;&amp;
((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))
</code></pre></div><h1>28. 为什么桶里面的链表要转红黑树？为什么不直接使用红黑树？链表转换为红黑树阈值是8？红黑树转链表阈值是6?</h1>
<ul>
<li>红黑树节点的大小大概是普通节点大小的两倍，所以转红黑树牺牲了空间换时间，是一种兜底策略，保证极端情况下的查找效率</li>
<li>因为当负载因子是0.75服从泊松分布，当单个桶内的元素达到8个时的概率小于千万分之一，几乎不可能，更印证了转红黑树只是兜底策略</li>
<li>因为如果这个阈值也设置成8，假如发生碰撞，节点增减刚好在8附近，会发生链表和红黑树的不断转换，导致资源浪费。</li>
</ul>
<h1>29. hash冲突后，将元素放到链表头还是尾？√</h1>
<ul>
<li>JDK1.7插入时采用头插法，多线程下，有链表闭环的bug。假设链表原来的元素是元素的顺序是C-&gt;B-&gt;A，此时线程1和2指向指向C，线程1和2.next指向B，当hashMap扩容并且线程2完成插入，此时链表的状态为A-&gt;B-&gt;C，此时线程1指向C，线程1.next指向B，此时线程1想要变量就变成C-&gt;B-&gt;C了，因为此时B.next-&gt;C</li>
<li>JDK1.8改成了尾插法，主要是为了减少线程安全的问题，转成红黑树后按照红黑树的规则来插了</li>
</ul>
<h1>30. HashMap哪些操作会导致扩容？ 扩容机制？resize方法的执行过程？扩容后的位置计算？为什么负载因子是0.75?</h1>
<ul>
<li>为了减少哈希冲突发生的概率，当HashMap元素个数达到一个临界值threshold的时候，就会触发扩容，是一个相当耗时的操作。</li>
<li>扩容时机
<ul>
<li>第一次调用HashMap的put方法且数组为null时，会调用resize方法对table数组进行初始化，默认大小为16。</li>
<li>当hashMap元素个数大于扩容阈值threshold = 负载因子loadFactor(0.75) * 初始容量capacity(16)时。容量变为原来的2倍，先插入数据再扩容</li>
</ul>
</li>
<li>容量范围：16-2^30个</li>
<li>加载因子过高，扩容频率变低，hash碰撞几率变大，查找时间长，但占用空间小，空间利用率变高</li>
<li>加载因子过低，扩容频率变高，hash碰撞几率变低，查找时间短，但占用空间大，空间利用率变低</li>
<li>扩容机制：扩容时，HashMap 会创建一个新的数组，其容量是原数组容量的两倍。然后将键值对放到新计算出的索引位置上。根据(e.hash &amp; oldCap)是否为0，使得扩容后的位置=原位置 or 原位置 + 旧容量（原哈希值的高位中新增的那一位是否为1，因为位置计算实际上是保留低位值，去掉所有高位值，比如原容量16则保留4位低位，扩容后32为保留5位低位，相差1位，而这1位刚好是原容量16所在的位置，因此只需hash与原容量与操作得到最新的位是1还是0决定新元素的位置，上面的推论都得益于长度是2的倍数和hash的高低位运算）</li>
</ul>
<h1>31. jdk1.8 对 HashMap 主要做了哪些优化呢？为什么？</h1>
<ul>
<li>数据结构：数组+链表改成了数组+链表或红黑树 原因：发生 hash 冲突，元素会存入链表，链表过长转为红黑树，将时间复杂度由O(n)降为O(logn)</li>
<li>链表插入方式：链表的插入方式从头插法改成了尾插法 原因：因为头插法扩容时，头插法会使链表发生反转，多线程环境下会产生环</li>
<li>扩容rehash：1.7 需要对原数组中的元素进行重新hash定位在新数组的位置，1.8新的位置不变或索引+新增容量大小。原因：提高扩容的效率，更快地扩容。</li>
<li>扩容时机：在插入时，1.7先判断是否需要扩容，再插入，1.8先插入，完成再判断是否需要扩容；</li>
<li>散列函数：1.7 做了四次移位和四次异或，jdk1.8只做一次。原因：做4次边际效用也不大，改为一次，提升效率。</li>
</ul>
<h1>32. 你能自己设计实现一个HashMap吗？</h1>
<ul>
<li>散列函数：hashCode()+除留余数法</li>
<li>冲突解决：链地址法</li>
<li>扩容：节点重新hash获取位置<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/007d9857d0d6a245a66cb.png" alt="myhashmap.png"></li>
</ul>
<h1>33. HashMap 为什么不是线程安全的？</h1>
<ul>
<li>JDK1.7多线程下扩容会死循环。使用头插法插入元素，在多线程的环境下，扩容时有可能导致出现环形链表，造成死循环，JDK8使用尾插法，扩容时会保持链表原来的顺序。</li>
<li>多线程put可能会导致元素的丢失。因为计算出来的位置可能会被其他线程的put覆盖，本来哈希冲突是应该用链表的，但多线程时由于没有加锁，相同位置的元素可能就被干掉了。</li>
<li>put和get并发时，可能导致get为null。线程1执行put时，因为元素个数超出阈值而导致出现扩容，线程2此时执行get，就有可能出现这个问题，因为线程1执行完table = newTab后，线程2中的table此时也发生了变化，此时去get时当然会get到null，因为元素还没有转移。</li>
</ul>
<h1>34. 如何解决HashMap线程不安全的问题呢？</h1>
<ul>
<li>HashTable直接在方法上加synchronized关键字，锁住整个table数组，粒度大</li>
<li>Collections.synchronizedMap使用 Collections 集合工具的内部类，内部定义了一个对象锁，方法内通过对象锁实现；</li>
<li>ConcurrentHashMap在jdk1.7中使用分段锁，在 jdk1.8 中使用 CAS+synchronized。</li>
</ul>
<h1>35. ConcurrentHashmap的实现？</h1>
<ul>
<li>jdk1.8 是基于CAS+synchronized实现。</li>
<li>数据结构和 HashMap 是一样的，数组+链表+红黑树。它实现线程安全的关键点在于 put 流程。</li>
<li>put流程
<ul>
<li>首先计算 hash，遍历 node 数组，如果 node 是空的话，就通过 CAS+自旋的方式初始化</li>
<li>如果当前数组位置是空则直接通过 CAS 自旋写入数据</li>
<li>如果 hash==MOVED，说明需要扩容，执行扩容</li>
<li>如果都不满足，就使用 synchronized 写入数据，写入数据同样判断链表、红黑树，链表写入和 HashMap 的方式一样，key hash 一样就覆盖，反之就尾插法，链表长度超过 8 就转换成红黑树</li>
</ul>
</li>
<li>get查询：和HashMap 基本相同，通过 key 计算位置，table 该位置 key 相同就返回，如果是红黑树按照红黑树获取，否则就遍历链表获取。</li>
</ul>
<h1>36. HashMap 内部节点是有序的吗？</h1>
<ul>
<li>HashMap 是无序的，根据 hash 值随机插入。LinkedHashMap 或者 TreeMap有序</li>
</ul>
<h1>37. LinkedHashMap怎么实现有序的？</h1>
<ul>
<li>LinkedHashMap维护了一个双向链表，有头尾节点，同时节点除了继承HashMap的Node属性，还有before和after用于标识前置节点和后置节点。可以实现按插入的顺序或访问顺序排序。</li>
</ul>
<h1>38. TreeMap怎么实现有序的？</h1>
<ul>
<li>TreeMap按照Key自然顺序或Comprator顺序进行排序，内部是通过红黑树来实现。所以要么key所属的类实现Comparable接口，或者自定义一个实现了Comparator接口的比较器，用于key比较</li>
</ul>
<h1>39. TreeMap 和 HashMap 的区别</h1>
<ul>
<li>HashMap 是基于数组+链表+红黑树实现的，put 元素的时候会先计算 key 的哈希值，然后通过哈希值计算出数组的索引，然后将元素插入到数组中，如果发生哈希冲突，会使用链表来解决，如果链表长度大于 8，会转换为红黑树。get 元素的时候同样会先计算 key 的哈希值，然后通过哈希值计算出数组的索引，如果遇到链表或者红黑树，会通过 key 的 equals 方法来判断是否是要找的元素。在没有发生哈希冲突的情况下，HashMap 的查找效率是 O(1)。适用于查找操作比较频繁的场景。</li>
<li>TreeMap 是基于红黑树实现的，put 元素的时候会先判断根节点是否为空，如果为空，直接插入到根节点，如果不为空，会通过 key 的比较器来判断元素应该插入到左子树还是右子树。get 元素的时候会通过 key 的比较器来判断元素的位置，然后递归查找。TreeMap 的查找效率是 O(logn)。并且保证了元素的顺序，因此适用于需要大量范围查找或者有序遍历的场景。</li>
</ul>
<h1>40. HashSet底层实现？</h1>
<ul>
<li>HashSet底层基于HashMap实现（除了clone()、writeObject()、readObject()是HashSet⾃⼰实现之外，其他⽅法都是直接调⽤HashMap中的⽅法。HashSet 会自动去重，因为HashMap 的键是唯一的（哈希值），相同键的值会覆盖掉原来的值，</li>
</ul>
<h1>41. HashSet 和 ArrayList 的区别</h1>
<ul>
<li>ArrayList 是基于动态数组实现的，HashSet 是基于 HashMap 实现的。</li>
<li>ArrayList 允许重复元素和 null 值；HashSet 元素唯一，基于元素的 hashCode 和 equals 方法来确定元素的唯一性。<br>
ArrayList 保持元素的插入顺序，可以通过索引访问元素；HashSet 不保证元素的顺序，存储顺序依赖于哈希算法，并且可能随着元素的添加或删除而改变</li>
</ul>
<h1>42. HashMap与Hashtable区别√</h1>
<ul>
<li>HashMap可以接收null键和值。当key为null时返回的值为0，Hashtable不能接受null键和值，会抛出空指针异常</li>
<li>HashMap线程不安全，Hashtable线程安全</li>
<li>HashMap默认大小是16，扩容每次为2的指数大小，HashTable中数组默认大小是11 ，扩容方法是old*2 + 1</li>
</ul>
<h1>43. HashMap和ConcurrentHashMap的区别？</h1>
<ul>
<li>ConcurrentHashMap线程安全；对整个桶数组进行了分割分段(Segment)，每一个分段上都用lock锁保护，ConCurrentHashMap不允许键值对null</li>
<li>HashMap线程不安全；HashMap的键值对允许有null</li>
</ul>
<h1>44. ConcurrentHashMap和Hashtable区别？</h1>
<ul>
<li>ConcurrentHashMap和Hashtable区别主要体现在实现线程安全的方式上不同。</li>
<li>底层数据结构： ConcurrentHashMap和hashMap一样。Hashtable和JDK1.7的HashMap一样</li>
<li>实现线程安全的方式：
<ul>
<li>ConcurrentHashMap：（JDK1.7分段锁） 对整个桶数组进行了分割分段(Segment)，每一把锁只锁容器其中一部分数据，多线程访问容器里不同数据段的数据，就不会存在锁竞争，提高并发访问率。（默认分配16个Segment） JDK1.8，使用 Node 数组+链表+红黑树的数据结构来实现，并发控制使用 synchronized 和 CAS 来操作。（JDK1.6以后 对 synchronized锁做了很多优化） HashTable 在每次同步执行时都要锁住整个结构。 ConcurrentHashMap锁的方式是稍微细粒度的</li>
<li>Hashtable(同一把锁) :使用synchronized保证线程安全，效率低下。当一个线程访问同步方法时，其他线程也访问同步方法，可能会进入阻塞或轮询状态</li>
</ul>
</li>
</ul>
<h1>45. 有哪些线程不安全的集合？高并发情况下如何保证线程安全？√</h1>
<ul>
<li>Vector、HashTable、Properties是线程安全的；</li>
<li>ArrayList、LinkedList、HashSet、TreeSet、HashMap、TreeMap等都是线程不安全的。</li>
<li>使用线程安全的类，使用synchronized关键字等</li>
<li>普通集合变为同步集合的工具方法Collections.synchronizedList(&lt;? extends Collection&gt; collection);</li>
</ul>
<h1>46. 集合如何排序？</h1>
<ul>
<li>排序：实现Comparator接口compare(T o1,T o2)小于、等于或者大于o2分别返回负整数、0或者正整数</li>
</ul>
<h1>47. set实现类HashSet、LinkedHashSet、TreeSet的数据结构以及各自有优点</h1>
<ul>
<li>HashSet：无序，唯一，底层采用HashMap来保存元素（数组机制）</li>
<li>LinkedHashSet：有序，唯一，基于 LinkedHashMap 实现 链表和哈希表组合</li>
<li>TreeSet：有序，唯一，红黑树(自平衡的排序二叉树)</li>
</ul>
<h1>49. Comparable和Comparator区别?</h1>
<ul>
<li>Comparable接口用于当前对象和其它对象的比较，compareTo(Object obj) 方法用来排序,在比较类上修改</li>
<li>Comparator接口用于传入的两个对象的比较，compare(Object obj1, Object obj2) 方法用来排序，新增一个类专门用于比较</li>
</ul>
<h1>50. 集合类使用注意事项</h1>
<ul>
<li>基于应用的需求来选择使用正确类型的集合。如果元素的大小是固定的且已知优先级此时使用Array，而不是ArrayList</li>
<li>指定初始大小避免重复扩容</li>
<li>使用泛型来保证类型安全，可靠性和健壮性</li>
<li>Map中尽量使用不可变类String作为一个key，可避免hashcode的实现和我们自定义类的equals方法</li>
<li>返回零长度的集合或者数组，而不是返回一个null ，这样可以防止底层集合是空的</li>
</ul>
<h1>51. Array与ArrayList区别与选用？</h1>
<ul>
<li>Array可以容纳基本类型和对象，而ArrayList只能容纳对象。</li>
<li>Array是指定大小的，而ArrayList大小是固定的，可自动扩容。</li>
<li>列表的大小已经指定且存储和遍历推荐使用Array</li>
<li>多维数组推荐使用Array[][]</li>
</ul>
]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/9d9065dbe4e0a916ac96f.jpg" type="image/jpeg"/>
    </item>
    <item>
      <title>java并发</title>
      <link>https://javaguide.cn/interview/javahighconcurrency.html</link>
      <guid>https://javaguide.cn/interview/javahighconcurrency.html</guid>
      <source url="https://javaguide.cn/rss.xml">java并发</source>
      <description>1. 并发与并行区别? 并发:指多个任务在同一时间执行。这些任务在单核或多核处理器上通过进程或线程轮流地占有处理器资源来执行。 并行:指多个任务在同一时刻执行。多个处理器同时执行多个任务，每个核心实际上可以在同一时间独立地执行不同的任务。 串行:多个事件按顺序执行 并行就是每个人对应一个阿姨，同时打饭；而并发就是一个阿姨，轮流给每个人打饭。 2. 进程...</description>
      <category>面试</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<!-- more -->
<h1>1. 并发与并行区别?</h1>
<ul>
<li>并发:指多个任务在同一时间执行。这些任务在单核或多核处理器上通过进程或线程轮流地占有处理器资源来执行。</li>
<li>并行:指多个任务在同一时刻执行。多个处理器同时执行多个任务，每个核心实际上可以在同一时间独立地执行不同的任务。</li>
<li>串行:多个事件按顺序执行</li>
<li>并行就是每个人对应一个阿姨，同时打饭；而并发就是一个阿姨，轮流给每个人打饭。</li>
</ul>
<h1>2. 进程和线程的区别？</h1>
<ul>
<li>进程是程序运行和操作系统资源分配的基本单位，而线程是cpu调度和执行的基本单位</li>
</ul>
<h1>3. 创建线程的几种方式？√</h1>
<ul>
<li>继承Thread类并覆盖run方法</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class MyThread extends Thread {
  @Override
  public void run() {
      System.out.println(Thread.currentThread().getName() + "正在执行！");
  }
  public static void main(String[] args) {
      new MyThread("新的线程！").start();
  }
}
</code></pre></div><ul>
<li>实现Runnable接口并实现run方法</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class MyRunnable implements Runnable{
  @Override
  public void run() {
    System.out.println(Thread.currentThread().getName() + "正在执行！");
  }
  public static void main(String[] args) {
    new Thread(new MyRunnable()).start();
  }
}
</code></pre></div><ul>
<li>通过Callable和Future创建线程</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class MyCallable implements Callable&lt;Integer&gt;{
    @Override
    public Integer call() {//调用FutureTask.get()得到返回值，调用后会阻塞主进程的继续往下执行
        System.out.println(Thread.currentThread().getName() + " call()方法执行中...");
        return 1;
    }
    public static void main(String[] args) throws ExecutionException, InterruptedException{
        FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;Integer&gt;(new MyCallable());
        Thread thread = new Thread(futureTask);
        thread.start();
        System.out.println("返回结果 " + futureTask.get());
    }
}
</code></pre></div><h1>4. 线程的run和start方法有什么区别？√</h1>
<ul>
<li>start方法启动线程并使线程进入就绪状态，jvm调用该线程的run方法</li>
<li>run方法普通方法调用</li>
</ul>
<h1>5. 如何停止一个正在运行的线程？</h1>
<ul>
<li>使用volatile退出标志，使线程正常退出，也就是当run方法完成后线程终止</li>
<li>使用interrupt方法中断线程。捕获中断异常后退出线程并结束阻塞状态</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>//响应中断
public void run() {
    try {
        while (!Thread.currentThread().isInterrupted()) {
            // 执行任务
        }
    } catch (InterruptedException e) {
        // 线程被中断时的清理代码
    } finally {
        // 线程结束前的清理代码
    }
}

</code></pre></div><ul>
<li>run方法结束</li>
</ul>
<h1>6. 一个线程如果出现了运行时异常会怎么样?</h1>
<ul>
<li>如果异常没有被捕获，那么线程就停止执行了。</li>
<li>如果线程持有某个某个对象的监视器，那么这个对象监视器会被立即释放。</li>
</ul>
<h1>7. 主线程可以捕获到子线程的异常吗？√</h1>
<ul>
<li>不能。但主线程可用Thread.setDefaultUncaughtExceptionHandler(new MyUncaughtExceptionHandler())捕获子线程异常</li>
</ul>
<h1>8. 线程有哪些常用的调度方法？</h1>
<ul>
<li>在Object类中用于线程的等待与通知方法
<ul>
<li>wait()：当线程A调用共享变量的wait()方法时，线程A会被阻塞挂起，直到线程B调用了共享对象notify()或者notifyAll()方法或者其他线程调用了线程A的interrupt()方法，线程A抛出InterruptedException异常才返回。</li>
<li>wait(long timeout)：如果线程A没有在timeout时间内被其它线程唤醒，那么这个方法会因为超时而返回。</li>
<li>wait(long timeout, int nanos)，其内部调用的是 wait(long timout) 方法。</li>
<li>notify()：线程A调用共享对象的notify()方法后，会随机唤醒一个在这个共享变量上调用wait系列方法后被挂起的线程</li>
<li>notifyAll()：唤醒所有在该共享变量上调用wait系列方法而被挂起的线程。</li>
<li>join()，线程A执行了thread.join()，当前线程A会等待thread线程终止之后才从thread.join()返回</li>
</ul>
</li>
<li>线程休眠
<ul>
<li>sleep(long millis)：静态方法，让出cpu。但不释放锁。指定的睡眠时间到了后该方法会正常返回，接着参与CPU调度，获取到CPU资源后就可以继续运行。</li>
</ul>
</li>
<li>让出优先权
<ul>
<li>yield()：静态方法，让出CPU，但是有可能立马又得到CPU调度</li>
</ul>
</li>
<li>线程中断：是一种线程间的协作模式，通过设置线程的中断标志并不能直接终止该线程的执行，而是被中断的线程会根据中断状态自行处理。
<ul>
<li>void interrupt()：中断线程，设置线程的中断标志为true。并抛出InterruptedException，但不会停止线程。需要用监视线程的状态为并做处理。会使wait、join、sleep方法抛出InterruptedException，然后执行catch代码</li>
<li>isInterrupted()： 检测当前线程是否被中断。不清除标志位</li>
<li>interrupted()： 检测当前线程是否被中断，如果发现当前线程被中断，则会清除中断标志。如果一个线程被中断了，第一次调用返回true，后面返回false。当抛出InterruptedException时候，会清除中断标志位，也就是说在调用isInterrupted会返回false</li>
</ul>
</li>
</ul>
<h1>9. sleep()和wait()的区别？√</h1>
<ul>
<li>wait()是Object实例方法，sleep()方法是Thread的静态方法</li>
<li>wait()必须在同步方法或者同步块中调用(必须已获得对象锁)。否则抛出IllegalMonitorStateException异常，sleep()可以在任何地方种使用</li>
<li>wait()会让出CPU并释放占有的对象锁。sleep()会让出CPU但不会释放掉对象锁</li>
<li>wait()必须等待Object.notify/notifyAll通知或者wait()等待时间到期后，再次获得CPU时间片才会继续执行，sleep()在休眠时间达到后如果再次获得CPU时间片就会继续执行</li>
</ul>
<h1>10. 线程状态及转换？</h1>
<p>Thread源码中定义了6种状态：</p>
<ul>
<li>new:初始状态，线程被构建，还没有调用start方法</li>
<li>runnnable:运行状态，java线程将操作系统的就绪和运行两种状态统称为运行中</li>
<li>blocked:阻塞状态，表示线程阻塞与锁</li>
<li>waiting:等待状态，表示当前线程需要等待其他线程通知或者中断</li>
<li>time_waiting:超时等待状态，可以在指定时间自行返回</li>
<li>terminated:终止状态，表示线程执行完毕<br>
![threadstatus.png)</li>
</ul>
<h1>11. 什么是线程上下文切换？</h1>
<ul>
<li>线程上下文切换是指操作系统在多个线程之间切换执行时，保存当前线程的执行状态并恢复另一个线程的执行状态的过程。</li>
</ul>
<h1>12. 守护线程Daemon与用户线程User区别？</h1>
<ul>
<li>用户(User)线程：运行在前台，执行具体的任务，如连接网络的子线程、main函数所在的线程等</li>
<li>守护(Daemon)线程：运行在后台，为其他前台线程服务。在守护线程中产生的新线程也是守护线程，必须在start()之前setDaemon(true)设置为守护线程，否则会抛异常，如垃圾回收线程</li>
<li>区别:程序运行完毕，JVM会等待非守护线程完成后关闭，但不会等待守护线程完成，因此守护线程中不能依靠finally块的内容来确保执行关闭或清理资源的逻辑</li>
</ul>
<h1>13. 线程间有哪些通信方式？</h1>
<ul>
<li>volatile和synchronized关键字
<ul>
<li>volatile修饰成员变量，告知程序任何对该变量的访问均需要从共享内存中获取，而对它的改变必须同步刷新回共享内存，保证所有线程对变量访问的可见性。</li>
<li>synchronized修饰方法，或者以同步代码块的形式来使用，确保多个线程在同一个时刻，只能有一个线程在执行某个方法或某个代码块。</li>
</ul>
</li>
<li>Object等待/通知机制
<ul>
<li>一个线程调用共享对象的wait()方法时，它会进入该对象的等待池，并释放已经持有的该对象的锁，进入等待状态，直到其他线程调用相同对象的notify()或notifyAll()方法。</li>
<li>一个线程调用共享对象的notify()方法时，它会唤醒在该对象等待池中等待的一个线程，使其进入锁池，等待获取锁。</li>
</ul>
</li>
<li>ReentrantLock等待/通知机制
<ul>
<li>Condition await()负责等待、signal()和signalAll()负责通知。与锁ReentrantLock一起使用，为线程提供了一种等待某个条件成真的机制，并允许其他线程在该条件变化时通知等待线程。</li>
</ul>
</li>
<li>管道输入/输出流
<ul>
<li>主要用于线程之间的数据传输，而传输的媒介为内存。主要包括了如下4种具体实现：PipedOutputStream、PipedInputStream、PipedReader和PipedWriter，前两种面向字节，而后两种面向字符。</li>
</ul>
</li>
<li>Thread.join()
<ul>
<li>如果一个线程A执行了thread.join()语句，其含义是：当前线程A等待thread线程终止之后才从thread.join()返回。</li>
</ul>
</li>
<li>使用ThreadLocal
<ul>
<li>一种用于实现线程局部变量的工具。它允许每个线程都拥有自己的独立副本，从而实现线程隔离。用于解决多线程中共享对象的线程安全问题。</li>
</ul>
</li>
<li>CountDownLatch、CyclicBarrier、Semaphore等并发工具类。</li>
</ul>
<h1>14. 什么是线程安全？导致原因？解决线程安全问题的方法？</h1>
<ul>
<li>
<p>线程安全，指并发编程中，代码能够正确地处理多个线程对共享数据的并发访问，不会导致数据的不一致或其他不可预见的结果</p>
</li>
<li>
<p>Servlet线程不安全，Servlet单实例多线程，当多个线程同时访问同一个方法，不能保证共享变量的线程安全。</p>
</li>
<li>
<p>Struts2线程安全，Action多实例多线程，每个请求过来都会new一个新的Action处理，完成后销毁。</p>
</li>
<li>
<p>SpringMVC线程不安全，和Servlet类似</p>
</li>
<li>
<p>原因：主内存和工作内存数据不一致和重排序导致表现全局变量及静态变量同时读写引起</p>
</li>
<li>
<p>synchronized 关键字可以用于方法和代码块，确保同一时间只有一个线程可以执行特定的代码段。</p>
</li>
<li>
<p>volatile 变量保证了变量的可见性，修改操作是立即同步到主存的，读操作从主存中读取。</p>
</li>
<li>
<p>ThreadLocal 为每个线程提供了变量的独立副本，每个线程都只能访问自己的副本，从而实现了线程隔离，保证了线程安全</p>
</li>
<li>
<p>并发包（java.util.concurrent.locks）中提供了 Lock 接口和一些实现类，如 ReentrantLock。相比于 synchronized，ReentrantLock 提供了公平锁和非公平锁。</p>
</li>
<li>
<p>原子变量类（如 AtomicInteger，AtomicLong 等），它们利用 CAS（比较并交换），实现了无锁的原子操作，适用于简单的计数器场景。</p>
</li>
<li>
<p>线程安全的集合类，如 ConcurrentHashMap，CopyOnWriteArrayList 等。这些集合类内部实现了必要的同步策略，提供了更高效的并发访问。</p>
</li>
</ul>
<h1>15. ThreadLocal的理解？</h1>
<ul>
<li>线程局部变量类。使得每个线程都可以存储和访问其自己的线程局部变量，从而实现了线程间的数据隔离。避免了线程安全问题</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>private static ThreadLocal&lt;Connection&gt; connectionHolder = new ThreadLocal&lt;Connection&gt;() {
  public Connection initialValue() {
      return DriverManager.getConnection(DB_URL);
  }
};
public static Connection getConnection() {
  return connectionHolder.get();
}
</code></pre></div><h1>16. ThreadLocal 使用场景？</h1>
<ul>
<li>用户信息上下文的存储。用户登录后的每次访问接口，都会在请求头中携带一个token，在控制层可以根据这个token，解析出用户的基本信息。在控制层拦截请求把用户信息存入ThreadLocal，这样在任何地方都可以取出ThreadLocal中的用户数据</li>
<li>线程级单例</li>
<li>为每个线程分配一个JDBC连接。保证每个线程的都在各自的JDBC连接上进行数据库的操作，不会出现A线程关了B线程正在使用的JDBC连接</li>
<li>tomcat处理请求</li>
<li>session、cookie管理</li>
</ul>
<h1>17. ThreadLocal怎么实现的呢？</h1>
<ul>
<li>ThreadLocal 通过为每个线程提供一个独立的 ThreadLocalMap 来实现线程间的数据隔离，ThreadLocalMap 是 ThreadLocal静态内部类，ThreadLocalMap内部维护着Entry数组，每个Entry代表一个完整的对象，key是ThreadLocal的弱引用，value是ThreadLocal的泛型值。Entry 继承了 WeakReference，因此 key 是一个弱引用，当一个线程调用 ThreadLocal的set或get方法时，实际上是访问线程自己的ThreadLocal.ThreadLocalMap</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class ThreadLocal&lt;T&gt; {
  public T get() {
      Thread t = Thread.currentThread();
      ThreadLocalMap map = getMap(t);
      if (map != null) {
          ThreadLocalMap.Entry e = map.getEntry(this);
          if (e != null) {
              @SuppressWarnings("unchecked")
              T result = (T)e.value;
              return result;
          }
      }
      return setInitialValue();
  }
  public void set(T value) {
      //获取当前线程
      Thread t = Thread.currentThread();
      //获取ThreadLocalMap
      ThreadLocalMap map = getMap(t);
      //将当前元素存入map
      if (map != null)
          map.set(this, value);
      else
          createMap(t, value);
  }
  ThreadLocalMap getMap(Thread t) {
      return t.threadLocals;
  }
  static class ThreadLocalMap {
    static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; {
        Object value;
        Entry(ThreadLocal&lt;?&gt; k, Object v) {
            super(k);
            value = v;
        }
    }
    private Entry[] table;
  }
}
public class Thread implements Runnable {
  //ThreadLocal.ThreadLocalMap是Thread的属性
  ThreadLocal.ThreadLocalMap threadLocals = null;
}
public class WeakReference&lt;T&gt; extends Reference&lt;T&gt; {
  public WeakReference(T referent) {
      super(referent);
  }
}
</code></pre></div><h1>18. 为什么key设计成弱引用？</h1>
<ul>
<li>为了防止内存泄漏。保证线程结束jvm垃圾回收时、或者内存不足时回收key。一旦 key 被回收，ThreadLocalMap 在进行 set、get 的时候就会对 key 为 null 的 Entry 进行清理。避免内存泄漏</li>
</ul>
<h1>19. ThreadLocal内存泄露问题及解决方案？</h1>
<ul>
<li>ThreadLocal的私有属性ThreadLocalMap中使用的key为ThreadLocal实例，弱引用,而value是强引用。通常情况下，随着线程 Thread 的结束，其内部的 ThreadLocalMap 也会被回收，从而避免了内存泄漏。但如果一个线程一直在运行，并且其 ThreadLocalMap 中的 Entry.value 一直指向某个强引用对象，那么这个对象就不会被回收，从而导致内存泄漏。当 Entry 非常多时，可能就会引发更严重的内存溢出问题。</li>
<li>每次使用完ThreadLocal，都finally调用它的remove()方法，清除数据。</li>
</ul>
<h1>20. ThreadLocalMap的结构？</h1>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/9c42c9f380bcb496ccaae.png" alt="threadlocalmapstructure.png" tabindex="0"><figcaption>threadlocalmapstructure.png</figcaption></figure>
<ul>
<li>元素数组:存储Entry类型的元素的数组，Entry 是 ThreaLocal 弱引用作为 key，Object 作为 value 的结构。</li>
<li>散列方法:哈希取余法取出 key 的 threadLocalHashCode，然后和 table 数组长度减一&amp;运算（相当于取余）。把对应的key映射到table 数组的相应下标int i = key.threadLocalHashCode &amp; (table.length - 1);每创建一个ThreadLocal对象，threadLocalHashCode就会新增0x61c88647，它是斐波那契数。好处是 hash 分布非常均匀。</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>private static final int HASH_INCREMENT = 0x61c88647;

private static int nextHashCode() {
    return nextHashCode.getAndAdd(HASH_INCREMENT);
}
</code></pre></div><h1>21. ThreadLocalMap怎么解决Hash冲突</h1>
<ul>
<li>开放定址法:
<ul>
<li>插入数据时通过hash计算后得到数组下标，如果对应位置已经有数据，而且Entry数据的key和当前不相等。就会线性向后查找，一直找到Entry为null的槽位才会停止查找，把元素放到空的槽中。</li>
<li>在获取数据时也会根据ThreadLocal对象的hash值，定位到table中的位置，然后判断该槽位Entry对象中的key是否和get的key一致，如果不一致，就判断下一个位置</li>
</ul>
</li>
</ul>
<h1>22. ThreadLocalMap扩容机制？</h1>
<ul>
<li>在ThreadLocalMap.set()最后，如果执行完启发式清理工作后，未清理到任何数据，且当前散列数组中Entry的数量已经达到了列表的扩容阈值(len*2/3)，就开始执行rehash()逻辑：</li>
<li>rehash()会先去清理过期的Entry，然后还要根据条件判断size &gt;= threshold* 3/4来决定是否需要扩容。</li>
<li>resize()扩容后的newTab的大小为老数组的两倍，然后遍历老的table数组，散列方法重新计算位置，开放地址解决冲突，然后放到新的newTab，遍历完成之后，oldTab中所有的entry数据都已经放入到newTab中了，然后table引用指向newTab</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold)
    rehash();
private void rehash() {
    //清理过期Entry
    expungeStaleEntries();

    //扩容
    if (size &gt;= threshold - threshold / 4)
        resize();
}

//清理过期Entry
private void expungeStaleEntries() {
    Entry[] tab = table;
    int len = tab.length;
    for (int j = 0; j &lt; len; j++) {
        Entry e = tab[j];
        if (e != null &amp;&amp; e.get() == null)
            expungeStaleEntry(j);
    }
}
</code></pre></div><figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/73d10d14f94df858737e5.png" alt="javathreadlocalresize.png" tabindex="0"><figcaption>javathreadlocalresize.png</figcaption></figure>
<h1>23. 父子线程怎么共享数据？</h1>
<ul>
<li>父线程使用InheritableThreadLocal来给子线程传值</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class InheritableThreadLocalTest {
    public static void main(String[] args) {
        final ThreadLocal threadLocal = new InheritableThreadLocal();
        // 主线程
        threadLocal.set("不擅技术");
        //子线程
        Thread t = new Thread() {
            @Override
            public void run() {
                super.run();
                System.out.println("鄙人三某 ，" + threadLocal.get());
            }
        };
        t.start();
    }
}
</code></pre></div><ul>
<li>原理？在 Thread 类里还有另外一个变量inheritableThreadLocals。在Thread.init的时候，如果父线程的inheritableThreadLocals不为空，就把它赋给当前线程（子线程）的inheritableThreadLocals 。</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class Thread {
  ThreadLocal.ThreadLocalMap inheritableThreadLocals = null;
}

if (inheritThreadLocals &amp;&amp; parent.inheritableThreadLocals != null)
    this.inheritableThreadLocals =
        ThreadLocal.createInheritedMap(parent.inheritableThreadLocals);
</code></pre></div><h1>24. 什么是JMM内存模型？</h1>
<ul>
<li>
<p>Java内存模型（Java Memory Model,JMM）是一种抽象的模型.主要用来定义多线程中变量的访问规则，用来解决变量的可见性、有序性和原子性问题，确保在并发环境中安全地访问共享变量。</p>
</li>
<li>
<p>JMM规定共享变量存储在主内存（Main Memory）中。每条线程都有私有的本地内存（Local Memory），本地内存中存储了共享变量的副本，线程对变量的所有操作（读取、赋值等）都必须在本地内存中进行，而不能直接读写主内存中的变量。不同的线程之间也无法直接访问对方本地内存中的变量，线程间的变量值的传递均需要通过主内存来完成。因此线程之间的变量变得不可见</p>
</li>
<li>
<p>当一个线程更改了本地内存中共享变量的副本后，它需要将这些更改刷新到主内存中，以确保其他线程可以看到这些更改。</p>
</li>
<li>
<p>当一个线程需要读取共享变量时，它可能首先从本地内存中读取。如果本地内存中的副本是过时的，线程将从主内存中重新加载共享变量的最新值到本地内存中。</p>
</li>
<li>
<p>本地内存是JMM中的抽象概念，并不真实存在。实际上，本地内存可能对应于CPU缓存、寄存器或者其他硬件和编译器优化。</p>
</li>
<li>
<p>对于多核CPU的系统架构，每个核包括ALU计算单元+PC+Registers(寄存器)+L1缓存+L2缓存，同一个CPU所有核共享L3缓存，还有除CPU外的主存(按块8字节（缓存行）将L3读入到内存),缓存的目的就是为了提高性能，避免每次都要向主内存取（具体指缓存行的状态Modified、Exclusive、Shared、Invalid）为了提高存取效率需要缓存行对齐。JMM的本地内存可能对应的L1、L2、L3缓存或者CPU寄存器。<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/36e655d8c884c2fc1727a.jpg" alt="multicorecpuarchitecture.png"><br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/20ce26451ceb038b9daac.png" alt="JMM内存模型JMM.png"></p>
</li>
<li>
<p>为什么线程要用自己的内存？</p>
<ul>
<li>多线程环境中，如果所有线程都直接操作主内存中的共享变量，会引发更多的内存访问竞争，这不仅影响性能，还增加了线程安全问题的复杂度。通过让每个线程使用本地内存，可以减少对主内存的直接访问和竞争，提高程序的并发性能</li>
<li>现代CPU为了优化执行效率，可能会对指令重排序。使用本地内存（CPU 缓存和寄存器）可以在不影响最终执行结果的前提下，提高执行效率。</li>
</ul>
</li>
</ul>
<h1>25. 在 Java 程序中怎么保证多线程的运行安全和并发编程三要素?</h1>
<ul>
<li>原子性：一个操作是不可分割、不可中断的，要么全部执行并且执行的过程不会被任何因素打断，要么就全不执行(线程切换引起:synchronized,LOCK,原子类)</li>
<li>可见性：一个线程修改了某一个共享变量的值时，其它线程能够立即知道这个修改。（工作内存和主内存不一致引起synchronized,volatile,LOCK,final）</li>
<li>有序性：对于一个线程的执行代码，从前往后依次执行，单线程下可以认为程序是有序的，但是并发时有可能会发生指令重排。(重排序引起synchronized,volatile,LOCK)</li>
</ul>
<p>编译优化-处理器可能会对指令进行重排序</p>
<h1>26. 什么是指令重排？</h1>
<ul>
<li>在执行程序时，为了提高性能，处理器和编译器常常会对指令进行重排序，分类如下
<ul>
<li>编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序；JMM的编译器重排序规则会禁止特定类型的编译器重排序</li>
<li>指令级并行的重排序。现代处理器采用了指令级并行技术ILP来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序；</li>
<li>内存系统的重排序。由于处理器使用缓存和读/写缓冲区，使得加载和存储操作看上去可能是在乱序执行的</li>
</ul>
</li>
<li>从Java源代码到最终实际执行的指令序列，经历3种重排序，源代码-&gt;编译器优化重排序-&gt;指令级并行重排序-&gt;内存系统重排序-&gt;最终执行的指令序列。重排序可能会导致多线程程序出现内存可见性问题</li>
<li>双重校验单例模式：Singleton instance=new Singleton()对应的JVM指令分为三步：分配内存空间-&gt;初始化对象-&gt;对象指向分配的内存空间，经过编译器指令重排序，第二、第三步就可能会重排序。<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/b2a1c6c49d8b99afb099f.png" alt="doublecheckerror.png"></li>
</ul>
<h1>27. 指令重排有限制吗？happens-before 了解吗？</h1>
<ul>
<li>happens-before保证多线程情况下指令重排序后程序正确性和内存的可见性</li>
<li>happens-before定义:
<ul>
<li>如果一个操作happens-before另一个操作，那么第一个操作的执行结果将对第二个操作可见.而且第一个操作的执行顺序在第二个操作之前</li>
<li>两个操作之间存在happens-before关系，并不意味着一定要按照happens-before原则制定的顺序来执行。只需重排序之后的执行结果与happens-before关系来执行的结果一致</li>
</ul>
</li>
<li>规则
<ul>
<li>程序次序规则（Program Order Rule）：在一个线程内，按照程序代码顺序，书写在前面的操作先行发生于书写在后面的操作</li>
<li>监视器锁定规则（Monitor Lock Rule）：一个锁的unlock操作happens-before对同一个锁的lock操作。</li>
<li>volatile变量规则（Volatile Variable Rule）：对一个volatile变量的写操作happens-before后面对这个变量的读操作，可以看成对变量读写加了锁</li>
<li>线程启动规则（Thread Start Rule）：Thread对象的start()方法happens-before此线程的每一个动作。保证释放锁和获取锁的两个线程之间的内存可见性</li>
<li>线程终止规则（Thread Termination Rule）：线程中的所有操作happens-before对此线程的终止检测，可通过Thread.join()方法结束、Thread.isAlive()的返回值等手段检测到线程已经终止执行。</li>
<li>线程中断规则（Thread Interruption Rule）：对线程interrupt()方法的调用happens-before被中断线程的代码检测到中断事件的发生，可通过Thread.interrupted()方法检测到是否有中断发生。</li>
<li>对象终结规则（Finalizer Rule）：一个对象的初始化完成（构造函数执行结束）happens-before它的finalize()方法的开始</li>
<li>传递性（Transitivity）：如果操作A happens-before B，B happens-before C，可以得出A happens-before C</li>
<li>join()规则：如果线程 A 执行操作 ThreadB.join()并成功返回，那么线程 B 中的任意操作 happens-before 于线程 A 从 ThreadB.join()操作成功返回</li>
</ul>
</li>
</ul>
<h1>28. as-if-serial又是什么？单线程的程序一定是顺序的吗？</h1>
<ul>
<li>as-if-serial保证单线程情况下指令重排序后程序正确性和内存的可见性</li>
<li>as-if-serial语义:不管怎么重排序，单线程程序的执行结果不变。编译器、runtime和处理器都必须遵守</li>
<li>为了遵守 as-if-serial 语义，存在数据依赖关系的不允许重排序</li>
</ul>
<h1>29. volatile关键字?√</h1>
<ul>
<li>保证可见性：确保对某个变量的更新对其他线程马上可见，一个变量被声明为volatile时，线程在写入变量时不会把值缓存在寄存器或者其他地方，而是会把值刷新回主内存 当其它线程读取该共享变量，会从主内存重新获取最新值，而不是使用当前线程的本地内存中的值，无上下文切换和调度，不会造成线程阻塞.</li>
<li>有序性：禁止编译器和处理器重排序;</li>
<li>原子性：部分原子性：volatile修饰long和double可以保证其操作原子性；volatile类型的引用的改变是原子性的，如果引用是数组/对象，修改数组元素/对象属性不是原子性的，</li>
<li>volatile 常用于多线程环境下的单次操作(单次读或者单次写)。</li>
<li>常用场景：状态标记变量（停止线程）、单例禁止重排序双重检查</li>
</ul>
<h1>30. volatile怎么保证可见性?</h1>
<ul>
<li>JVM实现通过对有volatile关键字的变量时，编译时在汇编代码中加入lock前缀指令（lock addl）锁住缓存行，引起处理器CPU缓存行的数据写回内存并导致其他处理器的缓存失效（处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期）。当处理器发现本地缓存失效后，就会从内存中重读该变量数据，即可以获取当前最新值（一次读取64字节缓存行）其实就相当于一个内存屏障（一组处理指令），用来实现对内存操作的顺序限制。内存屏障使用sfence mfence lfence等系统原语或者锁总线实现</li>
</ul>
<h1>31. volatile怎么保证有序性?</h1>
<ul>
<li>valatile限制编译器和处理器重排序<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/76465270e62b6e41c4af9.png" alt="reorder.png"></li>
<li>为了实现 volatile 的内存语义，编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序，强制把写缓冲区/高速缓存中的脏数据等写回主内存
<ul>
<li>①在每个 volatile 写操作的前面插入一个 StoreStore 屏障（禁止volatile写/普通写与volatile写重排序）</li>
<li>②在每个 volatile 写操作的后面插入一个 StoreLoad 屏障（禁止volatile写-volatile读）</li>
<li>③在每个 volatile 读操作的后面插入一个 LoadLoad 屏障（禁止volatile读与后面的读操作重排序）</li>
<li>④在每个 volatile 读操作的后面插入一个 LoadStore 屏障（禁止volatile读与后面的写操作重排序）</li>
<li>为什么少了普通读--volatile写禁止重排序？（volatile写前LoadStore屏障）因为一个是普通变量读，一个是volatile的读\写，两个变量之间本身不存在数据依赖与竞态条件； 普通变量写。因为普通变量读与普通变量写之间没有happens-before规则，所以会有竞态条件。但是volatile的写操作的内存语义与释放锁相同，即会刷新该线程的写缓冲到内存中，而普通变量读根本不涉及到写缓冲，所以即使重排序了也不会破坏volatile的内存语义。<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/ed5d433a7450dbaf88e23.jpg" alt="memorybarrier.png"></li>
</ul>
</li>
</ul>
<h1>32. 线程同步</h1>
<ul>
<li>如果多个线程同时读写某个共享资源（如变量、文件等），而没有适当的同步机制，就可能导致数据不一致、数据损坏等问题出现</li>
<li>线程同步的实现方式
<ul>
<li>互斥量（mutex）：本质上是一把锁，在访问共享资源前先对互斥量进行加锁，访问完后再解锁。对互斥量加锁后，任何其他试图再次对互斥量加锁的线程都会被阻塞，直到当前线程解锁。</li>
<li>读写锁：有三种状态，读模式加锁、写模式加锁和不加锁；一次只有一个线程可以占有写模式的读写锁，但是可以有多个线程同时占有读模式的读写锁。适合读多写少的场景。</li>
<li>条件变量：允许线程在满足特定条件时才继续执行，否则进入等待状态。条件变量通常与互斥量一起使用，防止竞争条件的发生</li>
<li>自旋锁：一种锁的实现方式，它不会让线程进入睡眠状态，而是一直循环检测锁是否被释放。自旋锁适用于锁的持有时间非常短的情况。</li>
<li>信号量（Semaphore）：本质上是一个计数器，用于为多个进程提供共享数据对象的访问。</li>
</ul>
</li>
</ul>
<h1>33. synchronized关键字</h1>
<ul>
<li>非公平锁、悲观锁、互斥锁</li>
<li>当一个线程访问某对象的 synchronized 方法或代码块时，其他线程对该对象的所有 synchronized 方法或代码块的访问将被阻塞，直到第一个线程完成操作。</li>
<li>synchronized关键字属于互斥量，它保证了同一时间只有一个线程可以访问共享资源。</li>
<li>synchronized保证原子性、可见性（锁释放会把数据刷回到主存）、有序性</li>
</ul>
<h1>34. synchronized锁类和静态方法的锁对象区别？</h1>
<ul>
<li>同步代码块synchronized (实例对象/this/xxx.class) {} 锁对象是指定的实例对象/类</li>
<li>同步方法synchronized void method(){} 锁对象是当前实例对象</li>
<li>静态同步方法public static synchronized void method(){}锁对象是当前Class类</li>
<li>注意事项
<ul>
<li>锁对象属性变化不影响，引用改变影响，一般设置为final</li>
<li>锁对象不能用字符串常量，可能与类库使用同一把锁</li>
</ul>
</li>
</ul>
<h1>35. synchronized同步代码、静态同步方法原理？</h1>
<ul>
<li>同步代码块原理：使用jvm的字节码指令monitorenter和monitorexit，monitorenter指令是在编译后插入到同步代码块的开始位置，而monitorexit是插入到方法结束处和异常处，JVM保证每个monitorenter必须有对应的monitorexit与之配对。依赖于底层的操作系统的Mutex Lock来实现，需要将当前线程挂起并从用户态切换到内核态来执行，效率低。jvm保证每个对象的都有Monitor监视器（Java任意对象都可以作为锁的原因），一个线程执行同步代码块，首先尝试获取monitor的持有权。当线程尝试获取锁的时候，如果获取不到锁会一直阻塞。如果获取对象锁失败，那当前线程就要阻塞等待，直到锁被另外一个线程释放为止、如果获取锁的线程进入休眠或者阻塞，除非当前线程异常，否则其他线程尝试获取锁必须一直等待。在执行完代码块之后，执行monitorexit释放锁。最后一个monitorexit是保证在异常情况下，锁也可以得到释放，避免死锁.<br>
<code>javap -c -s -v -l SynchronizedDemo.class</code><br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/567a83434eb62881d322b.png" alt="javamonitorenter.png"></li>
<li>静态/普通同步方法原理：依靠方法修饰符ACC_SYNCHRONIZED， 具体是在Class文件的方法表中将该方法的access_flags字段中的synchronized标志位置设置为1，表示该方法是同步方法，并使用调用该方法的对象或该方法所属的Class在JVM的内部对象表示Klass(类在HotSpot中的c++对等体)作为锁对象。<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/06ab05afe794f6421797d.png" alt="javaaccsynchornized.png"></li>
<li>monitorenter、monitorexit或者ACC_SYNCHRONIZED 都是基于Monitor实现。
<ul>
<li>实例对象结构里有对象头，对象头里面有一块结构叫Mark Word，Mark Word指针指向了monitor。</li>
<li>Monitor其实是一种同步机制。在Java虚拟机HotSpot中，Monitor是由ObjectMonitor实现</li>
</ul>
</li>
<li>ObjectMonitor工作原理
<ul>
<li>ObjectMonitor有两个队列：_WaitSet、_EntryList，用来保存ObjectWaiter对象列表；</li>
<li>_owner，获取Monitor对象的线程进入_owner区时，_count+1。如果线程调用了wait()方法，此时会释放Monitor 对象，_owner恢复为空， _count-1。同时该等待线程进入_WaitSet 中，等待被唤醒。</li>
</ul>
</li>
<li>monitorenter在判断拥有同步标识ACC_SYNCHRONIZED抢先进入此方法的线程会优先拥有Monitor的owner，此时计数器+1</li>
<li>monitorexit当执行完退出后计数器-1，归0后被其他进入的线程获得。</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>ObjectMonitor() {
    _header       = NULL;
    _count        = 0; // 记录线程获取锁的次数
    _waiters      = 0,
    _recursions   = 0;  //锁的重入次数
    _object       = NULL;
    _owner        = NULL;  // 指向持有ObjectMonitor对象的线程
    _WaitSet      = NULL;  // 处于wait状态的线程，会被加入到_WaitSet
    _WaitSetLock  = 0 ;
    _Responsible  = NULL ;
    _succ         = NULL ;
    _cxq          = NULL ;
    FreeNext      = NULL ;
    _EntryList    = NULL ;  // 处于等待锁block状态的线程，会被加入到该列表
    _SpinFreq     = 0 ;
    _SpinClock    = 0 ;
    OwnerIsThread = 0 ;
  }

</code></pre></div><h1>36. synchronized 怎么保证可见性？</h1>
<ul>
<li>线程加锁前，将清空工作内存中共享变量的值，从而使用共享变量时需要从主内存中重新读取最新的值。</li>
<li>线程加锁后，其它线程无法获取主内存中的共享变量</li>
<li>线程解锁前，把共享变量的最新值刷新到主内存中</li>
</ul>
<h1>37. synchronized 怎么保证有序性？</h1>
<ul>
<li>synchronized 同步的代码块，具有排他性，一次只能被一个线程拥有，所以 synchronized 保证同一时刻，代码是单线程执行的。因为 as-if-serial 语义的存在，单线程的程序能保证最终结果是有序的，但是不保证不会指令重排。所以 synchronized 保证的有序是执行结果的有序性，而不是防止指令重排的有序性。</li>
</ul>
<h1>38. synchronized 怎么实现可重入的呢？</h1>
<ul>
<li>synchronized 是可重入锁，允许一个线程二次请求自己持有对象锁的临界资源。</li>
<li>因为 synchronized 锁对象有个计数器，会随着线程获取锁后 +1 计数，当线程执行完毕后 -1，直到清零释放锁。</li>
</ul>
<h1>39. synchronized锁升级原理？</h1>
<ul>
<li>在Java对象头里的Mark Word记录对象自身的运行数据，如哈希码、GC 分代年龄、锁状态标志、偏向时间戳（Epoch）等。其中的锁状态标志位就是用来记录锁的状态的</li>
<li>jdk1.6中为了减少获得锁和释放锁带来的性能消耗而引入的偏向锁和轻量级锁</li>
<li>无锁-&gt;偏向锁-&gt;轻量级锁-&gt;重量级锁（执行过程自动升级 更低层 lock comxchg）(堆)</li>
<li>无锁：没有线程试图获取锁</li>
<li>偏向锁:当第一个线程访问同步块时，锁会进入偏向模式.Mark Word 会被设置为偏向模式，并且存储了获取它的线程 ID.为了消除同一线程的后续锁获取和释放的开销。如果同一线程再次请求锁，就无需再次同步。
<ul>
<li><strong>获取偏向锁</strong>
<ul>
<li>1.检测对象头中Mark Word是否为可偏向状态（偏向锁的标识位为1，锁标识位为01）</li>
<li>2.若为可偏向状态，则测试线程ID是否为当前线程ID？如果是则执行步骤（5）；否则，执行步骤（3）。</li>
<li>3.如果线程ID不为当前线程ID，则通过CAS操作竞争锁。成功则将Mark Word的线程ID替换为当前线程ID，则执行步骤（5）；否则执行步骤（4）。</li>
<li>4.通过CAS竞争锁失败，证明当前存在多线程竞争情况，当到达全局安全点，获得偏向锁的线程被挂起，偏向锁升级为轻量级锁，然后被阻塞在安全点的线程继续往下执行同步代码块。</li>
<li>5.执行同步代码块</li>
</ul>
</li>
<li>偏向锁撤销：偏向锁使用了等到竞争出现才释放锁的机制，所以当其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁。需要等待全局安全点（在这个时间点上没有正在执行的字节码）
<ul>
<li>首先暂停拥有偏向锁的线程，然后检查持有偏向锁的线程是否活着</li>
<li>如果线程不处于活动状态，则将对象头设置成无锁状态</li>
<li>如果线程仍然活着，拥有偏向锁的栈会被执行，遍历偏向对象的锁记录，栈中的锁记录和对象头的Mark Word要么重新偏向于其他线程，要么恢复到无锁或者标记对象不适合作为偏向锁，最后唤醒暂停的线程，被阻塞在安全点的线程继续往下执行同步代码块</li>
</ul>
</li>
<li>偏向锁注意事项
<ul>
<li>优势：偏向锁只需要在置换ThreadID的时候依赖一次CAS原子指令，其余时刻不需要CAS指令(相比其他锁)</li>
<li>隐患：由于一旦出现多线程竞争的情况就必须撤销偏向锁，所以偏向锁的撤销操作的性能损耗必须小于节省下来的CAS原子指令的性能消耗（这个通常只能通过大量压测才可知）</li>
<li>对比：轻量级锁是为了在线程交替执行同步块时提高性能，而偏向锁则是在只有一个线程执行同步块时进一步提高性能</li>
</ul>
</li>
</ul>
</li>
<li>轻量级锁：当有多个线程竞争锁，但没有锁竞争的强烈迹象（即线程交替执行同步块）时，偏向锁会升级为轻量级锁。
<ul>
<li><strong>JVM会先在当前线程的栈桢中创建用于存储锁记录的空间Lock Record，并将对象头中的Mark Word复制到锁记录中，官方称为Displaced Mark Word。然后线程尝试使用CAS将对象头中的Mark Word替换为指向锁记录的指针。如果成功，当前线程获得锁，如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。当一个线程旋超过10次，或者自旋线程数超过CPU核数的一半，如果还没有正常获取到要使用的对象，此时就会把锁从轻量级升级为重量级锁</strong></li>
<li>轻量级解锁时，会使用原子的CAS操作将Displaced Mark Word替换回到对象头，如果成功，则表示没有竞争发生。如果失败，表示当前锁存在竞争，锁就会膨胀成重量级锁。需要在释放锁的同时唤醒被阻塞的线程，之后线程间要根据重量级锁规则重新竞争重量级锁、因为自旋会消耗CPU，为了避免无用的自旋（比如获得锁的线程被阻塞住了），一旦锁升级成重量级锁，就不会再恢复到轻量级锁状态。当锁处于这个状态下，其他线程试图获取锁时，都会被阻塞住，当持有锁的线程释放锁之后会唤醒这些线程，被唤醒的线程就会进行新一轮的夺锁之争</li>
</ul>
</li>
<li>重量级锁：当锁竞争激烈时，轻量级锁会膨胀为重量级锁。效率低，由操作系统的Mutex Lock实现，如果要挂起或者唤醒一个线程，都需要操作系统帮忙完成，而操作系统实现线程之间的切换时需要从用户态转换到内核态，时间成本高。重量级锁通过将对象头的 Mark Word 指向监视器（Monitor）对象来实现，该对象包含了锁的持有者、锁的等待队列等信息。</li>
<li>锁的优缺点对比
<ul>
<li>偏向锁：加锁和解锁不需要额外的消耗，和执行非同步方法相比仅存在纳秒级的差距。如果线程间存在锁竞争，会带来额外的锁撤销的消耗。适用于只有一个线程访问同步块的场景</li>
<li>轻量级锁：线程竞争不阻塞，提高了程序的响应速度，得不到锁的线程自旋会消耗CPU，适用于追求响应时间响应速度。同步块执行速度非常快</li>
<li>重量级锁：线程竞争不自旋、不消耗CPU；线程阻塞，响应时间慢。适用于追求吞吐量。同步块执行速度较长<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/b0a1f7d7ac59d447ff05f.png" alt="64bithotSpotmarkword.png"></li>
</ul>
</li>
</ul>
<h1>40. synchronized 做了哪些优化？</h1>
<ul>
<li>偏向锁：当一个线程首次获得锁时，JVM 会将锁标记为偏向这个线程，将锁的标志位设置为偏向模式，并且在对象头中记录下该线程的 ID。之后，当相同的线程再次请求这个锁时，就无需进行额外的同步。如果另一个线程尝试获取这个锁，偏向模式会被撤销，并且锁会升级为轻量级锁。</li>
<li>轻量级锁：多个线程在不同时段获取同一把锁，即不存在锁竞争的情况，也就没有线程阻塞。针对这种情况，JVM 采用轻量级锁来避免线程的阻塞与唤醒。当一个线程尝试获取轻量级锁时，它会在自己的栈帧中创建一个锁记录（Lock Record），然后尝试使用 CAS 操作将对象头的 Mark Word 替换为指向锁记录的指针。如果成功，该线程持有锁；如果失败，表示有其他线程竞争，锁会升级为重量级锁。</li>
<li>自旋锁：当线程尝试获取轻量级锁失败时，它会进行自旋，即循环检查锁是否可用，以避免立即进入阻塞状态。自旋的次数不是固定的，而是根据之前在同一个锁上的自旋时间和锁的状态动态调整的。</li>
<li>锁粗化：如果 JVM 检测到一系列连续的锁操作实际上是在单一线程中完成的，则会将多个锁操作合并为一个更大范围的锁操作，这可以减少锁请求的次数。锁粗化主要针对循环内连续加锁解锁的情况进行优化。</li>
<li>锁消除：JVM的即时编译器（JIT）可以在运行时进行代码分析，如果发现某些锁操作不可能被多个线程同时访问，那么锁操作就会被消除。减少不必要的同步开销</li>
</ul>
<h1>41. synchronized和ReenTrantLock异同？√</h1>
<ul>
<li>都是可重入锁</li>
<li>用法不同：synchronized是关键字，可修饰方法、代码块，无需手动释放锁。ReentrantLock是类，调用tryLock和lock方法，需要在finally块中释放锁</li>
<li>功能特点不同：synchronized只支持非公平锁，ReentrantLock提供公平锁和非公平锁、等待可中断、选择性通知（锁可以绑定多个条件）等特性</li>
<li>synchronized发生异常时自动释放锁，故不会死锁。Lock发生异常，若没有主动释放，有死锁，故需在finally中调用unLock方法释放锁</li>
<li>实现机制不同：synchronized通过Java对象头锁标记和Monitor对象实现同步。ReentrantLock通过CAS、AQS（AbstractQueuedSynchronizer）和 LockSupport（用于阻塞和解除阻塞）实现同步。</li>
<li>可见性实现机制不同：synchronized依赖JVM内存模型保证包含共享变量的多线程内存可见性。ReentrantLock通过AQS的volatile state保证包含共享变量的多线程内存可见性</li>
<li>ReentrantLock 可以实现多条件通知（可以绑定多个 Condition），而 synchronized 只能通过 wait 和 notify/notifyAll 方法唤醒一个线程或者唤醒全部线程（单条件通知）；</li>
</ul>
<h1>42. AQS了解多少？</h1>
<ul>
<li>AbstractQueuedSynchronizer抽象同步队列，简称AQS。并发包中的锁就是基于AQS实现。</li>
<li>AQS是基于一个FIFO的双向队列，其内部定义了一个节点类Node，Node节点内部的SHARED用来标记该线程是获取共享资源时被阻挂起后放入AQS队列的，EXCLUSIVE用来标记线程是取独占资源时被挂起后放入AQS队列</li>
<li>AQS使用一个volatile修饰的int类型的成员变量state来表示同步状态，修改同步状态成功即为获得锁，volatile保证了变量在多线程之间的可见性，修改State值时通过CAS机制来保证修改的原子性</li>
<li>获取state的方式分为两种，独占方式和共享方式，一个线程使用独占方式获取了资源，其它线程就会在获取失败后被阻塞。一个线程使用共享方式获取了资源，另外一个线程还可以通过CAS的方式进行获取。</li>
<li>如果共享资源被占用，需要一定的阻塞等待唤醒机制来保证锁的分配，AQS中会将竞争共享资源失败的线程添加到一个变体的CLH队列中</li>
<li>AQS中的队列是CLH变体的虚拟双向队列，通过将每条请求共享资源的线程封装成一个节点来实现锁的分配：拥有以下特性：
<ul>
<li>AQS中队列是个双向链表，FIFO先进先出</li>
<li>通过Head、Tail头尾两个节点来组成队列结构，通过volatile修饰保证可见性</li>
<li>Head指向节点为已获得锁的节点，是一个虚拟节点，节点本身不持有具体线程</li>
<li>获取不到同步状态，会将节点进行自旋获取锁，自旋一定次数失败后会将线程阻塞</li>
<li>解锁时唤醒后继节点</li>
</ul>
</li>
</ul>
<h1>43. ReentrantLock实现原理？</h1>
<ul>
<li>ReentrantLock是可重入的独占锁，只能有一个线程可以获取该锁，其它获取该锁的线程会被阻塞。可重入表示同一个线程可以多次获得同一个锁而不会发生死锁。</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>//创建非公平锁
ReentrantLock lock=new ReentrantLock();
//获取锁操作
lock.lock();
try{
//执行代码逻辑
}catch(Exceptionex){
//...
}finally{
//解锁操作
lock.unlock();
}
</code></pre></div><ul>
<li>在公平锁模式下，锁会授予等待时间最长的线程。在非公平锁模式下，锁可能会授予刚刚请求它的线程，而不考虑等待时间。</li>
<li>ReentrantLock内部通过一个计数器来跟踪锁的持有次数。
<ul>
<li>当线程调用lock()方法获取锁时，ReentrantLock会检查当前状态，判断锁是否已经被其他线程持有。如果没有被持有，则当前线程将获得锁；如果锁已被其他线程持有，则当前线程将根据锁的公平性策略，可能会被加入到等待队列中。</li>
<li>线程首次获取锁时，计数器值变为1；如果同一线程再次获取锁，计数器增加；每释放一次锁，计数器减1。</li>
<li>当线程调用unlock()方法时，ReentrantLock会将持有锁的计数减1，如果计数到达0则释放锁，并唤醒等待队列中的线程来竞争锁</li>
</ul>
</li>
</ul>
<h1>44. ReentrantLock 怎么实现公平锁的？</h1>
<ul>
<li>new ReentrantLock()</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>//构造方法默认创建的是非公平锁 NonfairSync
public ReentrantLock() {
    sync = new NonfairSync();
}
//创建锁构造方法中传入具体参数创建公平锁 FairSync
ReentrantLock lock = new ReentrantLock(true);

// true 代表公平锁，false 代表非公平锁
//FairSync、NonfairSync 代表公平锁和非公平锁，两者都是 ReentrantLock 静态内部类，只不过实现不同锁语义。
public ReentrantLock(boolean fair) {
    sync = fair ? new FairSync() : new NonfairSync();
}
</code></pre></div><ul>
<li>非公平锁和公平锁的两处不同：
<ul>
<li>非公平锁在调用 lock 后，首先就会调用 CAS 进行一次抢锁，如果这个时候恰巧锁没有被占用，那么直接就获取到锁返回了。</li>
<li>非公平锁在 CAS 失败后，和公平锁一样都会进入到 tryAcquire 方法，在 tryAcquire 方法中，如果发现锁这个时候被释放了（state == 0），非公平锁会直接 CAS 抢锁，但是公平锁会判断等待队列是否有线程处于等待状态，如果有则不去抢锁，乖乖排到后面。</li>
</ul>
</li>
<li>非公平锁性能更好，因为吞吐量大。但非公平锁让获取锁的时间变得更加不确定，阻塞队列中的线程可能长期处于饥饿状态</li>
<li>怎么实现一个非公平锁呢？只需要在创建ReentrantLock实例时，不传递任何参数或者传递false给构造方法。</li>
</ul>
<h1>45. 什么是cas?</h1>
<ul>
<li>CAS叫做CompareAndSwap，⽐较并交换，是一个无锁的原子操作。CAS操作包含3个参数：共享变量的内存地址A、预期的值B和共享变量的新值C。只有当内存中地址A处的值等于B时，才能将内存中地址A处的值更新为新值C。</li>
<li>synchronized 是悲观锁，线程开始执行第一步就要获取锁，一旦获得锁，其他的线程进入后就会阻塞并等待锁。</li>
<li>CAS是乐观锁，线程执行的时候不会加锁，它会假设此时没有冲突，然后完成某项操作；如果因为冲突失败了就重试，直到成功为止</li>
<li>主要是通过处理器的指令来保证操作的原⼦性的。Unsafe 对 CAS 的实现是通过 C++ 实现的。Linux 的 X86 下主要是通过 cmpxchg 指令在 CPU 上完成 CAS 操作的，但在多处理器情况下，必须使用 lock 指令加锁来完成。不同的操作系统和处理器在实现方式上肯定会有所不同。</li>
</ul>
<h1>46. cas问题？</h1>
<ul>
<li>ABA问题：如果一个变量V初次读取的时候是A值，在赋值的时仍然是A值，在这段时间它的值可能被改为其他值，然后又改回A，CAS操作会误认为它从来没有被修改过。
<ul>
<li>使用AtomicStampedReference类解决，带有时间戳的对象引用，其中compareAndSet方法会比较前引用是否等于预期引用并且印戳是否等于预期印戳，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值</li>
<li>使用版本号去解决。每次修改变量，都在这个变量的版本号上加1，此时虽然值没变，但版本号变了。</li>
</ul>
</li>
<li>循环性能开销：自旋CAS（不成功就一直循环执行直到成功）如果长时间不成功，会给CPU带来非常大的执行开销。
<ul>
<li>限制自旋次数，超过一定次数停止自旋。</li>
</ul>
</li>
<li>只能保证一个共享变量的原子操作：cas无法保证多个共享变量操作的原子性，可以使用锁或者AtomicReference类把多个共享变量合并成一个共享变量来操作</li>
</ul>
<h1>47. Java保证原子性的方法？如何保证多线程下 i++ 结果正确？</h1>
<ul>
<li>使用循环原子类，例如AtomicInteger，实现i++原子操作</li>
<li>使用juc包下的锁，如ReentrantLock，对i++操作加锁lock.lock()来实现原子性</li>
<li>使用synchronized，对i++操作加锁</li>
</ul>
<h1>48. Java中的13个原子操作类√</h1>
<ul>
<li>java.util.concurrent.atomic包中的原子操作类提供了一种用法简单、性能高效、线程安全地更新一个变量的方式。</li>
<li>原理CAS(Compare&amp;Set或Compare&amp;Swap)原子操作volatile变量</li>
<li>原子更新基本类型类:
<ul>
<li>AtomicBoolean：原子更新布尔类型;</li>
<li>AtomicInteger：原子更新整型;</li>
<li>AtomicLong：原子更新长整型。</li>
<li>char、float和double原子类型的更新:使用compareAndSwapObject、compareAndSwapInt、compareAndSwapLong，参考AtomicBoolean</li>
</ul>
</li>
<li>原子更新数组某个元素：
<ul>
<li>AtomicIntegerArray：原子更新整型数组里的元素。</li>
<li>AtomicLongArray：原子更新长整型数组里的元素。</li>
<li>AtomicReferenceArray：原子更新引用类型数组里的元素。</li>
</ul>
</li>
<li>原子更新引用类型/多个对象属性：
<ul>
<li>AtomicReference：原子更新引用类型。</li>
<li>AtomicReferenceFieldUpdater：原子更新引用类型里的字段。</li>
<li>AtomicMarkableReference：原子更新带有标记位的引用类型。解决ABA问题。可以原子更新一个布尔类型的标记位和引用类型。构造方法是AtomicMarkableReference（V initialRef，boolean initialMark）。</li>
</ul>
</li>
<li>原子更新字段类：
<ul>
<li>AtomicIntegerFieldUpdater：原子更新整型的字段。</li>
<li>AtomicLongFieldUpdater：原子更新长整型字段。</li>
<li>AtomicStampedReference：原子更新带有版本号的引用类型(解决ABA)</li>
</ul>
</li>
</ul>
<h1>49. AtomicInteger 的原理？</h1>
<ul>
<li>使用CAS+volatile int实现</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>//AtomicInteger 的添加方法。以Unsafe类的实例来进行添加操作
public final int getAndIncrement() {
    return unsafe.getAndAddInt(this, valueOffset, 1);
}
//compareAndSwapInt是一个native方法，基于CAS来操作int类型变量。其它的原子操作类基本都是大同小异。
public final int getAndAddInt(Object var1, long var2, int var4) {
    int var5;
    do {
        var5 = this.getIntVolatile(var1, var2);
    } while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4));
    return var5;
}
</code></pre></div><h1>50. 什么是死锁</h1>
<ul>
<li>死锁：两个或两个以上的进程或线程在执行过程中因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>class DeadLockDemo {
    private static final Object lock1 = new Object();
    private static final Object lock2 = new Object();

    public static void main(String[] args) {
        new Thread(() -&gt; {
            synchronized (lock1) {
                System.out.println("线程1获取到了锁1");
                try {
                    Thread.sleep(1000);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                synchronized (lock2) {
                    System.out.println("线程1获取到了锁2");
                }
            }
        }).start();

        new Thread(() -&gt; {
            synchronized (lock2) {
                System.out.println("线程2获取到了锁2");
                try {
                    Thread.sleep(1000);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                synchronized (lock1) {
                    System.out.println("线程2获取到了锁1");
                }
            }
        }).start();
    }
}
</code></pre></div><h1>51. 死锁的产生条件</h1>
<ul>
<li>互斥条件：资源不能被多个线程共享，一次只能由一个线程使用。如果一个线程已经占用了一个资源，其他请求该资源的线程必须等待，直到资源被释放。</li>
<li>请求和保持条件：一个线程至少已经持有至少一个资源，且正在等待获取额外的资源，这些额外的资源被其他线程占有。</li>
<li>不可剥夺条件：资源不能被强制从一个线程中抢占过来，只能由持有资源的线程主动释放。</li>
<li>循环等待条件：存在一种线程资源的循环链，每个线程至少持有一个其他线程所需要的资源，然后又等待下一个线程所占有的资源。这形成了一个循环等待的环路。</li>
</ul>
<h1>52. 死锁避免？</h1>
<p>至少破坏死锁发生的一个条件</p>
<ul>
<li>破坏互斥条件：通常不可行，因为加锁就是为了互斥。</li>
<li>破坏持有并等待条件：要求线程在开始执行前一次性地申请所有需要的资源。</li>
<li>破坏非抢占条件：占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源。</li>
<li>破坏循环等待条件：对所有资源类型进行排序，强制每个线程按顺序申请资源，这样可以避免循环等待的发生。</li>
<li>避免一个线程同时获取多个锁。</li>
<li>避免一个线程在锁内同时占用多个资源，尽量保证每个锁只占用一个资源。</li>
<li>尝试使用定时锁，使用lock.tryLock（timeout）来替代使用内部锁机制。</li>
</ul>
<h1>87. 悲观锁和乐观锁？</h1>
<ul>
<li>悲观锁：认为每次访问共享资源时会发生冲突，所以每次访问共享资源的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁。关系型数据库里边的行锁，表锁等，读锁，写锁等.synchronized 和 ReentrantLock 等独占锁。适用于多写的情况。CAS 自旋的概率会比较大，从而浪费更多的 CPU 资源，效率低于 synchronized。</li>
<li>乐观锁：认为每次访问共享资源时不会发生冲突，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，适用于多读的应用类型，如数据库的write_condition 机制，atomic包下面的原子变量类.可以使用版本号机制和 CAS 算法实现。使用版本标识来确定读到的数据与提交时的数据是否一致。提交后修改版本标识，不一致时可以采取丢弃和再次尝试的策略.CAS ，当多个线程尝试使用 CAS 同时更新同一个变量时，只有其中一个线程能更新变量的值，而其它线程都失败，失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试。CAS 基于硬件实现，不需要进入内核，不需要切换线程，操作自旋几率较少，因此可以获得更高的性能，这样可以提高吞吐量。</li>
</ul>
<h1>54. jdk7中ConcurrentHashMap实现</h1>
<ul>
<li>JDK7时采用的是分段锁机制（Segment Locking），整个 Map 被分为若干段，每个段都可以独立地加锁。因此，不同的线程可以同时操作不同的段，从而实现并发访问。</li>
<li>由Segment数组结构和HashEntry数组构成的。Segment是一种可重入的锁ReentrantLock，HashEntry用于存储键值对数据。</li>
<li>一个 ConcurrentHashMap 里包含一个 Segment 数组，Segment 的结构和 HashMap 类似，是一种数组和链表结构，一个 Segment 里包含一个 HashEntry 数组，每个 HashEntry 是一个链表结构的元素，每个 Segment 守护着一个 HashEntry 数组里的元素，当对 HashEntry 数组的数据进行修改时，必须首先获得它对应的 Segment 锁。</li>
<li>put 流程：
<ul>
<li>计算 hash，定位到 segment，segment 如果是空就先初始化；</li>
<li>使用 ReentrantLock 加锁，如果获取锁失败则尝试自旋，自旋超过次数就阻塞获取，保证一定能获取到锁；</li>
<li>遍历 HashEntry，key 相同就直接替换，不存在就插入。</li>
<li>释放锁</li>
</ul>
</li>
<li>get流程:通过 hash(key)定位到segment，再遍历链表定位到具体的元素上，因为value是volatile的，所以不需要加锁<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/798b56179a1383beb4c98.png" alt="jdk7concurrenthashmapput.png"></li>
</ul>
<h1>55. jdk8中ConcurrentHashMap实现</h1>
<ul>
<li>JDK8以上ConcurrentHashMap使用桶锁以及CAS无锁算法。每个桶（Node 数组的每个元素）都可以独立地加锁，锁粒度更小</li>
<li>对于读操作，通常不需要加锁，可以直接读取，因为 ConcurrentHashMap 内部使用了 volatile 变量来保证内存可见性。</li>
<li>对于写操作，ConcurrentHashMap 使用 CAS 操作来实现无锁的更新，这是一种乐观锁的实现，因为它假设没有冲突发生，在实际更新数据时才检查是否有其他线程在尝试修改数据，如果有，采用悲观的锁策略，如 synchronized 代码块来保证数据的一致性。</li>
<li>采用 CAS + synchronized 来保证并发安全性，整个容器只有一个Segment，即table数组。Node使用 volatile 关键字，保证多线程操作时，变量的可见性！</li>
<li>put 流程</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>//1. 计算 hash，遍历 node 数组，如果 node 是空的话，就通过 CAS+自旋的方式初始化。
// 准备初始化
tab = initTable();
// 具体实现
private final Node&lt;K,V&gt;[] initTable() {
    Node&lt;K,V&gt;[] tab; int sc;
    while ((tab = table) == null || tab.length == 0) {
        //如果正在初始化或者扩容
        if ((sc = sizeCtl) &lt; 0)
            //等待
            Thread.yield(); // lost initialization race; just spin
        else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) {   //CAS操作
            try {
                if ((tab = table) == null || tab.length == 0) {
                    int n = (sc &gt; 0) ? sc : DEFAULT_CAPACITY;
                    @SuppressWarnings("unchecked")
                    Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n];
                    table = tab = nt;
                    sc = n - (n &gt;&gt;&gt; 2);
                }
            } finally {
                sizeCtl = sc;
            }
            break;
        }
    }
    return tab;
}
//2. 如果当前数组位置是空，直接通过 CAS 自旋写入数据。
static final &lt;K,V&gt; boolean casTabAt(Node&lt;K,V&gt;[] tab, int i,
                                    Node&lt;K,V&gt; c, Node&lt;K,V&gt; v) {
    return U.compareAndSwapObject(tab, ((long)i &lt;&lt; ASHIFT) + ABASE, c, v);
}
//3. 如果 hash==MOVED，说明需要扩容。
else if ((fh = f.hash) == MOVED)
    tab = helpTransfer(tab, f);
//扩容的具体实现：
final Node&lt;K,V&gt;[] helpTransfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt; f) {
    Node&lt;K,V&gt;[] nextTab; // 下一个表的引用，即新的扩容后的数组
    int sc; // 用于缓存sizeCtl的值
    // 检查条件：传入的表不为空，节点f是ForwardingNode类型，且f中的nextTable不为空
    if (tab != null &amp;&amp; (f instanceof ForwardingNode) &amp;&amp;
        (nextTab = ((ForwardingNode&lt;K,V&gt;)f).nextTable) != null) {
        int rs = resizeStamp(tab.length); // 根据当前表长度计算resize stamp
        // 检查循环条件：nextTab等于nextTable，table等于传入的tab，且sizeCtl为负数（表示正在进行或准备进行扩容）
        while (nextTab == nextTable &amp;&amp; table == tab &amp;&amp;
               (sc = sizeCtl) &lt; 0) {
            // 检查是否应该停止扩容（比如：resize stamp不匹配，或者已达到最大并发扩容线程数，或者transferIndex已经不大于0）
            if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 ||
                sc == rs + MAX_RESIZERS || transferIndex &lt;= 0)
                break;
            // 尝试通过CAS增加sizeCtl的值，以表示有更多线程参与扩容
            if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) {
                transfer(tab, nextTab); // 调用transfer方法，实际进行数据迁移
                break;
            }
        }
        return nextTab; // 返回新的表引用
    }
    return table; // 如果不符合扩容协助条件，返回当前表引用
}
//第四步，如果都不满足，就使用 synchronized 写入数据，和 HashMap 一样，key 的 hash 一样就覆盖，反之使用拉链法解决哈希冲突，当链表长度超过 8 就转换成红黑树。
</code></pre></div><figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/b9c204aae190e13fcbfd2.jpg" alt="jdk7concurrenthashmapput.jpg" tabindex="0"><figcaption>jdk7concurrenthashmapput.jpg</figcaption></figure>
<h1>56. ConcurrentHashMap 怎么保证可见性？</h1>
<ul>
<li>ConcurrentHashMap 保证可见性主要通过使用 volatile 关键字和 synchronized 同步块。</li>
<li>volatile 关键字保证了变量的可见性，即一个线程修改了一个 volatile 变量后，其他线程可以立即看到这个修改。在 ConcurrentHashMap 的内部实现中，有些关键的变量被声明为 volatile，比如 Segment 数组和 Node 数组等。</li>
<li>synchronized 同步块来保证复合操作的原子性。当一个线程进入 synchronized 同步块时，它会获得锁，然后执行同步块内的代码。当它退出 synchronized 同步块时，它会释放锁，并将在同步块内对共享变量的所有修改立即刷新到主内存，这样其他线程就可以看到这些修改了。</li>
</ul>
<h1>57. 为什么 ConcurrentHashMap 比 Hashtable 效率高</h1>
<ul>
<li>Hashtable 在任何时刻只允许一个线程访问整个 Map，通过对整个 Map 加锁来实现线程安全。</li>
<li>ConcurrentHashMap（尤其JDK8后）通过锁分离和 CAS 操作实现更细粒度的锁定策略，允许更高的并发。</li>
<li>CAS 操作是乐观锁，它不会阻塞线程，而是在更新时检查是否有其他线程已经修改了数据，如果没有就更新，如果有就重试。ConcurrentHashMap 允许多个读操作并发进行而不加锁，因为它通过 volatile 变量来保证读取操作的内存可见性。相比之下，Hashtable 对读操作也加锁，增加了开销</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>static final &lt;K,V&gt; boolean casTabAt(Node&lt;K,V&gt;[] tab, int i,
                                    Node&lt;K,V&gt; c, Node&lt;K,V&gt; v) {
    return U.compareAndSwapObject(tab, ((long)i &lt;&lt; ASHIFT) + ABASE, c, v);
}

public V get(Object key) {
    Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; int n, eh; K ek;
	// 1. 重hash
    int h = spread(key.hashCode());
    if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp;
        (e = tabAt(tab, (n - 1) &amp; h)) != null) {
        // 2. table[i]桶节点的key与查找的key相同，则直接返回
		if ((eh = e.hash) == h) {
            if ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))
                return e.val;
        }
		// 3. 当前节点hash小于0说明为树节点，在红黑树中查找即可
        else if (eh &lt; 0)
            return (p = e.find(h, key)) != null ? p.val : null;
        while ((e = e.next) != null) {
		//4. 从链表中查找，查找到则返回该节点的value，否则就返回null即可
            if (e.hash == h &amp;&amp;
                ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek))))
                return e.val;
        }
    }
    return null;
}
</code></pre></div><h1>58. CountDownLatch√</h1>
<ul>
<li>CountDownLatch允许一个或多个线程等待其他线程完成操作。</li>
<li>场景：
<ul>
<li>协调子线程结束动作：等待所有子线程运行结束</li>
<li>协调子线程开始动作：统一各线程动作开始的时机</li>
<li>多线程解析一个Excel里多个sheet的数据（或者使用join）</li>
</ul>
</li>
<li>CountDownLatch的构造函数接传入countDown调用次数n。直到countDown调用次数达到n，才从await方法返回</li>
<li>CountDownLatch不能重新初始化或者修改CountDownLatch对象的内部计数器的值。一个线程调用countDown方法happen-before，另外一个线程调用await方法</li>
</ul>
<h1>59. CyclicBarrier同步屏障</h1>
<ul>
<li>CyclicBarrier构造方法传入屏障拦截的线程数量n，直到await调用次数达到n，才从await方法返回继续执行</li>
<li>构造函数CyclicBarrier（int parties，Runnable barrierAction），用于在线程到达屏障时，优先执行barrierAction</li>
<li>CyclicBarrier可以用于多线程计算数据，最后合并计算结果的场景</li>
<li>CyclicBarrier可以重复利用</li>
</ul>
<h1>60. CycliBarriar 和 CountdownLatch 有什么区别？</h1>
<ul>
<li>
<p>都是用于控制并发的工具类，都可以实现让一段程序并发的执行，并最终汇总结果</p>
</li>
<li>
<p>CyclicBarrier是可重用的，其中的线程会等待所有的线程完成任务。届时，屏障将被拆除，并可以选择性地做一些特定的动作；CountDownLatch是一次性的，不同的线程在同一个计数器上工作，直到计数器为0</p>
</li>
<li>
<p>CyclicBarrier面向的是线程数	CountDownLatch面向的是任务数</p>
</li>
<li>
<p>在使用CyclicBarrier时，你必须在构造中指定参与协作的线程数，这些线程必须调用await()方法	使用CountDownLatch时，则必须要指定任务数，至于这些任务由哪些线程完成无关紧要</p>
</li>
<li>
<p>CyclicBarrier可以在所有的线程释放后重新使用	CountDownLatch在计数器为0时不能再使用</p>
</li>
<li>
<p>在CyclicBarrier中，如果某个线程遇到了中断、超时等问题时，则处于await的线程都会出现问题	在CountDownLatch中，如果某个线程出现问题，其他线程不受影响</p>
</li>
<li>
<p>CyclicBarrier 中的各个线程可以等待其他线程；CountDownLatch中的各个子线程不可以等待其他线程，只能完成自己的任务</p>
</li>
<li>
<p>CountDownLatch使用减数方式直至计数为0时释放所有等待线程，CyclicBarrier使用加数方式直至计数为指定时释放所有等待线程，并且重置为0，还可指定到达栅栏后优先执行的任务，如果计算发生错误，可以reset重置计数器，并让线程重新执行一次。</p>
</li>
<li>
<p>CountDownLatch调用countDown()方法计数减一，调用await()方法只进行阻塞，对计数没影响；CyclicBarrier调用await()方法计数加1 ，若加1后的值不等于构造方法的值，则线程阻塞</p>
</li>
<li>
<p>CountDownLatch强调一个线程等多个线程完成某件事情。CyclicBarrier是多个线程互等，等大家都完成，再携手共进</p>
</li>
</ul>
<h1>61. 控制并发线程数的Semaphore</h1>
<ul>
<li>Semaphore（信号量）是用来控制同时访问特定资源的线程数量</li>
<li>场景：流量控制，公用资源有限的应用场景，比如数据库连接。</li>
<li>Semaphore的acquire()方法获取一个许可证，使用完之后调用release()方法归还许可证。还可以用tryAcquire()方法尝试获取许可证。</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class SemaphoreTest {
    private static final int THREAD_COUNT = 30;
    private static ExecutorService threadPool = Executors.newFixedThreadPool(THREAD_COUNT);
    private static Semaphore s = new Semaphore(10);

    public static void main(String[] args) {
        for (int i = 0; i &lt; THREAD_COUNT; i++) {
            threadPool.execute(new Runnable() {
                @Override
                public void run() {
                    try {
                        s.acquire();
                        System.out.println("save data");
                        s.release();
                    } catch (InterruptedException e) {
                    }
                }
            });
        }
        threadPool.shutdown();
    }
}

</code></pre></div><h1>62. Exchanger</h1>
<ul>
<li>Exchanger用于进行线程间的数据交换。它提供一个同步点使得两个线程可以通过exchange方法交换彼此的数据，如果第一个线程先执行exchange()方法，它会一直等待第二个线程也执行exchange方法，当两个线程都到达同步点时，这两个线程就可以交换数据，将本线程生产出来的数据传递给对方。为了避免一直等待，可以使用exchange(V x, long timeOut, TimeUnit unit) 设置最大等待时长。</li>
<li>场景</li>
<li>遗传算法，选出两个人作为交配对象，这时候会交换两人的数据，并使用交叉规则得出2个交配结果。</li>
<li>校对工作，比如纸制银行流水通过人工的方式录入成电子银行流水，为了避免错误，采用AB岗两人进行录入，并看看两个Excel数据是否录入一致</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class ExchangerTest {
    private static final Exchanger&lt;String&gt; exgr = new Exchanger&lt;String&gt;();
    private static ExecutorService threadPool = Executors.newFixedThreadPool(2);

    public static void main(String[] args) {
        threadPool.execute(new Runnable() {
            @Override
            public void run() {
                try {
                    String A = "银行流水A"; // A录入银行流水数据
                    exgr.exchange(A);
                } catch (InterruptedException e) {
                }
            }
        });
        threadPool.execute(new Runnable() {
            @Override
            public void run() {
                try {
                    String B = "银行流水B"; // B录入银行流水数据
                    String A = exgr.exchange("B");
                    System.out.println("A和B数据是否一致：" + A.equals(B) + "，A录入的是："
                            + A + "，B录入是：" + B);
                } catch (InterruptedException e) {
                }
            }
        });
        threadPool.shutdown();
    }
}
</code></pre></div><h1>63. 为什么要使用线程池？</h1>
<ul>
<li>降低资源消耗：通过重复利用已创建的线程降低频繁线程创建和销毁造成的消耗</li>
<li>提高响应速度：当任务到达时，任务可以不需要的等到线程创建就能立即执行</li>
<li>线程池支持定时执行、周期性执行、单线程执行和并发数控制等功能</li>
</ul>
<h1>64. 线程池的应用？</h1>
<ul>
<li>多线程发送短信，公众号消息</li>
<li>处理9图gif</li>
<li>保存私密文件(头像、身份证)</li>
</ul>
<h1>65. 线程池的处理流程√</h1>
<ul>
<li>如果当前池中线程数小于corePoolSize，则创建一个线程执行该任务,即使当前核心线程池有空闲的线程。</li>
<li>如果当前线程池中线程数已经达到 corePoolSize，则将任务放入等待队列。</li>
<li>如果任务等待队列已满，若当前池中线程数小于maximumPoolSize，则创建一个临时线程执行该任务。</li>
<li>如果当前池中线程数已经等于maximumPoolSize，此时无法执行该任务，根据拒绝执行策略处理。</li>
<li>空闲的线程会从任务队列中取出任务来执行，当任务执行完毕后，线程并不会立即销毁，而是继续保持在池中等待下一个任务。</li>
<li>当线程空闲时间超出指定时间，且当前线程数量大于核心线程数时，线程会被回收。</li>
</ul>
<h1>66. 如何创建线程池？线程池常用参数?√</h1>
<p>通过ThreadPoolExecutor构造方法,参数如下</p>
<ul>
<li>corePoolSize核心池大小。即使这些线程处于空闲状态，它们也不会被回收.线程池保持在等待状态下的线程数。</li>
<li>maximumPoolSize允许的最大线程数，当工作队列满了之后，线程池会创建新线程来处理任务，直到线程数达到这个最大值</li>
<li>workQueue用于保存任务的阻塞队列,推荐使用有界队列。</li>
<li>RejectedExecutionHandler拒绝策略。定义了当线程池和工作队列都满了之后对新提交的任务的处理策略。</li>
<li>keepAliveTime空闲线程空闲存活时间。如果线程池中的线程数量超过了corePoolSize，那么这些多余的线程在空闲时间超过keepAliveTime时会被终止。如果任务很多，并且每个任务执行的时间比较短，可以调大时间，提高线程的利用率。</li>
<li>unit keepAliveTime参数的单位，如：毫秒、秒。</li>
<li>threadFactory创建线程的工程类。指定线程工厂为每个创建出来的线程设置更有意义的名字，方便查找并发问题原因</li>
</ul>
<h1>67. 拒绝策略?√</h1>
<ul>
<li>AbortPolicy：抛出 RejectedExecutionException来拒绝新任务的处理(默认)</li>
<li>CallerRunsPolicy：使用当前线程执行任务，可能会阻塞主线程</li>
<li>DiscardOldestPolicy： 丢弃在队列中队首的任务，并执行当前任务。</li>
<li>DiscardPolicy：直接丢弃后来的任务</li>
<li>实现RejectedExecutionHandler接口自定义策略。如记录日志或持久化存储不能处理的任务。</li>
</ul>
<h1>68. 线程池的阻塞队列</h1>
<ul>
<li>BlockingQueue:是一个支持两个附加操作的阻塞队列：在队列为空时，获取元素的线程会等待队列（阻塞）变为非空。当队列满时，存储元素的线程会等待队列可用（阻塞）
<ul>
<li>常用于生产者和消费者的场景，生产者是往队列里添加元素的线程，消费者是从队列里拿元素的线程。阻塞队列就是生产者存放元素的容器，而消费者也只从容器里拿元素</li>
<li>常用于socket客户端数据的读取和解析的场景，读取数据的线程不断将数据放入队列，然后解析线程不断从队列取数据解析</li>
</ul>
</li>
<li>ArrayBlockingQueue：用数组实现的有界阻塞队列，有序，按FIFO排序量。不保证线程公平的访问队列</li>
<li>LinkedBlockingQueue：是基于链表结构的阻塞队列，按FIFO排序任务，容量可以选择进行设置，不设置的话，将是一个无边界的阻塞队列，最大长度为Integer.MAX_VALUE，吞吐量通常要高于ArrayBlockingQuene；</li>
<li>DelayQueue（延迟队列）是一个任务定时周期的延迟执行的队列。根据指定的执行时间从小到大排序，否则根据插入到队列的先后排序。newScheduledThreadPool线程池使用了这个队列。队列中的元素必须实现Delayed接口，在创建元素时可以指定多久才能从队列中获取当前元素。只有在延迟期满时才能从队列中提取元素。
<ul>
<li>缓存系统的设计：DelayQueue保存缓存元素的有效期，使用一个线程循环查询DelayQueue，一旦能从DelayQueue中获取元素时，表示缓存有效期到了。</li>
<li>定时任务调度：DelayQueue保存执行的任务和执行时间，一旦从DelayQueue中获取到任务就执行，比如TimerQueue就是使用DelayQueue实现的</li>
</ul>
</li>
<li>PriorityBlockingQueue（优先级队列）是具有优先级的无界阻塞队列，不能保证同优先级元素的顺序</li>
<li>SynchronousQueue（同步队列）是一个不存储元素的阻塞队列，每个插入put操作必须等到另一个线程调用移除take操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于LinkedBlockingQuene，newCachedThreadPool线程池使用了这个队列。</li>
<li>LinkedTransferQueue：一个由链表结构组成的无界阻塞队列。</li>
<li>LinkedBlockingDeque：一个由链表结构组成的双向阻塞队列。</li>
</ul>
<h1>69. Runnable 和 Callable 有什么区别？√</h1>
<ul>
<li>Runnable接口中的run()方法无返回值，只是执行run()方法中的代码，不能抛异常</li>
<li>Callable接口中的call()方法返回值是泛型，能抛出异常，和Future、FutureTask配合可用来获取异步执行的结果</li>
</ul>
<h1>70. 执行execute()和submit()方法的区别？</h1>
<ul>
<li>execute(Runnable command)只能提交Runnable类型的任务，无法判断任务是否被线程池执行成功与否；用于提交不需要返回值的任务</li>
<li>submit(Runnable&nbsp;task)和submit(Callable&nbsp;task)用于提交需要返回值的任务、既能提交Runnable类型任务也能提交Callable类型任务。可以通过Future的get()方法阻塞当前线程直到任务完成并获取返回值，使用get（long timeout，TimeUnit unit）方法则会阻塞当前线程一段时间后立即返回（有可能任务没有执行完）。</li>
</ul>
<h1>71. 线程池的关闭</h1>
<ul>
<li>shutdown和shutdownNow方法,原理都是遍历线程池中所有的线程，然后依次调用interrupt方法中断线程。无法响应中断的任务可能永远无法终止</li>
<li>shutdown() 将线程池状态置为 shutdown,并不会立即停止，首先停止接收外部 submit 的任务，直到内部正在跑的任务和队列里等待的任务全部执行完成后才真正停止</li>
<li>shutdownNow将线程池的状态设置为STOP,一般会立即停止，风险较大.首先停止接收外部提交的任务，然后忽略队列里等待的任务并尝试将正在跑的任务 interrupt 中断最后返回未执行的任务列表，</li>
<li>两个方法都会使isShutdown方法返回true，当所有的线程都关闭成功，才表示线程池成功关闭，这时调用isTerminated方法才会返回true。</li>
<li>通常调用shutdown方法来关闭线程池，如果任务不一定要执行完，则可以调用shutdownNow方法</li>
</ul>
<h1>72. 线程池参数怎么设置？√</h1>
<ul>
<li>任务的性质：N为CPU核数：过小的线程池可能会导致任务一直在排队。过大的线程池可能会导致大家都在竞争 CPU 资源，增加上下文切换的开销
<ul>
<li>CPU密集型任务(加解密逻辑操作)（Ncpu+1），+1 是因为可能存在页缺失(就是可能存在有些数据在硬盘中需要多来一个线程将数据读入内存)。</li>
<li>IO密集型任务(数据库链接，通讯传输等)（2xNcpu）</li>
<li>混合型任务（拆分成一个CPU密集型任务和一个IO密集型任务）</li>
</ul>
</li>
<li>cpu 使用率：观察机器的 cpu 使用率和 cpu 负载两个参数来判断线程数是否合理。</li>
<li>内存使用率：队列的大小应该通过前期计算线程池任务的条数，来合理的设置队列的大小，不宜过小，让其不会溢出，因为溢出会走拒绝策略，多少会影响性能，也会增加复杂度。</li>
<li>下游系统抗并发能力：考虑下游系统是否能抗的住这么多并发量，不能把下游系统打挂了。</li>
<li>任务的优先级：高，中和低。PriorityBlockingQueue 如果一直有优先级高的任务提交到队列里，那么优先级低的任务可能永远不能执行。</li>
<li>任务的执行时间：长，中和短。如果一直有优先级高的任务提交到队列里，那么优先级低的任务可能永远不能执行。</li>
<li>任务的依赖性：是否依赖其他系统资源，如数据库连接。线程数应该设置越大</li>
<li>可以通过Runtime.getRuntime().availableProcessors()方法获得当前设备的CPU个数</li>
<li>建议使用有界队列。有界队列能增加系统的稳定性和预警能力，可以根据需要设大一点儿，比如几千。避免oom</li>
<li>尽量使用自定义的线程池，而不是使用 Executors 创建的线程池，因为 newFixedThreadPool 线程池由于使用了 LinkedBlockingQueue，队列的容量默认无限大，实际使用中出现任务过多时会导致内存溢出；newCachedThreadPool 线程池由于核心线程数无限大，当任务过多的时候会导致创建大量的线程，可能机器负载过高导致服务宕机。</li>
</ul>
<h1>73. Executors创建线程池对象的弊端? 阿里开发规范为什么不允许Executors快速创建线程池？</h1>
<ul>
<li>newSingleThreadExecutor (单线程的线程池) 适用于串行执行任务的场景，一个任务一个任务地执行。</li>
<li>newFixedThreadPool (固定数目线程的线程池) CPU密集型的任务</li>
<li>newCachedThreadPool (可缓存线程的线程池)用于并发执行大量短期的小任务。（60 秒不执行任务）的线程将被回收</li>
<li>newScheduledThreadPool (定时及周期执行的线程池)周期性执行任务的场景，需要限制线程数量的场景</li>
<li>FixedThreadPool和SingleThreadExecutor使用LinkedBlockingQueue允许请求的队列长度为Integer.MAX_VALUE，任务执行时间长，队列堆积导致OOM</li>
<li>CachedThreadPool和ScheduledThreadPool最大线程数量为Integer.MAX_VALUE，任务执行时间长，任务堆积导致创建大量线程导致OOM</li>
</ul>
<h1>74. 线程池异常怎么处理</h1>
<ul>
<li>trycatch捕获</li>
<li>submit执行，Future.get接受异常</li>
<li>重写ThreadPoolExcutor.afterExcute方法，处理传递的异常引用</li>
<li>实例化时，传入自定义ThreadFactory,设置Thread.uncaughtExceptionHandler处理未检测的异常</li>
</ul>
<h1>75. 线程池状态</h1>
<ul>
<li>RUNNING：正常状态，接受新的任务，处理等待队列中的任务。</li>
<li>SHUTDOWN：不接受新的任务提交，但是会继续处理等待队列中的任务。队列为空，并且线程池中执行的任务也为空,进入TIDYING状态;(shutdown)</li>
<li>STOP：不接受新的任务提交，不再处理等待队列中的任务，中断正在执行任务的线程。线程池中执行的任务为空,进入TIDYING状态;(shutdownnow)</li>
<li>TIDYING：所有的任务都销毁了，workCount为0，转换为此状态时会执行terminated()。</li>
<li>TERMINATED：terminated()方法结束后线程池的状态。<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/77b2ca8a8016db88b8754.png" alt="threadpoolstatus.png"></li>
</ul>
<h1>76. 线程池调优</h1>
<ul>
<li>事前评估-&gt;监控/告警-&gt;动态调整-&gt;事后观察</li>
</ul>
<h1>77. 线程池使用注意事项</h1>
<ul>
<li>选择合适的线程池大小</li>
<li>选择有界队列并设置大小，防止OOM</li>
<li>尽量使用自定义ThreadPoolExecutor而不是Executors 创建的线程池</li>
</ul>
<h1>78. 你能设计实现一个线程池吗</h1>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/16f08fa922ac6a89fcaea.png" alt="customthreadpool.png" tabindex="0"><figcaption>customthreadpool.png</figcaption></figure>
<h1>79. 单机线程池执行断电了应该怎么处理？</h1>
<ul>
<li>对阻塞队列持久化；正在处理任务事务控制；断电之后正在处理任务的回滚，通过日志恢复该次操作；服务器重启后阻塞队列中的数据再加载。</li>
</ul>
<h1>80. Fork/Join框架？</h1>
<ul>
<li>用于并行执行任务的框架，是一个把大任务分割成若干个小任务，最终汇总每个小任务结果后得到大任务结果的框架。</li>
<li>分而治之:Fork/Join 框架的定义体现了分治思想：将一个规模为 N 的问题分解为 K 个规模较小的子问题，这些子问题相互独立且与原问题性质相同。求出子问题的解，就可得到原问题的解。</li>
<li>工作窃取算法:大任务拆成了若干个小任务，把这些小任务放到不同的队列里，各自创建单独线程来执行队列里的任务。有的线程干活块，有的线程干活慢。干完活的线程去帮没干完活的线程干活。去其它线程的队列里窃取一个任务来执行，这就是所谓的工作窃取。工作窃取发生的时候，它们会访问同一个队列，为了减少窃取任务线程和被窃取任务线程之间的竞争，通常任务会使用双端队列，被窃取任务线程永远从双端队列的头部拿，而窃取任务的线程永远从双端队列的尾部拿任务执行。</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>//计算 1~n 之间的和：1+2+3+…+n 设置一个分割阈值，任务大于阈值就拆分任务 任务有结果，所以需要继承 RecursiveTask

public class CountTask extends RecursiveTask&lt;Integer&gt; {
    private static final int THRESHOLD = 16; // 阈值
    private int start;
    private int end;

    public CountTask(int start, int end) {
        this.start = start;
        this.end = end;
    }

    @Override
    protected Integer compute() {
        int sum = 0;
        // 如果任务足够小就计算任务
        boolean canCompute = (end - start) &lt;= THRESHOLD;
        if (canCompute) {
            for (int i = start; i &lt;= end; i++) {
                sum += i;
            }
        } else {
            // 如果任务大于阈值，就分裂成两个子任务计算
            int middle = (start + end) / 2;
            CountTask leftTask = new CountTask(start, middle);
            CountTask rightTask = new CountTask(middle + 1, end);
            // 执行子任务
            leftTask.fork();
            rightTask.fork(); // 等待子任务执行完，并得到其结果
            int leftResult = leftTask.join();
            int rightResult = rightTask.join(); // 合并子任务
            sum = leftResult + rightResult;
        }
        return sum;
    }

    public static void main(String[] args) {
        ForkJoinPool forkJoinPool = new ForkJoinPool(); // 生成一个计算任务，负责计算1+2+3+4
        CountTask task = new CountTask(1, 100); // 执行一个任务
        Future&lt;Integer&gt; result = forkJoinPool.submit(task);
        try {
            System.out.println(result.get());
        } catch (InterruptedException e) {
        } catch (ExecutionException e) {
        }
    }

}
</code></pre></div><ul>
<li>ForkJoinTask 与一般 Task 的主要区别在于它需要实现 compute 方法，在这个方法里，首先需要判断任务是否足够小，如果足够小就直接执行任务。如果比较大，就必须分割成两个子任务，每个子任务在调用 fork 方法时，又会进 compute 方法，看看当前子任务是否需要继续分割成子任务，如果不需要继续分割，则执行当前子任务并返回结果。使用 join 方法会等待子任务执行完并得到其结果。</li>
</ul>
<p>=====================================================================================================================</p>
<h1>81. 多线程的优缺点?</h1>
<ul>
<li>
<p>优点</p>
<ul>
<li>使用多线程可以把程序中占据时间长的任务放到后台去处理，如图片、视频的下载。生成订单快照、发送邮件等</li>
<li>发挥多核处理器的优势，并发执行让系统运行的更快、更流畅，用户体验更好</li>
</ul>
</li>
<li>
<p>缺点</p>
<ul>
<li>大量的线程降低代码的可读性</li>
<li>更多的线程需要更多的内存空间</li>
<li>当多个线程对同一个资源出现争夺时候要注意线程安全的问题</li>
</ul>
</li>
<li>
<p>CPU核之间的数据一致性保证方法</p>
<ul>
<li>总线加锁：通过在总线加LOCK#锁的方式；只能有一个CPU能够运行，其他CPU都阻塞，效率低下</li>
<li>缓存一致性协议MESI：确保每个缓存中使用的共享变量的副本是一致的：当某个CPU在写数据时，如果发现操作的变量是共享变量，则会通知其他CPU告知该变量的缓存行是无效的，其他CPU在读取该变量时，发现其无效会重新从主存中加载数据</li>
</ul>
</li>
</ul>
<h1>82. java如何实现原子操作？</h1>
<ul>
<li>原子操作是指一个不受其他操作影响的操作任务单元。处理器使用基于对缓存加锁或总线加锁的方式，来实现多处理器之间的原子操作</li>
<li>使用总线锁保证原子性：使用处理器提供的一个LOCK＃信号，当一个处理器在总线上输出此信号时，其他处理器的请求将被阻塞住，那么该处理器可以独占共享内存。对应#lock前缀 加上后面具体的指令</li>
<li>使用缓存锁保证原子性：通过缓存一致性协议实现，对应位测试和修改指令：BTS、BTR、BTC；交换指令XADD、CMPXCHG，以及其他一些操作数和逻辑指令（如ADD、OR）等</li>
<li>使用循环CAS实现原子操作，CAS利用了处理器提供的CMPXCHG指令(java)</li>
<li>使用锁机制实现原子操作，锁机制保证了只有获得锁的线程才能够操作锁定的内存区域。JVM内部实现了很多种锁机制，有偏向锁、轻量级锁和互斥锁。除了偏向锁，JVM实现锁的方式都用了循环CAS，即当一个线程想进入同步块的时候使用循环CAS的方式来获取锁，当它退出同步块的时候使用循环CAS释放锁。</li>
</ul>
<h1>83. wait和notify典型范式？</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code># 等待方
synchronized(对象){
    while(条件不满足){//为什么被通知后仍要检查条件？防止多线程情况下，都从wait()返回时条件不满足导致程序出错
        对象.wait();
    }
    对应的处理逻辑
}
# 通知方
synchronized(对象){
    改变条件
    对象.notifyAll();
}
</code></pre></div><h1>84. 多线程开发注意事项</h1>
<ul>
<li>给线程命名，方便找bug和跟踪、jstack分析程序或者问题排查</li>
<li>最小化同步范围</li>
<li>优先使用volatile，而不是 synchronized</li>
<li>尽可能使用更高层次的并发工具而非wait和notify方法来实现线程通信</li>
<li>优先使用并发容器，而非同步容器</li>
<li>考虑使用线程池</li>
<li>小心死锁</li>
<li>尽量避免上下文切换</li>
<li>控制资源
<ul>
<li>硬件资源：带宽的上传/下载速度、硬盘读写速度和CPU的处理速度；使用集群并行执行程序。让程序在多机上运行。比如使用ODPS、Hadoop或者自己搭建服务器集群，不同的机器处理不同的数据。可以通过“数据ID%机器数”，计算得到一个机器编号，然后由对应编号的机器处理这笔数据。</li>
<li>软件资源：数据库的连接数和socket连接数等；使用资源池将资源复用。比如使用连接池将数据库和Socket连接复用，或者在调用对方webservice接口获取数据时，只建立一个连接。</li>
<li>根据不同的资源限制调整程序的并发度</li>
</ul>
</li>
</ul>
<h1>85. final域的重排</h1>
<ul>
<li>基本数据类型:
<ul>
<li>final域写：禁止final域写与构造方法重排序，保证该对象对所有线程可见时，该对象的final域全部已经初始化过</li>
<li>final域读（针对处理器）：禁止初次读对象的引用与读该对象包含的final域的重排序。保证读一个对象的final域之前先读这个包含这个final域的对象的引用</li>
</ul>
</li>
<li>引用数据类型：
<ul>
<li>额外约束：禁止在构造函数对一个final修饰的对象的成员域的写入与随后将这个被构造的对象的引用赋值给引用变量重排序</li>
</ul>
</li>
<li>final实现
<ul>
<li>写final域会要求编译器在final域写之后，构造函数返回前插入一个StoreStore屏障</li>
<li>读final域会要求编译器在读final域的操作前插入一个LoadLoad屏障</li>
</ul>
</li>
</ul>
<h1>86. 锁分类（重入锁、互斥锁、读写锁、公平锁、非公平锁、自旋锁、适应自旋锁）</h1>
<ul>
<li>互斥锁：没有获取到锁的线程进入阻塞，线程阻塞涉及到用户态和内核态切换的问题，性能可能很差</li>
<li>读写锁：读取锁允许多个reader线程同时持有，而写入锁最多只能有一个writer线程持有</li>
<li>公平锁：先请求锁的人，在锁被释放时，优先获得锁，即同步队列的第一个节点先获取锁，需要频繁的上下文切换</li>
<li>不公平锁：无论先后，线程调度器将会随机给某个线程锁，不用计算线程时序，上下文切换较少，有可能刚释放锁的线程能再次获取到锁，导致其他线程永远无法获取到锁，造成“饥饿”现象</li>
<li>自旋锁：没有获取到锁的线程不进入阻塞，而是让该线程等待一段时间（执行一段无意义的循环），一直循环等待释放锁。自旋等待不能替代阻塞，虽然可以避免线程切换带来的开销，但是它占用了处理器的时间。如果持有锁的线程很快就释放了锁，那么自旋的效率高，反之，自旋的线程就会浪费处理器的资源，所以，自旋等待的时间（自旋次数）必须要有上限，如果自旋超过了定义的时间仍然没有获取到锁，则应该被挂起</li>
<li>自适应是指由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定自旋次数。线程如果自旋成功了，那么下次自旋的次数会更加多，因为虚拟机认为既然上次成功了，那么此次自旋也很有可能会再次成功，那么它就会允许自旋等待持续的次数更多。反之，如果对于某个锁，很少有自旋能够成功的，那么在以后要或者这个锁的时候自旋的次数会减少甚至省略掉自旋过程，以免浪费处理器资源。</li>
</ul>
<h1>88. 乐观锁常见的两种实现方式是什么？</h1>
<ul>
<li>版本号机制:一般是在数据表中加上一个数据版本号version字段表示数据被修改的次数，当数据被修改时version会加1。当线程要更新数据值时,会先读取version值，在提交更新时，若刚才读取到的version值为当前数据库中的version值相等时才更新，否则重试更新操作直到成功</li>
<li>CAS算法:compare and swap（比较与交换，是原子操作），不使用锁的情况下实现多线程之间的变量同步（非阻塞同步Non-blocking Synchronization）。CAS算法涉及到三个操作数：需要读写的内存值V；进行比较的值A；拟写入的新值B;当且仅当V的值等于A时，CAS通过原子方式用新值B来更新V值，否则不会执行任何操作。一般情况下会自旋（不断的重试。无限循环）</li>
</ul>
<h1>89. synchronized 和 volatile 的区别是什么？</h1>
<ul>
<li>volatile 本质是在告诉 JVM当前变量在寄存器（工作内存）中的值是不确定的，需要从主存中读取；synchronized 则是锁定当前变量，只有当前线程可以访问该变量，其他线程被阻塞住。</li>
<li>volatile 仅能使用在变量级别；synchronized 则可以使用在变量、方法、和类级别的。</li>
<li>volatile 仅能实现变量的修改可见性，不能保证原子性；而 synchronized 则可以保证变量的修改可见性和原子性。</li>
<li>volatile 不会造成线程的阻塞；synchronized 可能会造成线程的阻塞。</li>
<li>volatile 标记的变量不会被编译器优化；synchronized 标记的变量可以被编译器优化。</li>
</ul>
<h1>90. 什么场景下可以使用 volatile 替换 synchronized ？</h1>
<ul>
<li>只需要保证共享资源的可见性的时，synchronized保证可操作的原子性一致性和可见性。volatile适用于新值不依赖于旧值的情形</li>
<li>1 写 N 读</li>
<li>不与其他变量构成不变性条件时候使用 volatile</li>
</ul>
<h1>91. SimpleDateFormat是线程安全的吗？</h1>
<ul>
<li>DateFormat所有实现，包括SimpleDateFormat都不是线程安全的，可将SimpleDateFormat限制在ThreadLocal中。或者使用joda-time库</li>
</ul>
<h1>91.1. ConcurrentHashMap√</h1>
<ul>
<li>CopyOnWriteArrayList:适合读多写少的场景，不能用于实时读，因为执行写操作时会复制原数组并执行写入操作，读操作可以安全进行，但读取的可能是旧数据，原数组比较大时可能发生young gc或者full gc</li>
<li>ConcurrentLinkedQueue是一个基于链接节点的无界线程安全队列，先进先出</li>
</ul>
<h1>91.2. volatile 变量和 atomic 变量有什么不同？</h1>
<ul>
<li>volatile变量确保有序性，即写操作会发生在后续的读操作之前，但它并不能保证原子性。</li>
<li>AtomicInteger类提供的atomic方法具有原子性</li>
</ul>
<h1>91.3. 什么是 Callable、Future、FutureTask？</h1>
<ul>
<li>Callable 接口类似回调的 Runnable可以被 Future 拿到</li>
<li>Future 接口，表示异步任务，是还没有完成的任务给出的未来结果。所以说 Callable 用于产生结果，Future 用于获取结果。</li>
<li>FutureTask表示一个可以取消的异步运算。它有启动和取消运算、查询运算是否完成和取回运算结果等方法。只有当运算完成的时候结果才能取回，如果运算尚未完成get方法将会阻塞。实现基于AQS</li>
</ul>
]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/9c42c9f380bcb496ccaae.png" type="image/png"/>
    </item>
    <item>
      <title>jvm</title>
      <link>https://javaguide.cn/interview/javavirtualmachine.html</link>
      <guid>https://javaguide.cn/interview/javavirtualmachine.html</guid>
      <source url="https://javaguide.cn/rss.xml">jvm</source>
      <description>1. 什么是JVM? JVM，Java虚拟机，Java实现跨平台的基石。Java 程序运行的时候，编译器会将 Java 源代码（.java）编译成平台无关的 Java 字节码文件（.class），接下来对应平台的 JVM 会对字节码文件进行解释，翻译成对应平台的机器指令并运行。 2. Jvm主要组成部分及其作用？ 类加载器（ClassLoader）：负...</description>
      <category>面试</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[
<ul>
<li>JVM，Java虚拟机，Java实现跨平台的基石。Java 程序运行的时候，编译器会将 Java 源代码（.java）编译成平台无关的 Java 字节码文件（.class），接下来对应平台的 JVM 会对字节码文件进行解释，翻译成对应平台的机器指令并运行。</li>
</ul>
<h1>2. Jvm主要组成部分及其作用？</h1>
<ul>
<li>
<p>类加载器（ClassLoader）：负责从文件系统、网络或其他来源加载Class文件，将Class文件中的二进制数据读入到内存中</p>
</li>
<li>
<p>运行时数据区（Runtime Data Area）JVM 在执行 Java 程序时，需要在内存中分配空间来处理各种数据，这些内存区域主要包括方法区、堆、栈、程序计数器和本地方法栈。</p>
</li>
<li>
<p>执行引擎（Execution Engine）负责执行class文件中包含的字节码指令，包括一个虚拟处理器，还包括即时编译器（JIT Compiler）和垃圾回收器（Garbage Collector）。</p>
</li>
<li>
<p>本地库接口（Native Interface）调用C或C++实现的本地方法的代码返回结果</p>
</li>
<li>
<p>各组件的作用：首先通过类加载器（ClassLoader）把Java代码转换成字节码，运行时数据区（Runtime Data Area）再把字节码加载到内存中，由特定的命令解析器执行引擎（Execution Engine），将字节码翻译成底层系统指令，再交由CPU执行，而这个过程中需要调用其他语言的本地库接口（Native Interface）来实现整个程序的功能<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/70d43d52d3b9c5460213d.png" alt="jvmstructure.jpg"></p>
</li>
</ul>
<h1>3. 谈谈对运行时数据区的理解？</h1>
<ul>
<li>程序计数器(Program Counter Register)(线程私有) 当前线程所执行的字节码的行号指示器</li>
<li>java虚拟机栈(Java Virtual Machine Statcks)(线程私有)java方法执行的内存模型，生命周期与线程相同。当线程执行一个方法时，会创建一个对应的栈帧，用于存储局部变量表、操作数栈、动态链接、方法出口等信息，然后栈帧会被压入栈中。当方法执行完毕后，栈帧会从栈中移除。</li>
<li>本地方法栈(Native Method Stack)(线程私有) 执行虚拟机使用到的native方法服务。存放了native方法的局部变量、动态链接和方法出口等信息</li>
<li>java堆(Java Heap)(线程共享)主要用于存放对象实例，几乎所有的对象实例都在这分配内存</li>
<li>方法区（Method Area）和运行时常量池(Runtime Constant Pool)(线程共享)并不真实存在，属于Java 虚拟机规范中的一个逻辑概念，存储已被虚拟机加载的类信息，常量，静态变量，即时编译器编译后的代码等数据。在 HotSpot 虚拟机中，方法区的实现称为永久代（PermGen），在Jdk1.8后，已经被元空间（Metaspace）所替代。<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/75528e4b71c72c5449bd7.png" alt="jvmmemorystructure.jpg"></li>
</ul>
<h1>4. Java内存堆和栈区别？</h1>
<ul>
<li>堆属于线程共享的内存区域，栈属于线程私有的内存区域</li>
<li>堆存储大部分对象，栈存储局部变量、方法参数、对象引用等</li>
<li>堆对象生命周期可以在方法调用结束后继续存在，直到不再被任何变量引用，然后被垃圾收集器回收。栈对象通常随着方法调用的结束而自动释放，不需要垃圾收集器处理</li>
</ul>
<h1>5. JDK678内存区域的变化</h1>
<ul>
<li>JDK1.6 使用永久代实现方法区<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/bbae62bdce7fa9267b600.png" alt="jdk6memory.png"></li>
<li>JDK1.7 时发生了一些变化，将字符串常量池、静态变量，存放在堆上<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/ba9fce13a180a20954a3b.png" alt="jdk7memory.png"></li>
<li>在 JDK1.8 时彻底干掉了永久代，而在直接内存中划出一块区域作为元空间，运行时常量池、类常量池都移动到元空间。<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/d9b02e589e79a1b781b2b.png" alt="jdk8memory.png"></li>
</ul>
<h1>6. java对象（普通Java对象，不包括数组和Class对象等）创建过程？</h1>
<ul>
<li>1.类加载检查：虚拟机遇到一条new指令时，首先检查这个指令的参数是否能在常量池中定位到一个类的符号的引用，以及这个符号引用代表的类是否已被加载，解析和初始化过，如果没有，则执行类加载过程</li>
<li>2.分配内存：为新生对象分配内存，内存大小在类加载完成后便可完全确定。为对象分配空间的任务等同于把一块确定大小的内存从java堆中划分出来。有2种分配方法</li>
<li>3.初始化：将分配到的内存空间都初始化为零值（不包括对象头），可提前至TLAB分配时进行。保证了对象实例字段在java代码中不赋初始值就能访问到这些字段的数据类型所对应的零值</li>
<li>4.设置对象头信息：对对象进行设置，例如这个对象是哪个类的实例，如何才能找到类的元数据信息，对象的哈希码，对象GC分代年龄等信息。这些信息存放在对象的对象头(Object Header)中</li>
<li>5.上面的工作完成后，从虚拟机的角度看，一个新的对象已经产生了，但从java程序的视角看还需要执行init方法。由字节码中是否跟随invokespecial指令所决定，执行new指令之后会接着执行init方法，把对象初始化，这样一个真正可用的对象才算完全生产出来。</li>
</ul>
<h1>7. 对象的销毁过程了解吗？</h1>
<ul>
<li>对象创建完成后，就可以通过引用来访问对象的方法和属性，当对象不再被任何引用指向时，对象就会变成垃圾。垃圾收集器会通过可达性分析算法判断对象是否存活，如果对象不可达，就会被回收。垃圾收集器会通过标记清除、标记复制、标记整理等算法来回收内存，将对象占用的内存空间释放出来。常用的垃圾收集器有 CMS、G1、ZGC 等，它们的回收策略和效率不同，可以根据具体的场景选择合适的垃圾收集器。</li>
</ul>
<h1>8. 什么是指针碰撞？什么是空闲列表？java内存分配方法</h1>
<ul>
<li>内存分配有两种方式，指针碰撞（Bump The Pointer）、空闲列表（Free List）。</li>
<li>指针碰撞(Bump the Pointer)：假设堆内存是一个连续的空间，分为两个部分，一部分是已经被使用的内存，另一部分是未被使用的内存。在分配内存时，Java 虚拟机维护一个指针，指向下一个可用的内存地址，每次分配内存时，只需要将指针向后移动（碰撞）一段距离，然后将这段内存分配给对象实例即可。</li>
<li>空闲列表(Free List)：如果java堆中的内存不连续，已使用的内存和空闲的内存相互交错，虚拟机就必须维护一个列表，记录可用的内存块，从列表中找到一块足够大的空间分配给对象实例，并更新列表上的记录，这种分配方式称为空闲列表(Free List)</li>
<li>指针碰撞适用于管理简单、碎片化较少的内存区域（如年轻代），而空闲列表适用于内存碎片化较严重或对象大小差异较大的场景（如老年代）。</li>
</ul>
<h1>9. JVM里new对象时，堆会发生抢占吗？JVM 是怎么设计来保证线程安全的？</h1>
<ul>
<li>解决分配内存时线程不安全（多线程并发时正在给对象A分配内存，还没来得及修改指针，对象B又用这个指针分配内存）方案</li>
<li>方案1对分配内存空间动作进行同步处理，采用CAS配上失败重试的方式保证更新操作的原子性</li>
<li>方案2把内存分配的动作按照线程划分在不同的空间中进行，即每个线程在java堆中预先分配一小块内存，称为本地线程分配缓冲（Thread Local Allocation Buffer,TLAB）。哪个线程要分配内存，就在哪个线程的TLAB上分配，只有TLAB用完并分配新的TLAB时，才需要同步锁定，通过-XX:+/-UseTLAB参数使用TALB，</li>
</ul>
<h1>10. 对象在内存中的存储布局</h1>
<ul>
<li>对象在堆的内存布局是由 Java 虚拟机规范定义的，在 HotSpot 中可以划分为三个部分：
<ul>
<li>对象头（Object Header）存储堆对象的布局、类型、GC状态、同步状态和标识哈希码的基本信息。</li>
<li>实例数据（Instance Data）存储对象的数据信息，父类的信息，对象字段属性信息。</li>
<li>对齐填充（Padding）可选，当对象实例数据部分没有对齐时，就需要通过对齐填充来补全，为了计算机高效寻址。Hotspot的自动内存管理系统要求对象的真实地址和大小必须是8字节整数倍。否则有可能出现跨缓存行的字段。效率低</li>
</ul>
</li>
</ul>
<p><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/400b56e58c83f21914264.jpg" alt="objectstructure.png"><br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/0eb05907be32a0d335364.jpg" alt="objectstructureandspace.png"></p>
<ul>
<li>对象头
<ul>
<li>mark word存储对象自身的运行数据，如哈希码，GC分代年龄，锁状态标志，线程持有的锁，偏向线程ID等.在64位操作系统下占8个字节，-XX:+/-UseCompressedClassPointers //开启/关闭压缩类指针,-XX:+/-UseCompressedOops//开启/关闭压缩普通对象指针
<ul>
<li>锁标志位（lock）：区分锁状态，11时表示对象待GC回收状态, 最后2位锁标识(11)有效</li>
<li>biased_lock：是否偏向锁，由于无锁和偏向锁的锁标识都是01，没办法区分，引入一位的偏向锁标识位</li>
<li>分代年龄（age）：表示对象被GC的次数，当次数到达阈值的时候，对象就会转移到老年代</li>
<li>对象的hashcode（hash）：对象加锁后，计算的结果31位不够表示，在偏向锁，轻量锁，重量锁，hashcode会被转移到Monitor中</li>
<li>偏向锁的线程ID（JavaThread）：偏向模式的时候，当某个线程持有偏向锁对象的时候，对象这里就会被置为该线程的ID。 后续操作无需再进行尝试获取锁的动作。</li>
<li>epoch：偏向锁在CAS锁操作过程中，偏向性标识，表示对象更偏向哪个锁。</li>
<li>ptr_to_lock_record：轻量级锁状态下，JVM通过CAS操作在对象的标题字中设置指向栈中锁记录的指针。当锁获取是无竞争的时，JVM使用原子操作而不是OS互斥。这种技术称为轻量级锁定。</li>
<li>ptr_to_heavyweight_monitor：重量级锁状态下，指向对象监视器Monitor的指针。如果两个不同的线程同时在同一个对象上竞争，则必须将轻量级锁定升级到Monitor以管理等待的线程。</li>
</ul>
</li>
<li>类型指针Klass Pointer，指向对象所属类的元数据的指针，用于确定这个对象是哪个类的实例。并不是所有虚拟机实现都必须在对象数据上保留类型指针，也就是查找对象的元数据信息不一定通过对象本身。在开启指针压缩的情况下占4个字节，否则占8个字节。java -XX:+PrintFlagsFinal -version | grep UseCompressedOops 命令来查看当前 JVM 是否开启了压缩指针。jdk8默认开启</li>
<li>Length field如果对象是java数组，对象头中还必须有一块用于记录数组长度的数据，因为虚拟机可以通过普通java对象的元数据信息确定java对象的大小，但是从数组的元数据中无法确定数组的大小。占4个字节。<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/e58f17fe68f0ddc72c4e1.jpg" alt="objectheader.png"><br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/b0a1f7d7ac59d447ff05f.png" alt="64bithotSpotmarkword.png"></li>
</ul>
</li>
</ul>
<h1>11. 一个java对象占用多大内存</h1>
<p>在操作系统是64位的，并且JDK8中的压缩指针是默认开启的，因此new Object()的大小是 16 字节（12 字节的对象头（8字节markword+4字节类型指针） + 4 字节的对齐填充）。</p>
<ul>
<li>使用 JOL 工具来查看对象的内存布局</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>&lt;dependency&gt;
    &lt;groupId&gt;org.openjdk.jol&lt;/groupId&gt;
    &lt;artifactId&gt;jol-core&lt;/artifactId&gt;
    &lt;version&gt;0.9&lt;/version&gt;
&lt;/dependency&gt;
public class JOLSample {
    public static void main(String[] args) {
        // 打印JVM详细信息（可选）
        System.out.println(VM.current().details());

        // 创建Object实例
        Object obj = new Object();

        // 打印Object实例的内存布局
        String layout = ClassLayout.parseInstance(obj).toPrintable();
        System.out.println(layout);
    }
}

</code></pre></div><figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/cf23960d893800508fdad.png" alt="javaobjectsize.png" tabindex="0"><figcaption>javaobjectsize.png</figcaption></figure>
<ul>
<li>OFFSET：偏移地址，单位字节；</li>
<li>SIZE：占用的内存大小，单位字节；</li>
<li>TYPE DESCRIPTION：类型描述，其中 object header 为对象头；</li>
<li>VALUE：对应内存中当前存储的值，二进制 32 位；</li>
<li>对象头是 12 个字节，还有 4 个字节的 padding，一共 16 个字节。</li>
</ul>
<h1>12. 对象引用占多少大小？</h1>
<ul>
<li>HotSpot JVM 默认开启了压缩指针，在 64 位JVM 上，对象引用占用 4 字节。关闭则是8字节</li>
<li>ReferenceHolder.reference字段位于偏移量12，为4字节。这表明在64位JVM下且压缩指针开启，对象引用占用的内存大小为4字节</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>class ReferenceSizeExample {
    private static class ReferenceHolder {
        Object reference;
    }

    public static void main(String[] args) {
        System.out.println(VM.current().details());
        System.out.println(ClassLayout.parseClass(ReferenceHolder.class).toPrintable());
    }
}

</code></pre></div><figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/915406ceed01532cc31a6.png" alt="javaobjectreferencesize.png" tabindex="0"><figcaption>javaobjectreferencesize.png</figcaption></figure>
<h1>13. 对象怎么访问定位？</h1>
<ul>
<li>Java 程序会通过栈上的 reference 数据来访问堆上的具体对象。reference 类型是一个指向对象的引用，是由虚拟机实现而定的，主流的访问方式主要有使用句柄和直接指针两种：
<ul>
<li>如果使用句柄访问的话，Java 堆中将可能会划分出一块内存来作为句柄池，reference 中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与类型数据各自具体的地址信息，最大好处就是 reference 中存储的是稳定句柄地址，在对象被移动（垃圾收集时移动对象是非常普遍的行为）时只会改变句柄中的实例数据指针，而 reference 本身不需要被修改。</li>
<li>如果使用直接指针访问的话，Java 堆中对象的内存布局就必须考虑如何放置访问类型数据的相关信息，reference 中存储的直接就是对象地址，如果只是访问对象本身的话，就不需要多一次间接访问的开销，最大的好处就是速度更快，它节省了一次指针定位的时间开销，由于对象访问在 Java 中非常频繁，因此这类开销积少成多也是一项极为可观的执行成本。</li>
</ul>
</li>
<li>HotSpot 虚拟机主要使用直接指针来进行对象访问。</li>
</ul>
<h1>14. 内存溢出和内存泄漏是什么意思？</h1>
<ul>
<li>内存溢出：指当程序请求分配内存时，由于没有足够的内存空间满足其需求，会抛出 OutOfMemoryError。内存溢出可能是由于内存泄漏或者程序一次性尝试分配大量内存，内存直接就干崩溃了导致的</li>
<li>内存泄漏：是指程序在使用完内存后，未能释放已分配的内存空间，导致这部分内存无法再被使用。随着时间的推移，内存泄漏会导致可用内存逐渐减少，最终可能导致内存溢出。</li>
<li>内存泄漏通常发生在长期存活的对象持有短期存活对象的引用，而长期存活的对象又没有及时释放对短期存活对象的引用，从而导致短期存活对象无法被回收。</li>
</ul>
<h1>15. 举几个可能发生内存泄漏的情况？java内存泄漏的例子有哪些？举例并且说明解决方法</h1>
<ul>
<li>静态集合类：静态集合的生命周期和JVM一致，所以静态集合引用的对象不能被释放。尽量不要使用static成员变量，减少生命周期</li>
<li>单例模式：单例对象在初始化后将在JVM的整个生命周期中存在（以静态变量的方式），如果单例对象持有外部的引用，那么这个对象将不能被JVM正常回收，导致内存泄漏。</li>
<li>各种连接：比如数据库连接，网络连接(socket) 和IO连接，除非调用close()方法将其连接关闭，否则是不会自动被GC回收；及时关闭资源</li>
<li>变量不合理的作用域：变量的定义作用域大于其使用范围或不再使用对象没有及时将对象设置为 null，很可能导致内存泄漏的发生。不用的对象，手动设置为null</li>
<li>hash值发生变化：对象修改后的Hash值和存储进容器时的Hash值不同，所以无法找到存入的对象，无法单独删除</li>
<li>ThreadLocal 使用不当。使用完 ThreadLocal 一定要记得使用 remove 方法来进行清除。</li>
<li>监听器：释放对象的时候没有删除监听器；</li>
<li>内部类：内部类的引用是比较容易遗忘的一种，而且一旦没释放可能导致一系列的后继类对象没有释放；</li>
</ul>
<h1>16. jvm垃圾回收机制及垃圾判断算法</h1>
<ul>
<li>
<p>垃圾回收（Garbage Collection，GC），就是释放垃圾占用的空间，防止内存爆掉。有效的使用可以使用的内存，对内存堆中已经死亡的或者长时间没有使用的对象进行清除和回收。</p>
</li>
<li>
<p>垃圾收集器在对堆区和方法区进行回收前，首先要确定这些区域的对象哪些可以被回收，哪些暂时还不能回收，就要用到判断对象是否存活的算法。</p>
</li>
<li>
<p>引用计数算法(Reference Counting)给对象中添加一个引用计数器，初始值为1，每当一个地方引用它时，计数器值+1.引用失效时（一个对象实例的某个引用超过了生命周期或者被设置为一个新值时），计数器值-1；当计数器为0则直接回收。简单，判定效率高，实时性较高，无需等到内存不够的时候，才开始回收，但不能解决对象间相互循环引用问题。</p>
</li>
<li>
<p>可达性分析算法(Reachability Analysis)通过一系列称为GC Roots的对象为起始点，从这些节点向下搜索，搜索所走过的路径称为引用连（Reference Chain）,当一个对象到GC Roots没有任何引用链相连（从GC Roots到这个对象不可达）时，证明此对象是不可用的。</p>
</li>
<li>
<p>GC Roots的对象包括：</p>
<ul>
<li>java虚拟机栈（栈中的本地变量表）中引用的对象（方法的参数、局部变量等），</li>
<li>本地方法栈中JNI（native方法）引用的对象，</li>
<li>类静态变量，</li>
<li>运行时常量池中的常量（String 或 Class 类型）。</li>
</ul>
</li>
</ul>
<h1>17. 强软弱虚引用</h1>
<ul>
<li>强引用(Strong Reference) Object obj = new Object()，垃圾回收器永远不会回收掉被强引用的对象，即使抛出OutOfMemoryError</li>
<li>软引用(Soft Reference)描述一些还有用但非必须的对象，在系统将要发生内存溢出异常之前，将会对弱引用对象进行二次回收，如果这次回收还没有足够内存，才会抛出内存异常。SoftReference类实现软引用。可用来实现内存敏感的高速缓存。可以和一个引用队列（ReferenceQueue）联合使用，如果软引用所引用的对象被垃圾回收，JVM就会把这个软引用加入到与之关联的引用队列中</li>
<li>弱引用(Weak Reference)描述非必须对象，当垃圾回收时都会回收掉只被弱引用关联的对象。Weakreference类实现弱引用、可以和引用队列（ReferenceQueue）联合使用，如果弱引用所引用的对象被垃圾回收，Java虚拟机就会把这个弱引用加入到与之关联的引用队列中</li>
<li>虚引用(Phantom reference) 主要用来跟踪对象被垃圾回收的活动。虚引用不影响对象存活，也不能通过虚引用获得对象实例。PhantomReference类实现虚引用、虚引用<strong>必须</strong>和引用队列（ReferenceQueue）联合使用。如果虚引用所引用的对象被垃圾回收，JAVA虚拟机就会把这个虚引用加入到与之关联的引用队列中。程序如果发现虚引用已经被加入到引用队列，就可以在所引用的对象被回收前采取行动</li>
</ul>
<h1>18. 被标记为垃圾的对象一定会被回收吗？finalize()方法作用？</h1>
<ul>
<li>在可达性分析算法中不可达的对象.至少要经历两次标记过程。</li>
<li>第一次标记：如果对象在进行可达性分析后发现没有与GC Roots相连接的引用链，将会被第一次标记；</li>
<li>第二次标记：第一次标记后接着会进行一次筛选，筛选的条件是此对象是否有必要执行 finalize() 方法。在finalize()方法中没有重新与引用链建立关联关系的，将被进行第二次标记。第二次标记成功的对象将真的会被回收，如果对象在 finalize() 方法中重新与引用链建立了关联关系，那么将会存活。建议在这个方法中释放该对象持有的资源，不建议重写该方法。该方法有且仅会被调用一次</li>
</ul>
<h1>19. Java 堆的内存分区</h1>
<p>Java堆根据对象存活周期的不同将内存划分为</p>
<ul>
<li>新生代（Young Generation）包括一块较大的Eden空间和两块较小的Survivor空间,大小比例是8:1:1 (参数–XX:SurvivorRatio设定),新生代的垃圾收集主要采用标记-复制算法，因为新生代的存活对象比较少，每次复制少量的存活对象效率比较高。每次分配内存只使用 Eden 和其中一块 Survivor。发生垃圾收集时，将 Eden 和 Survivor 中仍然存活的对象一次性复制到另外一块 Survivor 空间上，然后直接清理掉 Eden 和已用过的那块 Survivor 空间。</li>
<li>老年代（Tenured Generation）因为对象存活率高、没有额外空间对它进行分配担保，使用“标记—清理”或者“标记—整理”算法来进行回收。默认新生代与老年代的比例的值为 1:2 (参数–XX:NewRatio指定)</li>
<li>永久代（Permanet Generation）存储class,method,filed对象，一般不会内存溢出，jdk1.8替换为Metaspace（元数据空间）。所占用的内存空间不在虚拟机内部，而是在本地内存空间中。修改原因：由于永久代内存经常不够用或发生内存泄露，爆出异常java.lang.OutOfMemoryError: PermGen</li>
<li>Virtual区：最大内存和初始内存的差值，就是Virtual区</li>
</ul>
<h1>20. 常用的垃圾回收算法，JVM中的垃圾回收了解吗？为什么新生代不用标记整理？√</h1>
<ul>
<li>
<p>标记-复制算法(Copying)：将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后对这一块内存空间进行回收，</p>
</li>
<li>
<p>不会产生连续内存碎片，内存分配时只要移动堆顶指针，按顺序分配内存即可，效率高；但内存减半，空间利用率低。适合只有少量对象存活的场景，适合新生代</p>
</li>
<li>
<p>标记-清除算法(Mark-Sweep)：标记所有需要回收的对象，在标记完成后统一回收所有标记的对象</p>
</li>
<li>
<p>会产生不连续的内存碎片，不利于分配大对象。适合对象不多的情况。标记和清除两个过程的效率都不高.适合老年代</p>
</li>
<li>
<p>标记-整理算法(Mark-Compact)标记所有需要回收的对象，在标记完成后让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存</p>
</li>
<li>
<p>不会产生内存碎片，缺点是需要移动对象，清除效率比标记清除低，适合老年代</p>
</li>
</ul>
<h1>21. Minor GC/Young GC、Major GC/Old GC、Mixed GC、Full GC都是什么意思？</h1>
<ul>
<li>新生代收集（Minor GC/Young GC）：指新生代的垃圾收集。</li>
<li>老年代收集（Major GC/Old GC）：指老年代的垃圾收集。CMS 收集器的特有行为。</li>
<li>混合收集（Mixed GC）：指G1 垃圾收集器特有的一种 GC 类型，它在一次 GC 中同时清理年轻代和部分老年代</li>
<li>整堆收集（Full GC）：收集整个 Java 堆和方法区的垃圾收集。会STOP THE WORD</li>
</ul>
<h1>22. Minor GC/Young GC 什么时候触发？</h1>
<ul>
<li>新创建的对象优先在新生代 Eden 区进行分配，如果 Eden 区没有足够的空间时，就会触发 Young GC 来清理新生代。</li>
</ul>
<h1>23. 什么时候会触发 Full GC？</h1>
<ul>
<li>Young GC 之前检查老年代：Young GC时发现老年代可用的连续内存空间 &lt; 新生代历次Young GC后升入老年代的对象总和的平均大小，说明本次 Young GC 后可能升入老年代的对象大小，可能超过了老年代当前可用内存空间,那就会触发 Full GC。</li>
<li>Young GC 之后老年代空间不足：执行 Young GC 之后有一批对象需要放入老年代，老年代没有足够的内存空间存放这些对象，就会触发 Full GC。</li>
<li>老年代空间不足，老年代内存使用率过高，达到一定比例，也会触发 Full GC。</li>
<li>空间分配担保失败（ Promotion Failure），新生代的 To 区放不下从 Eden 和 From 拷贝过来对象，或者新生代对象 GC 年龄到达阈值需要晋升这两种情况，老年代如果放不下的话都会触发 Full GC。</li>
<li>方法区内存空间不足：如果方法区由永久代实现，永久代空间不足 Full GC。</li>
<li>System.gc()等命令触发：System.gc()、jmap -dump 等命令会触发 full gc。</li>
</ul>
<h1>24. 对象什么时候会进入老年代？</h1>
<ul>
<li>长期存活的对象进入老年代。在对象的对象头信息中存储着对象的迭代年龄,迭代年龄会在每次 YoungGC 之后对象的移区操作中增加,每一次移区年龄加一.当这个年龄达到 15(默认)之后,这个对象将会被移入老年代。- XX:MaxTenuringThreshold设置</li>
<li>大对象直接分配到老年代。避免在Eden区和两个Survivor区之间发生大量的内存拷贝-XX：PretenureSizeThreshold设置</li>
<li>动态对象年龄判定。如果在survivor区中相同年龄的所有对象大小大于survivor空间的一半，则大于或等于该年龄的对象，可进入老年区</li>
<li>空间分配担保。Young GC后新生代仍然有大量对象存活，就需要老年代进行分配担保，把Survivor无法容纳的对象直接送入老年代</li>
</ul>
<h1>25. 分代收集算法(Generational Collection)</h1>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/e84e053a2828ccee7473c.png" alt="heapmemoryallocation.png" tabindex="0"><figcaption>heapmemoryallocation.png</figcaption></figure>
<ul>
<li>JVM垃圾回收机制采用的分代回收
<ul>
<li>对象优先在新生代Eden区上进行分配，每次使用Eden和其中一块Survivor。
<ul>
<li>如果Eden区空间不够时，尝试放入到Survivor0，发起Minor GC，
<ul>
<li>如果Survivor0可以放入，那么放入之后清除Eden区。</li>
<li>如果Survivor0不可以放入，那么尝试把Eden和Survivor0的存活对象放到Survivor1中。年龄+1，增加到一定年龄则移动到老年代中
<ul>
<li>如果Survivor1可以放入，那么放入Survivor1之后清除Eden和Survivor0 ，之后再把Survivor1中的对象复制到Survivor0中，保持Survivor1一直为空。</li>
<li>如果Survivor1不可以放入，那么直接把它们放入到老年代中，并清除Eden和Survivor0，这个过程也称为分配担保</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1>26. jvm垃圾回收器有哪些？作用是什么？</h1>
<ul>
<li>
<p>自动管理 Java 应用程序的运行时内存。它负责识别哪些内存是不再被应用程序使用，并释放这些内存以便重新使用。减少了程序员手动管理内存的负担，降低了内存泄漏和溢出错误的风险。</p>
</li>
<li>
<p>STW（stop the world）：所有工作线程暂停</p>
</li>
<li>
<p>JVM 的垃圾收集器主要分为两大类：分代收集器和分区收集器。分代收集器的代表是 CMS，分区收集器的代表是 G1 和 ZGC。</p>
</li>
<li>
<p>Serial/Serial Old收集器，单线程，进收集时会STW。-XX:+UseSerialGC：serial新生代使用标记复制，Serial Old老年代标记整理</p>
</li>
<li>
<p>ParNew/Serial Old收集器，Serial多线程版，-XX:+UseParNewGC：ParNew新生代使用标记复制，Serial Old老年代标记整理。</p>
</li>
<li>
<p>Parallel Scavenge/Parallel Old收集器，多线程.可设置吞吐量参数 吞吐量=运行用户代码时间/（运行用户代码时间+垃圾收集时间）</p>
<ul>
<li>-XX:+UseParallelGC年轻代使用ParallelGC垃圾回收器标记复制，老年代使用串行回收器</li>
<li>-XX:+UseParalledlOldGC年轻代使用ParallelGC垃圾回收器标记复制，老年代使用ParallelOldGC垃圾回收器标记-整理</li>
<li>-XX:MaxGCPauseMillis=n：设置并行收集最大暂停毫秒数</li>
<li>-XX:GCTimeRatio=n：设置垃圾回收时间占程序运行时间的百分比0~100，默认值为99，也就是垃圾回收时间不能超过1%</li>
<li>-XX:UseAdaptiveSizePolicy自适应GC模式，垃圾回收器将自动调整年轻代、老年代等参数，达到吞吐量、堆大小、停顿时间之间的平衡</li>
</ul>
</li>
<li>
<p>CMS （Concurrent Mark Sweep）多线程，回收时间短，标记—清除,-XX:+UseConcMarkSweepGC进行设置</p>
</li>
<li>
<p>G1 收集器（Garbage-First Garbage Collector） 年轻代标记复制，老年代标记整理。jdk9后默认。G1 有五个属性：分代、增量、并行、标记整理、STW。</p>
</li>
<li>
<p>G1 垃圾回收模式</p>
<ul>
<li>Eden空间耗尽时会触发Young GC。Eden空间的数据移动到Survivor空间中，如果Survivor空间不够，Eden空间的部分数据会直接晋升到年老代空间。Survivor区的数据移动到新的Survivor区中，也有部分数据晋升到老年代空间中。最终Eden空间的数据为空，GC停止工作，应用线程继续执行。</li>
<li>当大量对象晋升到老年代old region时，为了避免堆内存被耗尽，虚拟机会触发Mixed GC，回收整个Young Region和一部分的Old Region，可以选择哪些old region进行收集，从而可以对垃圾回收的耗时时间进行控制。当老年代大小占整个堆大小百分比达到该-XX:InitiatingHeapOccupancyPercent=n时触发。默认45%.它的GC步骤如下
<ul>
<li>1.全局并发标记（global concurrent marking），执行过程分为五个步骤：
<ul>
<li>初始标记（initial mark，STW）标记从根节点直接可达的对象，这个阶段会执行一次年轻代GC，会产生全局停顿</li>
<li>根区域扫描（root region scan）G1 GC 在初始标记的存活区扫描对老年代的引用，并标记被引用的对象。该阶段与应用程序（非 STW）同时运行，并且只有完成该阶段后，才开始下一次STW年轻代垃圾回收</li>
<li>并发标记（Concurrent Marking）G1 GC 在整个堆中查找可访问的（存活的）对象。该阶段与应用程序同时运行，可以被 STW 年轻代垃圾回收中断。</li>
<li>重新标记（Remark，STW）该阶段是 STW 回收，因为程序在运行，针对上一次的标记进行修正。</li>
<li>清除垃圾（Cleanup，STW）清点和重置标记状态，该阶段会STW，这个阶段并不会实际上去做垃圾的收集，等待evacuation阶段来回收。</li>
</ul>
</li>
<li>2.拷贝存活对象（evacuation）:该阶段是全暂停的。把一部分Region里的活对象拷贝到另一部分Region中，从而实现垃圾的回收清理</li>
</ul>
</li>
<li>Full GC</li>
<li>Remembered Set（已记忆集合）其作用是跟踪指向某个堆内的对象引用。每个Region初始化时，会初始化一个RSet，该集合用来记录并跟踪其它Region指向该Region中对象的引用，每个Region默认按照512Kb划分成多个Card，所以RSet需要记录的东西应该是 xx Region的 xx Card。</li>
</ul>
</li>
<li>
<p>G1参数设置 G1 GC 的吞吐量目标是 90% 的应用程序时间和 10%的垃圾回收时间，MaxGCPauseMillis不要设置太小</p>
<ul>
<li>-XX:+UseG1GC使用G1垃圾收集器</li>
<li>-XX:MaxGCPauseMillis设置期望达到的最大GC停顿时间毫秒（尽力保证），默认200</li>
<li>-XX:G1HeapRegionSize=n设置G1区域的大小。值是2的幂，1-32MB。目标是根据最小的Java堆大小划分出约2048个区域。默认是堆内存的1/2000</li>
<li>-XX:ParallelGCThreads=n设置STW工作线程数的值。n的值与逻辑处理器的数量相同，最多8</li>
<li>-XX:ConcGCThreads=n设置并行标记的线程数。将n设置为并行垃圾回收线程数 (ParallelGCThreads)的 1/4 左右</li>
<li>-XX:InitiatingHeapOccupancyPercent=n设置触发标记周期的Java堆占用率阈值。默认45%</li>
</ul>
</li>
<li>
<p>ZGC收集器 低延迟垃圾收集器，适用于大内存低延迟服务的内存管理和回收。ZGC 的两个关键技术：指针染色和读屏障，不仅应用在并发转移阶段，还应用在并发标记阶段：将对象设置为已标记，传统的垃圾回收器需要进行一次内存访问，并将对象存活信息放在对象头中；而在 ZGC 中，只需要设置指针地址的第 42-45 位即可，并且因为是寄存器访问，所以速度比访问内存更快。<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/54ef59c1775c762f596ea.png" alt="jvmzgc.png"></p>
</li>
</ul>
<h1>27. 什么是 OopMap ？</h1>
<ul>
<li>在 HotSpot 中，有个数据结构（映射表）称为OopMap。一旦类加载动作完成的时候，HotSpot 就会把对象内什么偏移量上是什么类型的数据计算出来，记录到 OopMap。在即时编译过程中，也会在安全点生成 OopMap，记录下栈上和寄存器里哪些位置是引用。</li>
</ul>
<h1>28. 什么是安全点？</h1>
<ul>
<li>Safe Point指Java线程执行到某个位置时JVM能够安全、可控的回收对象。如果一个Java线程分配一个对象，此时对象的地址还在寄存器中，这时候这个线程失去了CPU时间片，而此时STW GC发现没有任何GC ROOTS 与该对象关联起来，被认为是垃圾并被回收了，之后CPU重新获得时间片后发现此时对象已经不存在了，程序出错</li>
<li>SafePoint 指的特定位置主要有：
<ul>
<li>循环的末尾 (防止大循环的时候一直不进入 Safepoint ，而其他线程在等待它进入 Safepoint )。</li>
<li>方法返回前。</li>
<li>调用方法的 Call 之后。</li>
<li>抛出异常的位置</li>
</ul>
</li>
</ul>
<h1>29. cms执行过程？</h1>
<ul>
<li>初始标记（Initial Mark）：标记所有从 GC Roots 直接可达的对象，这个阶段需要 STW，但速度很快。</li>
<li>并发标记（Concurrent Mark）：从初始标记的对象出发，遍历所有对象，标记所有可达的对象。这个阶段是并发进行的，STW。</li>
<li>重新标记（Remark）：完成剩余的标记工作，包括处理并发阶段遗留下来的少量变动，这个阶段通常需要短暂的 STW 停顿。</li>
<li>并发清除（Concurrent Sweep）：清除未被标记的对象，回收它们占用的内存空间。</li>
</ul>
<h1>30. G1收集器？</h1>
<ul>
<li>多线程，缩短STW时间。</li>
<li>G1 把 Java 堆划分为多个大小相等的独立区域（Region），每个区域都可以扮演Eden、survivor、老年代角色，另外Humongous区存放巨型对象（超过分区容量50%）如果一个大对象超过了一个 Region 大小的 50%，就会被放入 Humongous 中。区域化管理使得 G1 可以更灵活地进行垃圾收集，只回收部分区域而不是整个新生代或老年代。</li>
<li>G1 收集器的运行过程：
<ul>
<li>并发标记，通过并发标记的方式找出堆中的垃圾对象。并发标记阶段与应用线程同时执行，不会导致应用线程暂停。</li>
<li>混合收集，在并发标记完成后，G1 会计算出哪些区域的回收价值最高（也就是包含最多垃圾的区域），然后优先回收这些区域。这种回收方式包括了部分新生代区域和老年代区域。选择回收成本低而收益高的区域进行回收，可以提高回收效率和减少停顿时间。</li>
<li>可预测的停顿，G1 在垃圾回收期间仍然需要「Stop the World」。不过，G1 在停顿时间上添加了预测机制，用户可以 JVM 启动时指定期望停顿时间，G1 会尽可能地在这个时间内完成垃圾回收。</li>
</ul>
</li>
</ul>
<h1>31. 有了 CMS，为什么还要引入 G1？</h1>
<ul>
<li>CMS最主要的优点是并发收集、低停顿。</li>
<li>CMS缺点。
<ul>
<li>Mark Sweep 算法会导致内存碎片比较多</li>
<li>CMS 的并发能力比较依赖于 CPU 资源，并发回收时垃圾收集线程可能会抢占用户线程的资源，导致用户程序性能下降。</li>
<li>并发清除阶段，用户线程依然在运行，会产生所谓的理“浮动垃圾”（Floating Garbage），本次垃圾收集无法处理浮动垃圾，必须到下一次垃圾收集才能处理。如果浮动垃圾太多，会触发新的垃圾回收，导致性能降低。</li>
</ul>
</li>
<li>G1 主要解决了内存碎片过多的问题。</li>
</ul>
<h1>32. G1 和 CMS 的区别？</h1>
<ul>
<li>CMS主要步骤：初始收集，并发标记，重新标记，并发清除（删除）、重置。</li>
<li>G1主要步骤：初始标记，并发标记，重新标记，复制清除（整理）</li>
<li>CMS缺点是对CPU要求高。G1将内存化成了多块，所有对内存要求高</li>
<li>CMS是清除，存在内存碎片。G1是整理，碎片空间较小。</li>
<li>G1和CMS都是响应时间优先，都是尽量控制 STW 时间。</li>
</ul>
<h1>33. 线上用的什么垃圾收集器？为什么要用它？</h1>
<ul>
<li>jdk8默认收集器java -XX:+PrintCommandLineFlags -version查看-&gt;-XX:+UseParallelGC表示的是新生代用的Parallel Scavenge收集器，老年代用的是Parallel Old 收集器。</li>
<li><strong>采用Parallel Scavenge + Parallel Old的组合。系统业务相对复杂，但并发并不是非常高，希望尽可能利用处理器资源，出于提高吞吐量的考虑</strong></li>
<li>采用Parallel New+CMS的组合，我们比较关注服务的响应速度，所以采用了 CMS 来降低停顿时间。</li>
<li>采用 G1 垃圾收集器，因为它不仅满足我们低停顿的要求，而且解决了 CMS 的浮动垃圾问题、内存碎片问题</li>
</ul>
<h1>34. 垃圾收集器应该如何选择？</h1>
<ul>
<li>Serial ：如果应用程序有一个很小的内存空间（大约 100 MB）亦或它在没有停顿时间要求的单线程处理器上运行。</li>
<li>Parallel：如果优先考虑应用程序的峰值性能，并且没有时间要求要求，或者可以接受 1 秒或更长的停顿时间。</li>
<li>CMS/G1：如果响应时间比吞吐量优先级高，或者垃圾收集暂停必须保持在大约 1 秒以内。</li>
<li>ZGC：如果响应时间是高优先级的，或者堆空间比较大</li>
</ul>
<h1>35. 对象一定分配在堆中吗？有没有了解逃逸分析技术？好处？</h1>
<ul>
<li>
<p>对象不一定分配在堆中。在编译期间，JIT 会对代码做很多优化。其中有一部分优化的目的就是减少内存堆分配压力，其中一种技术叫做逃逸分析。</p>
</li>
<li>
<p>逃逸分析是指分析指针动态范围的方法，它同编译器优化原理的指针分析和外形分析相关联。当变量（或者对象）在方法中分配后，其指针有可能被返回或者被全局引用，这样就会被其他方法或者线程所引用，这种现象称作指针（或者引用）的逃逸(Escape)。通俗点讲，当一个对象被 new 出来之后，它可能被外部所调用，如果是作为参数传递到外部了，就称之为方法逃逸。如果对象还有可能被外部线程访问到，例如赋值给可以在其它线程中访问的实例变量，这种就被称为线程逃逸。<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/49635d303930f7f90c7a7.png" alt="jvmescape.png"></p>
</li>
<li>
<p>逃逸分析的好处</p>
<ul>
<li>栈上分配:如果确定一个对象不会逃逸到线程之外，那么久可以考虑将这个对象在栈上分配，对象占用的内存随着栈帧出栈而销毁，这样一来，垃圾收集的压力就降低很多。</li>
<li>同步消除:线程同步本身是一个相对耗时的过程，如果逃逸分析能够确定一个变量不会逃逸出线程，无法被其他线程访问，那么这个变量的读写肯定就不会有竞争， 对这个变量实施的同步措施也就可以安全地消除掉。</li>
<li>标量替换:如果一个数据是基本数据类型，不可拆分，它就被称之为标量。把一个 Java 对象拆散，将其用到的成员变量恢复为原始类型来访问，这个过程就称为标量替换。假如逃逸分析能够证明一个对象不会被方法外部访问，并且这个对象可以被拆散，那么可以不创建对象，直接用创建若干个成员变量代替，可以让对象的成员变量在栈上分配和读写。</li>
</ul>
</li>
</ul>
<h1>36. 有哪些常用的命令行性能监控和故障处理工具？</h1>
<ul>
<li>操作系统工具
<ul>
<li>top：显示系统整体资源使用情况</li>
<li>vmstat：监控内存和 CPU</li>
<li>iostat：监控 IO 使用</li>
<li>netstat：监控网络使用</li>
</ul>
</li>
<li>JDK 性能监控工具
<ul>
<li>jps：虚拟机进程查看</li>
<li>jstat：虚拟机运行时信息查看</li>
<li>jinfo：虚拟机配置查看</li>
<li>jmap：内存映像（导出）</li>
<li>jhat：堆转储快照分析</li>
<li>jstack：Java 堆栈跟踪</li>
<li>jcmd：实现上面除了 jstat 外所有命令的功能</li>
</ul>
</li>
</ul>
<h1>37. 了解哪些可视化的性能监控和故障处理工具？</h1>
<ul>
<li>JConsole</li>
<li>VisualVM</li>
<li>Java Mission Control</li>
<li>MAT Java 堆内存分析工具。</li>
<li>GChisto GC 日志分析工具。</li>
<li>GCViewer GC 日志分析工具。</li>
<li>JProfiler 商用的性能分析利器。</li>
<li>arthas 阿里开源诊断工具。</li>
<li>async-profiler Java 应用性能分析工具，开源、火焰图、跨平台。</li>
</ul>
<h1>38. 常使用的jvm -XX参数 √</h1>
<ul>
<li>
<ol>
<li>堆设置</li>
</ol>
<ul>
<li>-Xms：初始堆大小 -Xms512m：等价于-XX:InitialHeapSize，设置JVM初始堆内存为512M。</li>
<li>-Xmx：最大堆大小 -Xmx2048m：等价于-XX:MaxHeapSize，设置JVM最大堆内存为2048M。</li>
<li>-Xmn	新生代大小</li>
<li>-XX:NewSize=n：设置年轻代大小</li>
<li>-XX:PermSize	初始化永久代大小</li>
<li>-XX:MaxPermSize=n：设置持久代大小</li>
<li>-XX:NewRatio=n：年轻代和年老代的比值。为3，表示年轻代与年老代比值为1：3，年轻代占整个年轻代年老代和的 1/4</li>
<li>-XX:SurvivorRatio=n：年轻代中 Eden 区与两个 Survivor 区的比值。注意 Survivor 区有两个。如：3，表示 Eden：Survivor=3：2，一个Survivor区占整个年轻代的 1/5</li>
<li>-XX:Xmn	设置年轻代大小</li>
</ul>
</li>
<li>
<ol start="2">
<li>收集器设置</li>
</ol>
<ul>
<li>-XX:+UserSerialGC	串行垃圾收集器</li>
<li>-XX:+UserParrallelGC	并行垃圾收集器</li>
<li>-XX:+UseParalledlOldGC:设置并行年老代收集器</li>
<li>-XX:+UseConcMarkSweepGC	并发标记扫描垃圾回收器</li>
<li>-XX:+UseG1GC	G1垃圾回收器</li>
</ul>
</li>
<li>并行收集器参数设置
<ul>
<li>-XX:ParallelCMSThreads=n	设置并行收集器收集时使用的 CPU 数。并行收集线程数</li>
<li>-XX:MaxGCPauseMillis=n:设置并行收集最大的暂停时间（如果到这个时间了，垃圾回收器依然没有回收完，也会停止回收）</li>
<li>-XX:GCTimeRatio=n:设置垃圾回收时间占程序运行时间的百分比。公式为：1/(1+n)</li>
<li>-XX:+CMSIncrementalMode:设置为增量模式。适用于单 CPU 情况</li>
<li>-XX:ParallelGCThreads=n:设置并发收集器年轻代手机方式为并行收集时，使用的 CPU 数。并行收集线程数</li>
</ul>
</li>
<li>
<ol start="3">
<li>垃圾回收统计信息 （<a href="https://gceasy.io" target="_blank" rel="noopener noreferrer">https://gceasy.io</a>）</li>
</ol>
<ul>
<li>-XX:+PrintGC：开启打印gc信息</li>
<li>-XX:+PrintGCDetails：打印 gc 详细信息<br>
‐ -XX:+PrintGCTimeStamps 输出GC的时间戳（以基准时间的形式）<br>
‐ -XX:+PrintGCDateStamps 输出GC的时间戳（以日期的形式，如 2013‐05‐04T21:53:59.234+0800）</li>
<li>-Xloggc:filename ../logs/gc.log 日志文件的输出路径（GC Easy工具可以直接选择日志文件查看）</li>
<li>‐XX:+PrintHeapAtGC 在进行GC的前后打印出堆的信息</li>
</ul>
</li>
<li>
<ol start="6">
<li>设置系统属性参数</li>
</ol>
<ul>
<li>-D&lt;名称&gt;=&lt;值&gt; 可通过System.getProperty("名称");获得</li>
<li>查看正在运行的java进程所有参数jinfo ‐flags pid</li>
<li>查看正在运行的java进程具体参数jinfo ‐flag MaxHeapSize pid</li>
<li>完整命令ps -ef |grep java |grep -w x.jar|grep -v 'grep'|awk '{print $2}'| xargs -i{}  jinfo ‐flags {}</li>
</ul>
</li>
</ul>
<h1>45. 有没有处理过内存溢出问题？</h1>
<ul>
<li>内存泄漏和内存溢出二者关系非常密切，内存溢出可能会有很多原因导致，内存泄漏最可能的罪魁祸首之一。</li>
<li>排查过程和排查内存泄漏过程类似。</li>
</ul>
<h1>46. 解释执行和编译执解释和编译的区别：</h1>
<ul>
<li>解释：将源代码逐行转换为机器码。</li>
<li>编译：将源代码一次性转换为机器码。</li>
<li>解释执行：程序运行时，将源代码逐行转换为机器码，然后执行。</li>
<li>编译执行：程序运行前，将源代码一次性转换为机器码，然后执行。</li>
<li>Java被称为“解释型语言”，因为Java代码执行前，需要先将源代码编译成字节码，然后在运行时，再由 JVM 的解释器“逐行”将字节码转换为机器码，然后执行。这也是 Java 被诟病“慢”的主要原因。</li>
<li>JIT 的出现打破了这种刻板印象，JVM 会将热点代码（即运行频率高的代码）编译后放入 CodeCache，当下次执行再遇到这段代码时，会从 CodeCache 中直接读取机器码，然后执行。这大大提升了 Java 的执行效率。<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/d38fbe4b99861fd6dfa24.png" alt="jvmexplain.png"></li>
</ul>
<h1>47. 类的加载机制？</h1>
<ul>
<li>JVM 的操作对象是 Class 文件，JVM 把 Class 文件中描述类的数据结构加载到内存中，并对数据进行校验、解析和初始化，最终形成可以被 JVM 直接使用的类型，这个过程被称为类加载机制。</li>
</ul>
<h1>48. 类的生命周期吗？</h1>
<ul>
<li>一个类从被加载到虚拟机内存中开始，到从内存中卸载，整个生命周期需要经过七个阶段：加载 （Loading）、验证（Verification）、准备（Preparation）、解析（Resolution）、初始化 （Initialization）、使用（Using）和卸载（Unloading），其中验证、准备、解析三个部分统称为连接（Linking）。<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/63d05f55215bb01703097.png" alt="classlife.png"></li>
</ul>
<h1>49. 类加载器是如何加载Class文件？</h1>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/6db427fa24fe468568e6b.png" alt="processofloadingclass.png" tabindex="0"><figcaption>processofloadingclass.png</figcaption></figure>
<ul>
<li>类加载过程有：载入、验证、准备、解析、初始化。这 5 个阶段一般是顺序发生的，但在动态绑定的情况下，解析阶段会发生在初始化阶段之后。</li>
<li>加载(Loading)，找到.class文件并把文件包含的字节码加载到内存中。使用系统提供或者的类加载器来完成加载。加载阶段完成后，虚拟机外部的二进制字节流就按照虚拟机所需的格式存储在方法区之中，而且在Java堆中也创建一个 java.lang.Class 类的对象，这样便可以通过该对象访问方法区中的这些数据。在加载阶段，虚拟机需要完成以下三件事情：
<ul>
<li>通过一个类的全限定名来获取其定义的二进制字节流。</li>
<li>将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。</li>
<li>在Java堆中生成一个代表这个类的 java.lang.Class 对象，作为对方法区中这些数据的访问入口。</li>
</ul>
</li>
<li>验证：对二进制字节流进行校验，只有符合 JVM 字节码规范的才能被 JVM 正确执行。</li>
<li>准备：对类变量（也称为静态变量，static 关键字修饰的变量）分配内存并初始化，初始化为数据类型的默认值，如 0、0L、null、false 等。</li>
<li>解析：是虚拟机将常量池内的符号引用替换为直接引用的过程。解析动作主要针对类或接口、字段、类方法、接口方法、成员方法等。</li>
<li>初始化：类变量将被赋值为代码期望赋的值。是执行类的构造方法（javap 中看到的 <code>&lt;clinit&gt;</code>() 方法）的过程。</li>
</ul>
<h1>50. jvm类加载器?</h1>
<ul>
<li>类加载器(ClassLoader)，负责加载类文件，将类文件加载到内存中，生成 Class 对象。</li>
<li>BootstrapLoader：启动类加载器，负责加载 JVM 的核心类库，如 rt.jar和位于JAVA_HOME/jre/lib目录下的类。其无法被Java程序直接引用。</li>
<li>ExtClassLoader：扩展类加载器 加载扩展类(就是继承类和实现类)，加载\lib\ext目录或者被 java.ext.dirs系统变量指定的路径中的所有类库</li>
<li>AppClassLoader：加载来自Java命令的-classpath选项、java.class.path系统属性或CLASSPATH环境变量所指定的jar包和类路径。编写的任何类都是由应用程序类加载器加载的，除非显式使用自定义类加载器。</li>
<li>用户自定义类加载器 (User-Defined ClassLoader)，通过继承java.lang.ClassLoader类来创建自己的类加载器。通常用于加载网络上的类、执行热部署（动态加载和替换应用程序的组件）或为了安全目的自定义类的加载方式。</li>
</ul>
<h1>51. 什么是双亲委派模型（Parent Delegation Mode）？</h1>
<ul>
<li>工作过程：ClassLoader先从自己已经加载的类缓存中，查询是否此类已经加载，如果已经加载则直接返回原来已经加载的类。如果没有则委托父类加载器去加载，父类加载器采用同样的策略，一直到bootstrap ClassLoader。当所有的父类加载器都没有加载的时候，再由当前的类加载器加载，并将其放入它自己的缓存中，以便下次有加载请求的时候直接返回。</li>
<li>保证Java程序的稳定运行，避免类重复加载（JVM 区分不同类的方式不仅仅根据类名，相同的类文件被不同的类加载器加载产生的是两个不同的类），</li>
<li>保证Java的核心API不被篡改。 假设通过网络传递一个名为java.lang.Integer的类，通过双亲委托模式传递到启动类加载器，而启动类加载器在核心Java API发现这个名字的类，发现该类已被加载，并不会重新加载网络传递的过来的java.lang.Integer，而直接返回已加载过的Integer.class</li>
<li>双亲委派模型的主要代码实现：在ClassLoader的loadClass()方法中，先检查是否已经被加载过，若没有加载则调用父加载器的loadClass()方法，若父加载器为空则默认使用启动类加载器作为父类加载器。如果父类加载失败，抛出ClassNotFoundException异常后，再调用自己的findClass()方法进行加载。</li>
<li>自定义类加载器继承ClassLoader类并重写loadClass()、findClass()方法；最主要的是重写loadClass方法，因为双亲委派机制的实现都是通过这个方法实现的，源码里会直接找到根加载器，重写了这个方法以后就能自己定义加载的方式了</li>
</ul>
<h1>52. 你觉得应该怎么实现一个热部署功能？</h1>
<ul>
<li>实现一个热部署（Hot Deployment）功能通常涉及到类的加载和卸载机制，使得在不重启应用程序的情况下，能够动态替换或更新应用程序的组件。<br>
-第一步，使用文件监控机制（如 Java NIO 的 WatchService）来监控类文件或配置文件的变更。当监控到文件变更时，触发热部署流程。</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>class FileWatcher {
    public static void watchDirectoryPath(Path path) {
        // 检查路径是否是文件夹
        try {
            Boolean isFolder = (Boolean) Files.getAttribute(path, "basic:isDirectory", LinkOption.NOFOLLOW_LINKS);
            if (!isFolder) {
                throw new IllegalArgumentException("Path: " + path + " is not a folder");
            }
        } catch (IOException ioe) {
            // 文件 I/O 错误
            ioe.printStackTrace();
        }

        System.out.println("Watching path: " + path);

        // 我们获得文件系统的WatchService对象
        FileSystem fs = path.getFileSystem();

        try (WatchService service = fs.newWatchService()) {
            // 注册路径到监听服务
            // 监听目录内文件的创建、修改、删除事件
            path.register(service, ENTRY_CREATE, ENTRY_MODIFY, ENTRY_DELETE);

            // 开始无限循环，等待事件发生
            WatchKey key = null;
            while (true) {
                key = service.take(); // 会阻塞直到有事件发生

                // 对于每个发生的事件
                for (WatchEvent&lt;?&gt; watchEvent : key.pollEvents()) {
                    WatchEvent.Kind&lt;?&gt; kind = watchEvent.kind();

                    // 获取文件路径
                    @SuppressWarnings("unchecked")
                    WatchEvent&lt;Path&gt; ev = (WatchEvent&lt;Path&gt;) watchEvent;
                    Path fileName = ev.context();

                    System.out.println(kind.name() + ": " + fileName);
                }

                // 重置watchKey
                boolean valid = key.reset();
                // 退出循环如果watchKey无效
                if (!valid) {
                    break;
                }
            }
        } catch (Exception e) {
            e.printStackTrace();
        }
    }

    public static void main(String[] args) {
        // 监控当前目录
        Path pathToWatch = Paths.get(".");
        watchDirectoryPath(pathToWatch);
    }
}
</code></pre></div><ul>
<li>第二步，创建一个自定义类加载器，继承自java.lang.ClassLoader，重写findClass()方法，实现类的加载。</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class HotSwapClassLoader extends ClassLoader {
    public HotSwapClassLoader() {
        super(ClassLoader.getSystemClassLoader());
    }

    @Override
    protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException {
        // 加载指定路径下的类文件字节码
        byte[] classBytes = loadClassData(name);
        if (classBytes == null) {
            throw new ClassNotFoundException(name);
        }
        // 调用defineClass将字节码转换为Class对象
        return defineClass(name, classBytes, 0, classBytes.length);
    }

    private byte[] loadClassData(String name) {
        // 实现从文件系统或其他来源加载类文件的字节码
        // ...
        return null;
    }
}
</code></pre></div><h1>53. Tomcat 的类加载机制了解吗？</h1>
<ul>
<li>Tomcat 实际上也是破坏了双亲委派模型的。Tomact 是 web 容器，可能需要部署多个应用程序。不同的应用程序可能会依赖同一个第三方类库的不同版本，但是不同版本的类库中某一个类的全路径名可能是一样的。如多个应用都要依赖 hollis.jar，但是 A 应用需要依赖 1.0.0 版本，但是 B 应用需要依赖 1.0.1 版本。这两个版本中都有一个类是 com.hollis.Test.class。如果采用默认的双亲委派类加载机制，那么无法加载多个相同的类。</li>
<li>所以，Tomcat 破坏了双亲委派原则，提供隔离的机制，为每个 web 容器单独提供一个 WebAppClassLoader 加载器。每一个 WebAppClassLoader 负责加载本身的目录下的 class 文件，加载不到时再交 CommonClassLoader 加载，这和双亲委派刚好相反。<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/751b7a8d517c94a20de68.png" alt="tomcatclassloader.png"></li>
</ul>
<p>==================================================================================================</p>
<h1>54. 类加载发生的时机？</h1>
<ul>
<li>遇到new、getstatic、putstatic、invokestatic 这四条字节码指令时，如果类还没进行初始化，则需要先触发其初始化。</li>
<li>使用 java.lang.reflect 包的方法对类进行反射调用的时候，如果类还没进行初始化，则需要先触发其初始化。</li>
<li>当初始化了一个类的时候，如果发现其父类还没进行初始化，则需要先触发其父类的初始化。</li>
<li>当虚拟机启动时的主类，即调用其 #main(String[] args) 方法，虚拟机则会先初始化该主类。</li>
<li>当使用JDK7的动态语言支持时，如果一个java.lang.invoke.MethodHandle实例最后的解析结果为REF_getStatic、REF_putStatic、REF_invokeStatic方法句柄，并且这个方法句柄所对应的类没有进行过初始化，则需要先触发其初始化</li>
</ul>
<h1>55. 为什么要有不同的引用类型？</h1>
<ul>
<li>为了控制对象被回收的时机，</li>
<li>利用软引用和弱引用解决OOM问题。通过软引用和hashMap实现Java对象的高速缓存。如用HashMap保存图片的路径和相应图片对象关联的软引用之间的映射关系，在内存不足时，JVM会自动回收缓存图片对象所占用的空间，有效避免OOM问题</li>
</ul>
<h1>56. OOM有哪些异常类型？√</h1>
<ul>
<li>
<p>Java heap space堆空间溢出，最常见的（对象创建太多）</p>
</li>
<li>
<p>java.lang.StackOverflowError栈空间溢出，栈管运行，每个方法就是一个栈帧，循环调用方法，会出现这种问题</p>
</li>
<li>
<p>Direct buffer memory 由于ByteBuffer. allocteDirect(capability)分配操作系统本地内存，不属于GC 管辖范围。不需要内存拷贝所以速度相对较快。分配太多内存不够</p>
</li>
<li>
<p>GC overhead limit exceeded GC连续多次GC都只回收了不到2%的极端情况下会抛出。</p>
</li>
<li>
<p>unable to create new native thread；多线程linux系统默认允许单个进程可以创建的线程数是1024个,应用创建超过这个数量，就会报</p>
</li>
<li>
<p>控制台查看错误日志。</p>
</li>
<li>
<p>使用JDK自带的jvisualvm工具查看系统的堆栈日志。<br>
定位出内存溢出的空间：堆，栈还是永久代（JDK8 以后不会出现永久代的内存溢出）。</p>
<ul>
<li>如果是堆内存溢出，看是否创建了超大的对象。</li>
<li>如果是栈内存溢出，看是否创建了超大的对象，或者产生了死循环。</li>
</ul>
</li>
</ul>
<h1>57. 代码优化</h1>
<ul>
<li>尽可能使用局部变量</li>
<li>尽量减少对变量的重复计算 如遍历时i小于list.size()可以改为i小于length</li>
<li>异常不应该用来控制程序流程.异常对性能不利。抛出异常首先要创建一个新的对象，Throwable接口的构造函数调用名为fillInStackTrace()的本地同步方法，fillInStackTrace()方法检查堆栈，收集调用跟踪信息。只要有异常被抛出，Java虚拟机就必须调整调用堆栈，因为在处理过程中创建一个新的对象。异常只能用于错误处理，不应该用来控制程序流程。</li>
<li>尽量采用懒加载的策略，即在需要的时候才创建</li>
<li>不要将数组声明为public static final 因为这毫无意义，数组的内容还是可以随意改变的，</li>
<li>不要创建一些不使用的对象，不要导入一些不使用的类</li>
<li>程序运行过程中避免使用反射</li>
<li>使用数据库连接池和线程池.重用对象，前者可以避免频繁地打开和关闭连接，后者可以避免频繁地创建和销毁线程。</li>
<li>容器初始化时尽可能指定长度。避免容器长度不足时，扩容带来的性能损耗。</li>
<li>ArrayList随机遍历快，LinkedList添加删除快</li>
<li>使用Entry遍历Map</li>
<li>不要手动调用System.gc();</li>
<li>String尽量少用正则表达式。其效率较低，replace() 不支持正则。replaceAll() 支持正则。如果仅仅是字符的替换建议使用replace()。</li>
<li>日志的输出要注意级别</li>
<li>对资源的close()建议分开操作</li>
</ul>
]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/70d43d52d3b9c5460213d.png" type="image/png"/>
    </item>
    <item>
      <title>linux</title>
      <link>https://javaguide.cn/interview/linux.html</link>
      <guid>https://javaguide.cn/interview/linux.html</guid>
      <source url="https://javaguide.cn/rss.xml">linux</source>
      <description>1. linux概述 基于Unix的开源免费的操作系统，系统的稳定性和安全性成为程序代码运行的最佳系统环境 Linux是由Linus Torvalds（林纳斯·托瓦兹）起初开发的 Linux系统的应用非常广泛，Android程序最底层就是运行在linux系统上的 linux.pnglinux.png 2. linux目录结构 linuxcatalogu...</description>
      <category>面试</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<!-- TOC -->
<!-- /TOC -->
<h1>1. linux概述</h1>
<ul>
<li>基于Unix的开源免费的操作系统，系统的稳定性和安全性成为程序代码运行的最佳系统环境</li>
<li>Linux是由Linus Torvalds（林纳斯·托瓦兹）起初开发的</li>
<li>Linux系统的应用非常广泛，Android程序最底层就是运行在linux系统上的</li>
</ul>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/4e7826159216b69203d4a.png" alt="linux.png" tabindex="0"><figcaption>linux.png</figcaption></figure>
<h1>2. linux目录结构</h1>
<p><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/282413c2d3f968819010f.png" alt="linuxcatalogue.png"><br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/4993b2fb295f0f768bd84.png" alt="linuxcataloguedesc.png"></p>
<h1>3. linux文件类型</h1>
<ul>
<li>普通文件(-)</li>
<li>套接字(s)</li>
<li>目录文件(d)</li>
<li>符号链接(l)（可以认为是window中的快捷方式）</li>
<li>设备文件(b、c)</li>
<li>FIFO(p)</li>
</ul>
<h1>4. 目录操作</h1>
<ul>
<li>查看目录
<ul>
<li>ls 看到该目录下的所有的目录和文件	-a 看到该目录下的所有文件和目录，包括隐藏的（一般为.开头） -l（缩写为ll）看到该目录下的所有目录和文件的详细信息</li>
<li>pwd：查看当前工作目录的完整路径</li>
</ul>
</li>
<li>查找目录/文件：
<ul>
<li>find 目录 参数 查找该目录及子目录下所有名字相同的文件（可以用*）查找/root下的与test相关的目录(文件)  find /root -name 'test*'</li>
</ul>
</li>
<li>目录切换命令
<ul>
<li>cd usr切换到该目录下usr目录</li>
<li>cd ../切换到上一层目录</li>
<li>cd /切换到系统根目录</li>
<li>cd ~切换到用户主目录</li>
<li>cd -切换到上一个所在目录(相当于撤销)</li>
<li>cd 绝对路径</li>
</ul>
</li>
<li>增加目录操作
<ul>
<li>mkdir 目录名称 -p 父目录不存在的情况下生成父目录(parents) -v 显示命令执行过程中的详细信息</li>
<li>mkdir -pv ./abc/123，在目录的目录下面建文件</li>
<li>mkdir 目录/目录名称</li>
</ul>
</li>
<li>修改目录\文件\压缩包的名称
<ul>
<li>mv 目录名称 新目录名称 （目录、文件、压缩包）</li>
</ul>
</li>
<li>移动目录\文件\压缩包的位置</li>
</ul>
]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/4e7826159216b69203d4a.png" type="image/png"/>
    </item>
    <item>
      <title>数学</title>
      <link>https://javaguide.cn/interview/math.html</link>
      <guid>https://javaguide.cn/interview/math.html</guid>
      <source url="https://javaguide.cn/rss.xml">数学</source>
      <description>排列 从n个不同元素中取出(m&amp;lt;=n)个元素所有排列的个数，按照一定顺序排列成一列，叫做从n个不同元素中取出m(m&amp;lt;=n)个元素的排列数（number of arrangement），用符号表示。 根据分布乘法计数原理可得排列数公式 证明：求排列数可以按依次填m个空位来考虑：假定有排好顺序的m个空位,从n个不同元素a1,a2,a3,…,an中任意取m个...</description>
      <category>面试</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<!-- TOC -->
<h1>排列</h1>
<ul>
<li>从n个不同元素中取出(m&lt;=n)个元素所有排列的个数，按照一定顺序排列成一列，叫做从n个不同元素中取出m(m&lt;=n)个元素的排列数（number of arrangement），用符号表示。</li>
<li>根据分布乘法计数原理可得排列数公式</li>
</ul>
<ul>
<li>证明：求排列数可以按依次填m个空位来考虑：假定有排好顺序的m个空位,从n个不同元素a1,a2,a3,…,an中任意取m个去填空,一个空位填1个元素，每一种填法就对应1个排列，因此，所有不同填法的种数就是排列数。填空可分为m个步骤：
<ul>
<li>第1步，第1位可以从n个元素中任选一个填上，共有n种填法；</li>
<li>第2步，第2位只能从余下的n-1个元素中任选一个填上，共有n-1种填法；</li>
<li>第3步，第3位只能从余下的n-2个元素中任选一个填上，共有n-2种填法；</li>
<li>……</li>
<li>第m步，当前面的m-1个空位都填上后，第m位只能从余下的n-(m-1)个元素中任选一个填上，共有n-m+1种填法。</li>
<li>根据分步计数原理，全部填满m个空位共有n(n-1)(n-2)…(n-m+1)种填法</li>
</ul>
</li>
</ul>
<h1>组合</h1>
<ul>
<li>组合公式的推导是由排列公式去掉重复的部分而来的,组合无序，排列有序</li>
<li>从n个不同元素中取出(m&lt;=n)个元素所有组合的个数，叫做从n个不同元素中取出m(m&lt;=n)个元素的组合数（number of combination），用符号表示。或者欧美记为</li>
</ul>
<ul>
<li>推导：利用排列组合关系推导,将排列问题分为2步：第1步，从n个元素中抽取m个，无序，就是组合问题;第2步，对m排序，根据乘法原理得到</li>
</ul>
<ul>
<li>m用n-(n-m)代替得到性质1-互补</li>
</ul>
<ul>
<li>当总元素个数从n变为n+1时，可分为不包含新元素的组合和包含新元素的组合，由分类加法计数原理，可得组合的性质2-组合恒等式</li>
</ul>
<ul>
<li>证明</li>
</ul>
<h1>二项式定理</h1>
<ul>
<li>二项式展开公式为</li>
</ul>
<ul>
<li>其中组合定义为</li>
</ul>
<ul>
<li>证明：若展开多项式的时候先不合并同类项（每项前面的系数都是 1）则若不合并相同项<br>
 有1项<br>
 有2项<br>
 有4项<br>
有8项<br>
$(a+b)^n $有项</li>
<li>相当于用a和b填满n个有序的位置，每个位置都可以取a或b，共有种排列，每种排列就是一项，所以共有项（不合并相同项）。把项中相同项进行合并，把其中出现了i个a及n-i个b的项都记为，那么共有个这样的项。把它们相加得 。所以</li>
</ul>
<h1>伯努利实验</h1>
<ul>
<li>若随机试验E只有2个可能的结果：A与 则称E为伯努利试验（Bernoulli trial）。若将E独立重复进行n次，则称n重伯努利试验。</li>
<li>伯努利试验中的2个结果A与 也被称为 “成功” 与 “失败”。所以当用数字1和0来表示的时候，这个数字被称为第n个试验的成功次数。即对n重伯努利试验，其成功次数X等于每个试验的成功次数之和,其中，为第<br>
次试验的成功次数。</li>
</ul>
<h1>二项分布</h1>
<ul>
<li>如果记X为n重伯努利试验中成功（记为事件A）的次数，则X的可能取值为0,1..,n。记p为每次试验中A发生的概率，即P(A)=p，则P() =1-p,n重伯努利试验的基本结果可以记作 其中为A或者为,这样的 共有个，组成了样本空间</li>
<li>下面求事件X的分布列，即{X=k}的概率。若某个样本点意味着中有k个A,n-k个,由事件的独立性知：</li>
</ul>
<ul>
<li>而事件{X=k}中这样的共有个，所以X的分布列为：</li>
</ul>
<ul>
<li>这个分布称为二项分布（binomial distribution），记为 X~b(n,p)</li>
<li>根据二项式定理有</li>
</ul>
<ul>
<li>并且从上式可以看出，二项概率恰好是二项式的展开式中的第k+1项，这正是其名称的由来。二项概率是一种离散分布</li>
</ul>
]]></content:encoded>
    </item>
    <item>
      <title>消息队列</title>
      <link>https://javaguide.cn/interview/messagequeue.html</link>
      <guid>https://javaguide.cn/interview/messagequeue.html</guid>
      <source url="https://javaguide.cn/rss.xml">消息队列</source>
      <description>1. 什么是消息队列？ mq：消息队列是一种先进先出的数据结构. 2. 为什么使用消息队列？消息队列优缺点？ 解耦：假设A系统要发送数据到B,C,D系统，如果E系统需要数据然后，D系统不需要了，此时A系统需要维护下游系统的调用，耦合性太高，引入消息队列后可以减少A系统维护成本 异步：同步很花费并且业务时效性不大的操作，可以使用异步来提升效果，比如发送微...</description>
      <category>面试</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<!-- TOC -->
<!-- /TOC -->
<h1>1. 什么是消息队列？</h1>
<ul>
<li>mq：消息队列是一种先进先出的数据结构.</li>
</ul>
<h1>2. 为什么使用消息队列？消息队列优缺点？</h1>
<ul>
<li>解耦：假设A系统要发送数据到B,C,D系统，如果E系统需要数据然后，D系统不需要了，此时A系统需要维护下游系统的调用，耦合性太高，引入消息队列后可以减少A系统维护成本</li>
<li>异步：同步很花费并且业务时效性不大的操作，可以使用异步来提升效果，比如发送微信通知</li>
<li>削峰、限流：解决高并发情况</li>
<li>系统可用性降低</li>
<li>系统复杂度提高</li>
<li>一致性问题</li>
</ul>
<h1>3. 消息队列协议</h1>
<ul>
<li>AMQP、MQTT、STOMP、XMPP协议</li>
</ul>
<h1>4. 消息队列有几种消费语义？</h1>
<ul>
<li>消息至多被消费一次（At most once）：消息可能会丢失，但绝不重传。</li>
<li>消息至少被消费一次（At least once）：消息可以重传，但绝不丢失。</li>
<li>消息仅被消费一次（Exactly once）：每一条消息只被传递一次。</li>
</ul>
<h1>5. Kafka、ActiveMQ、RabbitMQ、RocketMQ 有什么优缺点？</h1>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/523ea7439c3ef3a12016b.png" alt="mq.png" tabindex="0"><figcaption>mq.png</figcaption></figure>
<ul>
<li>中小型公司，技术实力较为一般，技术挑战不是特别高，用 RabbitMQ 是不错的选择；大型公司，基础架构研发实力较强，用 RocketMQ 是很好的选择。</li>
<li>如果是大数据领域的实时计算、日志采集等场景，用 Kafka 是业内标准的，绝对没问题，社区活跃度很高，绝对不会黄，何况几乎是全世界这个领域的事实性规范。</li>
<li>RabbitMQ延时最低，消息可靠性高，高可用，但扩展性较差。</li>
</ul>
<h1>6. 如何保证消息的不被重复消费/幂等性？</h1>
<ul>
<li>框架层统一封装：由 Producer 生成唯一标识。使用关系型数据库，增加一个排重表，使用消息编号作为唯一主键。需要让插入记录和业务逻辑在同一个事务</li>
<li>业务层实现：先查询数据库，判断数据是否已经被更新过。如果是，则直接返回消费完成，否则执行消费。</li>
</ul>
<h1>7. 如何防止消息丢失/可靠性传输</h1>
<p><a href="/interview/rabbitmq.md/#2-%E5%A6%82%E4%BD%95%E9%98%B2%E6%AD%A2%E6%B6%88%E6%81%AF%E4%B8%A2%E5%A4%B1%EF%BC%9F%E5%8F%AF%E9%9D%A0%E6%80%A7%E4%BC%A0%E8%BE%93%EF%BC%9F" target="_blank">rabbitmq如何防止消息丢失？可靠性传输？</a>√</p>
<p><a href="/interview/rocketmq.md/#9-%E5%A6%82%E4%BD%95%E9%98%B2%E6%AD%A2%E6%B6%88%E6%81%AF%E4%B8%A2%E5%A4%B1%EF%BC%9F%E5%8F%AF%E9%9D%A0%E6%80%A7%E4%BC%A0%E8%BE%93%EF%BC%9F" target="_blank">rocketmq如何防止消息丢失？可靠性传输？</a></p>
<h1>8. 如何保证消息的顺序性？</h1>
<p><a href="/interview/rabbitmq.md/#3-%E9%A1%BA%E5%BA%8F%E6%B6%88%E6%81%AF" target="_blank">rabbitmq顺序消息</a>√</p>
<p><a href="/interview/rocketmq.md/#8-%E9%A1%BA%E5%BA%8F%E6%B6%88%E6%81%AF" target="_blank">rocketmq顺序消息</a></p>
<h1>9. 如何保证消息队列的高可用？</h1>
<p><a href="/interview/rabbitmq.md/#4-%E9%AB%98%E5%8F%AF%E7%94%A8" target="_blank">rabbitmq高可用</a>√</p>
<p><a href="/interview/rocketmq.md/#10-%E9%AB%98%E5%8F%AF%E7%94%A8" target="_blank">rocketmq高可用</a></p>
<h1>10. 消息积压如何解决</h1>
<ul>
<li>临时紧急扩容，具体操作步骤和思路如下：
<ul>
<li>先修复consumer的问题，确保其恢复消费速度</li>
<li>新建一个topic，partition是原来的10倍，临时建立好原先10倍或者20倍的queue数量</li>
<li>然后写一个临时的分发数据的consumer程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的10倍数量的queue</li>
<li>接着临时征用10倍的机器来部署consumer，每一批consumer消费一个临时queue的数据</li>
<li>这种做法相当于是临时将queue资源和consumer资源扩大10倍，以正常的10倍速度来消费数据</li>
<li>等快速消费完积压数据之后，得恢复原先部署架构，重新用原先的consumer机器来消费消息</li>
</ul>
</li>
</ul>
<h1>11. 为什么kafka最高吞吐量</h1>
<ul>
<li>kafka采用顺序读写磁盘，写时分文件顺序写，读时按offset顺序读</li>
<li>Kafka利用了操作系统本身的Page Cache而不是JVM空间内存</li>
<li>Kafka 的生产和消费两个过程都使用了零拷贝（zero copy）：
<ul>
<li>网络数据持久化到磁盘(Producer 到 Broker使用了mmap)</li>
<li>磁盘文件通过网络发送(Broker 到 Consumer使用了sendfile+DMA采集)</li>
</ul>
</li>
<li>数据压缩
<ul>
<li>Kafka使用了批量压缩，即将多个消息一起压缩而不是单个消息压缩。（如果每个消息都压缩，压缩率相对较低。）</li>
<li>Kafka允许使用递归的消息集合，批量的消息可通过压缩的形式传输并且在日志中也可保持压缩格式，直到被消费者解压缩</li>
<li>Kafka支持多种压缩协议，包括Gzip、Snappy、LZ4</li>
</ul>
</li>
<li>批量传输
<ul>
<li>在向Kafka发送数据时，可以启用批次发送，这样可以避免在网络上频繁传输单个消息带来的延迟和带宽开销。假设网络带宽为10MB/S，一次性传输10MB的消息比传输1KB的消息10000万次显然要快得多。</li>
</ul>
</li>
<li>并行
<ul>
<li>由于不同 Partition 可位于不同机器，因此可以充分利用集群优势，实现机器间的并行处理。</li>
<li>由于 Partition 在物理上对应一个文件夹，即使多个 Partition 位于同一个节点，也可通过配置让同一节点上的不同 Partition 置于不同的磁盘上，从而实现磁盘间的并行处理，充分发挥多磁盘的优势。</li>
</ul>
</li>
</ul>
]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/523ea7439c3ef3a12016b.png" type="image/png"/>
    </item>
    <item>
      <title>MyBatis</title>
      <link>https://javaguide.cn/interview/mybatis.html</link>
      <guid>https://javaguide.cn/interview/mybatis.html</guid>
      <source url="https://javaguide.cn/rss.xml">MyBatis</source>
      <description>1. MyBatis Mybatis 是一个半 ORM（对象关系映射）框架，它内部封装了 JDBC，开发时只需要关注 SQL 语句本身，不需要花费精力去处理加载驱动、创建连接、创建 statement 等繁杂的过程。程序员直接编写原生态 sql，可以严格控制 sql 执行性能，灵活度高。 MyBatis 可以使用 XML 或注解来配置和映射原生信息，将...</description>
      <category>面试</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[
<ul>
<li>Mybatis 是一个半 ORM（对象关系映射）框架，它内部封装了 JDBC，开发时只需要关注 SQL 语句本身，不需要花费精力去处理加载驱动、创建连接、创建 statement 等繁杂的过程。程序员直接编写原生态 sql，可以严格控制 sql 执行性能，灵活度高。</li>
<li>MyBatis 可以使用 XML 或注解来配置和映射原生信息，将 POJO 映射成数据库中的记录，避免了几乎所有的 JDBC 代码和手动设置参数以及获取结果集。</li>
<li>缺点:sql语句编写工作量大，要求高，据库移植性差</li>
</ul>
<h1>2. JDBC</h1>
<ul>
<li>JDBC（Java Data Base Connectivity,java数据库连接）是一种用于执行SQL语句的Java API接口</li>
<li>可以为多种关系数据库提供统一访问，它由一组用Java语言编写的类和接口组成。是Java访问数据库的标准规范</li>
<li>而JDBC驱动是数据库厂商对接口的实现，用来连接自己的数据库</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>Class.forName(“com.mysql.jdbc.Driver”);//1.注册驱动
connection conn= DirverManger.getConnection	(jdbc:mysql://ip:port/数据库名，用户名，密码);//2.获得链接
String sql = "select \* from user where name = ?";
PreparedStatement psmt = conn.prepareStatement(sql);//3.获得预处理对象语句执行平台
//void setXxx(int index, Xxx xx); --设置实际参数
psmt.setString(1,'张三');//4.设置实际参数
//int executeUpdate(); --执行insert update delete语句.
//ResultSet executeQuery(); --执行select语句.
//boolean execute(); --执行select返回true 执行其他的语句返回false.
ResultSet rs = psmt.executeQuery();//5.执行sql
while( rs.next() ){//6.处理结果集
	Object getObject(int index) / Object getObject(String name) 获得任意对象
	String getString(int index) / Object getObject(String name) 获得字符串
	int getInt(int index) / Object getObject(String name) 获得整形
	double getDouble(int index) / Object getObject(String name) 获得双精度浮点型
}
rs.close();//7.释放所有资源
stmt.close();
con.close();
</code></pre></div><h1>3. Statement与PreparedStatement的区别</h1>
<ul>
<li>预编译：
<ul>
<li>Statement每次执行Statement对象的executeQuery或executeUpdate方法时，SQL 语句在数据库端都需要重新编译和执行。这适用于一次性执行的 SQL 语句</li>
<li>PreparedStatement：SQL语句在PreparedStatement对象创建时就被发送到数据库进行预编译。之后可以通过设置参数值来多次高效地执行这个 SQL 语句。这不仅减少了数据库编译 SQL 语句的开销，也提高了性能，尤其是对于重复执行的 SQL 操作。</li>
</ul>
</li>
</ul>
<h1>4. mybatis什么时候用的#{}、什么时候${} √</h1>
<ul>
<li>#{}是占位符，预编译处理；${}是拼接符，字符串替换，没有预编译处理。<br>
Mybatis 在处理#{}时，#{}传入参数是以字符串传入，会将 SQL 中的#{}替换为?号，调用 PreparedStatement 的 set 方法来赋值。</li>
<li>#{} 可以有效的防止 SQL 注入，提高系统安全性；${} 不能防止 SQL 注入</li>
<li>#{} 的变量替换是在 DBMS 中；${} 的变量替换是在 DBMS 外</li>
<li>#{}可实现preparedStatement向占位符中设置值，自动进行java类型和jdbc类型转换。自动加上''.</li>
<li>${}不进行java类型和jdbc类型转换， 不加'' 单条SQL不超过语句的最大限制max_allowed_packet（1m）</li>
</ul>
<h1>5. 模糊查询 like 语句该怎么写?</h1>
<ul>
<li>CONCAT('%',#{question},'%')或者"%"#{question}"%"</li>
</ul>
<h1>6. Mybatis 能执行一对一、一对多的关联查询吗</h1>
<ul>
<li>一对一<code>&lt;association&gt;</code>、一对多<code>&lt;collection&gt;</code></li>
</ul>
<h1>7. Mybatis 是否支持延迟加载？原理？</h1>
<ul>
<li>Mybatis 支持 association 关联对象和 collection 关联集合对象的延迟加载，association 指的就是一对一，collection 指的就是一对多查询。在 Mybatis 配置文件中，可以配置是否启用延迟加载 lazyLoadingEnabled=true|false。</li>
<li>原理是，使用 CGLIB 创建目标对象的代理对象，当调用目标方法时，进入拦截器方法，比如调用 a.getB().getName()，拦截器 invoke()方法发现 a.getB()是 null 值，那么就会单独发送事先保存好的查询关联 B 对象的 sql，把 B 查询上来，然后调用 a.setB(b)，于是 a 的对象 b 属性就有值了，接着完成 a.getB().getName()方法的调用。这就是延迟加载的基本原理。<br>
当然了，不光是 Mybatis，几乎所有的包括 Hibernate，支持延迟加载的原理都是一样的。</li>
</ul>
<h1>8. MyBatis事务管理形式</h1>
<ul>
<li>使用JDBC的事务管理机制。利用java.sql.Connection对象完成对事务的提交commit、回滚rollback、关闭close等操作。</li>
<li>使用MANAGED的事务管理机制。MyBatis自身不会去实现事务管理，而是让容器如WebLogic、JBOSS等实现对事物的管理。</li>
</ul>
<h1>9. mybatis一级缓存和二级缓存？</h1>
<ul>
<li>
<p>不推荐，因为分布式环境下缓存基于本地，会有脏数据，不如直接使用Redis、Memcached等分布式缓</p>
</li>
<li>
<p>一级缓存（默认打开）：基于PerpetualCache没有容量限定的HashMap缓存，作用域为sqlSession或者statement，有多个SqlSession或者分布式的环境下，数据库写操作会引起脏数据，建议设为Statement。配置：</p>
</li>
<li>
<p>二级缓存：基于PerpetualCache没有容量限定的HashMap缓存，其存储作用域为Mapper(Namespace)，可自定义存储源如Ehcache。配置：</p>
</li>
<li>
<p>对于缓存数据更新机制，当某一个作用域(一级缓存Session/二级缓存Namespaces)进行了C/U/D操作后，默认该作用域下所有select的缓存将被clear</p>
</li>
</ul>
<h1>10. mybatis执行顺序</h1>
<ul>
<li>读取 MyBatis 配置文件——mybatis-config.xml 、加载SQL映射文件Mapper.xml。最后生成一个配置对象</li>
<li>构造会话工厂：通过 MyBatis 的环境等配置信息构建会话工厂 SqlSessionFactory。</li>
<li>创建会话对象：由会话工厂创建 SqlSession 对象，该对象中包含了执行 SQL 语句的所有方法。</li>
<li>Executor 执行器：MyBatis 底层定义了一个 Executor 接口来操作数据库，它将根据 SqlSession 传递的参数动态地生成需要执行的 SQL 语句，同时负责查询缓存的维护。</li>
<li>StatementHandler：数据库会话器，串联起参数映射的处理和运行结果映射的处理。</li>
<li>ParameterHandler参数处理：对输入参数的类型进行处理，并预编译。</li>
<li>ResultSetHandler结果处理：对返回结果的类型进行处理，根据对象映射规则，返回相应的对象。</li>
</ul>
<h1>11. 动态SQL概念，作用，执行原理吗？</h1>
<ul>
<li>以XML标签的形式编写动态SQL ，完成逻辑判断和动态拼接SQL的功能。</li>
<li>动态SQL标签：<code>&lt;if /&gt;、&lt;choose /&gt;、&lt;when /&gt;、&lt;otherwise /&gt;、&lt;trim /&gt;、&lt;where /&gt;、&lt;set /&gt;、&lt;foreach /&gt;、&lt;bind /&gt;</code> 。</li>
<li>执行原理为使用OGNL的表达式，从SQL参数对象中计算表达式的值，根据表达式的值动态拼接SQL，以此来完成动态SQL功能。</li>
</ul>
<h1>12. Mapper接口与XML对应关系的原理？Mapper 接口里的方法，参数不同时，方法能重载吗？</h1>
<ul>
<li>Mapper接口XML对应的关系如下
<ul>
<li>接口的全限名映射文件namespace值</li>
<li>接口的方法名映射文件MappedStatement的id值</li>
<li>接口方法内的参数是传递给SQL的参数</li>
</ul>
</li>
<li>Mapper接口里的方法不能重载，因为是全限名+方法名的保存和寻找策略。</li>
<li>原理：每一个select、insert、update、delete标签，都会被解析为一个MappedStatement对象。Mapper接口的实现类通过使用JDK动态代理自动生成代理对象Proxy时会拦截接口方法，根据接口全限名+方法名拼接字符串作为key值，唯一定位一个对应的MappedStatement执行SQL<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/de704e9bac809e0be3798.jpg" alt="sqlexecutionprocedure.png"></li>
</ul>
<h1>13. Mybatis是否可以映射Enum枚举类？</h1>
<ul>
<li>EnumTypeHandler基于Enum.name属性(String)。默认。</li>
<li>EnumOrdinalTypeHandler基于Enum.ordinal属性(int)。可通过 </li>
<li>Mybatis可以映射任何对象到表的一列上。通过自定义一个TypeHandler类实现TypeHandler的#setParameter()和getResult() 接口完成从 javaType 至 jdbcType 的双向转换。</li>
</ul>
<h1>14. Mybatis都有哪些Executor执行器？它们之间的区别是什么？</h1>
<ul>
<li>SimpleExecutor：每执行一次update或select操作就创建一个Statement对象，用完立刻关闭Statement对象</li>
<li>ReuseExecutor：执行update或select操作，以SQL作为key查找缓存的Statement对象，存在就使用，不存在就创建；用完后放置于缓存Map&lt;String, Statement&gt;内</li>
<li>BatchExecutor：执行update操作（不支持select），将所有SQL都添加到批处理中（通过addBatch方法），等待统一执行（使用executeBatch方法）。它缓存了多个Statement对象，都是调用addBatch方法后，等待一次执行 executeBatch 批处理。过程与JDBC批处理是相同。</li>
<li>CachingExecutor ：在上述的三个执行器之上，增加二级缓存的功能。</li>
<li><code>&lt;setting name="defaultExecutorType" value=""&gt;</code> value=SIMPLE、REUSE、BATCH 三个值，分别使用SimpleExecutor、ReuseExecutor、BatchExecutor执行器</li>
<li><code>&lt;setting name="cacheEnabled" value=""&gt;</code> value=true时创建 CachingExecutor 执行器。</li>
</ul>
<h1>15. MyBatis 如何执行批量操作？</h1>
<ul>
<li>使用 foreach 标签：foreach 标签的属性主要有 item，index，collection，open，separator，close。</li>
<li>使用 ExecutorType.BATCH</li>
</ul>
<h1>16. 简述 Mybatis 的插件运行原理？以及如何编写一个插件？</h1>
<ul>
<li>插件的原理就是在这四大对象调度的时候，使用JDK动态代理，插入一些我我们自己的代码。</li>
<li>仅可以自定义ParameterHandler、ResultSetHandler、StatementHandler、Executor的插件</li>
<li>为需要拦截的接口生成代理对象以实现接口方法拦截功能，每当执行这4种接口对象的方法时，就会进入拦截方法，具体就是 InvocationHandler 的 #invoke(...)方法。</li>
<li>1.实现Interceptor接口实现intercept(...) 方法。</li>
<li>2.在给插件编写注解，指定要拦截哪一个接口的哪些方法即可</li>
<li>3.在配置文件中配置你编写的插件。</li>
</ul>
<h1>17. Mybatis是如何进行分页的？分页插件的原理？</h1>
<ul>
<li>不推荐：使用RowBounds对象针对ResultSet结果集执行的内存分页，而非数据库分页</li>
<li>推荐：在SQL输入分页参数；使用分页插件自动添加分页条件来完成数据库分页</li>
<li>原理是使用插件接口，实现自定义分页插件。拦截Executor的query方法，重写SQL，根据dialect方言，添加对应的物理分页语句和物理分页参数。</li>
<li>常用分页插件：Mybatis-PageHelper MyBatis-Plus</li>
</ul>
]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/de704e9bac809e0be3798.jpg" type="image/jpeg"/>
    </item>
    <item>
      <title>mysql</title>
      <link>https://javaguide.cn/interview/mysql.html</link>
      <guid>https://javaguide.cn/interview/mysql.html</guid>
      <source url="https://javaguide.cn/rss.xml">mysql</source>
      <description>1. 什么是MySQL？ 开源的关系型数据库管理系统，隶属Oracle 2. MySQL 的内连接、左连接、右连接、交叉连接、笛卡尔积有什么区别？ inner join内连接，取得两张表中满足连接条件的记录。只有当两个表中都有匹配的记录时，这些记录才会出现在查询结果中。如果某一方没有匹配的记录，则该记录不会出现在结果集中。相当于两个数据集的交集。 外连...</description>
      <category>面试</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[
<ul>
<li>开源的关系型数据库管理系统，隶属Oracle</li>
</ul>
<h1>2. MySQL 的内连接、左连接、右连接、交叉连接、笛卡尔积有什么区别？</h1>
<ul>
<li>inner join内连接，取得两张表中满足连接条件的记录。只有当两个表中都有匹配的记录时，这些记录才会出现在查询结果中。如果某一方没有匹配的记录，则该记录不会出现在结果集中。相当于两个数据集的交集。</li>
<li>外连接（outer join）：不只取得两张表中满足连接条件的记录，还包括某张表（或两张表）中不满足匹配关系的记录。分为左链接和右连接</li>
<li>left join返回左表（FROM子句中指定表）所有记录，以及右表满足连接条件的记录。如果右表中没有匹配的记录，则结果中右表的部分会以NULL填充</li>
<li>right join返回右表（FROM子句中指定表）所有记录，以及左表中满足连接条件的记录。如果左表中没有匹配的记录，则结果中左表的部分会以NULL填充</li>
<li>交叉连接（crossjoin）：显示两张表所有记录一一对应，没有匹配关系进行筛选，它是笛卡尔积在SQL中的实现，如果A表有m行，B表有n行，那么A和B交叉连接的结果就有m*n行。</li>
<li>笛卡尔积：例如集合A={a,b}，集合B={0,1,2}，那么A✖️B={&lt;a,o&gt;,&lt;a,1&gt;,&lt;a,2&gt;,&lt;b,0&gt;,&lt;b,1&gt;,&lt;b,2&gt;,}。</li>
</ul>
<h1>3. 数据库三大范式？</h1>
<ul>
<li>第一范式(1NF)：字段值具有原子性,不能再分;例如：姓名字段,其中姓和名是一个整体,如果区分姓和名那么必须设立两个独立字段</li>
<li>第二范式(2NF)：满足第一范式基础上，要求数据库表中每一列都和主键相关，而不能只与主键的某一部分相关（主要针对联合主键而言）。例如订单表里，存储了商品信息（商品价格、商品类型），那就需要把商品 ID 和订单 ID 作为联合主键，才满足第二范式。</li>
<li>第三范式(3NF)：在满足第二范式基础上，一个表中不能包涵其他相关表中非关键字段的信息,即数据表不能有冗余字段。订单表中包含订单编号和商品编号，存在冗余数据，比如说商品名称、单位、商品价格等，应该将其拆分为订单表、订单商品关联表、商品表。</li>
<li>三大范式的作用是为了控制数据库的冗余，节省空间，实际上可以通过冗余一些数据，避免跨表跨库，利用空间换时间，提高性能,减少join的查询;例如：相册表中会添加图片的点击数字段,在相册图片表中也会添加图片的点击数字段;</li>
</ul>
<h1>4. varchar与char区别？</h1>
<ul>
<li>
<p>char表示定长字符串，长度固定</p>
</li>
<li>
<p>如果插入数据的长度小于char的固定长度时，则用空格填充；CHAR会自动删除插入数据的尾部空格</p>
</li>
<li>
<p>因为长度固定，所以存取速度要比varchar快，但可能会占据多余的空间，是空间换时间的做法</p>
</li>
<li>
<p>char最多能存放的字符个数为255，和编码无关</p>
</li>
<li>
<p>varchar(50)中50的涵义最多存放50个字符。varchar(50)和(200)存储所占空间一样，但后者在排序时会消耗更多内存，因为 ORDER BY col 采用 fixed_length 计算 col 长度(memory引擎也一样)</p>
</li>
<li>
<p>varchar表示可变长字符串，长度不固定</p>
</li>
<li>
<p>按照插入的数据长度来存储；VARCHAR不会删除尾部空格</p>
</li>
<li>
<p>因为长度不固定，varchar比char存取慢，不占据多余的空间，是时间换空间的做法</p>
</li>
<li>
<p>varchar最多能存放的字符个数为65532</p>
</li>
<li>
<p>对于长度相对固定的字符串，可以使用char，对于长度不确定的，使用varchar更合适一些。</p>
</li>
</ul>
<h1>5. blob和text有什么区别？</h1>
<ul>
<li>都在保存较大文本时使用</li>
<li>blob用于存储二进制数据，比如照片；而text用于存储大字符串。比如一篇文章或者日记</li>
<li>blob没有字符集，text有字符集，并且根据字符集的校对规则对值进行排序和比较</li>
</ul>
<h1>6. DATETIME和TIMESTAMP的异同？</h1>
<ul>
<li>相同点
<ul>
<li>存储时间的表现格式一致YYYY-MM-DD HH:MM:SS</li>
<li>都包含「日期」和「时间」部分。</li>
<li>都可以存储微秒的小数秒（秒后6位小数秒）</li>
</ul>
</li>
<li>区别
<ul>
<li>日期范围：DATETIME的日期范围是1000-01-0100:00:00.000000到9999-12-31 23:59:59.999999；范围大。TIMESTAMP的时间范围是1970-01-0100:00:01.000000UTC到2038-01-0903:14:07.999999UTC，范围小。</li>
<li>存储空间：DATETIME的存储空间为8字节；TIMESTAMP的存储空间为4字节</li>
<li>时区相关：DATETIME存储时间与时区无关；TIMESTAMP存储时间与时区有关</li>
<li>默认值：DATETIME的默认值为null；TIMESTAMP字段不为空(notnull)，默认值为当前时间(CURRENT_TIMESTAMP)</li>
</ul>
</li>
</ul>
<h1>7. in和exists的区别？</h1>
<ul>
<li>in语句是把外表（in所在的子查询的表）和内表（from子句中的表）作hash连接，而exists语句是对外表作loop循环，每次loop循环再对内表进行查询</li>
<li>如果查询的两个表大小相当，那么用in和exists差别不大。</li>
<li>如果两个表中一个较小，一个是大表，则子查询表大的用exists，子查询表小的用in。</li>
<li>如果查询语句使用了not in，那么内外表都进行全表扫描，没有用到索引；而not extsts的子查询依然能用到表上的索引。所以无论那个表大，用not exists都比not in要快。</li>
</ul>
<h1>8. MySQL里记录货币用什么字段类型？ip呢？</h1>
<ul>
<li>常用Decimal和Numric类型表示，例如salary DECIMAL(9,2)，9(precision)代表将被用于存储值的总的小数位数，而2(scale)代表将被用于存储小数点后的位数。存储在salary列中的值的范围是从-9999999.99到9999999.99。</li>
<li>DECIMAL和NUMERIC值作为字符串存储，而不是作为二进制浮点数，以便保存那些值的小数精度。</li>
<li>float和double是以二进制存储的，存在误差，不使用。</li>
<li>ip地址的存储 bigint insert into sessions (ipaddress)values (inet_aton('192.168.0.1')); select inet_ntoa(ipaddress) from sessions;</li>
<li>范围查询IP select * from t where inet_aton(ip)&gt;=inet_aton('192.168.1.3') and inet_aton(ip)&lt;=inet_aton('192.168.1.20')</li>
</ul>
<h2>8.1. MySQL怎么存储emoji😊?</h2>
<ul>
<li>使用字符串存储emoji。同时使用4字节的utf8mb4编码。</li>
<li>alter table blogs modify content text CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci not null;</li>
</ul>
<h2>8.2. drop、delete 与 truncate 的区别？</h2>
<ul>
<li>在不再需要一张表的时候，用drop；在想删除部分数据行时候，用delete；在保留表而删除所有数据的时候用truncate。</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th>delete</th>
<th>truncate</th>
<th>drop</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">类型</td>
<td>属于DML</td>
<td>属于DDL</td>
<td>属于DDL</td>
</tr>
<tr>
<td style="text-align:center">回滚</td>
<td>可回滚</td>
<td>不可回滚</td>
<td>不可回滚</td>
</tr>
<tr>
<td style="text-align:center">删除内容</td>
<td>表结构还在，删除表的全部或者一部分数据行不释放空间</td>
<td>表结构还在，删除表中的所有数据释放空间删除数据后重新写数据会从1开始</td>
<td>从数据库中删除表，所有数据行，索引和权限也会被删除</td>
</tr>
<tr>
<td style="text-align:center">删除速度</td>
<td>速度慢，需要逐行删除</td>
<td>速度快</td>
<td>速度最快</td>
</tr>
</tbody>
</table>
<h1>9. UNION 与 UNION ALL 的区别？</h1>
<ul>
<li>Union：对两个结果集进行并集操作，不包括重复行，同时进行默认规则的排序；</li>
<li>Union All：对两个结果集进行并集操作，包括重复行，不进行排序；速度较快</li>
</ul>
<h1>10. count(1)、count(*)、count(主键|列名)的区别？</h1>
<ul>
<li>
<p>MyISAM执行count(*)会直接返回存储在磁盘上的表的总行数，效率高；</p>
</li>
<li>
<p>InnoDB执行count(*)需要把数据一行一行地从引擎里面读出来，然后累积计数；因为innodb支持事务，每个事务查询结果有差异，故不存储表的总行数</p>
</li>
<li>
<p>count(*) 统计所有行（允许null）。为了减少扫描数据量，自动扫描索引树小的。不取值，按行累加</p>
</li>
<li>
<p>count(1)统计所有行（允许null），不取值，按行累加。用1代表代码行，速度比count(主键id)快。因为从引擎返回id会涉及到解析数据行，以及拷贝字段值的操作</p>
</li>
<li>
<p>count(主键id) 统计不为null的行。遍历整张表把每一行的id值都取出来返回给server层</p>
</li>
<li>
<p>count(列名)统计不为null的行。只包括列名那一列</p>
</li>
<li>
<p>按照效率排序的话，count(字段)&lt;count(主键id)&lt;count(1)≈count(<em>)，建议尽量使用count(</em>)。</p>
</li>
</ul>
<h1>11. 一条SQL查询语句的执行顺序？√</h1>
<ul>
<li>FROM：对FROM子句中的左表&lt;left_table&gt;和右表&lt;right_table&gt;执行笛卡儿积（Cartesianproduct），产生虚拟表VT1</li>
<li>ON：对虚拟表VT1应用ON筛选，只有那些符合&lt;join_condition&gt;的行才被插入虚拟表VT2中</li>
<li>JOIN：如果指定了OUTERJOIN（如LEFTOUTERJOIN、RIGHTOUTERJOIN），那么保留表中未匹配的行作为外部行添加到虚拟表VT2中，产生虚拟表VT3。如果FROM子句包含两个以上表，则对上一个连接生成的结果表VT3和下一个表重复执行步骤1）～步骤3），直到处理完所有的表为止</li>
<li>WHERE：对虚拟表VT3应用WHERE过滤条件，只有符合&lt;where_condition&gt;的记录才被插入虚拟表VT4中</li>
<li>GROUP BY：根据GROUP BY子句中的列，对VT4中的记录进行分组操作，产生VT5</li>
<li>ACG_FUNC聚合函数</li>
<li>CUBE|ROLLUP：对表VT5进行CUBE或ROLLUP操作，产生表VT6</li>
<li>HAVING条件过滤：对虚拟表VT6应用HAVING过滤器，只有符合&lt;having_condition&gt;的记录才被插入虚拟表VT7中。</li>
<li>SELECT投影列：第二次执行SELECT操作，选择指定的列，插入到虚拟表VT8中</li>
<li>DISTINCT：去除重复数据，产生虚拟表VT9</li>
<li>ORDER BY：将虚拟表VT9中的记录按照&lt;order_by_list&gt;进行排序操作，产生虚拟表VT10。11）</li>
<li>LIMIT：取出指定行的记录，产生虚拟表VT11，并返回给查询用户</li>
<li>聚合函数在WHERE之后执行 在WHERE判断条件里加入聚合函数是做不到的</li>
</ul>
<h1>12. SQL分类</h1>
<p>SQL(Structure Query Language)结构化查询语言，关系型数据库应用语音</p>
<ul>
<li>DDL(Data Definition Languages数据库定义语言) 定义不同的数据段、数据库、表、列、索引等数据库对象(create、alter、drop等)</li>
<li>DML(Data Manipulation Language数据库操作语言) 用于添加、删除、更新和查询数据库记录，并检查数据完整性(insert、delete、update)</li>
<li>DQL(Data Query Language数据库查询语言)查询数据库中表的记录(select)</li>
<li>DCL(Data Control Language数据库控制语言) 用于控制不同数据段直接的许可和访问级别的语句。定义了数据库、表、字段、用户的访问权限和安全级别(grant,revoke等)</li>
</ul>
<h2>12.1. DDL语句</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code># 创建数据库
mysql&gt; CREATE DATABASE 数据库名 [charset 字符集] [collate 校对规则];

# 查看所有数据库
# information_schema：存储了系统中的一些数据库对象信息。比如用户表信息、列信息、权限信息、分区信息等
# cluster：存储了系统的集群信息
# mysql：存储了系统的用户权限信息
mysql&gt; SHOW DATABASES;

# 查看数据库详细说明(编码)
mysql&gt; SHOW CREATE DATABASE 数据库名;

# 选择操作的数据库
mysql&gt; USE 数据库名;

# 查看当前操作的数据库
mysql&gt; SELECT DATABASE();

# 查看数据库的表
mysql&gt; SHOW TABLES;

# 改变数据库的全局特性
mysql&gt; ALTER DATABASE [db_name] [CHARACTER SET charset] [COLLATE collation];

# 删除数据库
mysql&gt; DROP DATABASE 数据库名;

# 创建表
mysql&gt; CREATE TABLE 表名(列名 数据类型(长度)[约束] (s) )[NGINE=存储引擎][CHARSET 字符集 collate 校对规则]

# 创建MEMORY表
mysql&gt; CREATE TABLE 表名 ENGINE=MEMORY select子句

# 创建MERGE表
mysql&gt; CREATE TABLE 表名(列名 类型(长度)[约束] (s)) engine=merge union=(表名(s)) [INSERT_METHOD=LAST|FIRST|NO]

# 查看表定义/建表sql
mysql&gt; DES 表名;
mysql&gt; show create table 表名;

# 删除表
mysql&gt; DROP TABLE 表名;
mysql&gt; truncate table 表名;删表重建，auto_increment重新记录,删除的数据找不回

# 增加表字段
mysql&gt; ALTER TABLE 表名 ADD 列名 类型（长度）[约束][FIRST | AFTER 列名];

# 修改表字段类型(长度)[约束]
mysql&gt; ALTER TABLE 表名 MODIFY 列名 类型(长度)[约束][FIRST | AFTER 列名]

# 改整个字段
mysql&gt; ALTER TABLE 表名 CHANGE  旧列名 新列名 类型(长度)[约束] [FIRST | AFTER 列名]

# 删除字段
mysql&gt; ALTER TABLE 表名 DROP 列名;

# 改表名
mysql&gt; ALTER TABLE 旧表名 RENAME  新表名

# 改表字符集
mysql&gt; ALTER TABLE 表名 character set 字符集;

# 修改存储引擎
mysql&gt; ALTER TABLE 表名 engine = innodb;

# 增加外键
# RESTRICT和NO ACTION是指限制在子表有关联记录的情况下主表不能更新；CASCADE 表示主表在更新或者删除时，更新或者删除子表对应记录；SET NULL表示主表在更新或者删除的时候，子表的对应字段被 SET NULL
mysql&gt; ALTER TABLE 子表 add [constraint 外键名(以_fk结尾)] foreign key (从表外键列名) references 主表 (主表主键)[ON DELETE/UPDATE RESTRICT/CASCADE/SET NULL/NO ACTION(s)];

# 添加主键约束
mysql&gt; ALTER TABLE table_name ADD PRIMARY KEY (column_name);

# 删外键
mysql&gt; alter table 从表 drop foreign key 外键名称;

# 查字符集对应的校对规则
mysql&gt; show character set;

# 查看MySQL编码
mysql&gt; SHOW VARIABLES LIKE 'char%';

# 修改mysql的隔离级别
mysql&gt; set session transaction isolation level

# 创建索引
mysql&gt; CREATE [UNIQUE|FULLTEXT|SPATIAL] INDEX 索引名称 [USING 索引类型] ON 表名 (列名)[(长度)(s)],...

# 删除索引
mysql&gt; DROP INDEX 索引名称 ON 表名
</code></pre></div><h2>12.2. DML语句</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code># 添加记录
mysql&gt; INSERT INTO 表名 [(列名1，列名2，列名3...)] VALUES (值1，值2，值3)[,(值3, 值3, 值5)...]

# 修改(多表)记录
mysql&gt; UPDATE 表名(s) SET 列名=值[,列名=值(s)] [where 条件];
mysql&gt; UPDATE t1[,t2…tn] SET t1.field1=expr1[,tn.fieldn=exprn] [where 条件]

# 删除(多表)记录
mysql&gt; DELETE FROM 表名 [where 条件] auto_increment记录不清空，同一个事务可以找回数据
mysql&gt; DELETE t1,t2…tn FROM t1,t2…tn [where 条件]

# 开始事务
mysql&gt; START TRANSACTION;
# 提交事务
mysql&gt; COMMIT;
# 回滚事务
mysql&gt; ROLLBACK;
</code></pre></div><h2>12.3. DQL语句</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code># 查询记录
mysql&gt; SELECT [distinct全部列,非第一列] */列名 [as `别名`](s) FROM 表名 [inner/left/right join 表名 on 条件] [where 条件] [group by 条件 [WITH ROLLUP 对分类聚合后的结果进行再汇总 和ORDER BY是互相排斥] [having 条件 对分类后的结果再进行条件的过滤]]  [order by 条件 asc/desc(s)多个字段时，相同的按第二个字段排，依次类推，默认升序] [limit offset_start[,row_count] offset_start=(第几页-1)*row_count row_count每页数量]

# 隐式内连接
mysql&gt; select *from A,B where 条件
# 显示内连接
mysql&gt; select * from A [inner] join B on 条件
# 左外连接: 包含所有的左边表中的记录甚至是右边表中没有和它匹配的记录
mysql&gt; select * from A left outer join B on 条件
# 右外连接: 包含所有的右边表中的记录甚至是左边表中没有和它匹配的记录
mysql&gt; select * from B right outer join A on 条件 左连接：
# 子查询(in、not in、=、!=、exists、not exists、ALL、ANY、SOME),表连接在很多情况下用于优化子查询
mysql&gt; select * from 表名 where 列名=（select where 列名=值）;


- 表与表的关系
  - 一对一：可以创建成一张表
  - 一对多：部门与员工、客户和订单、分类和商品
  - 从表（多）创建字段并添加外键指向主表（一）的主键
  - 多对多：学生和课程、商品和订单、人和角色
  - 建立中间表，至少两字段。作为从表，指向各方（多）的主键（拆成两个一对多）
- 外键操作
  - 从表外键是对主表主键的引用、从表外键类型必须与主表主键类型一样
  - 从表不能添加(更新)，主表中不存在的数据。主表不能删除（更新），从表中已经使用的数据
  - 外键的目的是保证数据完整性
  - 删除主表中与从表有关联关系的数据
  - ①解除主从表的约束关系
  - ②先删除从表中与主表有关系的数据，再删除主表中的数据
</code></pre></div><h2>12.4. DCL语句</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code># 创建用户
mysql&gt; CREATE USER 'username'@'host' IDENTIFIED BY 'password';
# 授权
mysql&gt; GRANT ALL[PRIVILEGES]/SELECT/INSERT ON database_name.table_name TO 'username'@'localhost' IDENTIFIED BY 'ermazi'
# 回收
mysql&gt; REVOKE ALL[PRIVILEGES]/SELECT/INSERT ON database_name.table_name FROM 'username'@'localhost'
# 删除用户
mysql&gt; DROP USER 'username'@'host';
</code></pre></div><h1>13. 介绍一下MySQL bin目录下的可执行文件</h1>
<ul>
<li>mysql：客户端程序，用于连接MySQL服务器</li>
<li>mysqldump：数据库备份工具，用于创建一个或多个MySQL数据库级别的SQL转储文件，包括数据库的表结构和数据。用于数据备份、迁移或恢复。</li>
<li>mysqladmin：管理工具，用来执行一些管理操作，比如说创建数据库、删除数据库、查看MySQL服务器的状态等。</li>
<li>mysqlcheck：命令行工具，用于检查、修复、分析和优化数据库表，对数据库的维护和性能优化非常有用。</li>
<li>mysqlimport：用于从文本文件中导入数据到数据库表中，非常适合用于批量导入数据。</li>
<li>mysqlshow：用于显示MySQL数据库服务器中的数据库、表、列等信息。</li>
<li>mysqlbinlog：用于查看MySQL二进制日志文件的内容，可以用于恢复数据、查看数据变更等。</li>
</ul>
<h1>14. 第 3-10 条记录怎么查</h1>
<ul>
<li>limit 语句用于限制查询结果的数量，偏移量表示从哪条记录开始，行数表示返回的记录数量。</li>
<li>SELECT * FROM table_name LIMIT 2, 8;</li>
</ul>
<h1>15. mysql函数</h1>
<p>字符串函数</p>
<ul>
<li>
<p>CANCAT(S1,S2,…Sn) 连接 S1,S2,…Sn 为一个字符串，任何字符串与NULL连接的结果都是NULL</p>
</li>
<li>
<p>LENGTH(): 返回字符串的长度。</p>
</li>
<li>
<p>SUBSTRING(str,x,y) 返回从字符串 str x 位置起 y 个字符长度的字串</p>
</li>
<li>
<p>REPLACE(str,a,b) 用字符串 b 替换字符串 str 中所有出现的字符串 a</p>
</li>
<li>
<p>LOWER(str)、UPPER(str) 将字符串 str 中所有字符变为小、大写</p>
</li>
<li>
<p>TRIM(str) 去掉字符串行尾和行头的空格</p>
</li>
<li>
<p>INSERT(str,x,y,instr) 将字符串 str 从第 x 位置开始，y 个字符长的子串替换为字符串 instr</p>
</li>
<li>
<p>LEFT(str ,x) 返回字符串 str 最左边的 x 个字符，如果第二个参数是 NULL，那么将不返回任何字符串</p>
</li>
<li>
<p>RIGHT(str,x) 返回字符串 str 最右边的 x 个字符，如果第二个参数是 NULL，那么将不返回任何字符串</p>
</li>
<li>
<p>LPAD(str,n,pad) 用字符串 pad 对 str 最左边进行填充，直到长度为 n 个字符长度</p>
</li>
<li>
<p>RPAD(str,n,pad) 用字符串 pad 对 str 最右边进行填充，直到长度为 n 个字符长度</p>
</li>
<li>
<p>REPEAT(str,x) 返回 str 重复 x 次的结果</p>
</li>
<li>
<p>STRCMP(s1,s2)函数：比较字符串 s1 和 s2 的 ASCII 码值的大小</p>
</li>
</ul>
<p>数值函数</p>
<ul>
<li>
<p>ABS(x) 返回x绝对值</p>
</li>
<li>
<p>CEIL(x) 返回大于或等于给定数值的最小整数。</p>
</li>
<li>
<p>FLOOR(x) 返回小于或等于给定数值的最大整数。</p>
</li>
<li>
<p>ROUND(x,y) 返回x四舍五入有y位小数的值。如果是整数，将会保留y位数量的0；如果不写y，则默认y为0，即将x四舍五入后取整。适合于将所有数字保留同样小数位的情况</p>
</li>
<li>
<p>MOD(x，y) 返回x/y的模</p>
</li>
<li>
<p>RAND() 返回0到1内随机值 产生0～100随机整数 ceil(100*rand())</p>
</li>
<li>
<p>TRUNCATE(x,y) 返回数字x截断为y位小数的结果，不进行四舍五入</p>
</li>
<li>
<p>BIT_OR()、BIT_AND()配合GROUP BY降低存储量，提高统计查询效率。统计数字字段的情况，比如使用十进制数字存储某个人购买过的商品，每一位的1表示购买了某种商品，0表示没购买，则可以使用BIT_OR表示客户购买过哪些商品，BIT_AND表示客户每次都来买的商品</p>
</li>
</ul>
<p>日期和时间函数</p>
<ul>
<li>
<p>NOW() 返回当前日期和时间，年月日时分秒</p>
</li>
<li>
<p>CURDATE() 返回当前日期，年月日</p>
</li>
<li>
<p>CURTIME() 返回当前时间，时分秒</p>
</li>
<li>
<p>DATE_ADD(date,INTERVAL expr type) 和 DATE_SUB()返回一个日期或时间值加上、减去一个时间间隔的时间值</p>
<ul>
<li>HOUR 小时 hh</li>
<li>MINUTE 分 mm</li>
<li>SECOND 秒 ss</li>
<li>YEAR 年 YY</li>
<li>MONTH 月 MM</li>
<li>DAY 日 DD</li>
<li>YEAR_MONTH 年和月 YY-MM</li>
<li>DAY_HOUR 日和小时 DD hh</li>
<li>DAY_MINUTE 日和分钟 DD hh:mm</li>
<li>DAY_ SECOND 日和秒 DD hh:mm:ss</li>
<li>HOUR_MINUTE 小时和分 hh:mm</li>
<li>HOUR_SECOND 小时和秒 hh:ss</li>
<li>MINUTE_SECOND 分钟和秒 mm:ss</li>
</ul>
</li>
<li>
<p>DATEDIFF(expr,expr2) 返回起始时间 expr 和结束时间 expr2 之间的天数</p>
</li>
<li>
<p>UNIX_TIMESTAMP(date) 返回日期date的UNIX时间戳</p>
</li>
<li>
<p>FROM_UNIXTIME 返回 UNIX 时间戳的日期值</p>
</li>
<li>
<p>WEEK(date) 返回日期 date 为一年中的第几周</p>
</li>
<li>
<p>YEAR(date) 返回日期 date 的年份</p>
</li>
<li>
<p>HOUR(time) 返回 time 的小时值</p>
</li>
<li>
<p>MINUTE(time) 返回 time 的分钟值</p>
</li>
<li>
<p>DATE_FORMAT(date,fmt) 返回按字符串 fmt 格式化日期 date 值</p>
<ul>
<li>%S,%s 两位数字形式的秒（00,01,...,59）</li>
<li>%i 两位数字形式的分（00,01,...,59）</li>
<li>%H 两位数字形式的小时，24 小时（00,01,...,23）</li>
<li>%h,%I 两位数字形式的小时，12 小时（01,02,...,12）</li>
<li>%k 数字形式的小时，24 小时（0,1,...,23）</li>
<li>%l 数字形式的小时，12 小时（1,2,...,12）</li>
<li>%T 24 小时的时间形式（hh:mm:ss）</li>
<li>%r 12 小时的时间形式（hh:mm:ssAM 或 hh:mm:ssPM）</li>
<li>%p AM 或 PM</li>
<li>%W 一周中每一天的名称（Sunday,Monday,...,Saturday）</li>
<li>%a 一周中每一天名称的缩写（Sun,Mon,...,Sat）</li>
<li>%d 两位数字表示月中的天数（00,01,...,31）</li>
<li>%e 数字形式表示月中的天数（1,2，...,31）</li>
<li>%D 英文后缀表示月中的天数（1st,2nd,3rd,...）</li>
<li>%w 以数字形式表示周中的天数（0=Sunday,1=Monday,...,6=Saturday）</li>
<li>%j 以 3 位数字表示年中的天数（001,002,...,366）</li>
<li>%U 周（0,1,52），其中 Sunday 为周中的第一天</li>
<li>%u 周（0,1,52），其中 Monday 为周中的第一天</li>
<li>%M 月名（January,February,...,December）</li>
<li>%b 缩写的月名（January,February,...,December）</li>
<li>%m 两位数字表示的月份（01,02,...,12）</li>
<li>%c 数字表示的月份（1,2,...,12）</li>
<li>%Y 4 位数字表示的年份</li>
<li>%y 两位数字表示的年份</li>
<li>%% 直接值“%”</li>
</ul>
</li>
</ul>
<p>聚合函数</p>
<ul>
<li>SUM(): 计算数值列的总和。</li>
<li>AVG(): 计算数值列的平均值。</li>
<li>COUNT(): 计算某列的行数。</li>
<li>MAX() 和 MIN(): 分别返回列中的最大值和最小值。</li>
<li>GROUP_CONCAT(): 将多个行值连接为一个字符串。</li>
</ul>
<p>流程函数</p>
<ul>
<li>IF(value,t f)如果value是真，返回t；否则返回f</li>
<li>IFNULL(value1,value2) 如果value1不为空返回value1，否则返回value2</li>
<li>CASE WHEN [value1] THEN[result1]…ELSE[default]END 如果value1是真，返回 result1，否则返回 default</li>
<li>CASE [expr] WHEN [value1] THEN[result1]…ELSE[default]END 如果expr等于value1，返回result1，否则返回default</li>
<li>COALESCE(): 返回参数列表中的第一个非 NULL 值。</li>
</ul>
<p>格式化函数</p>
<ul>
<li>FORMAT(): 格式化数字为格式化的字符串，通常用于货币显示。SELECT FORMAT(1234567.8945, 2) AS formatted_number;</li>
</ul>
<p>类型转换函数</p>
<ul>
<li>CAST(): 将一个值转换为指定的数据类型。SELECT CAST('2024-01-01' AS DATE) AS casted_date;</li>
<li>CONVERT(): 类似于CAST()，用于类型转换。SELECT CONVERT('123', SIGNED INTEGER) AS converted_number;</li>
</ul>
<h1>16. SQL 的隐式数据类型转换？</h1>
<ul>
<li>当不同数据类型的值进行运算或比较时，会发生隐式数据类型转换。</li>
</ul>
<h1>17. MySQL的基础架构</h1>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/ffe5c6730d04f821f724c.png" alt="mysqlinfrastructure.png" tabindex="0"><figcaption>mysqlinfrastructure.png</figcaption></figure>
<ul>
<li>客户端：最上层的服务并不是MySQL所独有的，大多数基于网络的客户端/服务器的工具或者服务都有类似的架构。比如连接处理、授权认证、安全等等</li>
<li>Server层：所有跨存储引擎的功能都在这一层实现，比如函数、存储过程、触发器等。不同的存储引擎共用一个Server层
<ul>
<li>连接器：连接器负责跟客户端建立连接、获取权限、维持和管理连接。</li>
<li>查询缓存(MySQL 8.0后移除，因为表更新后缓存随时失效) 如果你的查询能够直接在这个缓存中找到key(查询的语句)，那么这个value(查询结果)就会被直接返回给客户端。如果语句不在查询缓存中，就会继续后面的执行阶段。执行完成后，执行结果会被存入查询缓存中。</li>
<li>分析器：先会做“词法分析”。识别出里面的字符串分别是什么，代表什么。然后做“语法分析”，判断你输入的这个SQL语句是否满足MySQL语法。</li>
<li>优化器：在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序</li>
<li>执行器：执行语句，然后从存储引擎返回数据。</li>
</ul>
</li>
<li>存储引擎层：负责数据存储和提取。支持InnoDB(默认)、MyISAM、Memory等多个存储引擎。可在create table语句中使用engine = MyISAM指定引擎.Server层通过API与存储引擎进行通信。这些接口屏蔽了不同存储引擎之间的差异，使得这些差异对上层的查询过程透明。</li>
</ul>
<h1>18. 一条SQL查询语句在MySQL中如何执行的？</h1>
<ul>
<li>客户端发送 SQL 查询语句到 MySQL 服务器。</li>
<li>连接器检查客户端对表有没有执行查询的权限，没有则返回没有权限的错误，</li>
<li>查询缓存，如果有，直接返回给客户端；(MySQL8.0版本以前)。</li>
<li>分析器进行语法分析，提取sql语句中select等关键元素，然后判断sql语句是否有语法错误，比如关键词是否正确等等。</li>
<li>优化器对查询的语句进行优化，确定 SQL 语句的执行计划。确定使用的索引等</li>
<li>执行器按照生成的执行计划调用数据库引擎接口，取这个表的每一行，判断ID值是不是10，如果不是则跳过，如果是则将这行存在结果集中，直到取到这个表的最后一行，返回执行结果。</li>
</ul>
<h1>19. MySQL有哪些常见存储引擎？</h1>
<ul>
<li>mysql5.5后默认存储引擎改为innodb，5.6InnoDB支持全文索引。</li>
<li>InnoDB支持事务、全文索引、B+树索引、哈希索引（自适应，不能人为干预）、外键</li>
<li>MyISAM支持全文索引、B+树索引</li>
<li>MEMORY支持B+树索引、哈希索引</li>
</ul>
<h1>20. 存储引擎应该怎么选择？</h1>
<ul>
<li>首选InnoDB：需要支持事务，并发控制(在并发条件下要求数据的一致性)，外键，崩溃恢复，数据操作除了插入和查询以外，还包括很多的更新、删除操作。适合类似计费系统或者财务系统等对数据准确性要求比较高的系统</li>
<li>选择MyISAM：如果数据表主要用来插入和查询记录，只有很少的更新和删除操作，并且对事务的完整性、并发性要求不是很高，在Web、数据仓储和其他应用环境下最常使用的存储引擎之一。</li>
<li>选择MEMORY：如果只是临时存放数据，需要快速访问，数据量不大，内容变化不频繁(代码表)并且不需要较高的数据安全性，可以作为临时表，存放查询的中间结果。需要保证数据库异常后能恢复。且表大小有限制</li>
<li>MERGE：用于将一系列等同的 MyISAM 表以逻辑方式组合在一起，并作为一个对象引用它们。优点在于可以突破对单个MyISAM表大小的限制，并且通过将不同的表分布在多个磁盘上，可有效地改善MERGE表的访问效率。主要用于诸如数据仓储等VLDB环境</li>
<li>使用哪一种引擎可以根据需要灵活选择，因为存储引擎是基于表的，所以一个数据库中多个表可以使用不同的引擎以满足各种性能和实际需求。使用合适的存储引擎将会提高整个数据库的性能。</li>
</ul>
<h1>21. InnoDB和MylSAM主要区别？</h1>
<ul>
<li>存储结构
<ul>
<li>MyISAM：用三种格式的文件来存储，.frm 文件存储表的定义；.MYD 存储数据；.MYI 存储索引。</li>
<li>InnoDB：用两种格式的文件来存储，.frm 文件存储表的定义；.ibd 存储数据和索引。</li>
</ul>
</li>
<li>事务支持：MyISAM不支持事务；InnoDB支持事务</li>
<li>最小锁粒度：MyISAM只支持表级锁，高并发中写操作存在性能瓶颈；InnoDB支持行级锁。并发写入性能高（命中索引时）</li>
<li>索引类型：
<ul>
<li>MyISAM的索引为非聚簇索引，数据结构是B树，索引和数据分开存储，索引保存的是数据文件的指针；</li>
<li>InnoDB的索引是聚簇索引，索引和数据不分开。数据结构是B+树。</li>
</ul>
</li>
<li>主键必需：MyISAM表可以没有主键；InnoDB如果没有设定主键或者非空唯一索引，<strong>就会自动生成一个6字节的主键(用户不可见)</strong>，数据是主索引的一部分，附加索引保存的是主索引的值。</li>
<li>表的具体行数：MyISAM保存了表的总行数;InnoDB没有保存表的总行数</li>
<li>外键支持：MyISAM不支持外键；InnoDB支持外键。外键对于维护数据一致性非常有帮助，但是对性能有一定的损耗。因此，通常情况下，不建议在实际生产项目中使用外键，在业务代码中进行约束即可！</li>
<li>MyISAM 不支持数据库异常崩溃后的安全恢复，InnoDB支持。依赖于 redo log</li>
<li>MyISAM 不支持MVCC，InnoDB支持MVCC，MVCC可以看作是行级锁的一个升级，可以有效减少加锁操作，提高性能。</li>
</ul>
<h1>22. MySQL日志文件及作用？</h1>
<ul>
<li>
<p>错误日志（errorlog）：记录了当mysql启动、停止、运行过程中发生任何严重错误时的信息</p>
</li>
<li>
<p>慢查询日志（slowquerylog）：记录执行时间超过long_query_time值的查询语句</p>
</li>
<li>
<p>一般查询日志（generallog）记录了所有对MySQL数据库请求的信息，对于访问频繁的系统，不建议开启</p>
</li>
<li>
<p>二进制日志（binlog）：记录了数据库所有执行的DDL和DML语句（除了数据查询语句select、show等），用于数据恢复</p>
</li>
<li>
<p>重做日志（redolog）：记录对于InnoDB表的每个写操作，是物理级别的，主要用于崩溃恢复(InnoDB独有)</p>
</li>
<li>
<p>回滚日志（undolog）：记录数据被修改前的值，用于事务的回滚(InnoDB独有)</p>
</li>
<li>
<p>binlog 是一种物理日志，会在磁盘上记录下数据库的所有修改操作，以便进行数据恢复和主从复制。</p>
<ul>
<li>当发生数据丢失时，binlog 可以将数据库恢复到特定的时间点。</li>
<li>主服务器（master）上的二进制日志可以被从服务器（slave）读取，从而实现数据同步。</li>
</ul>
</li>
<li>
<p>binlog 包括两类文件：二进制索引文件（.index）、二进制日志文件（.00000*）</p>
</li>
<li>
<p>binlog 默认不启用。需要在配置文件（my.cnf 或 my.ini）中设置 log_bin 参数。show variables like '%log_bin%'; 查看 binlog 是否开启。</p>
</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>log_bin = mysql-bin #开启binlog MySQL数据目录生成 db-bin.000001、db-bin.000002 等日志文件。

#mysql-bin.*日志文件最大字节（单位：字节）
#设置最大100MB 当 binlog 文件达到这个大小时，MySQL 会关闭当前文件并创建一个新的 binlog 文件。
max_binlog_size=104857600

#设置了只保留7天BINLOG（单位：天）过期的 binlog 文件将被自动删除。防止长时间累积的binlog文件占用过多存储空间
expire_logs_days = 7

#binlog日志只记录指定库的更新
#binlog-do-db=db_name

#binlog日志不记录指定库的更新
#binlog-ignore-db=db_name

#写缓冲多少次，刷一次磁盘，默认0 表示 MySQL 不会主动触发同步操作，而是依赖操作系统的磁盘缓存策略。即当执行写操作时，数据会先写入操作系统的缓存，当缓存区满了再由操作系统将数据写入磁盘。设置为 1 每次 binlog 写操作后都会同步到磁盘，这可以提高数据安全性，但可能会对性能产生影响。

sync_binlog=0
</code></pre></div><h1>23. binlog和redolog有什么区别？</h1>
<ul>
<li>binlog会记录所有与数据库有关的日志记录，包括InnoDB、MyISAM等存储引擎的日志，而redolog只记InnoDB存储引擎的日志</li>
<li>记录的内容不同，binlog记录事务的具体操作内容，是逻辑日志。redolog记录每个页（Page）的更改的物理情况</li>
<li>写入的时间不同，binlog仅在事务提交前进行提交，也就是只写磁盘一次。而在事务进行的过程中，却不断有redoertry被写入redolog中</li>
<li>写入的方式也不相同，binlog是追加写入，不会覆盖已经写的文件。redolog是循环写入和擦除，</li>
</ul>
<h1>24. 一条更新语句怎么执行的了解吗？</h1>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/6bea766b8e9e8609d05ff.png" alt="mysqlexecuteupdate.jpg" tabindex="0"><figcaption>mysqlexecuteupdate.jpg</figcaption></figure>
<ul>
<li>执行器先找引擎获取ID=2这一行。ID是主键，存储引擎检索数据，找到这一行。如果ID=2这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。</li>
<li>执行器拿到引擎给的行数据，把这个值加上1，比如原来是N，现在就是N+1，得到新的一行数据，再调用引擎接口写入这行新数据。- 引擎将这行新数据更新到内存中，同时将这个更新操作记录到redolog里面，此时redolog处于prepare状态。然后告知执行器执行完成了，随时可以提交事务。</li>
<li>执行器生成这个操作的binlog，并把binlog写入磁盘。</li>
<li>执行器调用引擎的提交事务接口，引擎把刚刚写入的redolog改成提交（commit）状态，更新完成。</li>
<li>MySQL在执行更新语句的时候，在服务层进行语句的解析和执行，在引擎层进行数据的提取和存储；同时在服务层对binlog进行写入，在InnoDB内进行redolog的写入。</li>
<li>在对redolog写入时有两个阶段的提交，一是binlog写入之前prepare状态的写入，二是binlog写入之后commit状态的写入</li>
</ul>
<h1>25. 为什么要两阶段提交呢？</h1>
<ul>
<li>假设不采用两阶段提交的方式，而是采用“单阶段”进行提交，即要么先写入redolog，后写入binlog；要么先写入binlog，后写入redolog。这两种方式的提交都会导致原先数据库的状态和被恢复后的数据库的状态不一致。</li>
<li>假设ID=2的行字段c的值是0，再假设执行update T set c=c+1 where ID=2;语句过程中在写完第一个日志后，第二个日志还没有写完期间发生了crash，会出现什么情况呢？
<ul>
<li>先写redo log后写binlog。假设在redo log写完，MySQL进程异常重启。redo log已写，崩溃恢复以后事务生效，这一行c的值是1。而用这个binlog来恢复临时库的话，由于这个语句的binlog丢失，恢复出来的这一行c的值就是0，与数据库的值不同</li>
<li>先写binlog后写redo log。假设binlog写完，MySQL进程异常重启。redo log未写，崩溃恢复以后事务无效，这一行c的值是0。而用binlog来恢复的时候就多了“把c从0改成1”这个日志，恢复出来的这一行c的值就是1，与数据库的值不一样</li>
</ul>
</li>
<li>简单说，redolog和binlog都可以用于表示事务的提交状态，而两阶段提交就是让这两个状态保持逻辑上的一致。</li>
</ul>
<h1>26. redo log怎么刷入磁盘的知道吗？</h1>
<ul>
<li>redo log是固定大小的。redo log可以看作是一个逻辑上的loggroup，由一定数量的redologblock组成。块的大小是固定的512字节。它的写入方式是从头到尾开始写，写到末尾又回到开头循环写。 其中有两个标记位置：writepos是当前记录的位置，一边写一边后移，写到第3号文件末尾后就回到0号文件开头。checkpoint是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到磁盘。write pos和checkpoint(cp)之间的是空闲部分，可以用来记录新的操作。当write_pos追上checkpoint时，表示redolog日志已经写满。这时候就不能接着往里写数据了，需要执行checkpoint规则腾出可写空间。所谓的checkpoint规则，就是checkpoint触发后，将buffer中日志页都刷到磁盘。</li>
<li>redo log的写入机制：事务执行过程中，先把日志写到redo log buffer。 然后写到 redo log 的文件系统缓存里面(fwrite)，然后再同步到磁盘文件（fsync）</li>
<li>在如下的一些情况中，redo log buffer的数据会刷入磁盘：</li>
<li>log buffer空间不足时：如果当前写入redo log buffer的日志量超过logbuffer总容量innodb_log_buffer_size的一半，后台线程会主动写盘fwrite，保存在文件系统的page cache，但没有调用fsync</li>
<li>并行的事务提交时，顺带将这个事务的redo log buffer持久化到磁盘。当innodb_flush_log_at_trx_commit=1，假设一个事务A执行到一半，已经写了一些redo log到buffer中，这时候有另外一个线程的事务B提交，事务B要把redo log buffer里的日志全部持久化到磁盘。这时候会带上事务A在redo log buffer里的日志一起持久化到磁盘。</li>
<li>后台线程输入：innodb_flush_log_at_trx_commit=2时，有一个后台线程，大约每秒都会刷新一次redo log buffer中的redo log到磁盘。</li>
<li>正常关闭服务器时</li>
<li>触发checkpoint规则：</li>
</ul>
<h1>31. 索引的分类</h1>
<ul>
<li>功能分类</li>
<li>主键索引: 表中每行数据唯一标识的索引，强调列值的唯一性和非空性。一张数据表有只能有一个主键</li>
<li>唯一索引: 保证数据列中每行数据的唯一性，允许有空值。</li>
<li>普通索引: 基本的索引类型，用于加速查询。允许数据重复和NULL</li>
<li>全文索引：用于检索大文本数据中的关键字的信息，而不用使用 like ‘%…%’</li>
<li>外键索引：只有InnoDB类型的表才可以使用外键索引，保证数据的一致性、完整性和实现级联操作。</li>
<li>从数据结构上分类
<ul>
<li>B+树索引：一种将索引值按照一定的算法，存入一个树形的数据结构中（二叉树），每次查询都从树的根节点开始，一次遍历叶子节点，找到对应的值。查询效率是O(logN)。</li>
<li>Hash索引：基于哈希表的索引，查询效率可以达到O(1)，但是只适合=和in查询，不适合范围查询和排序。当发生哈希冲突的时候也是通过拉链法来解决。InnoDB并不提供直接创建哈希索引的选项。但InnoDB使用了一种名为“自适应哈希索引”（Adaptive Hash Index, AHI）的技术，可通过SHOW VARIABLES LIKE 'innodb_adaptive_hash_index';查看</li>
</ul>
</li>
<li>从存储位置上分类：
<ul>
<li>聚簇索引：聚簇索引的叶子节点保存了一行记录的所有列信息。聚簇索引的叶子节点中，包含了一个完整的记录行。</li>
<li>非聚簇索引：叶子节点只包含一个主键值，通过非聚簇索引查找记录要先找到主键，然后通过主键再到聚簇索引中找到对应的记录行，这个过程被称为回表。</li>
</ul>
</li>
<li>InnoDB存储引擎的主键使用的是聚簇索引，MyISAM存储引擎不管是主键索引，还是二级索引使用的都是非聚簇索引。</li>
</ul>
<h1>37. 为什么 InnoDB 要使用 B+树作为索引？</h1>
<ul>
<li>
<p>磁盘读写代价更低：B+树的内部节点并没有指向关键字具体信息的指针，因此其内部节点相对B树更小。如果把所有同一内部节点的关键字存放在同一盘块中，那么盘块所能容纳的关键字数量也越多，一次性读入内存的需要查找的关键字也就越多，相对IO读写次数就降低了。</p>
</li>
<li>
<p>查询性能更加稳定：由于非终结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引。所以任何关键字的查找必须走一条从根结点到叶子结点的路。这种特性使得所有关键字查询的路径长度相同，导致每一个数据的查询效率相当。</p>
</li>
<li>
<p>支持高效的范围查询：B+树的叶子节点存储了所有数据记录的指针，并且形成了一个有序链表，这使得范围查询变得非常高效。数据库经常需要查询某个范围内的数据，B+树的结构能够很好地满足这一需求。</p>
</li>
<li>
<p>减少回表操作：B+树的内部节点只存储索引信息，不存储数据记录的具体信息。当查询条件能够命中索引时，可以先通过索引找到数据记录的指针，然后再根据指针到数据页中查找具体的数据记录。这种方式可以减少回表操作，提高查询效率。</p>
</li>
<li>
<p>支持并发访问：InnoDB 存储引擎支持行级锁定，而 B+树的结构可以很方便地支持这种锁定方式。当对某个数据记录进行锁定时，只需要锁定该数据记录所在的叶子节点即可，这样可以减少锁定的范围，提高并发访问的性能。</p>
</li>
<li>
<p>在InnoDB存储引擎中，默认的页大小是16KB。可以通过showvariableslike'innodb_page_size';查看。</p>
</li>
<li>
<p>B树是一种自平衡的多路查找树，和红黑树、二叉平衡树不同，B树的每个节点可以有m个子节点，而红黑树和二叉平衡树都只有2个</p>
</li>
<li>
<p>内存和磁盘在进行IO读写的时候，有一个最小的逻辑单元，叫做页（Page），页的大小一般是4KB</p>
</li>
<li>
<p>为了提高读写效率，从磁盘往内存中读数据的时候，一次会读取至少一页的数据，比如说读取2KB的数据，实际上会读取4KB的数据；读取5KB的数据，实际上会读取8KB的数据。我们要尽量减少读写的次数。因为读的次数越多，效率就越低。</p>
</li>
<li>
<p>树越高，意味着查找数据时就需要更多的磁盘IO，因为每一层都可能需要从磁盘加载新的节点。B树的节点大小通常与页的大小对齐，这样每次从磁盘加载一个节点时，可以正好是一个页的大小。因为B树的节点可以有多个子节点，可以填充更多的信息以达到一页的大小。</p>
</li>
<li>
<p>B树的一个节点通常包括三个部分：键值：即表中的主键；指针：存储子节点的信息；数据：表记录中除主键外的数据。正是因为B树的每个节点上都存了数据，就导致每个节点能存储的键值和指针变少了，因为每一页的大小是固定的，于是B+树就来了，B+树的非叶子节点只存储键值，不存储数据，而叶子节点存储了所有的数据，并且构成了一个有序链表。这样做的好处是，非叶子节点上由于没有存储数据，就可以存储更多的键值对，树就变得更加矮。由此一来，查找数据进行的磁盘IO就更少了，查询的效率也就更高了。</p>
</li>
<li>
<p>再加上叶子节点构成了一个有序链表，范围查询时就可以直接通过叶子节点间的指针顺序访问整个查询范围内的所有记录，而无需对树进行多次遍历。</p>
</li>
</ul>
<h1>38. 那一棵B+树能存储多少条数据呢？</h1>
<ul>
<li>InnoDB 存储引擎的最小存储单元是页，默认大小是 16k。假设主键ID是bigint类型，长度为8个字节。指针大小为6字节，这样一共14字节。所以非叶子节点(一页)可以存储16384/14=1170个这样的单元(键值+指针)。</li>
<li>一个指针指向一个存放记录的页，一页可以放16条数据，树深度为2的时候，可以存放1170*16=18720条数据。</li>
<li>树深度为3的时候，可以存储的数据为1170<em>1170</em>16=21902400条记录。</li>
<li>理论上，在InnoDB存储引擎中，B+树的高度一般为2-4层，就可以满足千万级数据的存储。查找数据的时候，一次页的查找代表一次IO，当我们通过主键索引查询的时候，最多只需要2-4次IO就可以了。</li>
</ul>
<h1>39. 为什么要用B+树，而不用普通二叉树？</h1>
<ul>
<li>
<p>为什么不用普通二叉树？普通二叉树存在退化的情况，如果它退化成链表，相当于全表扫描。平衡二叉树相比于二叉查找树来说，查找效率更稳定，总体的查找速度也更快。</p>
</li>
<li>
<p>为什么不用平衡二叉树呢？读取数据的时候，是从磁盘读到内存。如果树这种数据结构作为索引，那每查找一次数据就需要从磁盘中读取一个节点，也就是一个磁盘块，但是平衡二叉树可是每个节点只存储一个键值和数据的，如果是B+树，可以存储更多的节点数据，树的高度也会降低，因此读取磁盘的次数就降下来啦，查询效率就快。</p>
</li>
</ul>
<h1>40. 为什么用B+树而不用B树呢？√</h1>
<ul>
<li>更高的查询效率：B+树的所有值（数据记录或指向数据记录的指针）都存在于叶子节点，并且叶子节点之间通过指针连接，形成一个有序链表。使得 B+树非常适合进行范围查询。一旦到达了范围的开始位置，接下来的元素可以通过遍历叶子节点的链表顺序访问，而不需要回到树的上层。而 B 树的数据分布在整个树中，进行范围查询时可能需要遍历树的多个层级。</li>
<li>更高的空间利用率：在 B+树中，非叶子节点不存储数据，只存储键值，这意味着非叶子节点可以拥有更多的键，从而有更多的分叉。这导致树的高度更低，进一步降低了查询时磁盘 I/O 的次数，因为每一次从一个节点到另一个节点的跳转都可能涉及到磁盘 I/O 操作。</li>
<li>B+树的磁盘读写代价更低：根节点和枝节点不保存数据区，所以一个节点可以保存更多的关键字，一次磁盘加载的关键字更多，IO次数更少。</li>
<li>排序能力更强：因为叶子节点上有下一个数据区的指针，数据形成了链表。</li>
<li>查询效率更稳定：B+树中所有叶子节点深度相同，所有数据查询路径长度相等，保证了每次搜索的性能稳定性。而在 B 树中，数据可以存储在内部节点，不同的查询可能需要不同深度的搜索。</li>
</ul>
<h1>41. Hash索引和B+树索引区别是什么？</h1>
<ul>
<li>B+树可以进行范围查询，Hash索引不能。</li>
<li>B+树支持联合索引的最左侧原则，Hash索引不支持。</li>
<li>B+树支持orderby排序，Hash索引不支持。</li>
<li>Hash索引在等值查询上比B+树效率更高。</li>
<li>B+树使用like进行模糊查询的时候，like后面（比如%开头）的话可以起到优化的作用，Hash索引根本无法进行模糊查询。</li>
</ul>
<h1>42. 聚簇索引与非聚簇索引的区别？</h1>
<ul>
<li>在聚簇索引中，索引结构和数据一起存放。主键索引属于聚集索引。表的.ibd文件就包含了该表的索引和数据，该表的索引(B+树)的每个非叶子节点存储索引，叶子节点存储索引和索引对应的数据。</li>
<li>在非聚簇索引中，索引结构和数据分开存放的索引。非聚簇索引的叶子节点不直接包含数据记录，而是包含了指向数据行的指针</li>
<li>在非聚簇索引的叶子节点上存储的并不是真正的行数据，而是主键ID，所以当我们使用非聚簇索引进行查询时，首先会得到一个主键ID，然后再使用主键ID去聚簇索引上找到真正的行数据，我们把这个过程称之为回表查询。</li>
<li>MyISAM采用的是非聚簇索引，InnoDB采用的是聚簇索引。</li>
<li>聚簇索引直接将数据存储在B+树的叶子节点中，而非聚簇索引的叶子节点存储的是指向数据行的指针。</li>
<li>一个表只能有一个聚簇索引，但可以有多个非聚簇索引。</li>
<li>聚簇索引改善了顺序访问的性能，但更新主键的成本较高；非聚簇索引适合快速插入和更新操作，但检索数据可能需要更多的磁盘I/O。</li>
</ul>
<h1>43. 回表了解吗？</h1>
<ul>
<li>在InnoDB存储引擎里，利用辅助索引查询，先通过辅助索引找到主键索引的键值，再通过主键值查出主键索引里面没有符合要求的数据，它比基于主键索引的查询多扫描了一棵索引树，这个过程就叫回表。</li>
</ul>
<h1>44. 覆盖索引了解吗？</h1>
<ul>
<li>查询时已经在索引树上获得要返回的数据，无需回表的查询，可以通过建立联合索引支持覆盖索引，牺牲空间</li>
</ul>
<h1>45. 什么是最左前缀原则/最左匹配原则？</h1>
<ul>
<li>在InnoDB的联合索引中，查询的时候只有匹配了前一个/左边的值之后，才能匹配下一个。根据最左匹配原则，最左前缀可以是联合索引的最左N个字段，也可以是字符串索引的最左M个字符。例如：用（name，age）这个联合索引，where name = '张三'或者where name like '张%'，</li>
</ul>
<h1>46. 什么是索引下推优化？</h1>
<ul>
<li>索引条件下推优化（Index Condition Pushdown(ICP)）是MySQL5.6添加的，用于优化数据查询。</li>
<li>不使用索引条件下推优化时存储引擎通过索引检索到数据，然后返回给MySQLServer，MySQLServer进行过滤条件的判断。</li>
<li>当使用索引条件下推优化时，如果存在某些被索引的列的判断条件时，MySQLServer将这一部分判断条件下推给存储引擎，然后由存储引擎通过判断索引是否符合MySQLServer传递的条件，只有当索引符合条件时才会将数据检索出来返回给MySQL服务器</li>
<li>索引条件下推优化可以减少存储引擎查询基础表的次数，也可以减少MySQL服务器从存储引擎接收数据的次数。</li>
</ul>
<h1>47. MySQL中有哪几种锁</h1>
<ul>
<li>按锁粒度划分
<ul>
<li>表锁：开销小，加锁快；锁定粒度大，发生锁冲突概率高，并发度最低;不会出现死锁。</li>
<li>行锁：开销大，加锁慢；会出现死锁；锁定粒度小，发生锁冲突的概率低，并发度高。</li>
<li>页锁：开销和加锁速度介于表锁和行锁之间；会出现死锁；锁定粒度介于表锁和行锁之间，并发度一般</li>
</ul>
</li>
<li>按照兼容性
<ul>
<li>共享锁（SLock）,也叫读锁（readlock），相互不阻塞。</li>
<li>排他锁（XLock），也叫写锁（writelock），排它锁是阻塞的，在一定时间内，只有一个请求能执行写入，并阻止其它锁读取正在写入的数据。</li>
</ul>
</li>
<li>按加锁机制
<ul>
<li>乐观锁：假设冲突在系统中出现的频率较低，因此在数据库事务执行过程中，不会频繁地去锁定资源。相反，它在提交更新的时候才检查是否有其他事务已经修改了数据。可以通过在数据表中使用版本号（Version）或时间戳（Timestamp）来实现，每次读取记录时，同时获取版本号或时间戳，更新时检查版本号或时间戳是否发生变化。如果没有变化，则执行更新并增加版本号或更新时间戳；如果检测到冲突（即版本号或时间戳与之前读取的不同），则拒绝更新。</li>
<li>悲观锁：假设冲突是常见的，因此在数据处理过程中，它会主动锁定数据，防止其他事务进行修改。可以直接使用数据库的锁机制，如行锁或表锁，来锁定被访问的数据。常见的实现是 SELECT FOR UPDATE 语句，它在读取数据时就加上了锁，直到当前事务提交或回滚后才释放。</li>
</ul>
</li>
</ul>
<h1>48. 如何解决库存超卖问题？</h1>
<ul>
<li>按照乐观锁的方式：</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>UPDATE inventory SET count = count - 1, version = version + 1 WHERE product_id = 1 AND version = current_version;
</code></pre></div><ul>
<li>按照悲观锁的方式：</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>START TRANSACTION;
SELECT * FROM inventory WHERE product_id = 1 FOR UPDATE;
UPDATE inventory SET count = count - 1 WHERE product_id = 1;
COMMIT;
</code></pre></div><h1>49. 说说InnoDB里的行锁实现?</h1>
<ul>
<li>
<p>RecordLock记录锁：记录锁就是直接锁定某行记录。当使用唯一性的索引(包括唯一索引和聚簇索引)进行等值查询且精准匹配到一条记录时，此时就会直接将这条记录锁定。例如select * from t where id = 6 for update;就会将id=6的记录锁定</p>
</li>
<li>
<p>GapLock间隙锁：间隙指的是两个记录之间逻辑上尚未填入数据的部分,是一个左开右开空间。间隙锁就是锁定某些间隙区间的。当使用等值查询或者范围查询，并且没有命中任何一个record，此时就会将对应的间隙区间锁定。例如select * from t where id = 3 for update;或者select * from t where id&gt;1 and id&lt;6 for update;就会将(1,6)区间锁定。</p>
</li>
<li>
<p>Next-keyLock临键锁：间隙加上它右边的记录组成的左开右闭区间。比如上述的(1,6]、(6,8]等。临键锁就是记录锁(RecordLocks)和间隙锁(GapLocks)的结合，即除了锁住记录本身，还要再锁住索引之间的间隙。当我们使用范围查询，并且命中了部分record记录，此时锁住的就是临键区间。注意，临键锁锁住的区间会包含最后一个record的右边的临键区间。例如select*fromtwhereid&gt;5andid&lt;=7forupdate;会锁住(4,7]、(7,+∞)。mysql默认行锁类型就是临键锁(Next-KeyLocks)。当使用唯一性索引，等值查询匹配到一条记录的时候，临键锁(Next-KeyLocks)会退化成记录锁；没有匹配到任何记录的时候，退化成间隙锁。</p>
</li>
<li>
<p>间隙锁(GapLocks)和临键锁(Next-KeyLocks)都是用来解决幻读问题的，在已提交读（READCOMMITTED）隔离级别下，间隙锁(GapLocks)和临键锁(Next-KeyLocks)都会失效！</p>
</li>
<li>
<p>Insert Intention Lock插入意向锁</p>
</li>
<li>
<p>一个事务在插入一条记录时需要判断一下插入位置是不是被别的事务加了意向锁，如果有的话，插入操作需要等待，直到拥有gap锁的那个事务提交。但是事务在等待的时候也需要在内存中生成一个锁结构，表明有事务想在某个间隙中插入新记录，但是现在在等待。这种类型的锁命名为Insert Intention Locks，也就是插入意向锁。</p>
</li>
<li>
<p>假如我们有个T1事务，给(1,6)区间加上了意向锁，现在有个T2事务，要插入一个数据，id为4，它会获取一个（1,6）区间的插入意向锁，又有有个T3事务，想要插入一个数据，id为3，它也会获取一个（1,6）区间的插入意向锁，但是，这两个插入意向锁锁不会互斥。</p>
</li>
</ul>
<h1>50. 意向锁是什么知道吗？</h1>
<ul>
<li>意向锁是一个表级锁，不要和插入意向锁搞混。</li>
<li>意向锁的出现是为了支持InnoDB的多粒度锁，它解决的是表锁和行锁共存的问题。</li>
<li>当给一个表加表锁的时候，需要根据表中有没有数据行被锁定，以确定是否能加成功。</li>
<li>假如没有意向锁，那么遍历表中所有数据行来判断有没有行锁；</li>
<li>有了意向锁这个表级锁之后，则我们直接判断一次就知道表中是否有数据行被锁定了。</li>
<li>有了意向锁之后，要执行的事务A在申请行锁（写锁）之前，数据库会自动先给事务A申请表的意向排他锁。当事务B去申请表的互斥锁时就会失败，因为表上有意向排他锁之后事务B申请表的互斥锁时会被阻塞。</li>
</ul>
<h1>51. MySQL的乐观锁和悲观锁了解吗？</h1>
<ul>
<li>悲观锁（PessimisticConcurrencyControl）：认为被它保护的数据是极其不安全的，每时每刻都有可能被改动，一个事务拿到悲观锁后，其他任何事务都不能对该数据进行修改，只能等待锁被释放才可以执行。行锁，表锁，读锁，写锁均为悲观锁。</li>
<li>乐观锁（OptimisticConcurrencyControl）认为数据的变动不会太频繁。通常是通过在表中增加一个版本(version)或时间戳(timestamp)来实现，其中，版本最为常用。</li>
<li>事务在从数据库中取数据时，会将该数据的版本也取出来(v1)，当事务对数据变动完毕想要将其更新到表中时，会将之前取出的版本v1与数据中最新的版本v2相对比，如果v1=v2，那么说明在数据变动期间，没有其他事务对数据进行修改，此时，就允许事务对表中的数据进行修改，并且修改时version会加1，以此来表明数据已被变动。如果，v1不等于v2，那么说明数据变动期间，数据被其他事务改动了，此时不允许数据更新到表中，一般的处理办法是通知用户让其重新操作。不同于悲观锁，乐观锁通常是由开发者实现的。</li>
</ul>
<h1>53. MySQL事务特性？</h1>
<ul>
<li>原子性：事务的所有操作要么全部提交成功，要么全部失败回滚，对于一个事务中的操作不能只执行其中一部分。</li>
<li>一致性：一个事务中，事务前后数据的完整性必须保持一致。一致性确保事务从一个一致的状态转换到另一个一致的状态。比如在银行转账事务中，无论发生什么，转账前后两个账户的总金额应保持不变。假如A账户（100块）给B账户（10块）转了10块钱，不管成功与否，A和B的总金额都是110块。</li>
<li>隔离性：多个并发事务之间需要相互隔离，即一个事务的执行不能被其他事务干扰。主要是为了解决事务并发执行时可能出现的问题，如脏读、不可重复读、幻读等。数据库系统通过事务隔离级别（如读未提交、读已提交、可重复读、串行化）来实现事务的隔离性。</li>
<li>持久性：事务一旦提交，它对数据库所做的更改就是永久性的，即使发生系统崩溃，修改的数据也不会丢失</li>
</ul>
<h1>54. ACID怎么保证？</h1>
<ul>
<li>
<p>原子性（Atomicity），undolog记录了事务发生之前的数据，如果事务失败，InnoDB会根据undolog回滚数据。当事务开始修改数据时，InnoDB首先会在undolog中记录旧值（即修改前的值）。如果事务顺利进行并最终提交，undolog会在某个时间点被清除。如果事务中的某个操作失败或者事务被明确地回滚，InnoDB会使用undolog中的信息来撤销所有更改，确保数据的原子性</p>
</li>
<li>
<p>一致性（Consistency），只要保证原子性、隔离性、持久性，自然也就保证了数据的一致性。还有业务代码</p>
</li>
<li>
<p>隔离性(Isolation)，MySQL使用多种隔离级别来控制事务如何与其他并发事务隔离。InnoDB存储引擎使用MVCC(多版本并发控制)机制来处理并发事务，确保每个事务都有自己的数据版本，每次更新记录时，都会生成记录的一个新版本，而不是覆盖老版本。每个版本都会有两个额外的属性：一个表示版本的创建时间（或事务ID），另一个表示版本的过期时间（或下一个版本的事务ID）。当事务尝试读取记录时，它会看到该事务开始时有效的那个版本。不同的事务会看到不同版本的数据行，这取决于事务的开始时间和它的隔离级别。对于如"读未提交"（READUNCOMMITTED）这样的较低隔离级别，事务可能会看到其他未提交事务所做的更改。但在更高的隔离级别，如"可重复读"（REPEATABLEREAD）或"串行化"（SERIALIZABLE），事务不会看到其他事务所做的更改，直到它们被提交。</p>
</li>
<li>
<p>持久性(Durability)，存储引擎（如InnoDB）通过写入磁盘来确保。即使在系统崩溃之后，已提交事务的更改也不会丢失</p>
</li>
<li>
<p>InnoDB使用“redolog”来记录数据的更改，在系统崩溃后，redolog可用于恢复数据。保证数据永不丢失</p>
</li>
<li>
<p>redolog是一种物理日志，记录了对数据页的物理更改。当事务进行写操作时，InnoDB首先会写入redolog，并不会立即修改数据文件。这种写入方式被称为“write-aheadlogging”（先写日志）。</p>
</li>
<li>
<p>当redolog填满或在某些其他情况下，InnoDB会异步将这些更改刷新到数据文件中。</p>
</li>
<li>
<p>系统崩溃时，由于数据可能还没有被真正写入数据文件，但已经在redolog中，因此系统可以在启动时使用这些日志来重新执行或“重做”这些更改，确保数据的持久性。</p>
</li>
<li>
<p>即使数据库在事务提交后立即崩溃，由于事务的更改已经记录在redolog中，这些更改在数据库恢复时仍然是安全的。</p>
</li>
</ul>
<h1>55. 事务的隔离级别？默认隔离级别是什么？</h1>
<ul>
<li>读未提交（ReadUncommitted）读取尚未提交的数据 ：哪个问题都不能解决</li>
<li>读已提交（ReadCommitted）读取已经提交的数据 ：可解决脏读（oracle默认）</li>
<li>可重复读（RepeatableRead）可重复读：指一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的.除非是自己修改的数据。可解决脏读和不可重复读，（mysql默认）</li>
<li>串行化（Serializable）对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。可解决 脏读 不可重复读 和 幻读</li>
<li>性能read uncommitted&gt;read committed&gt;repeatable read&gt;serialazable</li>
<li>安全性read uncommitted&lt;read committed&lt;repeatable read&lt;serialazable</li>
</ul>
<h1>56. 什么是幻读，脏读，不可重复读呢？</h1>
<ul>
<li>脏读（dirty read） : 一个事务读取到了另一个事务尚未提交的数据</li>
<li>不可重复读（non-repeatable read）: 一个事务读到了另一个事务已经提交的update数据 两次读取的数据的内容不一致</li>
<li>幻读/虚读（phantom read） : 一个事务读到了另一个事务已经提交的insert、delete数据 两次读取的数据的数量不一致</li>
</ul>
<h1>57. 事务的各个隔离级别都是如何实现的？</h1>
<ul>
<li>读未提交
<ul>
<li>读不加锁。不阻塞其他事务的读和写</li>
<li>事务写阻塞其他事务写，但不阻塞其他事务读；</li>
</ul>
</li>
<li>读取已提交&amp;可重复读
<ul>
<li>利用了ReadView和MVCC，也就是每个事务只能读取它能看到的版本（ReadView）。</li>
<li>READCOMMITTED：每次读取数据前都生成一个ReadView</li>
<li>REPEATABLEREAD：在第一次读取数据时生成一个ReadView</li>
</ul>
</li>
<li>串行化：对于同一行事务，写会加写锁，读会加读锁。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。</li>
</ul>
<h1>58. MVCC实现原理？</h1>
<ul>
<li>MVCC(MultiVersionConcurrencyControl)，多版本并发控制，主要用来解决数据库并发问题。MVCC是通过版本链和 ReadView 机制来实现的</li>
<li>版本链：对于InnoDB存储引擎，每一行记录都有两个隐藏列DB_TRX_ID、DB_ROLL_PTR
<ul>
<li>DB_TRX_ID，保存创建这个版本的事务 ID。</li>
<li>DB_ROLL_PTR，指向 undo 日志记录的指针，这个记录包含了该行的前一个版本的信息。通过这个指针，可以访问到该行数据的历史版本。</li>
<li>每次变动都会先把undo日志记录下来，并用DB_ROLL_PTR指向undo日志地址。因此可以认为，对该条记录的修改日志串联起来就形成了一个版本链，版本链的头节点就是当前记录最新的值。</li>
</ul>
</li>
<li>ReadView：对于ReadCommitted和RepeatableRead隔离级别来说，都需要读取已经提交的事务所修改的记录，也就是说如果版本链中某个版本的修改没有提交，那么该版本的记录时不能被读取的。所以需要确定在ReadCommitted和RepeatableRead隔离级别下，版本链中哪个版本是能被当前事务读取的。于是就引入了ReadView这个概念来解决这个问题。</li>
<li>ReadView就是事务执行快照读时，产生的读视图，相当于某时刻表记录的一个快照，通过这个快照，我们可以获取：
<ul>
<li>m_ids：表示在生成ReadView时当前系统中活跃的读写事务的事务id列表。</li>
<li>min_trx_id：表示在生成ReadView时当前系统中活跃的读写事务中最小的事务id，也就是m_ids中的最小值。</li>
<li>max_trx_id：表示生成ReadView时系统中应该分配给下一个事务的id值。</li>
<li>creator_trx_id：表示生成该ReadView的事务的事务id</li>
</ul>
</li>
<li>有了这个ReadView，这样在访问某条记录时，只需要按照下边的步骤判断记录的某个版本是否可见：
<ul>
<li>如果被访问版本的DB_TRX_ID属性值与ReadView中的creator_trx_id值相同，意味着当前事务在访问它自己修改过的记录，所以该版本可以被当前事务访问。</li>
<li>如果被访问版本的DB_TRX_ID属性值小于ReadView中的min_trx_id值，表明生成该版本的事务在当前事务生成ReadView前已经提交，所以该版本可以被当前事务访问。</li>
<li>如果被访问版本的DB_TRX_ID属性值大于ReadView中的max_trx_id值，表明生成该版本的事务在当前事务生成ReadView后才开启，所以该版本不可以被当前事务访问。</li>
<li>如果被访问版本的DB_TRX_ID属性值在ReadView的min_trx_id和max_trx_id之间，那就需要判断一下trx_id属性值是不是在m_ids列表中，如果在，说明创建ReadView时生成该版本的事务还是活跃的，该版本不可以被访问；如果不在，说明创建ReadView时生成该版本的事务已经被提交，该版本可以被访问。</li>
<li>如果某个版本的数据对当前事务不可见的话，那就顺着版本链找到下一个版本的数据，继续按照上边的步骤判断可见性，依此类推，直到版本链中的最后一个版本。如果最后一个版本也不可见的话，那么就意味着该条记录对该事务完全不可见，查询结果就不包含该记录。</li>
</ul>
</li>
<li>READCOMMITTED是每次读取数据前都生成一个ReadView，这样就能保证自己每次都能读到其它事务提交的数据；</li>
<li>REPEATABLEREAD是在第一次读取数据时生成一个ReadView，这样就能保证后续读取的结果完全一致。</li>
</ul>
<h1>59. 数据库读写分离了解吗？</h1>
<p>读写分离的基本原理是将数据库读写操作分散到不同的节点上。读写分离的基本实现是:</p>
<ul>
<li>数据库服务器搭建主从集群，一主一从、一主多从都可以。</li>
<li>数据库主机负责写操作，从机只负责读操作。</li>
<li>数据库主机通过复制将数据同步到从机，每台数据库服务器都存储了所有的业务数据。</li>
</ul>
<h1>60. 读写分离的分配怎么实现呢？</h1>
<ul>
<li>程序代码封装：在代码中抽象一个数据访问层（所以有的文章也称这种方式为"中间层封装"），实现读写操作分离和数据库服务器连接的管理。例如，基于Hibernate进行简单封装，就可以实现读写分离：淘宝的 TDDL （Taobao Distributed Data Layer</li>
<li>中间件封装：独立一套系统出来，实现读写操作分离和数据库服务器连接的管理。中间件对业务服务器提供SQL兼容的协议，业务服务器无须自己进行读写分离。对于业务服务器来说，访问中间件和访问数据库没有区别，事实上在业务服务器看来，中间件就是一个数据库服务器。</li>
</ul>
<h1>61. 主从复制原理了解吗？</h1>
<ul>
<li>MySQL 的主从复制（Master-Slave Replication）是一种数据同步机制，用于将数据从一个主数据库（master）复制到一个或多个从数据库（slave）。用于数据备份、灾难恢复和数据分析等场景。</li>
<li>在主服务器上，所有修改数据的语句（如 INSERT、UPDATE、DELETE）会被记录到binlog日志中。</li>
<li>主服务器上的一个线程（二进制日志转储线程）负责读取binlog日志的内容并发送给从服务器。</li>
<li>从服务器接收到二进制日志数据后，会将这些数据写入自己的中继日志（Relay Log）。中继日志是从服务器上的一个本地存储</li>
<li>从服务器上有一个 SQL 线程会读取中继日志，并在本地数据库上执行，从而将更改应用到从数据库中，完成同步。<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/eb5eaa6b07dd6988b2e6e.png" alt="mysqlslave.jpg"></li>
</ul>
<h1>62. 主从同步延迟怎么处理？</h1>
<ul>
<li>
<p>主从同步延迟的原因:一个服务器开放Ｎ个链接给客户端来连接的，这样有会有大并发的更新操作,但是从服务器的里面读取binlog的线程仅有一个，当某个SQL在从服务器上执行的时间稍长或者由于某个SQL要进行锁表就会导致，主服务器的SQL大量积压，未被同步到从服务器里。这就导致了主从不一致，也就是主从延迟。</p>
</li>
<li>
<p>写操作后的读操作指定发给数据库主服务器.例如，注册账号完成后，登录时读取账号的读操作也发给数据库主服务器。这种方式和业务强绑定，对业务的侵入和影响较大，如果哪个新来的程序员不知道这样写代码，就会导致一个bug。</p>
</li>
<li>
<p>读从机失败后再读一次主机。即"二次读取"，二次读取和业务无绑定，只需要对底层数据库访问的API进行封装即可，实现代价较小，不足之处在于如果有很多二次读取，将大大增加主机的读操作压力。例如，黑客暴力破解账号，会导致大量的二次读取操作，主机可能顶不住读操作的压力从而崩溃。</p>
</li>
<li>
<p>关键业务读写操作全部指向主机，非关键业务采用读写分离。例如，对于一个用户管理系统来说，注册+登录的业务读写操作全部访问主机，用户的介绍、爰好、等级等业务，可以采用读写分离，因为即使用户改了自己的自我介绍，在查询时却看到了自我介绍还是旧的，业务影响与不能登录相比就小很多，还可以忍受。</p>
</li>
</ul>
<h1>63. 百万级别以上的数据如何删除？</h1>
<ul>
<li>由于索引需要额外的维护成本，因为索引文件是单独存在的文件,所以当我们对数据的增加,修改,删除,都会产生额外的对索引文件的操作,这些操作需要消耗额外的IO,会降低增/改/删的执行效率。在删除数据库百万级别数据的时候删除数据的速度和创建的索引数量是成正比的。</li>
<li>删除索引</li>
<li>删除其中无用数据</li>
<li>重新创建索引</li>
</ul>
<h1>64. 百万千万级大表如何添加字段？</h1>
<ul>
<li>通过中间表转换过去，创建一个临时的新表，把旧表的结构完全复制过去，添加字段，再把旧表数据复制过去，删除旧表，新表命名为旧表的名称，这种方式可能回丢掉一些数据。</li>
<li>用pt-online-schema-change是percona公司开发的一个工具，它可以在线修改表结构，它的原理也是通过中间表。</li>
<li>先在从库添加再进行主从切换：如果一张表数据量大且是热表（读写特别频繁），则可以考虑先在从库添加，再进行主从切换，切换后再将其他几个节点上添加字段。</li>
</ul>
<h1>66. mysql自增id用完怎么办?</h1>
<ul>
<li>表定义的自增值达到上限后，再申请时值保持不变。导致继续插入数据时报主键冲突的错误</li>
<li>无主键自增row_id 6字节(0到2^48-1)达到上限后会归0重新递增。如果出现相同的row_id则覆盖原有的数据。InnoDB维护了一个全局的dict_sys.row_id值，所有无主键的InnoDB表，每插入一行数据，都将当前的dict_sys.row_id值作为要插入数据的row_id，然后把dict_sys.row_id的值加1</li>
</ul>
]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/ffe5c6730d04f821f724c.png" type="image/png"/>
    </item>
    <item>
      <title>问题解决</title>
      <link>https://javaguide.cn/interview/problemsolve.html</link>
      <guid>https://javaguide.cn/interview/problemsolve.html</guid>
      <source url="https://javaguide.cn/rss.xml">问题解决</source>
      <description>问题排查 找出那个进程出问题，执行top列出系统各个进程的资源占用情况。 top.pngtop.png 找到CPU或者内存高的进程，执行top -Hp 【pid】列出对应进程里面的线程占用资源情况 tophp.pngtophp.png java进程CPU 100% 打印堆栈信息jstack [pid] | grep -A 10 [tid的十六进制 pr...</description>
      <category>面试</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<!--more-->
<h1>问题排查</h1>
<ul>
<li>找出那个进程出问题，执行top列出系统各个进程的资源占用情况。</li>
</ul>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/0dcfd52cf39085f7207e5.jpg" alt="top.png" tabindex="0"><figcaption>top.png</figcaption></figure>
<ul>
<li>找到CPU或者内存高的进程，执行top -Hp 【pid】列出对应进程里面的线程占用资源情况</li>
</ul>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/544496f7094b3e0bf4356.jpg" alt="tophp.png" tabindex="0"><figcaption>tophp.png</figcaption></figure>
<h2>java进程CPU 100%</h2>
<ul>
<li>打印堆栈信息jstack [pid] | grep -A 10 [tid的十六进制 printf "%x" 线程id]</li>
<li>导出该线程的堆栈信息（jstack pid）&gt; log.txt，线程栈分析可使用 VisualVM 插件 TDA。</li>
<li>重点关注：WAITING/BLOCKED</li>
<li>找到线程中waiting on <code>&lt;xx&gt;</code>或 blocked的都有哪些，根据锁的地址找到是哪个线程持有<code>&lt;xx&gt;</code>这把锁，里面有代码行数</li>
</ul>
<h2>mysql死锁？</h2>
<ul>
<li>使用JDK自带的一些性能监控工具进行排查，比如说jps、jstat、jinfo、jmap、jstack、jcmd等等。</li>
<li>使用jstack进程号查看当前Java进程的线程堆栈信息，看看是否有线程在等待锁资源<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/8c55500fa63a5b8c34e0f.png" alt="javadeadlockjps.png"></li>
</ul>
<p>排查死锁步骤：</p>
<ul>
<li>查看死锁日志show engine innodb status;LATESTDETECTED DEADLOCK记录最后的死锁信息，TRANSACTION是事务信息</li>
<li>找出死锁sql</li>
<li>分析sql加锁情况</li>
<li>模拟死锁案发</li>
<li>分析死锁日志</li>
<li>分析死锁结果</li>
</ul>
<h2>java进程内存Mem 100%</h2>
<ul>
<li>一般是因为创建了大量对象所导致，持续飚高说明垃圾回收跟不上对象创建的速度，或者内存泄露导致对象无法回收。</li>
<li>先观察垃圾回收的情况，看看是不是因为持久代或年老代满了，产生Full GC，导致CPU利用率和内存持续飙高
<ul>
<li>监控系统：大部分公司都会有，可全方位监控 JVM 的各项指标。</li>
<li>查看概况jstat -gcutil PID 1000 5监控gc，每1s 输出一次，一共 5 次。
<ul>
<li>S0、S1：Survivor空间0和1的使用率（以百分比表示）。</li>
<li>E：Eden区的使用率（百分比）。</li>
<li>O：老年代的使用率（百分比）。</li>
<li>M：Metaspace的使用率（百分比，Java 8及以后版本）。</li>
<li>CCS：压缩类空间的使用率（百分比，如果存在）。</li>
<li>YGC：Minor GC次数。</li>
<li>YGCT：Minor GC耗时（秒）。</li>
<li>FGC：Full GC次数。</li>
<li>FGCT：Full GC耗时（秒）。</li>
<li>GCT：GC总耗时（秒）。</li>
</ul>
</li>
</ul>
</li>
</ul>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/f2a965b44585b2777b677.jpg" alt="jstatgcutil.png" tabindex="0"><figcaption>jstatgcutil.png</figcaption></figure>
<ul>
<li>查询详细jstat -gc -h3 PID 250 10监控gc，每三行输出一次表头 ，每250ms 输出一次，一共 10 次。
<ul>
<li>S0C、S1C、S0U、S1U：Survivor空间0和1的容量（Capacity）和使用量（Usage）。</li>
<li>EC、EU：Eden区的容量和使用量KB。</li>
<li>OC、OU：老年代的容量和使用量。</li>
<li>MC、MU：Metaspace元数据区的容量和使用量（在Java 8及以后版本）。</li>
<li>CCSC、CCSU：压缩类空间的容量和使用量（如果存在）。</li>
<li>YGC、YGCT：Minor GC（新生代GC）的次数和总耗时。</li>
<li>FGC、FGCT：Full GC的次数和总耗时。</li>
<li>GCT：GC的总耗时（Minor GC和Full GC的总和）。</li>
</ul>
</li>
</ul>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/bc00ae1d99e53ed81ef0a.jpg" alt="jstatgc.png" tabindex="0"><figcaption>jstatgc.png</figcaption></figure>
<ul>
<li>jmap -histo PID | head -20 查看堆内存占用空间最大的前 20 个对象类型,可初步查看是哪个对象占用了内存。</li>
</ul>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/007d82138398ee26a1dd7.jpg" alt="jmaphisto.png" tabindex="0"><figcaption>jmaphisto.png</figcaption></figure>
<ul>
<li>如果每次 GC 次数频繁，而且每次回收的内存空间也正常，那说明是因为对象创建速度快导致内存一直占用很高；</li>
<li>如果每次回收的内存非常少，那么很可能是因为内存泄露导致内存一直无法被回收。</li>
<li>导出堆内存多次
<ul>
<li>(推荐)jmap ‐dump:format=b,file=/tmp/dump.hprof pid</li>
<li>开启HeapDumpOnOutOfMemoryError会stoptheworld(分布式) ‐Xms8m ‐Xmx8m ‐XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=./heapdump.hprof溢出时自动生成 java_pidxxxx.hprof</li>
</ul>
</li>
<li>离线分析
<ul>
<li>使用jhat工具：jhat ‐port 9999 /tmp/dump.dat ，访问<a href="http://ip:9999" target="_blank" rel="noopener noreferrer">http://ip:9999</a> 通过OQL查询</li>
<li>(推荐)下载jvisualvm工具，高版本不自带，需要配置本地etc/visualvm_jdkhome：菜单 &gt; 文件 &gt; 装入 dump 文件。，通过summary查询；或者远程连接别的jvm<br>
‐ Dcom.sun.management.jmxremote #允许使用JMX远程管理<br>
‐ Dcom.sun.management.jmxremote.port=9999 #JMX远程连接端口
<ul>
<li>Dcom.sun.management.jmxremote.authenticate=false #不进行身份认证，任何用</li>
<li>Dcom.sun.management.jmxremote.ssl=false #不使用ssl</li>
</ul>
</li>
<li>jprofiler商业软件,GCViewer 工具。</li>
<li>在线分析平台 GCEasy。</li>
<li>使用MAT工具(基于Eclipse免费)分析内存溢出，查看Leak Suspects</li>
</ul>
</li>
</ul>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/b2f191c4405c1d75c38d4.png" alt="matanalyze.png" tabindex="0"><figcaption>matanalyze.png</figcaption></figure>
<ul>
<li>
<p>问题解决</p>
<ul>
<li>频繁 minor gc 怎么办？通常情况下，由于新生代空间较小，Eden 区很快被填满，就会导致频繁Minor GC，可通过增大新生代空间-Xmn来降低 Minor GC频率</li>
<li>频繁 Full GC /内存泄漏问题怎么办？
<ul>
<li>程序导致 FGC原因
<ul>
<li>大对象：系统一次性加载了过多数据到内存中（比如 SQL 查询未做分页），导致大对象进入了老年代。</li>
<li>内存泄漏：频繁创建了大量对象，但是无法被回收（比如 IO 对象使用完后未调用 close 方法释放资源）</li>
<li>程序频繁生成一些长生命周期的对象，当这些对象的存活年龄超过分代年龄时便会进入老年代，</li>
<li>程序 BUG</li>
<li>代码中显式调用了 gc方法，包括自己的代码甚至框架中的代码。</li>
<li>JVM 参数设置问题：包括总内存大小、新生代和老年代的大小、Eden区和S区的大小、元空间大小、垃圾回收算法等等</li>
</ul>
</li>
<li>查看监控，了解出现问题的时间点以及当前 FGC 的频率（可对比正常情况看频率是否正常）</li>
<li>了解该时间点之前有没有程序上线、基础组件升级等情况。</li>
<li>再对步骤 1 中列出的可能原因做排除法，其中元空间被打满、内存泄漏、代码显式调用 gc 方法比较容易排查。</li>
<li>针对大对象或者长生命周期对象导致的 FGC，可通过 jmap -histo 命令并结合 dump 堆内存文件作进一步分析，需要先定位到可疑对象。</li>
<li>通过可疑对象定位到具体代码再次分析，这时候要结合 GC 原理和 JVM 参数设置，弄清楚可疑对象是否满足了进入到老年代的条件才能下结论。</li>
<li>了解 JVM 的参数设置，包括：堆空间各个区域的大小设置，新生代和老年代分别采用了哪些垃圾收集器，然后分析 JVM 参数设置是否合理。</li>
</ul>
</li>
</ul>
</li>
<li>
<p>查询有多少台机器连接到这个端口netstat -nat | grep 12200 –c</p>
</li>
<li>
<p>查看网络流量。cat /proc/net/dev</p>
</li>
<li>
<p>查看系统平均负载。cat /proc/loadavg</p>
</li>
<li>
<p>查看系统内存情况。cat /proc/meminfo</p>
</li>
<li>
<p>查看CPU的利用率。cat /proc/stat</p>
</li>
</ul>
<h2>1.3. mysqlCPU100%/内存100%</h2>
<ul>
<li>showprocesslist，查看session情况，确定是不是有消耗资源的sql在运行。</li>
<li>找出消耗高的sql，看看执行计划是否准确，索引是否缺失，数据量是否太大。</li>
<li>查看 MySQL 慢查询日志，看是否有慢 SQL 。</li>
<li>处理：
<ul>
<li>kill掉这些线程(同时观察cpu使用率是否下降)，</li>
<li>进行相应的调整(比如说加索引、改sql、改内存参数)</li>
<li>重新跑这些SQL。</li>
<li>优化或者添加索引</li>
</ul>
</li>
</ul>
<h1>2. 微服务高可用配置</h1>
<ul>
<li>nacos + MySQL 4C 8G 3节点 4000TPS</li>
<li>gateway 4C 8G 3节点 启用HTTPS+GZIP 1wQPS</li>
<li>zookeeper 4C 8G 3节点 4000TPS</li>
<li>alibaba Sentinel + nacos + MySQL 3节点</li>
<li>rabbitmq 3节点 镜像集群模式</li>
<li>Elasticsearch 3节点</li>
<li>mysql MGR 1主2从 3节点</li>
<li>skywalking + nacos 2节点</li>
<li>XXL-JOB 2节点</li>
<li>RocketMQ 1主2从</li>
</ul>
<p><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/94a93ae3261174a41f896.jpg" alt="nacos.png"><br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/caab71e44ec86eb81791c.jpg" alt="gateway.png"><br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/e9ad99261d364d09b1e32.jpg" alt="zookeeper.png"></p>
<h1>3. 项目难点</h1>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/4c4b49aab79ea76a06c7b.png" alt="jvmadjust.png" tabindex="0"><figcaption>jvmadjust.png</figcaption></figure>
<ul>
<li>案例：电商公司的运营后台系统，偶发性的引发 OOM 异常，堆内存溢出。
<ul>
<li>1）因为是偶发性的，所以第一次简单的认为就是堆内存不足导致，单方面的加大了堆内存从 4G 调整到 8G -Xms8g。</li>
<li>2）问题依然没有解决，只能从堆内存信息下手，通过开启了-XX:+HeapDumpOnOutOfMemoryError参数 获得堆内存的 dump 文件</li>
<li>3）用 JProfiler 对 堆 dump 文件进行分析，通过 JProfiler 查看到占用内存最大的对象是 String 对象，本来想跟踪着 String 对象找到其引用的地方，但 dump 文件太大，跟踪进去的时候总是卡死，而 String 对象占用比较多也比较正常，最开始也没有认定就是这里的问题，于是就从线程信息里面找突破点。</li>
<li>4）通过线程进行分析，先找到了几个正在运行的业务线程，然后逐一跟进业务线程看了下代码，有个方法引起了我的注意，导出订单信息</li>
<li>5）因为订单信息导出这个方法可能会有几万的数据量，首先要从数据库里面查询出来订单信息，然后把订单信息生成 excel，这个过程会产生大量的 String 对象。</li>
<li>6）为了验证自己的猜想，于是准备登录后台去测试下，结果在测试的过程中发现导出订单的按钮前端居然没有做点击后按钮置灰交互事件，后端也没有做防止重复提交，因为导出订单数据本来就非常慢，使用的人员可能发现点击后很久后页面都没反应，然后就一直点，结果就大量的请求进入到后台，堆内存产生了大量的订单对象和 EXCEL 对象，而且方法执行非常慢，导致这一段时间内这些对象都无法被回收，所以最终导致内存溢出。</li>
<li>7）知道了问题就容易解决了，最终没有调整任何 JVM 参数，只是做了两个处理：
<ul>
<li>在前端的导出订单按钮上加上了置灰状态，等后端响应之后按钮才可以进行点击</li>
<li>后端代码加分布式锁，做防重处理</li>
<li>这样双管齐下，保证导出的请求不会一直打到服务端，问题解决！</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1>4. sql优化</h1>
<h2>4.1. 开启慢查询日志</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>my.cnf配置或者--log-slow-queries[=file_name]选项启动
slow_query_log = ON
slow_query_log_file = /usr/local/mysql/data/slowselect.log
long_query_time = 1 #超过1秒则为慢查询

# 检查慢查日志是否开启/阈值（默认10s）/位置
mysql&gt; show variables like 'slow_query_log'
mysql&gt; show VARIABLES like 'long_query_time';
mysql&gt; show variables like 'slow_query_log_file';


# 检查慢查日志开启/位置/阈值
mysql&gt; set slow_query_log='ON';
mysql&gt; set long_query_time = 2;
mysql&gt; set slow_query_log_file=' /usr/share/mysql/sql_log/mysql-slow.log' 

# 查看慢查询日志。
shell&gt; more localhost-slow.log

# 慢查询日志存储格式
  # Time: 180526  1:06:54 查询的执行时间
  # User@Host: root[root] @ localhost []  Id:4  执行sql的主机信息
  # Query_time：0.000401 SQL的查询时间
  # Lock_time：0.000105 锁定时间
  # Rows_sent：2 所发送的行数
  # Rows_examined：2 扫描了多少行。执行器每次调用引擎获取数据行都会累加。行数越少，访问磁盘数据的次数越少，消耗的CPU资源越少。但引擎扫描行数跟rows_examined并不是完全相同的。
  # SET timestamp=1527268014; SQL执行时间
  # select * from staff; SQL的执行内容
</code></pre></div><h2>4.2. 慢SQL如何定位</h2>
<ul>
<li>通过工具比如mysqldumpslow去分析对应的慢查询日志。</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>shell&gt;mysqldumpslow --help
Usage: mysqldumpslow [ OPTS... ] [ LOGS... ]

Parse and summarize the MySQL slow query log. Options are

  --verbose    verbose
  --debug      debug
  --help       write this text to standard output

  -v           verbose
  -d           debug
  -s ORDER     what to sort by (al, at, ar, c, l, r, t), 'at' is default
                al: average lock time
                ar: average rows sent
                at: average query time
                 c: count
                 l: lock time
                 r: rows sent
                 t: query time
  -r           reverse the sort order (largest last instead of first)
  -t NUM       just show the top n queries
  -a           don't abstract all numbers to N and strings to 'S'
  -n NUM       abstract numbers with at least n digits within names
  -g PATTERN   grep: only consider stmts that include this string
  -h HOSTNAME  hostname of db server for *-slow.log filename (can be wildcard),
               default is '*', i.e. match all
  -i NAME      name of server instance (if using mysql.server startup script)
  -l           don't subtract lock time from total time

锁定时间最长的前10条
shell&gt;mysqldumpslow -s l -t 10 /var/lib/mysql/mysql-slow.log

返回记录集最多的10个SQL
shell&gt;mysqldumpslow -s r -t 10 mysql_slow.log

访问次数最多的10个SQL
shell&gt;mysqldumpslow -s c -t 10 mysql_slow.log

按照时间排序的前10条里面含有左连接的查询语句
shell&gt;mysqldumpslow -s t -t 10 -g “left join” mysql_slow.log
</code></pre></div><ul>
<li>使用show processlist命令查看当前MySQL在进行的线程，state包括线程的状态、是否锁表、SQL的执行情况</li>
<li>服务监控：可以在业务的基建中加入对慢SQL的监控，常见的方案有字节码插桩、连接池扩展、ORM框架过程，对服务运行中的慢SQL进行监控和告警</li>
<li>使用 EXPLAIN 命令查看 MySQL 是如何执行 SQL 语句</li>
</ul>
<h2>4.3. 怎么看explain执行计划？</h2>
<p>查看执行计划explain xxx</p>
<ul>
<li>
<p>id：查询的序列号,表示查询中执行Select子句或操作表的顺序。id值相同,执行顺序由上而下。id值越大越先被执行.id列为null的就表是这是一个结果集，不需要使用它来进行查询。</p>
</li>
<li>
<p>select_type，查询的类型</p>
<ul>
<li>SIMPLE : 查询中不包含子查询或者UNION或者表连接</li>
<li>PRIMARY: 查询中若包含复杂的子查询或者union,最外层的查询则标记为PRIMARY</li>
<li>SUBQUERY : 在SELECT或者WHERE列表中包含子查询</li>
<li>DERIVED : 在from列表中包含子查询被标记为DRIVED衍生,MYSQL会递归执行这些子查询,把结果放到临时表中</li>
<li>UNION: UNION 中的第二个或者后面的查询语句, 若union包含在from子句的子查询中,外层 select被标记为:derived</li>
<li>dependent union：与union一样，出现在union 或union all语句中，但是这个查询要受到外部查询的影响</li>
<li>dependent subquery：与dependent union类似，表示这个subquery的查询要受到外部表查询的影响</li>
<li>union result：包含union的结果集，在union和union all语句中,因为它不需要参与查询，所以id字段为null</li>
<li>UNION RESULT: 从union表获取结果的select</li>
</ul>
</li>
<li>
<p>table：正在访问的表。null表示不涉及对数据表的操作，<code>&lt;derived N&gt;</code>表示临时表，结果来自于查询id为N的结果集。如果是&lt;union M,N&gt;，表示结果来自于union查询id为M,N的结果集。</p>
</li>
<li>
<p>type列：表示关联类型或访问类型，速度system&gt;const&gt;eq_ref&gt;ref&gt;fulltext&gt;ref_or_null&gt;index_merge&gt;unique_subquery&gt;index_subquery&gt;range&gt;index&gt;ALL最好能优化到range级别或则ref级别</p>
<ul>
<li>system：表仅有一行记录(系统表)，往往不需要进行磁盘IO，速度非常快</li>
<li>const：表示查询时命中primarykey主键或者unique唯一索引，或者被连接的部分是一个常量(const)值。这类扫描效率极高，返回数据量少，速度快</li>
<li>eq_ref：多表连接时命中主键primarykey或者uniquekey索引</li>
<li>ref : 多表连接中使用普通索引</li>
<li>ref_or_null：与ref方法类似，只是增加了null值的比较</li>
<li>fulltext：全文索引检索，若全文索引和普通索引同时存在时优先选择使用全文索引</li>
<li>index_merge：使用了索引合并优化方法，查询使用了两个以上的索引。最后取交集或者并集，常见and ，or的条件使用了不同的索引，官方排序这个在ref_or_null之后，但是实际上由于要读取所个索引，性能可能大部分时间都不如range</li>
<li>unique_subquery：用于where中的in形式子查询，子查询返回不重复值唯一值</li>
<li>index_subquery：用于where中的in形式子查询，子查询可能返回重复值</li>
<li>range：使用索引选择行，仅检索给定范围内的行。简单点说就是针对一个有索引的字段，给定范围检索数据。在where语句中使用bettween...and、&lt;、&gt;、&lt;=、in等条件查询type都是range。</li>
<li>index：扫描整个索引表, 遍历索引索引文件,从索引中读取数据</li>
<li>ALL:全表扫描</li>
</ul>
</li>
<li>
<p>possible_keys：可能使用哪些索引来查找，</p>
</li>
<li>
<p>key：真正使用的索引,如果为null,则表示没有使用索引，</p>
</li>
<li>
<p>key_len：使用的索引的最大可能长度,在不损失精确度的情况下,长度越短越好</p>
</li>
<li>
<p>ref：显示索引的哪一列被使用了,const使用的常数等值查询，，如果是连接查询，被驱动表的执行计划这里会显示驱动表的关联字段，如果是条件使用了表达式或者函数，或者条件列发生了内部隐式转换，这里可能显示为func,NULL，表示没有使用索引</p>
</li>
<li>
<p>rows：估算找出所需记录要读取的行数 (有多少行记录被优化器读取) ,越少越好</p>
</li>
<li>
<p>Extra：额外信息</p>
<ul>
<li>distinct：在select部分使用了distinc关键字</li>
<li>no tables used：不带from字句的查询或者From dual查询、使用not in()形式子查询或not exists运算符的连接查询，这种叫做反连接。即，一般连接查询是先查询内表，再查询外表，反连接就是先查询外表，再查询内表</li>
<li>Using filesort:说明mysql会对数据使用一个外部的索引排序,而不是按照表内的索引顺序进行读取,Mysql中无法利用索引完成的排序操作称为文件排序</li>
<li>Using temporary:使用了临时表保存中间结果,常见于order by 和分 组查询group by</li>
<li>Using index：使用了覆盖索引，以避免回表。如果同时出现了using where, 表明索引被用来执行索引键值的查找。没有则表明索引用来读取数据而非执行查找动作</li>
<li>using where : 使用了where条件过滤。没有使用索引覆盖，需要回表</li>
<li>using join buffer : 表明使用了连接缓存, join次数太多了可能会出现</li>
<li>impossible where : where子句中的值总是false,不能用来获取任何数据</li>
<li>using intersect：表示使用and的各个索引的条件时，该信息表示是从处理结果获取交集</li>
<li>using union：表示使用or连接各个使用索引的条件时，该信息表示从处理结果获取并集</li>
<li>using sort_union和using sort_intersection：与前面两个对应的类似，只是他们是出现在用and和or查询信息量大时，先查询主键，然后进行排序合并后，才能读取记录并返回。</li>
<li>firstmatch(tb_name)：常见于where字句含有in()类型的子查询。如果内表的数据量比较大，就可能出现这个</li>
<li>loosescan(m..n)：5.6.x之后引入的优化子查询的新特性之一，在in()类型的子查询中，子查询返回的可能有重复记录时，就可能出现这个</li>
</ul>
</li>
<li>
<p>filtered：表示存储引擎返回的数据在server层过滤后，剩下多少满足查询的记录数量的比例，注意是百分比，不是具体记录数</p>
</li>
</ul>
<h2>4.4. 有哪些方式优化慢SQL？</h2>
<ul>
<li>减少请求列(select *)、请求行(limit,where)</li>
<li>删除数据时，切分删除：如果一个大的语句一次性完成的话，可能需要一次性锁住很多数据、占满整个事务日志，耗尽系统资源、阻塞其他查询</li>
<li>where高于having，能写在where限定的条件就不要去having限定了</li>
<li>分页优化(数据量大优化)</li>
<li>延迟关联：先通过where条件提取出主键，在将该表与原数据表关联，</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>select a.* from table a, 
 (select id from table where type = 2 and level = 9 order by id asc limit 190289,10 ) b
 where a.id = b.id
</code></pre></div><ul>
<li>书签方式:记住上一次查询返回的最后一行的某个值，然后下一次查询从这个值开始，避免了扫描大量不需要的行。</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>SELECT id, name
FROM users
WHERE id &gt; last_max_id  -- 假设last_max_id是上一页最后一行的ID
ORDER BY id
LIMIT 20;
</code></pre></div><ul>
<li>索引优化:合理地设计和避免索引失效场景
<ul>
<li>临时添加/修改/删除索引，
<ul>
<li>假设一主一备，主库A、备库B，
<ul>
<li>备库关闭binlog：set sql_log_bin=off，然后执行alter table 语句加上索引</li>
<li>主备切换；</li>
<li>在原来主库关闭binlog：set sql_log_bin=off，然后执行alter table 语句加上索引</li>
</ul>
</li>
<li>gh-ost方案</li>
</ul>
</li>
<li>修改SQL：MySQL 5.7提供了query_rewrite把输入的一种语句改写成另外一种模式。<br>
mysql&gt; insert into query_rewrite.rewrite_rules(pattern, replacement, pattern_database) values ("select * from t where id + 1 = ?", "select * from t where id = ? - 1", "db1");<br>
mysql&gt; call query_rewrite.flush_rewrite_rules();</li>
<li>强制索引 select * from t force index(a) where a=xxx;</li>
</ul>
</li>
<li>JOIN优化
<ul>
<li>优化子查询：尽量使用Join语句来替代子查询，因为子查询是嵌套查询，而嵌套查询会新创建一张临时表，而临时表的创建与销毁会占用一定的系统资源以及花费一定的时间，同时对于返回结果集比较大的子查询，其对查询性能的影响更大</li>
<li>小表驱动大表：关联查询的时候要拿小表去驱动大表，因为关联的时候，MySQL内部会遍历驱动表，再去连接被驱动表。</li>
<li>子查询尽量不要放在被驱动表，有可能使用不到索引</li>
<li>若必须用到子查询，可将子查询设置为驱动表，因为驱动表的type 肯定是 all，而子查询返回的结果表没有索引，必定也是all</li>
<li>确定on或者using子句的列上有索引</li>
<li>适当增加冗余字段；可以减少大量的连表查询，空间换时间的优化策略.因为多张表的连表查询性能很低，</li>
<li>避免使用JOIN关联太多的表：《阿里巴巴Java开发手册》规定不要join超过三张表，第一join太多降低查询的速度，第二join的buffer会占用更多的内存。如果不可避免要join多张表，可以考虑使用数据异构的方式异构到ES中查询。</li>
</ul>
</li>
<li>排序优化</li>
<li>利用索引扫描做排序：MySQL有两种方式生成有序结果：其一是对结果集进行排序的操作，其二是按照索引顺序扫描得出的结果自然是有序的。但是如果索引不能覆盖查询所需列，就不得不每扫描一条记录回表查询一次，这个读操作是随机IO，通常会比顺序全表扫描还慢。因此，在设计索引时，尽可能使用同一个索引既满足排序又用于查找行。只有当索引的列顺序和ORDERBY子句的顺序完全一致，并且所有列的排序方向都一样时，才能够使用索引来对结果做排序</li>
<li>UNION优化
<ul>
<li>条件下推：MySQL处理union的策略是先创建临时表，然后将各个查询结果填充到临时表中最后再来做查询，很多优化策略在union查询中都会失效，因为它无法利用索引：最好手工将where、limit等子句下推到union的各个子查询中，以便优化器可以充分利用这些条件进行优化</li>
<li>除非确实需要服务器去重，一定要使用unionall，如果不加all关键字，MySQL会给临时表加上distinct选项，这会导致对整个临时表做唯一性检查，代价很高。</li>
</ul>
</li>
</ul>
<h2>4.5. sql已经走索引了还是很慢，为什么，怎么优化？√</h2>
<ul>
<li>命中索引还得结合explain中的rows扫描行数</li>
<li>扫描行数过多可能是走了全表扫描，如果删除数据造成空洞太多可以定期用ANALYZE分析表减少空洞</li>
</ul>
<h2>4.6. 为什么使用索引会加快查询？</h2>
<ul>
<li>
<p>减少磁盘I/O操作：数据库通常存储在磁盘上，而磁盘I/O操作是数据库操作中耗时较多的部分。没有索引时，数据库为了找到匹配的行，需要进行全表扫描，即读取表中的每一行数据，这会导致大量的磁盘I/O操作。而使用索引后，数据库可以直接定位到索引指示的数据位置，从而减少了磁盘I/O操作的次数。</p>
</li>
<li>
<p>优化查询时间复杂度：全表扫描的时间复杂度是O(n)，意味着随着数据量的增加，查询时间呈线性增长。而使用索引后，数据库可以利用索引的数据结构（如MySQL的InnoDB存储引擎默认的B+树）来快速定位数据，B+树的查询效率非常高，时间复杂度为O(logN)，因此可以显著加快查询速度。</p>
</li>
<li>
<p>索引文件体积小：索引文件相较于数据库文件，其体积要小得多。因此，查询索引文件所需的磁盘I/O操作也会相应减少。当在索引中找到匹配项后，再映射到实际的数据库记录，整体查询效率会显著提高。</p>
</li>
</ul>
<h2>4.7. 如何设计索引？</h2>
<ul>
<li>选择合适的列作为索引：经常作为连接（JOIN）列、查询条件（WHERE子句）、分组条件（GROUPBY子句）、排序条件（ORDERBY子句）</li>
<li>避免过多的索引（索引的功能相同）</li>
<li>利用覆盖索引:InnoDB使用非主键索引查询数据时会回表，但是如果索引的叶节点中已经包含要查询的字段，那它没有必要再回表查询了，这就叫覆盖索引</li>
<li>适当使用前缀索引，降低索引的空间占用，提高索引查询效率。但无法做order by和group by操作，也无法作为覆盖索引</li>
<li>正确使用联合索引，注意最左匹配原则。索引的顺序应根据列在查询中的使用频率和重要性来安排。</li>
</ul>
<h2>4.9. 索引不适合哪些场景呢？</h2>
<ul>
<li>数据量比较少的表不适合加索引</li>
<li>更新比较频繁的字段</li>
<li>区分度低的字段不适合加索引（如性别）</li>
<li>不建议用无序的值(身份证、UUID)作为索引，当主键具有不确定性，会造成叶子节点频繁分裂，出现磁盘存储的碎片化</li>
</ul>
<h2>4.8. 索引哪些情况下会失效呢？√</h2>
<ul>
<li>
<p>在索引列上使用内置函数或者表达式</p>
</li>
<li>
<p>对索引列运算（如，+、-、*、/），</p>
</li>
<li>
<p>索引字段上使用（!=或者&lt;&gt;，notin）时，可能会导致索引失效。!=、&lt;&gt;在主键字段和唯一索引字段中会走索引，在普通索引的字段上不会走索引。解决方法：通过把不等于操作符改成or，可以使用索引，避免全表扫描</p>
</li>
<li>
<p>like通配符(%xxx或者_xx)。</p>
</li>
<li>
<p>查询条件包含or，可能会导致索引失效 or中有一个不用索引就会索引失效,尽量使用union all代替</p>
</li>
<li>
<p>MySQL优化器估计使用全表扫描要比使用索引快，则不使用索引。</p>
</li>
<li>
<p>联合索引不满足最左前缀原则时，索引会失效。</p>
</li>
<li>
<p>如果字段类型是字符串，where时一定要用引号括起来，否则会因为隐式类型转换，索引失效。相当于函数运算。查看数据类型转换系统默认规则：select “10” &gt; 9 =&gt;1表示“将字符串转成数字”，0表示“将数字转成字符串”</p>
</li>
<li>
<p>索引字段上使用isnull，isnotnull，可能导致索引失效。</p>
</li>
<li>
<p>左连接查询或者右连接查询关联的字段编码格式不一样，可能导致索引失效(Concat\CAST\CONVERT)。</p>
</li>
<li>
<p>对于连续的数值，能用 between 就不要用 in 了。如果是子查询，可以用exists代替in，如果是子查询，可以用exists代替in</p>
</li>
<li>
<p>order by索引失效：where子句出现索引的范围查询,复合条件排序类别desc、asc不一致</p>
</li>
</ul>
<h2>4.10. 索引是不是建的越多越好呢？</h2>
<ul>
<li>当然不是。</li>
<li>索引会占据磁盘空间</li>
<li>降低更新表的速度：更新表（INSERT、UPDATE、DELETE操作）时，所有的索引都需要被更新。</li>
<li>维护索引文件需要成本；还会导致页分裂，IO次数增多。</li>
<li>单表索引不超过5个</li>
</ul>
]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/0dcfd52cf39085f7207e5.jpg" type="image/jpeg"/>
    </item>
    <item>
      <title>redis</title>
      <link>https://javaguide.cn/interview/redis.html</link>
      <guid>https://javaguide.cn/interview/redis.html</guid>
      <source url="https://javaguide.cn/rss.xml">redis</source>
      <description>1. 什么是 Redis? Redis：Remote Dictionary Service 基于键值对（key-value）的 NoSQL 数据库。 Redis 中的 value 支持 string（字符串）、hash（哈希）、 list（列表）、set（集合）、zset（有序集合）、Bitmaps（位图）、HyperLogLog（基数估算）、GEO（...</description>
      <category>面试</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[
<ul>
<li>Redis：Remote Dictionary Service 基于键值对（key-value）的 NoSQL 数据库。</li>
<li>Redis 中的 value 支持 string（字符串）、hash（哈希）、 list（列表）、set（集合）、zset（有序集合）、Bitmaps（位图）、HyperLogLog（基数估算）、GEO（地理信息定位）等多种数据结构。</li>
<li>因为 Redis 的所有数据都存放在内存当中，所以它的读写性能非常出色。</li>
<li>Redis 还可以将内存数据持久化到硬盘上，这样在发生类似断电或者机器故障的时候，内存中的数据并不会“丢失”。</li>
<li>Redis 还提供了键过期、发布订阅、事务、流水线、Lua 脚本等附加功能，是互联网技术领域中使用最广泛的缓存中间件。</li>
</ul>
<h1>Redis 和 MySQL 的区别？</h1>
<ul>
<li>Redis：数据存储在内存中的 NoSQL 数据库，读写性能非常好。</li>
<li>MySQL：数据存储在硬盘中的关系型数据库，适用于需要事务支持和复杂查询的场景</li>
</ul>
<h1>2. 单线程 Redis 的 QPS 是多少？</h1>
<ul>
<li>Redis的QPS（Queries Per Second每秒查询率）受多种因素影响，包括硬件配置（如 CPU、内存、网络带宽）、数据模型、命令类型、网络延迟等<br>
。一个普通服务器的 Redis 实例通常可以达到每秒数万到几十万的 QPS。</li>
<li>基准测试命令：redis-benchmark -h 127.0.0.1 -p 6379 -c 50 -n 10000（-c：并发连接数，-n：请求总数）</li>
</ul>
<h1>3. redis使用场景？</h1>
<ul>
<li>缓存：减轻数据库查询压力，提高应用的响应速度和吞吐量</li>
<li>分布式锁：控制跨多个进程或服务器的资源访问。</li>
<li>热门列表与排行榜：利用 zSet（有序集合）根据score实现</li>
<li>Session共享：集群服务的同一个用户session可能落在不同机器上，这会导致用户频繁登陆；采用Redis保存Session后，无论用户落在那台机器上都能够获取到对应的Session</li>
<li>计数器/限速器：利用Redis中原子性的自增操作，统计类似用户点赞数、用户访问数等。限速器比较典型的使用场景是限制某个用户访问某个API的频率</li>
<li>好友关系：利用集合的一些命令，比如求交集、并集、差集等。可以方便解决一些共同好友、共同爱好之类的功能；</li>
<li>消息队列：利用List来实现一个队列机制，异步解耦，比如：到货通知、邮件发送之类的需求，不需要高可靠，但是会带来非常大的DB压力；</li>
<li>数据过期处理: 订单30分钟自动取消</li>
<li>交集、并集和差集</li>
<li>发布/订阅</li>
<li>数据持久化</li>
<li>事务</li>
</ul>
<h1>4. Redis 支持的数据类型有哪些？什么场景？相关指令？</h1>
<ul>
<li>String:存储字符串（JSON、XML、token）、数字、二进制（图片、音频、视频），但最大不能超过512MB。用于缓存、计数、共享Session、限速</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code># 设置key的value并则覆盖
set key value 
# 获得key的String值
get key
# 将指定的key的value原子性的递增/减1
incr/decr key
# 将指定的key的value原子性的递增/减crement
incrby/decrby key increment/decrement
</code></pre></div><ul>
<li>list:字符串有序集合，可重复,在链表的两头插入或删除元素(高效),模拟队列,堆,栈 ,关注列表，粉丝列表，消息队列</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code># 在list头/尾部添加多个values，key不存在就创建，成功返回个数，移除时返回个数为0则键删除
lpush/rpush key value1 value2.. 
# 获取链表中从start到end的元素的值lrange key 0 -1 查全部
lrange key start end 
# 返回并弹出链表中的头/尾部value。删除了
lpop/rpop key
# 返回指定链表中的value数量 
llen key 
</code></pre></div><ul>
<li>set:字符串无序集合、不重复，多个Sets之间的聚合计算操作效率高。点赞功能。共同关注、二度好友、标签</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code># 向set中添加数据，如果该key的值已有则不会重复添加，点赞(/收藏)
sadd key value1、value2…
# 删除set中指定的成员 取消点赞（/收藏）
srem key member1、member2…
# 获取set中所有的成员 获取所有点赞(/收藏)用户  
smembers key
# 获取set中成员的数量 获取点赞用户数量
scard key
# 判断参数中指定的成员是否在该set中，1存在，0不在或者key本身就不在 判断是否点赞(/收藏) 
sismember key member
# 随机返回set中的一个成员
srandmember key
# 与key的顺序有关。返回差集”相减“
sdiff key1 key2
# 将key1、key2相差的成员存储在destination上
sdiffstore destination key1 key2
# 返回交集
sinter key key1,key2…
# 将返回的交集存储在destination上
sinterstore destination key1 key2
# 返回并集
sunion key1、key2
# 将返回的并集存储在destination上
sunionstore destination key1 key2
</code></pre></div><ul>
<li>sorted set:有序集合。元素唯一，通过分数进行从小到大的排序。添加、删除或更新一个成员的时间复杂度为集合中成员数量的对数。效率高。(top-n)排名：排名/排行榜。</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code># 将所有成员以及该成员的分数存放到sorted-set中
zadd key score member score2 member2 …
# 移除集合中指定的成员，可以指定多个成员。返回删除的数量
zrem key member[member…]
# 设置指定成员的增加的分数increment。并返回该成员更新后的分数（分数改变后相应它的index也会改变）
zincrby key increment member
# 获取集合中的成员数量
zcard key
# 获取分数在[min,max]之间的成员数量
zcount key min max
# 获取集合中脚标为start-end的成员及分数/倒序 【0-1】表示返回所有成员
zrange/zrerange key start end [withscores]
# 获取集合中分数为min max的成员及分数，并低到高排序
zrangebyscore key min max [withscores] [limit offset count]
# 返回成员在集合中的位置排名，从小到大
zrank key member
# 返回成员在集合中的位置排名，从大到小
zrevrank key member
# 返回指定成员的分数
zscore key member
</code></pre></div><ul>
<li>hash:键值对集合，用于保存对象（用户信息）、分组，缓存购物车对象</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code># 为指定的key设定field/value对（键值对）
hset key field value
# 返回指定的key中的field的值
hget key field
# 获取key中的所有filed-vaule 
hgetall key
# 删除键为 key 的哈希表中的一个或多个字段
HDEL key field
# 判断指定的key中的filed是否存在
hexists key field value
# 获取key所包含的field的数量
hlen key
# 设置key中filed的值增加increment
hincrby key field increment
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code># 获取所有与pattern匹配的，key * 表示多个字符，？表示任意一个字符
key keys pattern
# 取出所有的key
Key *
# 删除指定key
del kye1  key2
# 判断key是否存在，1在，0不在
exists key
# 为当前的key重命名
rename key newkey 
# 设置过期时间
expire key second
# 获取该key所剩超时时间，没超时则-1
ttl key
# 返回key 的类型，不存在返回none
type key
# 清除key的过期时间。Key持久化。-1是永久保存 -2
persist key
</code></pre></div><ul>
<li>Bitmap：通过一个bit 数组来存储特定数据的一种数据结构，每一个bit位都能独立包含信息，大量节省空间。</li>
<li>应用场景：判断海量用户中某个用户是否在线，用户每个月的签到情况，连续签到用户总数</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code># 判断用户是否在线 key=login_status表示存储用户登陆状态集合数据，将用户ID作为offset，在线就设置为1，下线设置0
SETBIT &lt;key&gt; &lt;offset&gt; &lt;value&gt; // 设置用户是否已登陆
GETBIT &lt;key&gt; &lt;offset&gt;       // 获取用户是否在线

# 统计用户每个月打开情况 key = uid:sign:{userId}:{yyyyMM}，月份的每一天的值-1作为 offset（因为offset从0开始）
SETBIT uid:sign:89757:202105 15 1  // 表示记录用户在 2021 年 5 月 16 号打卡
GETBIT uid:sign:89757:202105 15    // 编号 89757 用户在 2021 年 5 月 16 号是否打卡。
BITCOUNT uid:sign:89757:202105     // 统计该用户在 5 月份的打卡次数，使用 BITCOUNT 指令
BITPOS uid:sign:89757:202105 1     // 获取 userID = 89757 在 2021 年 5 月份首次打卡日期

# 统计连续签到用户总数(连续7天) key = {yyyyMMdd}， offset=userId 打卡则设置成1。key对应的集合的每个bit位的数据则是一个用户在该日期的打卡记录。对这7个Bitmap的对应的bit位做与运算。
# 一个一亿个位的Bitmap大约占12MB的内存（10^8/8/1024/1024），7天的Bitmap占用84 MB。同时最好给Bitmap设置过期时间，让Redis删除过期的打卡数据，节省内存
SETBIT 20210500 userId 1                //记录用户在2021年5月1日打卡
BITOP AND[OR、NOT、XOR] destinationmap 20210500 20210501...  //记录用户在2021年5月1-7日连续打卡的userId和状态到destinationmap
BITCOUNT destinationmap               //查询destinationmap连续打卡总人数

- HyperLogLog、Geo、Bitmap、BloomFilter、RedisSearch、Redis-ML、JSON
</code></pre></div><h1>5. Redis为什么单线程那么快？</h1>
<ul>
<li>基于内存的数据存储，内存的访问速度远超硬盘，</li>
<li>单线程模型，避免了线程切换和锁竞争带来的消耗。</li>
<li>IO 多路复⽤，基于 Linux 的 select/epoll 机制。该机制允许内核中同时存在多个监听套接字和已连接套接字，内核会一直监听这些套接字上的连接请求或者数据请求，一旦有请求到达，就会交给 Redis 处理，就实现了所谓的 Redis 单个线程处理多个 IO 读写的请求。</li>
<li>高效的数据结构。如字符串（String）、列表（List）、集合（Set）、有序集合（Sorted Set）等</li>
</ul>
<h1>6. I/O 多路复用？</h1>
<ul>
<li>I/O多路复用允许单个线程或进程同时监控多个I/O流（如文件或网络连接），并在有数据可读或可写时进行相应的处理，从而高效地利用系统资源。</li>
<li>Linux 系统有三种方式实现 IO 多路复用：select、poll 和 epoll。</li>
<li>epoll 方式是将用户 socket 对应的 fd 注册进 epoll，然后 epoll 帮你监听哪些 socket 上有消息到达，这样就避免了大量的无用操作。此时的 socket 应该采用非阻塞模式。这样，整个过程只在进行 select、poll、epoll 这些调用的时候才会阻塞，收发客户消息是不会阻塞的，整个进程或者线程就被充分利用起来，这就是事件驱动，所谓的 reactor 模式。</li>
</ul>
<h1>7. Redis 是单线程的吗？</h1>
<ul>
<li>Redis单线程指的是网络I/O线程以及Set和Get操作是单线程的。但是Redis的持久化、集群同步还是使用其他线程来完成</li>
<li>Redis 4.0 之后多线程是用来处理数据的读写和协议解析，但是 Redis执行命令还是单线程的。这样做的⽬的是因为 Redis 的性能瓶颈在于⽹络 IO ⽽⾮ CPU，使⽤多线程能提升 IO 读写的效率，从⽽整体提⾼ Redis 的性能。<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/1e419b34a2ddcd1e552d4.png" alt="redismultiplethread.png"></li>
</ul>
<h1>9. Redis有哪几种持久化方式？有什么区别？</h1>
<ul>
<li>
<p>【全量】Rdb持久化(默认)：通过创建数据的快照来保存数据。定期把内存中当前时刻内存中的数据以二进制的方式保存到磁盘。产生的数据文件为dump.rdb。数据恢复时直接将RDB文件读入内存完成恢复。实际操作过程是fork一个子进程，先将数据集写入临时文件，写入成功后，再替换之前的文件，用二进制压缩存储.可通过 save 和 bgsave 命令两个命令来手动触发 RDB 持久化操作</p>
<ul>
<li>save命令会同步地将Redis的所有数据保存到磁盘上的一个RDB文件中。会阻塞所有客户端请求。不推荐在生产环境中使用</li>
<li>bgsave命令：fork出一个子进程，在后台异步地创建 Redis 的数据快照，并将快照保存到磁盘上的 RDB 文件中。这个命令会立即返回，不阻塞客户端请求。在生产环境中执行 RDB 持久化的推荐方式。</li>
</ul>
</li>
<li>
<p>【增量】AOF持久化：通过记录每个写入命令来保存数据。执行命令并将写操作记录日志到追加到aof文件中，数据恢复时则需要将全量AOF日志都执行一遍。工作流程</p>
<ul>
<li>命令写入（append）：当AOF功能开启，Redis会将接收到的所有写命令追加到 AOF 缓冲区（buffer）的末尾。</li>
<li>文件同步（sync）：将缓冲区中的命令持久化到磁盘中的 AOF 文件，同步策略包括：
<ul>
<li>always：每次写命令都会同步到AOF文件，安全性搞，但可能因为磁盘 I/O 的延迟而影响性能。</li>
<li>everysec（默认）：每秒同步一次，提供了较好的性能和数据安全性。如果系统崩溃，最多可能丢失最后一秒的数据。</li>
<li>no：只会在AOF关闭、Redis关闭或由操作系统内核触发。如果宕机，那么丢失的数据量由操作系统内核的缓存冲洗策略决定</li>
</ul>
</li>
<li>文件重写（rewrite）：随着操作的不断执行，AOF 文件会不断增长，为了减小 AOF 文件大小，Redis重写AOF文件：
<ul>
<li>重写过程将当前内存中的数据库状态转换为一系列写命令，然后保存到新的AOF文件.由 BGREWRITEAOF 命令触发，它会创建一个子进程来执行重写操作，因此不会阻塞主进程。重写过程中，新的写命令会继续追加到旧的 AOF 文件中，同时也会被记录到一个缓冲区中。一旦重写完成，Redis 会将这个缓冲区中的命令追加到新的 AOF 文件中，然后切换到新的 AOF 文件上，以确保数据的完整性。</li>
</ul>
</li>
<li>重启加载（load）：当Redis服务器启动时，如果配置为使用AOF持久化方式，它会读取 AOF 文件中的所有命令并重新执行它们，以恢复数据库的状态</li>
</ul>
</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code># aof
appendonly no //表示是否开启AOF持久化策略(默认no，关闭)
appendfilename "appendonly.aof"//持久化文件名称
</code></pre></div><h1>10. rdb持久化触发条件</h1>
<ul>
<li>在 Redis 配置文件（通常是 redis.conf）中，可以通过save <code>&lt;seconds&gt;</code> <code>&lt;changes&gt;</code>指令配置自动触发 RDB 持久化的条件。这个指令可以设置多次，每个设置定义了一个时间间隔（秒）和该时间内发生的变更次数阈值。</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>save 900 1 如果至少有 1 个键被修改，900 秒后自动触发一次 RDB 持久化。
save 300 10 如果至少有 10 个键被修改，300 秒后自动触发一次 RDB 持久化。
save 60 10000 如果至少有 10000 个键被修改，60 秒后自动触发一次 RDB 持久化。
</code></pre></div><ul>
<li>通过 SHUTDOWN 命令正常关闭时执行 一次RDB 持久化，以确保数据在下次启动时能够恢复。</li>
<li>在 Redis 复制场景中，当一个 Redis 实例被配置为从节点并且与主节点建立连接时，它可能会根据配置接收主节点的 RDB 文件来初始化数据集。这个过程中，主节点会在后台自动触发 RDB 持久化，然后将生成的 RDB 文件发送给从节点。</li>
</ul>
<h1>11. RDB 和 AOF 各自有什么优缺点？</h1>
<ul>
<li>RDB文件相对小，恢复速度快，但实时性差，数据容易丢失，备份时间长。适合全量备份</li>
<li>AOF文件相对大，恢复速度慢，但实时性好，数据不易丢失，数据写入性能高，适合增量备份</li>
</ul>
<h1>12. 如何选择合适的持久化方式？</h1>
<ul>
<li>用AOF做增量持久化,保证数据不丢失; 用RDB全量持久化,做不同程度的冷备;因为RDB耗时长，在停机的时候会导致大量丢失数据，所以需要AOF来配合使用。</li>
</ul>
<h1>13. Redis 的数据恢复？</h1>
<ul>
<li>把RDB或者AOF文件拷贝到 Redis 的数据目录下，如果使用 AOF 恢复，配置文件开启 AOF，然后启动 redis-server 即可</li>
<li>Redis 启动时加载数据的流程：
<ul>
<li>AOF 持久化开启且存在 AOF 文件时，优先加载 AOF 文件。</li>
<li>AOF 关闭或者 AOF 文件不存在时，加载 RDB 文件。</li>
<li>加载 AOF/RDB 文件成功后，Redis 启动成功。</li>
<li>AOF/RDB 文件存在错误时，Redis 启动失败并打印错误信息</li>
</ul>
</li>
</ul>
<h1>14. Redis 4.0 的混合持久化了解吗？√</h1>
<ul>
<li>在 Redis 4.0 版本中，混合持久化模式会在 AOF 重写的时候同时生成一份 RDB 快照，然后将这份快照作为 AOF 文件的一部分，最后再附加新的写入命令。当需要恢复数据时，Redis 先加载 RDB 文件来恢复到快照时刻的状态，然后应用 RDB 之后记录的 AOF 命令来恢复之后的数据更改，既快又可靠。</li>
</ul>
<h1>15. redis如何实现高可用？</h1>
<ul>
<li>主从复制（Master-Slave Replication）：允许一个 Redis 服务器（主节点）将数据复制到一个或多个 Redis 服务器（从节点）。可以实现读写分离，适合读多写少的场景。</li>
<li>哨兵模式（Sentinel）：用于监控主节点和从节点的状态，实现自动故障转移和系统消息通知。如果主节点发生故障，哨兵可以自动将一个从节点升级为新的主节点，保证系统的可用性。</li>
<li>集群模式（Cluster）：Redis 集群通过分片的方式存储数据，每个节点存储数据的一部分，用户请求可以并行处理。集群模式支持自动分区、故障转移，并且可以在不停机的情况下进行节点增加或删除。</li>
</ul>
<h1>16. 什么是主从复制？</h1>
<ul>
<li>指将一台 Redis 服务器的数据，复制到其他的 Redis 服务器。前者称为主节点(master)，后者称为从节点(slave)。且数据的复制是单向的，只能由主节点到从节点。Redis 主从复制支持 主从同步 和 从从同步 两种</li>
</ul>
<h1>17. 主从复制主要的作用?</h1>
<ul>
<li>数据备份：实现数据的热备份，是持久化之外的一种数据冗余方式。</li>
<li>故障恢复：当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复 (服务冗余)。</li>
<li>负载均衡：在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务，分担服务器负载。尤其是在写少读多的场景下，通过多个从节点分担读负载，可以大大提高 Redis 服务器的并发量。</li>
<li>不推荐在Redis中使用读写分离。主要有两个原因：
<ul>
<li>Redis Sentinel只保证主节点的故障的失效转移，如Jedis只监听了主节点的变化，但是从节点故障时是不进行处理的。导致Jedis读会访问到从节点。Redisson库功能强大，已经支持从节点的故障监听</li>
<li>如果到达需要读写分离的体量，大量写操作考虑Redis Cluster方案更可靠</li>
</ul>
</li>
</ul>
<h1>18. Redis 主从有几种常见的拓扑结构？</h1>
<ul>
<li>Redis的复制拓扑结构可以支持单层或多层复制关系，根据拓扑复杂性可以分为</li>
<li>一主一从结构：用于主节点出现宕机时从节点提供故障转移支持。</li>
<li>一主多从结构：（星形拓扑结构）使得应用端可以利用多个从节点实现读写分离。对于读占比较大的场景，可以把读命令发送到从节点来分担主节点压力。</li>
<li>树状主从结构（树状拓扑结构）使得从节点不但可以复制主节点数据，同时可以作为其他从节点的主节点继续向下层复制。通过引入复制中间层，可以有效降低主节点负载和需要传送给从节点的数据量。<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/8d36eea3d0eb3f10097b0.png" alt="redismasterslavestructure.png"><br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/e666f55d51dd82b781e4f.png" alt="redismasterslavestructure2.png"></li>
</ul>
<h1>19. Redis 的主从复制原理</h1>
<ul>
<li>保存主节点（master）信息:只是保存主节点信息，ip 和 port。</li>
<li>主从建立连接:从节点（slave）发现新的主节点后，会尝试和主节点建立网络连接。</li>
<li>发送 ping 命令:从节点发送 ping 请求进行首次通信，主要是检测主从之间网络套接字是否可用、主节点当前是否可接受处理命令。</li>
<li>权限验证:如果主节点要求密码验证，从节点必须正确的密码才能通过验证。</li>
<li>同步数据集:主从复制连接正常通信后，主节点会把持有的数据全部发送给从节点。</li>
<li>命令持续复制:接下来主节点会持续地把写命令发送给从节点，保证主从数据一致性<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/2ae083f185ce950c4ca66.png" alt="redismasterslaveprinciple.png"></li>
</ul>
<h1>20. 说说主从数据同步的方式？</h1>
<ul>
<li>Redis 在 2.8 及以上版本使用 psync 命令完成主从数据同步，同步过程分为：全量复制和部分复制。</li>
<li>全量复制:用于初次复制场景，把主节点全部数据一次性发送给从节点，当数据量较大时，会对主从节点和网络造成很大的开销<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/ffedbc5a058de697f61a5.png" alt="fullreplication.png">
<ul>
<li>建立连接：从服务器和主服务器建立连接，从服务器执行replicaof命令并发送 psync 命令进行数据同步，由于是第一次进行复制，从节点没有复制偏移量和主节点的运行 ID，所以发送 psync ? -1。</li>
<li>主节点根据 psync ? -1 解析出当前为全量复制，回复+FULLRESYNC 响应。</li>
<li>从节点接收主节点的响应数据保存运行 ID 和偏移量 offset</li>
<li>主节点执行 bgsave 保存 RDB 文件到本地</li>
<li>主节点发送 RDB 文件给从节点，从节点把接收的 RDB 文件保存在本地并直接作为从节点的数据文件</li>
<li>对于从节点开始接收 RDB 快照到接收完成期间，主节点仍然响应读写命令，因此主节点会把这期间写命令数据保存在复制客户端缓冲区内，当从节点加载完RDB文件后，主节点再把缓冲区内的数据发送给从节点，保证主从之间数据一致性</li>
<li>从节点接收完主节点传送来的全部数据后会清空自身旧数据并开始加载 RDB 文件</li>
<li>从节点成功加载完 RDB 后，如果当前节点开启了 AOF 持久化功能， 它会立刻做 bgrewriteaof 操作，为了保证全量复制后 AOF 持久化文件立刻可用。</li>
</ul>
</li>
<li>部分复制:使用 psync{runId}{offset}命令实现。当从节点（slave）正在复制主节点 （master）时，如果出现网络闪断或者命令丢失等异常情况时，从节点会向 主节点要求补发丢失的命令数据，如果主节点的复制积压缓冲区内存在这部分数据则直接发送给从节点，这样就可以保持主从节点复制的一致性。<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/eaeefc5f1f4452d5b8dc8.png" alt="partialreplication.png">
<ul>
<li>当主从节点之间网络出现中断时，如果超过 repl-timeout 时间，主节点会认为从节点故障并中断复制连接</li>
<li>主从连接中断期间主节点依然响应命令，但因复制连接中断命令无法发送给从节点，不过主节点内部存在的环形复制积压缓冲区repl_backlog_buffer，依然可以保存最近一段时间的写命令数据，默认最大缓存 1MB。所以当缓冲区写满后，主服务器继续写入的话，就会覆盖之前的数据。用于主从服务器断连后，从中找到差异的数据；主服务器使用 master_repl_offset 来记录自己写到的位置，从服务器使用 slave_repl_offset 来记录自己读到的位置</li>
<li>当主从节点网络恢复后，从节点会再次连上主节点</li>
<li>当主从连接恢复后，由于从节点之前保存了自身已复制的偏移量和主节点的运行 ID。因此会把它们当作 psync 参数发送给主节点，要求进行部分复制操作。</li>
<li>主节点接到 psync 命令后首先核对参数 runId 是否与自身一致，如果一 致，说明之前复制的是当前主节点；之后根据参数 slave_repl_offset 和slave_repl_offset在自身复制积压缓冲区查找，如果偏移量之后的数据存在缓冲区中，则对从节点发送+CONTINUE 响应，表示可以进行部分复制。否则全量复制</li>
<li>主节点根据偏移量把复制积压缓冲区里的数据发送给从节点，保证主从复制进入正常状态。</li>
</ul>
</li>
<li>repl_backlog_buffer缓冲区尽可能的大一些，减少出现从服务器要读取的数据被覆盖的概率，可以根据公式估算second （从服务器断线后重新连接上主服务器所需的平均时间(秒)）* write_size_per_second（主服务器平均每秒产生的写命令数据量大小）修改redis.conf的repl-backlog-size 1mb 即可</li>
</ul>
<h1>21. 主从复制存在哪些问题呢？</h1>
<ul>
<li>没法完成自动故障转移：一旦主节点出现故障，需要手动将一个从节点晋升为主节点，同时需要修改应用方的主节点地址，还需要命令其他从节点去复制新的主节点，整个过程都需要人工干预。(高可用)</li>
<li>主节点的写和存储能力受到单机的限制。(分布式)</li>
</ul>
<h1>22. Redis Sentinel（哨兵）了解吗？</h1>
<ul>
<li>解决了主从复制的没法自动故障转移问题.由两部分组成，哨兵节点和数据节点
<ul>
<li>哨兵节点： 哨兵系统由一个或多个哨兵节点组成，不存储数据，对数据节点进行监控。</li>
<li>数据节点： 主节点和从节点都是数据节点；</li>
</ul>
</li>
<li>哨兵功能的描述：
<ul>
<li>监控（Monitoring）： 哨兵会不断地检查主节点和从节点是否运作正常。</li>
<li>自动故障转移（Automatic failover）： 当 主节点 不能正常工作时，哨兵会开始 自动故障转移操作，它会将失效主节点的其中一个 从节点升级为新的主节点，并让其他从节点改为复制新的主节点。使得哨兵可以及时发现主节点故障并完成转移。而配置提供者和通知功能，则需要在与客户端的交互中才能体现</li>
<li>配置提供者（Configuration provider）： 客户端在初始化时，通过连接哨兵来获得当前Redis服务的主节点地址。</li>
<li>通知（Notification）： 哨兵可以将故障转移的结果发送给客户端。并且通知客户端与新 master 建立连接。<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/f59a33b39eaf18665a5d2.png" alt="redissentinel.png"></li>
</ul>
</li>
</ul>
<h1>23. Redis Sentinel（哨兵）实现原理</h1>
<ul>
<li>
<p>组成命令sentinel monitor <code>&lt;master-name&gt;</code> <code>&lt;ip&gt;</code> <code>&lt;redis-port&gt;</code> <code>&lt;quorum&gt;</code></p>
</li>
<li>
<p>哨兵节点之间是通过 Redis 的发布者/订阅者机制来相互发现的。在主从集群中，主节点上有一个名为__sentinel__:hello的频道，不同哨兵就是通过它来相互发现，实现互相通信的</p>
</li>
<li>
<p>哨兵模式是通过哨兵节点完成对数据节点的监控、下线(主客观下线)、领导者sentinel选举、故障转移。</p>
</li>
<li>
<p>定时监控</p>
<ul>
<li>主从信息获取：每隔10秒，每个 Sentinel 节点会向主节点和从节点发送 info 命令获取最新的拓扑结构</li>
<li>哨兵信息发布：每隔2秒，每个 Sentinel 节点会向 Redis 数据节点的sentinel：hello 频道上发送该 Sentinel 节点对于主节点的判断以及当前 Sentinel 节点的信息</li>
<li>节点心跳检测：每隔 1 秒，每个 Sentinel 节点会向主节点、从节点、其余 Sentinel 节点发送一条 ping 命令做一次心跳检测，来确认这些节点当前是否可达</li>
</ul>
</li>
<li>
<p>主观下线和客观下线：</p>
<ul>
<li>主观下线：每个 Sentinel 节点会每隔 1 秒对主节点、从节点、其他 Sentinel 节点发送 ping 命令做心跳检测，当这些节点超过 down-after-milliseconds 没有进行有效回复，Sentinel 节点将该节点标记为主观下线。</li>
<li>客观下线：当 Sentinel 标记主观下线的节点是主节点时，该 Sentinel 节点会通过 is- master-down-by-addr 命令向其他 Sentinel 节点询问对主节点的判断，当超过 <code>&lt;quorum&gt;</code>（一般为哨兵个数的二分之一加1）个数，Sentinel 节点认为主节点确实有问题，这时该 Sentinel 节点会标记主节点客观下线</li>
</ul>
</li>
<li>
<p>领导者 Sentinel 节点选举：Sentinel 节点之间会选出一个节点作为领导者进行故障转移的工作。使用Raft算法实现</p>
</li>
<li>
<p>故障转移：领导者选举出的 Sentinel 节点负责故障转移，过程如下：</p>
<ul>
<li>选出主节点：在从节点列表中选出一个节点作为新的主节点，</li>
<li>设置主节点：Sentinel 领导者节点会对第一步选出来的从节点执行 slaveof no one 命令让其成为主节点</li>
<li>从节点同步：Sentinel 领导者节点会向剩余的从节点发送SLAVEOF ip port命令，让它们成为新主节点的从节点</li>
<li>通知客户端：哨兵就会向 +switch-master 频道将新主节点的IP地址和信息，通过发布者/订阅者机制通知给客户端；</li>
<li>原节点转从：Sentinel 节点集合继续监视原来的主节点，当其恢复后发送 SLAVEOF IP port命令它去复制新的主节点</li>
</ul>
</li>
</ul>
<h1>24. 领导者 Sentinel 节点选举了解吗？</h1>
<ul>
<li>
<p>使用了 Raft 算法实 现领导者选举，大致流程如下：</p>
</li>
<li>
<p>每个在线的 Sentinel 节点都有资格成为领导者，当它确认主节点主观 下线时候，会向其他 Sentinel 节点发送 is-master-down-by-addr 命令， 要求将自己设置为领导者。</p>
</li>
<li>
<p>收到命令的 Sentinel 节点，如果没有同意过其他 Sentinel 节点的 is-master-down-by-addr 命令，将同意该请求，否则拒绝。</p>
</li>
<li>
<p>如果该 Sentinel 节点发现自己的票数已经大于等于 max（quorum， num（sentinels）/2+1），那么它将成为领导者</p>
</li>
<li>
<p>如果此过程没有选举出领导者，将进入下一次选举</p>
</li>
<li>
<p>为什么哨兵节点至少要有3个？如果哨兵集群中只有2个哨兵节点，此时如果一个哨兵想要成功成为Leader，必须获得2票，而不是1票。如果有个哨兵挂掉了，剩下的哨兵想要成为Leader，票数就没法达到2票，就无法成功成为Leader，无法进行主从节点切换的。因此，通常配置3个哨兵节点。如果3个哨兵节点挂了2个怎么办？人为介入，或者增加多一点哨兵节点</p>
</li>
</ul>
<h1>25. 新的主节点是怎样被挑选出来的</h1>
<ul>
<li>过滤：“不健康”（主观下线、断线）、5 秒内没有回复过 Sentinel 节 点 ping 响应、与主节点失联超过 down-after-milliseconds*10秒</li>
<li>选择 slave-priority（从节点优先级）最高的从节点列表，如果存在则返回，不存在则继续。</li>
<li>选择复制偏移量最大的从节点（复制的最完整），哪个从「主节点」接收的复制数据多(如果某个从节点的 slave_repl_offset 最接近 master_repl_offset)，如果存在则返 回，不存在则继续。</li>
<li>选择节点id runid 最小的从节点。</li>
</ul>
<h1>26. Redis 集群了解吗？</h1>
<ul>
<li>主从存在高可用和分布式的问题，哨兵解决了高可用的问题，而集群解决高可用和分布式问题。</li>
<li>数据分区：将数据分散到多个节点，突破了 Redis 单机内存大小的限制，存储容量大大增加；每个主节点都可以对外提供读服务和写服务，大大提高了集群的响应能力。</li>
<li>高可用：集群支持主从复制和主节点的自动故障转移（与哨兵类似），当任一节点发生故障时，集群仍然可以对外提供服务</li>
</ul>
<h1>27. 切片集群了解吗？</h1>
<ul>
<li>切片集群是一种将数据分片存储在多个 Redis 实例上的集群架构，每个 Redis 实例负责存储部分数据。比如说把 25G 的数据平均分为 5 份，每份 5G，然后启动 5 个 Redis 实例，每个实例保存一份数据。</li>
<li>数据和实例之间如何映射呢？Redis Cluster是针对切片集群提供的解决方案；在 Redis Cluster 中，数据和实例之间的映射是通过哈希槽（hash slot）来实现的。Redis Cluster 有 16384 个哈希槽，每个键根据其名字的 CRC16 值被映射到这些哈希槽上。然后，这些哈希槽会被均匀地分配到所有的 Redis 实例上。CRC16 是一种哈希算法，它可以将任意长度的输入数据映射为一个 16 位的哈希值。需要存储或检索一个键值对时，Redis Cluster 会先计算这个键的哈希槽，然后找到负责这个哈希槽的 Redis 实例，最后在这个实例上进行操作。即crc16（key）&amp; 16384</li>
</ul>
<h1>28. 集群中数据如何分区？</h1>
<p>在 Redis 集群中，数据分区是通过将数据分散到不同的节点来实现的，常见的数据分区规则有三种：节点取余分区、一致性哈希分区、虚拟槽分区。</p>
<ul>
<li>节点取余分区：数据项的键经过哈希函数计算后，对节点数量取余，然后将数据项分配到余数对应的节点上。缺点是扩缩容时，大多数数据需要重新分配，因为节点总数的改变会影响取余结果，这可能导致大量数据迁移。</li>
<li>一致性哈希分区：将哈希值空间组织成一个环，数据项和节点都映射到这个环上。数据项由其哈希值直接映射到环上，然后顺时针分配到遇到的第一个节点。从而来减少节点变动时数据迁移的量。相比节点取余最大的好处在于加入和删除节点只影响哈希环中相邻的节点，对其他节点无影响。节点在圆环上分布不平均，会造成部分缓存节点的压力较大；当某个节点故障时，这个节点所要承担的所有访问都会被顺移到另一个节点上，会对后面这个节点造成压力。</li>
<li>虚拟槽（哈希槽）分区中，存在固定数量的槽位（例如 Redis Cluster 有 16384 个槽），每个键通过哈希算法（CRC16）映射到这些槽上，每个集群节点负责管理一定范围内的槽。可以灵活地将槽（以及槽中的数据）从一个节点迁移到另一个节点，从而实现平滑扩容和缩容；数据分布也更加均匀，Redis Cluster 采用的正是这种分区方式。
<ul>
<li>在虚拟槽分区中，槽是数据管理和迁移的基本单位。假设系统中有 4 个实际节点，假设为其分配了 16 个槽(0-15)；槽 0-3 位于节点 node1；槽 4-7 位于节点 node2；槽 8-11 位于节点 node3；槽 12-15 位于节点 node4。如果此时删除 node2，只需要将槽 4-7 重新分配即可，例如将槽 4-5 分配给 node1，槽 6 分配给 node3，槽 7 分配给 node4，数据在节点上的分布仍然较为均衡。如果此时增加 node5，也只需要将一部分槽分配给 node5 即可，比如说将槽 3、槽 7、槽 11、槽 15 迁移给 node5，节点上的其他槽位保留。当然了，这取决于 CRC16(key) % 槽的个数 的具体结果。因为在 Redis Cluster 中，槽的个数刚好是 2 的 14 次方，这和 HashMap 中数组的长度必须是 2 的幂次方有着异曲同工之妙。它能保证扩容后，大部分数据停留在扩容前的位置，只有少部分数据需要迁移到新的槽上。</li>
</ul>
</li>
</ul>
<h1>29. Redis 集群的原理吗？</h1>
<ul>
<li>Redis 集群通过数据分区来实现数据的分布式存储，通过自动故障转移实现高可用。</li>
<li>集群创建：数据分区是在集群创建的时候完成的。
<ul>
<li>设置节点：Redis 集群一般由多个节点组成，节点数量至少为 6 个才能保证组成完整高可用的集群。每个节点需要开启配置 cluster-enabled yes，让 Redis 运行在集群模式下。</li>
<li>节点握手：指一批运行在集群模式下的节点通过 Gossip 协议彼此通信， 达到感知对方的过程。节点握手是集群彼此通信的第一步，由客户端发起命令：cluster meet{ip}{port}。完成节点握手之后，一个个的 Redis 节点就组成了一个多节点的集群</li>
<li>分配槽（slot）：Redis 集群把所有的数据映射到 16384 个槽中。每个节点对应若干个槽，只有当节点分配了槽，才能响应和这些槽关联的键命令。通过 cluster addslots 命令为节点分配槽。</li>
<li>故障转移：Redis 集群的故障转移和哨兵的故障转移类似，但是 Redis 集群中所有的节点都要承担状态维护的任务。</li>
<li>故障发现：Redis 集群内节点通过 ping/pong 消息实现节点通信，集群中每个节点都会定期向其他节点发送 ping 消息，接收节点回复 pong 消息作为响应。如果在 cluster-node-timeout 时间内通信一直失败，则发送节 点会认为接收节点存在故障，把接收节点标记为主观下线（pfail）状态。当某个节点判断另一个节点主观下线后，相应的节点状态会跟随消息在集群内传播。通过 Gossip 消息传播，集群内节点不断收集到故障节点的下线报告。当 半数以上持有槽的主节点都标记某个节点是主观下线时。触发客观下线流程。</li>
<li>故障恢复：故障节点变为客观下线后，如果下线节点是持有槽的主节点则需要在它 的从节点中选出一个替换它，从而保证集群的高可用。流程如下
<ul>
<li>资格检查：每个从节点都要检查最后与主节点断线时间，判断是否有资格替换故障 的主节点。</li>
<li>准备选举时间：当从节点符合故障转移资格后，更新触发故障选举的时间，只有到达该 时间后才能执行后续流程。</li>
<li>发起选举：当从节点定时任务检测到达故障选举时间（failover_auth_time）到达后，发起选举流程。</li>
<li>选举投票：持有槽的主节点处理故障选举消息。投票过程其实是一个领导者选举的过程，如集群内有 N 个持有槽的主节 点代表有 N 张选票。由于在每个配置纪元内持有槽的主节点只能投票给一个 从节点，因此只能有一个从节点获得 N/2+1 的选票，保证能够找出唯一的从节点。</li>
<li>替换主节点：当从节点收集到足够的选票之后，触发替换主节点操作。</li>
</ul>
</li>
</ul>
</li>
<li>部署 Redis 集群至少需要几个物理节点？ 在投票选举的环节，故障主节点也算在投票数内，假设集群内节点规模是 3 主 3 从，其中有 2 个主节点部署在一台机器上，当这台机器宕机时，由于从节点无法收集到 3/2+1 个主节点选票将导致故障转移失败。这个问题也适用于故障发现环节。因此部署集群时所有主节点最少需要部署在 3 台物理机上才能避免单点问题。</li>
</ul>
<h1>30. 说说集群的伸缩？</h1>
<ul>
<li>Redis 集群提供了灵活的节点扩容和收缩方案，可以在不影响集群对外服务的情况下，为集群添加节点进行扩容也可以下线部分节点进行缩容。集群扩容和缩容的关键点，就在于槽和节点的对应关系，扩容和缩容就是将一部分槽和数据迁移给新节点。扩容实例缩容也是类似，先把槽和数据迁移到其它节点，再把对应的节点下线。</li>
</ul>
<h1>31. redis缓存穿透，缓存击穿，缓存雪崩及其解决方案√</h1>
<ul>
<li>
<p>缓存穿透:指查询不存在的数据，由于缓存没有命中（因为数据根本就不存在），请求每次都会穿过缓存去查询数据库。如果这种查询非常频繁，就会给数据库造成很大的压力，可能由自身业务代码或者爬虫恶意攻击造成</p>
</li>
<li>
<p>缓存击穿:指某一个或少数几个数据被高频访问，当这些数据在缓存中过期的那一刻，大量请求就会直接到达数据库，导致数据库瞬间压力过大。</p>
</li>
<li>
<p>缓存雪崩:某一个时间点，由于大量的缓存数据同时过期或缓存服务器突然宕机了，导致所有的请求都落到了数据库上，对数据库造成巨大压力，甚至导致数据库崩溃的现象。</p>
</li>
<li>
<p>缓存穿透:</p>
<ul>
<li>缓存空对象：不管是数据不存在，还是系统故障都缓存过期时间很短的空结果，最长不超过五分钟（防止浪费内存）(带来的问题：需要更多的内存空间，推荐设置较短的过期时间，让其自动剔除；缓存层和存储层的数据会有一段时间窗口的不一致，可能影响业务。可以利用消息系统或者其他异步方式清除掉缓存层中的空对象)，适用于数据命中不高，数据频繁实时性高，代码维护简单，需要更多缓存空间，数据不一致</li>
<li>布隆过滤器拦截：当收到一个对key请求时先用布隆过滤器验证是key否存在，如果存在在进入缓存层、存储层。可以使用bitmap当作布隆过滤器，适用于数据命中不高、数据相对固定、实时性低的场景，代码复杂，但缓存空间占用少</li>
</ul>
</li>
<li>
<p>缓存击穿:（热点数据，重建缓存）</p>
<ul>
<li>加锁更新，⽐如请求查询 A，发现缓存中没有，对 A 这个 key 加锁，同时去数据库查询数据，写⼊缓存，再返回给⽤户，这样后⾯的请求就可以从缓存中拿到数据了。如果在查询数据库和重建缓存（key失效后进行了大量的计算）时间过长，可能导致死锁和线程池阻塞，高并发情景下吞吐量会大大降低！但是这种方法能降低后端存储负载，数据一致性好</li>
<li>手动过期：缓存上不设置过期时间并将过期时间存在KEY对应的VALUE里。获取缓存并通过VALUE的过期时间判断是否过期。如果未过期，则直接返回；如果已过期，则通过一个后台的异步线程进行缓存的构建，即“手动”过期。通过后台的异步线程，保证有且只有一个线程去查询DB。然后返回。保证服务的可用性，虽然损失了一定的时效性。</li>
</ul>
</li>
<li>
<p>缓存雪崩</p>
<ul>
<li>提高缓存可用性，
<ul>
<li>集群部署：降低单点故障的风险。即使某个缓存节点发生故障，其他节点仍然可以提供服务，从而避免对数据库的大量直接访问。利用 Redis Cluster或者第三方集群方案 Codis。</li>
<li>采用多级缓存，本地进程一级缓存，redis二级缓存，不同级别的缓存设置的超时时间不同
<ul>
<li>本地缓存的实时性怎么保证？
<ul>
<li>方案一，引入消息队列。在数据更新时，发布数据更新的消息；而进程中相应的消费者消费消息，更新本地缓存</li>
<li>方案二，设置较短的过期时间，请求时从DB重新拉取</li>
<li>方案三，使用 「如果避免缓存"击穿"的问题？」 问题的【方案二】，手动过期。</li>
</ul>
</li>
<li>每个进程可能会本地缓存相同的数据，导致内存浪费？
<ul>
<li>方案一，配置本地缓存的过期策略和缓存数量上限。</li>
<li>方案二：使用Ehcache、Guava Cache 实现本地缓存的功能。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>缓存的过期时间加上随机值，尽量让不同的key过期时间不同</li>
<li>限流和降级：通过设置合理的系统限流策略，如令牌桶或漏斗算法，来控制访问流量，防止在缓存失效时数据库被打垮。此外，系统可以实现降级策略，在缓存雪崩或系统压力过大时，暂时关闭一些非核心服务，确保核心服务的正常运行</li>
</ul>
</li>
</ul>
<h1>32. 能说说布隆过滤器吗？</h1>
<ul>
<li>布隆过滤器由一个长度为 m 的位数组和 k 个哈希函数组成。当一个元素被添加到过滤器中时，它会被 k 个哈希函数分别计算得到 k 个位置，然后将位数组中对应的位设置为 1。当检查一个元素是否存在于过滤器中时，同样使用 k 个哈希函数计算位置，如果任一位置的位为 0，则该元素肯定不在过滤器中；如果所有位置的位都为 1，则该元素可能在过滤器中。</li>
<li>因为布隆过滤器占用的内存空间非常小，所以查询效率也非常高，所以在 Redis 缓存中，使用布隆过滤器可以快速判断请求的数据是否在缓存中。因为哈希算法有一定的碰撞的概率。故存在误判。而且不支持删除元素</li>
</ul>
<h1>33. 如何保证缓存和数据库数据的一致性？</h1>
<ul>
<li>更新缓存还是删除缓存？删除缓存速度快，因为更新缓存的值可能来自不同的表，需要经过复杂计算出来，代价大</li>
<li>产生原因
<ul>
<li>并发的场景下，导致读取老的DB数据，更新到缓存中。</li>
<li>缓存和DB的操作，不在一个事务中，可能只有一个DB操作成功，而另一个Cache操作失败，导致数据不一致。</li>
</ul>
</li>
<li>缓存和DB的一致性，指的是最终一致性。使用缓存只要是提高读操作的性能，真正在写操作的业务逻辑，还是以数据库为准</li>
<li>都是2步中间被其他线程连续完成2步</li>
<li>先删除缓存，后更新数据库
<ul>
<li>请求A先删除缓存1，请求B读缓存发现没有，读取到旧值1，请求B存入缓存1，请求A写数据库2，数据不一致。</li>
<li>解决方案：串行写。在写请求时，先淘汰缓存之前，先获取该分布式锁。在读请求时，发现缓存不存在时，先获取分布式锁</li>
</ul>
</li>
<li>先更新数据库，后删除缓存
<ul>
<li>请求A读缓存发现不存在，读旧值1；请求B刷新数据库2；并删除缓存，请求A将旧值x=1写入缓存，数据不一致</li>
<li>缓存删除失败，并发导致写入了脏数据</li>
<li>问题1：概率低，必须满足3个条件
<ul>
<li>缓存刚好已失效</li>
<li>读请求 + 写请求并发</li>
<li>请求B更新数据库+删除缓存的时间，要比请求A读数据库+写缓存时间短（概率低,因为写数据库一般会加锁，通常是要比读数据库的时间更长）</li>
</ul>
</li>
<li>问题2：
<ul>
<li>引入消息队列保证缓存被删除。当数据库更新完成后，将更新事件发送到消息队列。有专门的服务监听这些事件并负责更新或删除缓存。缺点是对业务代码有一定的侵入</li>
<li>数据库订阅+消息队列保证缓存被删除。专门起一个服务（比如 Canal，阿里巴巴 MySQL binlog 增量订阅&amp;消费组件）去监听 MySQL 的 binlog，获取需要操作的数据。然后用一个公共的服务获取订阅程序传来的信息，进行缓存删除。降低了对业务的侵入，但增加了整个系统的复杂度，适合基建完善的大厂。</li>
<li>延时双删防止脏数据。在第一次删除缓存之后，过一段时间之后，再次删除缓存。主要针对缓存不存在，但写入了脏数据的情况。在先删缓存，再写数据库的更新策略下发生的比较多。延时时间需要仔细考量和测试。</li>
<li>设置缓存过期时间兜底：兜底策略，给缓存设置一个合理的过期时间，即使发生了缓存和数据库的数据不一致问题，也不会永远不一致下去，缓存过期后，自然就一致了。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1>34. 如何保证本地缓存和分布式缓存的一致</h1>
<ul>
<li>本地缓存对应服务器的内存缓存比如Caffeine，分布式缓存基本就是采用 Redis</li>
<li>设置本地缓存的过期时间，当本地缓存过期时，就从 Redis 缓存中去同步。</li>
<li>使用Redis的 Pub/Sub 机制，当 Redis 缓存发生变化时，发布一个消息，本地缓存订阅这个消息，然后删除对应的本地缓存</li>
<li>Redis 缓存发生变化时，引入消息队列，比如 RocketMQ、RabbitMQ 去更新本地缓存。</li>
</ul>
<h1>35. 怎么处理热 key？</h1>
<ul>
<li>热 key指在很短时间内被频繁访问的键。 Redis 是集群部署，热 key 可能会造成整体流量的不均衡（网络带宽、CPU 和内存资源），个别节点出现 OPS 过大的情况，极端情况下热点 key 甚至会超过 Redis 本身能够承受的 OPS。表示 Redis 每秒钟能够处理的命令数。</li>
<li>通常以 Key 被请求的频率来判定
<ul>
<li>QPS 集中在特定的 Key：总的 QPS（每秒查询率）为 10000，其中一个 Key 的 QPS 飙到了 8000。</li>
<li>带宽使用率集中在特定的 Key：一个拥有上千成员且总大小为 1M 的哈希 Key，每秒发送大量的 HGETALL 请求</li>
<li>CPU 使用率集中在特定的 Key：一个拥有数万个成员的 ZSET Key，每秒发送大量的 ZRANGE 请求。</li>
</ul>
</li>
<li>对热 key 的处理
<ul>
<li>监控热key
<ul>
<li>客户端：在客户端设置全局字典（key 和调用次数），每次调用 Redis 命令时，使用这个字典进行记录。</li>
<li>代理端：像 Twemproxy、Codis 这些基于代理的 Redis 分布式架构，所有客户端的请求都是通过代理端完成的，可以在代理端进行监控。</li>
<li>Redis 服务端：使用 monitor 命令统计热点 key：redis-cli monitor；分析热 Key。redis-cli --bigkeys</li>
</ul>
</li>
<li>处理热key
<ul>
<li>热 key 打散到不同的服务器，降低压⼒。</li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>// N 为 Redis 实例个数，M 为 N 的 2倍
const M = N * 2
//生成随机数
random = GenRandom(0, M)
//构造备份新 Key
bakHotKey = hotKey + "_" + random
data = redis.GET(bakHotKey)
if data == NULL {
    data = redis.GET(hotKey)
    if data == NULL {
        data = GetFromDB()
        // 可以利用原子锁来写入数据保证数据一致性
        redis.SET(hotKey, data, expireTime)
        redis.SET(bakHotKey, data, expireTime + GenRandom(0, 5))
    } else {
        redis.SET(bakHotKey, data, expireTime + GenRandom(0, 5))
    }
}

</code></pre></div><ul>
<li>加⼊⼆级缓存，当出现热 Key 后，把热 Key 加载到 JVM 中，后续针对这些热 Key 的请求，直接从 JVM 中读取。比如 Caffeine、Guava 等，或者直接使用 HashMap 作为本地缓存都是可以的。需要防止本地缓存过大。</li>
</ul>
<h1>36. 缓存预热怎么做呢？</h1>
<ul>
<li>缓存预热是提前将相关的缓存数据加载到缓存系统，避免在用户请求的时候，先查询数据库，然后再将数据缓存造成数据库压力过大的问题，用户直接查询事先被预热的缓存数据。</li>
<li>缓存预热方案
<ul>
<li>数据量不大的时候，项目启动时初始化。</li>
<li>数据量大的时候，定时任务刷新缓存</li>
<li>直接写个界面、接口、脚本，上线时手动操作</li>
</ul>
</li>
<li>缓存数据的淘汰策略有哪些？
<ul>
<li>缓存服务器自带的缓存自动失效策略</li>
<li>定时去清理过期的缓存。维护大量缓存的 key 是比较麻烦</li>
<li>当有用户请求过来时，再判断这个请求所用到的缓存是否过期，过期的话就去底层系统得到新数据并更新缓存。每次用户请求过来都要判断缓存失效，逻辑相对比较复杂！</li>
</ul>
</li>
</ul>
<h1>37. 热点 key 重建？问题？解决？</h1>
<ul>
<li>使用“缓存+过期时间”的策略，既可以加速数据读写，又保证数据的定期更新，基本能够满足绝大部分需求。</li>
<li>但是当 key 是一个热点 key，并发量大。且重建缓存时间长，可能是一个复杂计算，例如复杂的 SQL、多次 IO、多个依赖等。在缓存失效的瞬间，有大量线程来重建缓存，造成后端负载加大，甚至可能会让应用崩溃。</li>
<li>解决方案
<ul>
<li>互斥锁（mutex key）：只允许一个线程重建缓存，其他线程等待重建缓存的线程执行完，重新从缓存获取数据即可。</li>
<li>永远不过期：为每个 value 设置一个逻辑过期时间，当发现超过逻辑过期时间后，会使用单独的线程去构建缓存。</li>
</ul>
</li>
</ul>
<h1>38. 无底洞问题吗？如何解决？</h1>
<ul>
<li>添加 Memcache 节点，但是发现性能不但没有好转反而下降了，这种现象称为缓存的“无底洞”现象。</li>
<li>为什么?键值数据库由于通常采用哈希函数将 key 映射到各个节点上，造成 key 的分布与业务无关，但是由于数据量和访问量的持续增长，造成需要添加大量节点做水平扩容，导致键值分布到更多的 节点上，所以无论是 Memcache 还是 Redis 的分布式，批量操作通常需要从不同节点上获取，相比于单机批量操作只涉及一次网络操作，分布式批量操作会涉及多次网络时间。</li>
<li>无底洞问题如何优化呢？
<ul>
<li>客户端一次批量操作会涉及多次网络操作，也就意味着批量操作会随着节点的增多，耗时会不断增大。</li>
<li>网络连接数变多，对节点的性能也有一定影响。</li>
</ul>
</li>
<li>优化思路
<ul>
<li>命令本身的优化，例如优化操作语句等。</li>
<li>减少网络通信次数。</li>
<li>降低接入成本，例如客户端使用长连/连接池、NIO 等。</li>
</ul>
</li>
</ul>
<h1>39. Redis 报内存不足怎么处理？</h1>
<ul>
<li>redis.conf配置maxmemory 100mb</li>
<li>config set maxmemory 命令动态设置内存上限</li>
<li>修改内存淘汰策略，及时释放内存空间</li>
<li>使用 Redis 集群模式，进行横向扩容。</li>
</ul>
<h1>40. Redis的过期键的删除策略</h1>
<ul>
<li>惰性过期：只有当访问key已过期时才清除。可以节省CPU资源，内存占用大。</li>
<li>定期清除：每隔一定的时间扫描一定数量的数据库的expires字典中一定数量的key，并清除其中已过期的key。通过调整定时扫描的时间间隔和每次扫描的限定耗时，使得CPU和内存资源达到最优的平衡效果。(expires字典会保存所有设置了过期时间的key的过期时间数据，其中，key是指向键空间中的某个键的指针，value是该键的毫秒精度的UNIX时间戳表示的过期时间。键空间是指该Redis集群中保存的所有键。)</li>
<li>config get hz每秒执行其内部定时任务（如过期键的清理）的频率几次。CONFIG SET hz 20 进行调整，或者直接通过配置文件中的 hz 设置。</li>
</ul>
<h1>41. Redis内存淘汰策略有哪些？</h1>
<ul>
<li>
<p>Redis的内存淘汰策略是指在Redis的用于缓存的内存不足时，怎么处理需要新写入且需要申请额外空间的数据。</p>
</li>
<li>
<p>no-eviction(默认)：当内存不足以容纳新写入数据时，新写入操作会报错。</p>
</li>
<li>
<p>allkeys-lru：从数据集（server. db[i]. dict），移除最近最少使用（访问时间小）的key。</p>
</li>
<li>
<p>allkeys-random：从数据集（server. db[i]. dict），随机移除某个key。</p>
</li>
<li>
<p>allkeys-lfu 从数据集（server. db[i]. dict），移除最近访问的频率/次数最少的key</p>
</li>
<li>
<p>volatile-lru：从设置了过期时间的键空间（server. db[i]. expires）中，移除最近最少使用的key。</p>
</li>
<li>
<p>volatile-random：从设置了过期时间的键空间（server. db[i]. expires）中，随机移除某个key。</p>
</li>
<li>
<p>volatile-lfu 从设置了过期时间的键空间（server. db[i]. expires）中，移除最近访问的频率最少的key</p>
</li>
<li>
<p>volatile-ttl：从设置了过期时间的键空间（server. db[i]. expires）中，移除将要过期的key。</p>
</li>
<li>
<p>Redis使用近似的LRU算法，通过随机采样法淘汰数据，每次随机出maxmenory-samples（默认5）个key，从里面淘汰掉最近最少使用的key。maxmenory-samples越大，淘汰结果越接近于严格的LRU算法，每个key额外增加了一个24bit的字段，用来存储该key最后一次被访问的时间。Redis不实现严格的LRU算是的原因是，因为消耗更多的内存。</p>
</li>
<li>
<p>Redis3.0新算法会维护一个候选池（大小为16），池中的数据根据访问时间进行排序，第一次随机选取的key都会放入池中，随后每次随机选取的key只有在访问时间小于池中最小的时间才会放入池中，直到候选池被放满。当放满后，如果有新的key需要放入，则将池中最后访问时间最大（最近被访问）的移除。当需要淘汰的时候，则直接从池中选取最近访问时间最小（最久没被访问）的key淘汰掉就行。</p>
</li>
<li>
<p>获取当前内存淘汰策略：config get maxmemory-policy</p>
</li>
<li>
<p>修改淘汰策略：config set maxmemory-policy allkeys-lru</p>
</li>
<li>
<p>redis.conf文件：maxmemory-policy allkeys-lru</p>
</li>
</ul>
<h1>42. Redis 阻塞？怎么解决？</h1>
<ul>
<li>API 或数据结构使用不合理：对于高并发的场景，应该尽量避免在大对象上执行算法复杂 度超过 O（n）的命令。对慢查询的处理分为两步：
<ul>
<li>发现慢查询： slowlog get{n}命令可以获取最近 的 n 条慢查询命令；</li>
<li>优化慢查询：
<ul>
<li>修改为低算法复杂度的命令，如 hgetall 改为 hmget 等，禁用 keys、sort 等命 令</li>
<li>调整大对象：缩减大对象数据或把大对象拆分为多个小对象，防止一次命令操作过多的数据。</li>
</ul>
</li>
</ul>
</li>
<li>CPU饱和的问题 Redis 单核 CPU 使用率跑到接近 100%。
<ul>
<li>判断当前 Redis 并发量是否已经达到极限，可以使用统计命令 redis-cli-h{ip}-p{port}--stat 获取当前 Redis 使用情况如果 Redis 的请求几万+，那么大概就是 Redis 的 OPS 已经到了极限，应该做集群化水品扩展来分摊 OPS 压力如果只有几百几千，那么就得排查命令和内存的使用</li>
</ul>
</li>
<li>持久化相关的阻塞
<ul>
<li>fork 阻塞：fork 操作发生在 RDB 和 AOF 重写时，Redis 主线程调用 fork 操作产生共享 内存的子进程，由子进程完成持久化文件重写工作。如果 fork 操作本身耗时过长，必然会导致主线程的阻塞。</li>
<li>AOF 刷盘阻塞：当开启 AOF 持久化功能时，文件刷盘的方式一般采用每秒一次，后台线程每秒对 AOF 文件做 fsync 操作。当硬盘压力过大时，fsync 操作需要等 待，直到写入完成。如果主线程发现距离上一次的 fsync 成功超过 2 秒，为了 数据安全性它会阻塞直到后台线程执行 fsync 操作完成。</li>
<li>HugePage 写操作阻塞：对于开启 Transparent HugePages 的 操作系统，每次写命令引起的复制内存页单位由 4K 变为 2MB，放大了 512 倍，会拖慢写操作的执行时间，导致大量写操作慢查询。</li>
</ul>
</li>
</ul>
<h1>43. 大 key 问题了解吗？</h1>
<ul>
<li>大 key 指的是存储了大量数据的键，比如：单个简单的 key 存储的 value 很大，size 超过 10KB。hash，set，zset，list 中存储过多的元素（以万为单位）</li>
<li>大 key 会造成的问题呢？
<ul>
<li>客户端超时</li>
<li>对大 key 进行 IO 操作时，会严重占用带宽和 CPU</li>
<li>造成 Redis 集群中数据倾斜</li>
<li>主动删除、被动删等，可能会导致阻塞</li>
</ul>
</li>
<li>如何找到大 key?
<ul>
<li>bigkeys 参数：使用 bigkeys 命令以遍历的方式分析 Redis 实例中的所有 Key，并返回整体统计信息与每个数据类型中 Top1 的大 Key。redis-cli --bigkeys</li>
<li>redis-rdb-tools：redis-rdb-tools 是由 Python 语言编写的用来分析 Redis 中 rdb 快照文件的工具。</li>
</ul>
</li>
<li>如何处理大 key?
<ul>
<li>删除大 key
<ul>
<li>当Redis版本大于4.0 时，可使用 UNLINK 命令安全地删除大 Key，该命令能够以非阻塞的方式，逐步地清理传入的大 Key。</li>
<li>当Redis版本小于 4.0 时，建议通过 SCAN 命令执行增量迭代扫描 key，然后判断进行删除。</li>
</ul>
</li>
<li>压缩和拆分 key
<ul>
<li>当vaule是string时，使用序列化、压缩算法将key的大小控制在合理范围内，但是序列化和反序列化都会带来额外的性能消耗</li>
<li>当 value 是 string，压缩之后仍然是大 key 时，则需要进行拆分，将一个大 key 分为不同的部分，记录每个部分的 key，使用 multiget 等操作实现事务读取。</li>
<li>当 value 是 list/set 等集合类型时，根据预估的数据规模来进行分片，不同的元素计算后分到不同的片。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1>44. Redis 常见性能问题和解决方案？</h1>
<ul>
<li>Master 最好不要做任何持久化工作，包括内存快照和 AOF 日志文件，特别是不要启用内存快照做持久化。因为Master写内存快照，save命令调度rdbSave函数，会阻塞主线程的工作，当快照比较大时对性能影响是非常大的，会间断性暂停服务，而Master AOF持久化，如果不重写AOF文件，AOF 文件过大会影响 Master 重启的恢复速度。</li>
<li>如果数据比较关键，某个 Slave 开启 AOF 备份数据，策略为每秒同步一次。</li>
<li>为了主从复制的速度和连接的稳定性，Slave 和 Master 最好在同一个局域网内。</li>
<li>尽量避免在压力较大的主库上增加从库。可以考虑在从上挂载其它的从。</li>
<li>Master 调用 BGREWRITEAOF 重写 AOF 文件会占大量的 CPU 和内存资源，导致服务 load 过高，出现短暂服务暂停现象。</li>
<li>为了 Master 的稳定性，主从复制不要用图状结构，用单向链表结构更稳定，即主从关为：Master&lt;–Slave1&lt;–Slave2&lt;–Slave3…，这样的结构也方便解决单点故障问题，实现 Slave 对 Master 的替换，也即，如果 Master 挂了，可以立马启用 Slave1 做 Master，其他不变。从节点在切换主节点作为复制源的时候，会重新发起全量复制。所以此处通过 Slave1 挂在 Slave 下，可以规避这个问题。同时，也减少了 Master 的复制压力。坏处是 Slave1 的延迟可能会高一些些，所以需要取舍。</li>
</ul>
<h1>45. 使用 Redis 如何实现异步队列？</h1>
<ul>
<li>使用 list 作为队列，lpush 生产消息，rpop 消费消息， 消费者死循环 rpop 从队列中消费消息。但是这样，即使队列里没有消息，也会进行 rpop，会导致 Redis CPU 的消耗。可以通过让消费者休眠的方式的方式来处理，但是这样又会又消息的延迟问题。</li>
<li>使用 list 作为队列，lpush 生产消息，brpop 消费消息 brpop 是 rpop 的阻塞版本，list 为空的时候，它会一直阻塞，直到 list 中有值或者超时。只能实现一对一的消息队列。</li>
<li>使用 Redis 的 pub/sub 来进行消息的发布/订阅：可以 1：N 的消息发布/订阅。发布者将消息发布到指定的频道频道（channel），订阅相应频道的客户端都能收到消息。但是这种方式不是可靠的，在消费者下线的情况下，生产的消息会丢失，</li>
<li>所以，一般的异步队列的实现还是交给专业的消息队列。</li>
</ul>
<h1>46. Redis 如何实现延时队列?</h1>
<p>使用 Redis 的 zset（有序集合）来实现延时队列。</p>
<ul>
<li>第一步，将任务添加到 zset 中，score 为任务的执行时间戳，value 为任务的内容。ZADD delay_queue 1617024000 task1</li>
<li>第二步，定期（例如每秒）从 zset 中获取 score 小于当前时间戳的任务，然后执行任务。ZREMRANGEBYSCORE delay_queue -inf 1617024000</li>
<li>第三步，从 zset 中删除任务。ZREM delay_queue task1</li>
<li>Redis 真的真的真的不推荐作为消息队列使用，它最多只是消息队列的存储层，上层的逻辑，还需要做大量的封装和支持。</li>
<li>在 Redis 5.0 增加了 Stream 功能，一个新的强大的支持多播的可持久化的消息队列，提供类似 Kafka 的功能。</li>
</ul>
<h1>47. Redis 支持事务吗？</h1>
<ul>
<li>Redis支持事务，可将多个命令打包，然后一次性按照顺序执行。主要通过 multi、exec、discard、watch 等命令来实现：
<ul>
<li>multi：标记一个事务块的开始</li>
<li>exec：执行所有事务块内的命令</li>
<li>discard：取消事务，放弃执行事务块内的所有命令</li>
<li>watch：监视一个或多个 key，如果在事务执行之前这个 key 被其他命令所改动，那么事务将被打断</li>
</ul>
</li>
<li>Redis 事务的原理：
<ul>
<li>使用 MULTI 命令开始一个事务。从这个命令执行之后开始，所有的后续命令都不会立即执行，而是被放入一个队列中。在这个阶段，Redis 只是记录下了这些命令。</li>
<li>在事务开启之前，如果客户端与服务器之间出现通讯故障并导致网络断开，其后所有待执行的语句都将不会被服务器执行。使用 EXEC 命令触发事务的执行。一旦执行了 EXEC，之前 MULTI 后队列中的所有命令会被原子地（atomic）执行。意味着这些命令要么全部执行，要么（在出现错误时）全部不执行。Lua 脚本也能实现原子操作。</li>
<li>如果在执行 EXEC 之前决定不执行事务，可以使用 DISCARD 命令来取消事务。这会清空事务队列并退出事务状态。</li>
<li>WATCH 命令用于实现乐观锁。WATCH 命令可以监视一个或多个键，如果在执行事务的过程中（即在执行 MULTI 之后，执行 EXEC 之前），被监视的键被其他命令改变了，那么当执行 EXEC 时，事务将被取消，并且返回一个错误。</li>
<li>Redis事务中如果有某一条命令执行失败，其后的命令仍然会被继续执行。Lua脚本不具备。<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/f34f8d376ea048a0b46b7.png" alt="redistransaction.png"></li>
</ul>
</li>
</ul>
<h1>48. Redis 事务的注意点有哪些？</h1>
<ul>
<li>Redis 事务是不支持回滚的，一旦 EXEC 命令被调用，所有命令都会被执行，即使有些命令可能执行失败。失败的命令不会影响到其他命令的执行。</li>
</ul>
<h1>49. Redis 事务为什么不支持回滚？</h1>
<ul>
<li>引入事务回滚机制会大大增加 Redis 的复杂性，因为需要跟踪事务中每个命令的状态，并在发生错误时逆向执行命令以恢复原始状态。</li>
<li>Redis 是一个基于内存的数据存储系统，其设计重点是实现高性能。事务回滚需要额外的资源和时间来管理和执行，这与 Redis 的设计目标相违背。因此，Redis 选择不支持事务回滚。</li>
</ul>
<h1>50. Redis 和 Lua 脚本的使用了解吗？</h1>
<ul>
<li>Lua 脚本在 Redis 中是原子执行的，执行过程中间不会插入其他命令。</li>
<li>Lua 脚本可以帮助开发和运维人员创造出自己定制的命令，并可以将这 些命令常驻在 Redis 内存中，实现复用的效果。</li>
<li>Lua 脚本可以将多条命令一次性打包，有效地减少网络开销。</li>
<li>比如这一段很（烂）经（大）典（街）的秒杀系统利用 lua 扣减 Redis 库存的脚本：</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>  -- 库存未预热
  if (redis.call('exists', KEYS[2]) == 1) then
      return -9;
  end;
  -- 秒杀商品库存存在
  if (redis.call('exists', KEYS[1]) == 1) then
      local stock = tonumber(redis.call('get', KEYS[1]));
      local num = tonumber(ARGV[1]);
      -- 剩余库存少于请求数量
      if (stock &lt; num) then
          return -3
      end;
      -- 扣减库存
      if (stock &gt;= num) then
          redis.call('incrby', KEYS[1], 0 - num);
          -- 扣减成功
          return 1
      end;
      return -2;
  end;
  -- 秒杀商品库存不存在
  return -1;
</code></pre></div><h1>51. Redis 的管道Pipelining了解吗？</h1>
<ul>
<li>Redis提供三种将客户端多条命令打包发送给服务端执行的方式：Pipelining(管道) 、 Transactions(事务) 和 Lua Scripts(Lua 脚本) 。</li>
<li>Pipelining（管道）:当客户端需要执行多条 redis 命令时，可以通过管道一次性将要执行的多条命令发送给服务端，使用 nc 命令将两条指令发送给 redis 服务端。Redis 服务端接收到管道发送过来的多条命令后，会一直执命令，并将命令的执行结果进行缓存，直到最后一条命令执行完成，再所有命令的执行结果一次性返回给客户端 。</li>
<li>Pipelining 的优势
<ul>
<li>节省了 RTT：将多条命令打包一次性发送给服务端，减少了客户端与服务端之间的网络调用次数</li>
<li>减少了上下文切换：当客户端/服务端需要从网络中读写数据时，都会产生一次系统调用，系统调用是非常耗时的操作，其中设计到程序由用户态切换到内核态，再从内核态切换回用户态的过程。只会产生一次上下文切换。</li>
</ul>
</li>
</ul>
<h1>52. Redis 实现分布式锁了解吗？</h1>
<ul>
<li>
<p>分布式锁考虑要点</p>
<ul>
<li>1.正确的获得锁(保证有且只有一个进程获得到) set 指令附带 nx 参数</li>
<li>2.正确的释放锁:使用 Lua 脚本，比对锁持有的是不是自己。如果是，则进行del指令删除来释放。</li>
<li>3.超时的自动释放锁set 指令附带 expire参数，通过过期机制来实现超时释放。</li>
<li>4.未获得到锁的等待机制:sleep或者基于Redis订阅 Pub/Sub 机制。一些业务场景，可能需要支持获得不到锁，直接返回false ，不等待</li>
<li>5.重入性(可选):通过<code>ThreadLocal&lt;Integer&gt;</code>记录是第几次获得相同的锁。有且第一次计数为1&amp;&amp;获得锁时，才向 Redis 发起获得锁的操作;有且计数为 0 &amp;&amp; 释放锁时，才向 Redis 发起释放锁的操作。</li>
<li>6、锁超时的处理：可以考虑告警 + 后台线程自动续锁的超时时间。通过这样的机制，保证有且仅有一个线程，正在持有锁。</li>
<li>7、Redis 分布式锁丢失问题 看方案2 Redlock</li>
</ul>
</li>
<li>
<p>方案1。使用set指令SET key_name my_random_value NX PX 30000</p>
<ul>
<li>NX表示if not exist 就设置并返回True，否则不设置并返回False</li>
<li>PX表示过期时间用毫秒级， 30000表示这些毫秒时间后此key过期</li>
<li>del释放锁</li>
<li>缺点是加锁时只作用在一个Redis节点上，即使Redis通过sentinel保证高可用，如果这个master节点由于某些原因发生了主从切换，在Redis的master节点上拿到了锁；但是这个加锁的key还没有同步到slave节点；master故障，发生故障转移，slave节点升级为master节点；导致锁丢失。</li>
</ul>
</li>
<li>
<p>方案2:使用Redlock，多Redis节点的场景下，会存在分布式锁丢失的问题。</p>
<ul>
<li>客户端业务逻辑</li>
<li>获取当前Unix时间，以毫秒为单位。</li>
<li>依次尝试从5个实例，使用相同的key和具有唯一性的value（例如UUID）获取锁。当向Redis请求获取锁时，客户端应该设置一个网络连接和响应超时时间，这个超时时间应该小于锁的失效时间。例如你的锁自动失效时间为10秒，则超时时间应该在5-50毫秒之间。这样可以避免服务器端Redis已经挂掉的情况下，客户端还在死死地等待响应结果。如果服务器端没有在规定时间内响应，客户端应该尽快尝试去另外一个Redis实例请求获取锁。</li>
<li>客户端使用当前时间减去开始获取锁时间（步骤1记录的时间）就得到获取锁使用的时间。当且仅当从大多数（N/2+1，这里是3个节点）的Redis节点都取到锁，并且使用的时间小于锁失效时间时，锁才算获取成功</li>
<li>如果取到了锁，key的真正有效时间等于有效时间减去获取锁所使用的时间（步骤3计算的结果）。</li>
<li>如果因为某些原因，获取锁失败（没有在至少N/2+1个Redis实例取到锁或者取锁时间已经超过了有效时间），客户端应该在所有的Redis实例上进行解锁（即便某些Redis实例根本就没有加锁成功，防止某些节点获取到锁但是客户端没有得到响应而导致接下来的一段时间不能被重新获取锁）。</li>
</ul>
</li>
</ul>
<h1>53. 说说 Redis 底层数据结构？</h1>
<ul>
<li>Redis 的底层数据结构有动态字符串(sds)、链表(list)、字典(ht)、跳跃表(skiplist)、整数集合(intset)、压缩列表(ziplist) 等。<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/286143af1a640cebce01b.png" alt="redisobject.png"><br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/8a6db82c6dc41e933a53c.png" alt="redistype.png"></li>
<li>list 是通过链表实现的，hash 是通过字典实现的，set 是通过字典实现的，zset 是通过跳跃表实现的。</li>
</ul>
<h1>54. 简单介绍下 SDS</h1>
<ul>
<li>string 是通过 SDS(simple dynamic String) 实现的.Redis 是通过 C 语言实现的，但 Redis 实现了一种叫做动态字符串 SDS 的类型。SDS 保存了⻓度信息将获取字符串⻓度的时间由 O(N) 降低到了 O(1)。</li>
<li>针对缓存频繁修改的情况：SDS分配内存不仅会分配需要的空间，还会分配额外的空间。小于1MB的SDS每次分配与len属性同样大小的空间大于1MB的每次分配1MB</li>
<li>两种编码方式：object encoding [key]查看
<ul>
<li>embstr编码：保存长度&lt;=39字符串值</li>
<li>raw编码： 对embstr字符串执行任何修改命令时，程序会转换编码为raw。</li>
<li>中文默认占三个字符。</li>
</ul>
</li>
<li>优先使用embstr编码的原因：embstr只会分配一块连续内存，读取快，只用释放1块内存；而raw分配2块不连续内存，读取较慢，需要释放2块内存</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>struct sdshdr {
    int len; // buf 中已使用的长度 记录SDS所保存的字符串长度,保证了O(1) 时间复杂度查询字符串长度信息。
    int free; // buf 中未使用的长度 惰性释放策略：不立即使用内存重分配来回收缩短后多出来的字节，而是使用free属性，记录buf数组中未使用字节的数量。空闲出来的空间，可以让str在进行append的时候重新使用
    char buf[]; // 字节数组，用于保存字符串
};
</code></pre></div><h1>55. 简单介绍下链表 linkedlist</h1>
<ul>
<li>Redis 的链表是⼀个双向⽆环链表结构，链表的节点由⼀个叫做 listNode 的结构来表示，每个节点都有指向其前置节点和后置节点的指针，同时头节点的前置和尾节点的后置均指向 null。<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/08b7a2d79fab187c13b68.png" alt="redislinkedlist.png"></li>
</ul>
<h1>56. 简单介绍下字典 dict</h1>
<ul>
<li>⽤于保存键值对的抽象数据结构。Redis 使⽤ hash 表作为底层实现，一个哈希表里可以有多个哈希表节点，而每个哈希表节点就保存了字典里中的一个键值对。</li>
<li>每个字典带有两个 hash 表，供平时使⽤和 rehash 时使⽤，hash 表使⽤链地址法来解决键冲突，被分配到同⼀个索引位置的多个键值对会形成⼀个单向链表，在对 hash 表进⾏扩容或者缩容的时候，为了服务的可⽤性，rehash 的过程不是⼀次性完成的，⽽是渐进式的。<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/5b18144627f882d3c2c70.png" alt="redisdict.png"></li>
</ul>
<h1>57. 简单介绍下跳跃表 skiplist</h1>
<ul>
<li>跳跃表（也称跳表）是有序集合 Zset 的底层实现之⼀。在 Redis 7.0 之前，如果有序集合的元素个数小于 128 个，并且每个元素的值小于 64 字节时，Redis 会使用压缩列表作为 Zset 的底层实现，否则会使用跳表；在 Redis 7.0 之后，压缩列表已经废弃，交由 listpack 来替代。</li>
<li>跳表由 zskiplist 和 zskiplistNode 组成，zskiplist ⽤于保存跳表的基本信息（表头、表尾、⻓度、层高等）。</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>typedef struct zskiplist {
    struct zskiplistNode *header, *tail;
    unsigned long length;
    int level;
} zskiplist;
</code></pre></div><p>zskiplistNode ⽤于表示跳表节点，每个跳表节点的层⾼是不固定的，每个节点都有⼀个指向保存了当前节点的分值和成员对象的指针</p>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>typedef struct zskiplistNode {
    sds ele;
    double score;
    struct zskiplistNode *backward;
    struct zskiplistLevel {
        struct zskiplistNode *forward;
        unsigned int span;
    } level[];
} zskiplistNode;
</code></pre></div><figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/32d61a5bdb21dda3126a4.png" alt="redisskiplist.png" tabindex="0"><figcaption>redisskiplist.png</figcaption></figure>
<h1>58. 简单介绍下整数集合 intset</h1>
<ul>
<li>⽤于保存整数值的集合抽象数据结构，不会出现重复元素，底层实现为数组。<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/2189558ff281b5d485a73.png" alt="redisintset.png"></li>
</ul>
<h1>59. 简单介绍下压缩列表 ziplist</h1>
<ul>
<li>压缩列表是为节约内存⽽开发的顺序性数据结构，它可以包含任意多个节点，每个节点可以保存⼀个字节数组或者整数值。<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/6b67240f69c591b8c961e.png" alt="redisintset.png"></li>
</ul>
<h1>60. 简单介绍下紧凑列表 listpack</h1>
<ul>
<li>listpack 是 Redis 用来替代压缩列表（ziplist）的一种内存更加紧凑的数据结构。<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/1a8fd93a9d6d25ebab65e.png" alt="redislistpack1.png"><br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/1495870c3cce2463435cd.png" alt="redislistpack2.png"></li>
<li>为了避免 ziplist 引起的连锁更新问题，listpack 中的元素不再像 ziplist 那样，保存其前一个元素的长度，而是保存当前元素的编码类型、数据，以及编码类型和数据的长度。</li>
<li>listpack 每个元素项不再保存上一个元素的长度，而是优化元素内字段的顺序，来保证既可以从前也可以向后遍历。但因为 List/Hash/Set/ZSet 都严重依赖 ziplist，所以这个替换之路很漫长。</li>
</ul>
<h1>61. Redis 的 SDS 和 C 中字符串相比有什么优势？</h1>
<ul>
<li>C 语言使用了一个长度为 N+1 的字符数组来表示长度为 N 的字符串，并且字符数组最后一个元素总是 \0，这种简单的字符串表示方式 不符合 Redis 对字符串在安全性、效率以及功能方面的要求。</li>
<li>C 语言的字符串可能有什么问题？
<ul>
<li>获取字符串长度复杂度高 ：因为 C 不保存数组的长度，每次都需要遍历一遍整个数组，时间复杂度为 O(n)；</li>
<li>不能杜绝 缓冲区溢出/内存泄漏 的问题 : C 字符串不记录自身长度带来的另外一个问题是容易造成缓存区溢出（buffer overflow），例如在字符串拼接的时候，新的 C 字符串 只能保存文本数据 → 因为 C 语言中的字符串必须符合某种编码（比如 ASCII），例如中间出现的 '\0' 可能会被判定为提前结束的字符串而识别不了；</li>
</ul>
</li>
<li>Redis 如何解决？优势？
<ul>
<li>多增加 len 表示当前字符串的长度：这样就可以直接获取长度了，复杂度 O(1)；</li>
<li>自动扩展空间：当 SDS 需要对字符串进行修改时，首先借助于 len 和 alloc 检查空间是否满足修改所需的要求，如果空间不够的话，SDS 会自动扩展空间，避免了像 C 字符串操作中的溢出情况；</li>
<li>有效降低内存分配次数：C 字符串在涉及增加或者清除操作时会改变底层数组的大小造成重新分配，SDS 使用了 空间预分配 和 惰性空间释放 机制，简单理解就是每次在扩展时是成倍的多分配的，在缩容是也是先留着并不正式归还给 OS；</li>
<li>二进制安全：C 语言字符串只能保存 ascii 码，对于图片、音频等信息无法保存，SDS 是二进制安全的，写入什么读取就是什么，不做任何过滤和限制；</li>
</ul>
</li>
</ul>
<h1>62. 字典是如何实现的？Rehash 了解吗？</h1>
<ul>
<li>字典是 Redis中的复合型数据结构。除了 hash 结构的数据会用到字典外，整个 Redis 数据库的所有 key 和 value 也组成了一个 全局字典，还有带过期时间的 key 也是一个字典。(存储在 RedisDb 数据结构中)</li>
<li>字典结构是什么样的呢？
<ul>
<li>Redis 中的字典相当于 HashMap，内部实现也差不多类似，采用哈希与运算计算下标位置；通过 "数组 + 链表" 的链地址法 来解决哈希冲突，同时这样的结构也吸收了两种不同数据结构的优点。<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/6a33584914c5e7460bb24.png" alt="redisdictstructure.png"></li>
</ul>
</li>
<li>字典是怎么扩容的？字典结构内部包含 两个 hashtable，通常情况下只有一个哈希表 ht[0] 有值，在扩容的时候，把 ht[0]里的值 rehash 到 ht[1]，然后进行 渐进式 rehash ——指的是这个 rehash 的动作并不是一次性、集中式地完成的，而是分多次、渐进式地完成的。待搬迁结束后，h[1]就取代 h[0]存储字典的元素。</li>
</ul>
<h1>63. 跳表是如何实现的？原理？</h1>
<ul>
<li>
<p>跳表（skiplist）是一种有序的数据结构，它通过在每个节点中维持多个指向其它节点的指针，从而达到快速访问节点的目的。<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/a7951d9857a4280688544.png" alt="redisskipliststructure.png"></p>
</li>
<li>
<p>为什么使用跳表？</p>
<ul>
<li>首先，因为 zset 要支持随机的插入和删除，所以不宜使用数组来实现，关于排序问题，为什么 Redis 不使用 红黑树/ 平衡树 这样的树形结构呢？
<ul>
<li>性能考虑： 在高并发的情况下，树形结构需要执行一些类似于 rebalance 这样的可能涉及整棵树的操作，相对来说跳跃表的变化只涉及局部；</li>
<li>实现考虑： 在复杂度与红黑树相同的情况下，跳跃表实现起来更简单，看起来也更加直观；</li>
</ul>
</li>
</ul>
</li>
<li>
<p>基于以上的一些考虑，Redis 基于 William Pugh 的论文做出一些改进后采用了 跳跃表 这样的结构。本质是解决查找问题。</p>
</li>
<li>
<p>跳跃表是怎么实现的？</p>
<ul>
<li>层:跳跃表节点的 level 数组可以包含多个元素，每个元素都包含一个指向其它节点的指针，程序可以通过这些层来加快访问其它节点的速度，一般来说，层的数量月多，访问其它节点的速度就越快。每次创建一个新的跳跃表节点的时候，程序都根据幂次定律，随机生成一个介于 1 和 32 之间的值作为 level 数组的大小，这个大小就是层的“高度”</li>
<li>前进指针:每个层都有一个指向表尾的前进指针（level[i].forward 属性），用于从表头向表尾方向访问节点。跳跃表从表头到表尾，遍历所有节点的路径：<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/3136d8d54c55cc6c2f03e.png" alt="redisskiplist2.png"></li>
<li>跨度:层的跨度用于记录两个节点之间的距离。跨度是用来计算排位（rank）的：在查找某个节点的过程中，将沿途访问过的所有层的跨度累计起来，得到的结果就是目标节点在跳跃表中的排位。例如查找，分值为 3.0、成员对象为 o3 的节点时，沿途经历的层：查找的过程只经过了一个层，并且层的跨度为 3，所以目标节点在跳跃表中的排位为 3。<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/98080a9ce2004af2da6e2.png" alt="redisskiplist3.png"></li>
<li>分值和成员
<ul>
<li>节点的分值（score 属性）是一个 double 类型的浮点数，跳跃表中所有的节点都按分值从小到大来排序。</li>
<li>节点的成员对象（obj 属性）是一个指针，它指向一个字符串对象，而字符串对象则保存这一个 SDS 值。</li>
</ul>
</li>
</ul>
</li>
<li>
<p>为什么 hash 表范围查询效率比跳表低？</p>
<ul>
<li>哈希表是一种基于键值对的数据结构，主要用于快速查找、插入和删除操作。哈希表通过计算键的哈希值来确定值的存储位置，这使得它在单个元素的访问上非常高效，时间复杂度为 O(1)。然而，哈希表内的元素是无序的。因此，对于范围查询（如查找所有在某个范围内的元素），哈希表无法直接支持，必须遍历整个表来检查哪些元素满足条件，这使得其在范围查询上的效率低下，时间复杂度为 O(n)。</li>
<li>跳表是一种有序的数据结构，能够保持元素的排序顺序。它通过多层的链表结构实现快速的插入、删除和查找操作，其中每一层都是下一层的一个子集，并且元素在每一层都是有序的。当进行范围查询时，跳表可以从最高层开始，快速定位到范围的起始点，然后沿着下一层继续直到找到范围的结束点。这种分层的结构使得跳表在进行范围查询时非常高效，时间复杂度为 O(log n) 加上范围内元素的数量。</li>
</ul>
</li>
</ul>
<h1>64. 压缩列表了解吗？</h1>
<ul>
<li>压缩列表是 Redis 为了节约内存 而使用的一种数据结构，是由一系列特殊编码的连续内存快组成的顺序型数据结构。</li>
<li>一个压缩列表可以包含任意多个节点（entry），每个节点可以保存一个字节数组或者一个整数值。</li>
<li>压缩列表由这么几部分组成：
<ul>
<li>zlbyttes:记录整个压缩列表占用的内存字节数</li>
<li>zltail:记录压缩列表表尾节点距离压缩列表的起始地址有多少字节</li>
<li>zllen:记录压缩列表包含的节点数量</li>
<li>entryX:列表节点</li>
<li>zlend:用于标记压缩列表的末端</li>
</ul>
</li>
</ul>
<h1>65. 快速列表 quicklist 了解吗？</h1>
<ul>
<li>Redis 早期版本存储 list 列表数据结构使用的是压缩列表 ziplist 和普通的双向链表 linkedlist，也就是说当元素少时使用 ziplist，当元素多时用 linkedlist。但考虑到链表的附加空间相对较高，prev 和 next 指针就要占去 16 个字节（64 位操作系统占用 8 个字节），另外每个节点的内存都是单独分配，会家具内存的碎片化，影响内存管理效率。</li>
<li>后来 Redis 新版本（3.2）对列表数据结构进行了改造，使用 quicklist 代替了 ziplist 和 linkedlist，quicklist 是综合考虑了时间效率与空间效率引入的新型数据结构。</li>
<li>quicklist 由 list 和 ziplist 结合而成，它是一个由 ziplist 充当节点的双向链表。<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/e75ae267da34aae84f393.png" alt="redisquicklist.png"></li>
</ul>
<h1>66. 假如 Redis 里面有 1 亿个 key，其中有 10w 个 key 是以某个固定的已知的前缀开头的，如何将它们全部找出来？</h1>
<ul>
<li>keys指令可以扫出指定模式的key列表（keys xxx*）但会导致线程阻塞，线上服务会停顿，直到指令执行完毕，服务才恢复。</li>
<li>使用scan指令无阻塞的提取出指定模式的key列表，但可能重复，在客户端做去重就可以了，但是整体所花费的时间会比直接用 keys指令长。(scan 0 match "api_<em>"...-&gt;scan 100 match "api_</em>")一直到cursor为0</li>
</ul>
<p>==========================================================================================================</p>
<h1>67. AOF实现原理？混合模式下什么时候aof，什么时候rdb√?</h1>
<ul>
<li>
<p>AOF以协议文本的方式，将所有对数据库进行过写入的命令（及其参数）记录到AOF文件</p>
</li>
<li>
<p>aof过程：将写操作命令保存到AOF文件的过程称为同步，则包括下面三个步骤</p>
<ul>
<li>命令传播：服务端接收到客服端发送的协议文本，转换成执行命令数据，Redis将执行完的命令、命令的参数、命令的参数个数等信息发送到AOF程序中。</li>
<li>缓存追加：AOF程序根据接收到的命令数据，将命令转换为网络通讯协议的格式，然后将协议内容追加到服务器的AOF缓存（redis.h/redisServer结构的aof_buf）中。</li>
<li>文件写入和保存：调用aof.c/flushAppendOnlyFile函数，利用SAVE方法将AOF缓存中的内容写入到AOF文件末尾；如果满足保存条件，调用fsync或fdatasync函数，将写入的内容真正地保存S到磁盘中</li>
</ul>
</li>
<li>
<p>aof保存模式：决定flushAppendOnlyFile函数的WRITE和SAVE的调用条件</p>
<ul>
<li>AOF_FSYNC_NO：不保存。WRITE由主线程执行，阻塞主进程，不执行SAVE；SAVE只会在Redis被关闭、AOF功能被关闭、系统的写缓存被刷新（可能是缓存已经被写满，或者定期保存操作被执行）执行</li>
<li>AOF_FSYNC_ALWAYS：每次执行完命令，SAVE和WRITE都由主进程执行，阻塞主进程。效率最低</li>
<li>AOF_FSYNC_EVERYSEC：每秒钟保存一次。WRITE由主进程执行，阻塞主进程。SAVE由子线程执行，不阻塞主进程，但保存操作完成的快慢会影响写入操作的阻塞时长。注意，实际程序在这种模式下对fsync或fdatasync的调用并不是每秒一次，它和调用flushAppendOnlyFile函数时Redis所处的状态有关。可能会出现以下四种情况：如果在情况1中发生故障停机， 用户损失小于2秒内所产生的所有数据。如果在情况2发生故障停机， 那么用户损失的数据是可以超过2秒的。AOF在官网“每一秒钟保存一次”时发生故障， 只丢失1秒钟数据的说法， 实际上并不准确<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/d2657edd4a6537c3fa680.png" alt="aofsavemodel.png"><br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/aec14a48266b109e90cbd.png" alt="aofsavemodelcompare.png"></li>
</ul>
</li>
</ul>
<h1>68. redis优缺点？</h1>
<ul>
<li>
<p>优点</p>
<ul>
<li>速度快：因为数据存在内存中</li>
<li>支持丰富数据类型String，List，Set，Sorted Set，Hash 五种基础的数据结构。单个Value最大限制是1GB，还提供Bitmap、HyperLogLog、GEO 等高级的数据结构</li>
<li>丰富的特性：订阅发布Pub/Sub功能；Key过期策略；事务；支持多个DB；计数；Stream功能，支持多播的可持久化的消息队列，提供类似Kafka的功能</li>
<li>持久化存储：提供RDB和AOF两种数据的持久化存储方案，解决内存数据库数据丢失问题</li>
<li>高可用：内置Redis Sentinel提供高可用方案，实现主从故障自动转移。内置Redis Cluster提供集群方案，实现基于槽的分片方案，从而支持更大的Redis规模</li>
</ul>
</li>
<li>
<p>缺点</p>
<ul>
<li>Redis单台机器存储的数据量，受限于机器本身的内存大小。虽然有Key过期策略，但是还是要预估和节约内存。如果内存增长过快，需要定期删除数据。可用Redis Cluster、Codis等方案进行分区，从单机Redis变成集群Redis</li>
<li>如果进行完整重同步，需要生成RDB文件和传输，会占用主机的 CPU ，并会消耗现网的带宽。</li>
<li>修改配置文件重启，时间比较久。在这个过程中，Redis 不能提供服务。</li>
</ul>
</li>
</ul>
<h1>69. Redis 不适合的场景？</h1>
<ul>
<li>数据量太大、数据访问频率非常低的业务，数据太大会增加成本，访问频率太低，保存在内存中纯属浪费资源。</li>
</ul>
<h1>73. list类型底层数据结构？</h1>
<ul>
<li>
<p>底层结构：quickList双链表结构，每个双链表节点中保存一个ziplist，每个ziplist中存一批list中的数据，既避免大量链表指针带来的内存消耗，也可避免ziplist更新导致的大量性能损耗<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/71b6924cc20e198b2aebc.png" alt="quicklist.png"></p>
</li>
<li>
<p>ziplist与linkedlist优缺点对比：</p>
<ul>
<li>两端进行push和pop操作时间复杂度都是O(1)</li>
<li>双向链表linkedlist内存开销比较大。每个节点上除了要保存数据之外，还要额外保存两个指针；其次，双向链表的各个节点是单独的内存块，地址不连续，节点多了容易产生内存碎片。</li>
<li>ziplist存储上一个entry的长度和当前entry的长度，通过长度推算下一个元素在什么地方，使用连续的内存块，存储效率很高。但是插入和删除操作需要申请和释放内存(重新生成一个新的ziplist来作为更新后的list)。可能会导致大批量的数据拷贝。适合每个列表项要么就是小整数值，要么就是长度比较短的字符串的场景</li>
</ul>
</li>
<li>
<p>当列表对象保存的所有字符串元素的长度都小于64字节且元素数量小于512个时使用ziplist，否则使用linkedlist</p>
</li>
<li>
<p>ziplist结构及遍历过程<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/7a043efdfeb556b9b5ce0.png" alt="ziplist.jpg"></p>
</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>- 从前向后遍历时，程序从指向节点e1的指针p开始，计算节点e1的长度（e1-size）， 然后将p加上 e1-size ，就将指针后移到了下一个节点e2 ...如此反复，直到p遇到ZIPLIST_ENTRY_END为止
                              p + e1-size + e2-size
                 p + e1-size     |
           p          |          |
           |          |          |
           V          V          V
+</code></pre></div>]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/1e419b34a2ddcd1e552d4.png" type="image/png"/>
    </item>
    <item>
      <title>场景设计</title>
      <link>https://javaguide.cn/interview/scenedesign.html</link>
      <guid>https://javaguide.cn/interview/scenedesign.html</guid>
      <source url="https://javaguide.cn/rss.xml">场景设计</source>
      <description>1. 支付系统设计 1.1. 支付系统架构图 payprocess.pngpayprocess.png 1.2. 商户系统设计 下单时需要同时插入需要做的记录和状态，比如报名活动下单时是delete=1，回调成功则变成delete=1，而不是成功回调才插入 下单时提交额外参数最好是id，回调的时候根据id修改订单和记录的状态delete=0 支付后最先...</description>
      <category>面试</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<!-- more -->
<!-- TOC -->
<!-- TOC -->
<h1>1. 支付系统设计</h1>
<h2>1.1. 支付系统架构图</h2>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/d4a02ad890b4cf42ab109.png" alt="payprocess.png" tabindex="0"><figcaption>payprocess.png</figcaption></figure>
<h2>1.2. 商户系统设计</h2>
<ul>
<li>下单时需要同时插入需要做的记录和状态，比如报名活动下单时是delete=1，回调成功则变成delete=1，而不是成功回调才插入</li>
<li>下单时提交额外参数最好是id，回调的时候根据id修改订单和记录的状态delete=0</li>
<li>支付后最先判断订单是否已经处理，保持幂等性</li>
<li>收入订单和支出订单前缀不要一样</li>
<li>涉及支付回调或者阻塞都是先设置status为0的状态的记录并提交事务，然后调用他们的接口回填status的状态</li>
</ul>
<h2>1.3. 发起下单网络调用超时订单表会保存么？</h2>
<ul>
<li>分场景</li>
<li>如果是没有额外成本，比如用户支付到企业且价格不会变，则不需要记录，然后直接提醒失败事务回滚提示前端，让用户再次发起</li>
<li>如果有额外成本，比如企业支付到用户，那么需要记录，并且需要延时消息去补偿和重试，最后将结果通知用户</li>
</ul>
<h2>1.4. 先发起下单再保存数据库还是相反？</h2>
<ul>
<li>前者可以再异常状况下比如超时不用再修改一次订单状态，但可能事务比较长，后者事务短但是异常需要修改订单状态</li>
</ul>
<h2>1.5. 如何防止重复支付？</h2>
<ul>
<li>使用分布式锁保证，查询是否已经报名，查询是否正在支付</li>
</ul>
<h2>1.6. 调用第三方银行接口怎么保证不超过银行的qps？</h2>
<ul>
<li>积压到rocketmq流量削峰</li>
<li>限流</li>
</ul>
<h2>1.7. 回调没收到怎么办？掉单</h2>
<ul>
<li>采用异步补偿方案
<ul>
<li>定时轮询:
<ul>
<li>第三步调用支付通道之后，如果支付通道端返回支付受理成功或者支付处理中，将调用第四步。将这类订单插入掉单表。</li>
<li>第五步，补单应用将会定时查询数据库，批量查询掉单记录。</li>
<li>第六步，补单应用使用线程池，多线程异步的方式发起掉单查询</li>
<li>第七步，调用支付通道支付查询接口。</li>
<li>如果第七步支付结果查询为以下状态:支付结果为扣款成功、明确失败、掉单记录查询达到最大次数，第八步就会删除掉单记录。</li>
<li>最后，如果掉单查询依旧还是处理中，那么经过一定的延时之后，重复第五步，再次重新掉单补偿，直到成功或者查询到达最大次数。</li>
</ul>
</li>
<li>问题：为什么需要新建一张掉单表?不能直接使用支付订单表，查询未成功的订单吗?确实可以直接使用的支付订单表，然后批量查询当天未成功的订单，补单程序发起支付查询。主要是因为数据库查询效率问题，因为支付订单表每天都会大量记录新增，随着时间，这张表记录将会越来越多越来越大。支付记录越多，批量范围查询效率就会变低，查询速度将会变慢。所以为了查询效率，新建一张掉单表。这张表里仅记录支付未成功的订单，所以数据量就会很小，那么查询效率就会很高。另外，掉单表里的记录，不会被永久保存，只是临时性。当支付结果查询成功，或者支付结果明确失败，再或者查询次数到达规定最大次数，就会删除掉单记录。这就是第八步为什么需要删除掉单表的原因。如果需要保存每次掉单表查询详情，那么这里建议再新增一张掉单查询记录表，保存每一次的查询记录,</li>
<li>方案优缺点
<ul>
<li>优点是系统架构方案比较简单，比较容易实施。</li>
<li>缺点主要在于定时任务上。
<ul>
<li>1.轮询效率稍低</li>
<li>2.每次查询数据库，已经被执行过记录，仍然会被扫描(补单程序将会根据一定策略决定是否发起支付通道查询)，有重复计算的嫌疑</li>
<li>3.时效性不够好，如果每小时轮询一次，最差的情况下，时间误差会达到1小时</li>
<li>4.如果为了解决时效性问题，增加定时任务查询效率，那么1中查询效率跟2 的重复计算问题将会更加明显<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/4021f4a12d493c1a96e79.jpg" alt="定时轮询方案.png"></li>
</ul>
</li>
</ul>
</li>
<li>延迟消息
<ul>
<li>第四步的流程从插入掉单表变更为往延迟队列发送掉单消息。</li>
<li>第五步，补单程序接收掉单消息，然后触发支付掉单查询</li>
<li>第八步，如果第七步支付结果查询为以下状态:支付结果为扣款成功、明确失败、掉单记录查询达到最大次数。补单程序将会告知延迟队列消费成功，延迟队列将会删除这条掉单消息。其他状态将会告知消费失效，延迟队列将会在一定延时之后，再次发送掉单消息，然后继续重复第五步</li>
<li>延时消息参考下面30分钟关闭订单<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/f718d072b6567151798eb.jpg" alt="延迟消息方案.png"></li>
</ul>
</li>
<li>延迟消息的方案相对于定时轮询方案来讲:
<ul>
<li>无需再查询全部订单，效率高</li>
<li>时效性较好</li>
<li>不过延迟消息这种方案，需要基于延迟队列，实现复杂，</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2>1.8. 超时30分钟怎么自动关闭订单</h2>
<ul>
<li>数据库定时任务（如Quartz）quartz-scheduler 支持集群操作；对服务器内存消耗大，数据库压力大，存在延时，最坏延时为定时时间</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>&lt;dependency&gt;
    &lt;groupId&gt;org.quartz-scheduler&lt;/groupId&gt;
    &lt;artifactId&gt;quartz&lt;/artifactId&gt;
    &lt;version&gt;2.2.2&lt;/version&gt;
&lt;/dependency&gt;
public class MyJob implements Job {
    public void execute(JobExecutionContext context) throws JobExecutionException {
        System.out.println("要去数据库扫描啦。。。");
    }
    public static void main(String[] args) throws Exception {
        // 创建任务
        JobDetail jobDetail = JobBuilder.newJob(MyJob.class)
                .withIdentity("job1", "group1").build();
        // 创建触发器 每3秒钟执行一次
        Trigger trigger = TriggerBuilder
                .newTrigger()
                .withIdentity("trigger1", "group3")
                .withSchedule(
                        SimpleScheduleBuilder
                                .simpleSchedule()
                                .withIntervalInSeconds(3).
                                repeatForever())
                .build();
        Scheduler scheduler = new StdSchedulerFactory().getScheduler();
        // 将任务及其触发器放入调度器
        scheduler.scheduleJob(jobDetail, trigger);
        // 调度器开始调度任务
        scheduler.start();
    }
}
</code></pre></div><ul>
<li>JDK的DelayQueue延迟队列(无界阻塞队列)只有在延迟期满的时候才能从中获取元素。 延迟低；服务器重启后，数据全部消失，怕宕机 集群扩展相当麻烦 容易就出现OOM异常</li>
<li>Poll():获取并移除队列的超时元素，没有则返回空.take():获取并移除队列的超时元素，如果没有则 wait 当前线程，直到有元素满足超时条件，返回结果。</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class OrderDelay implements Delayed {
    private String orderId;
    private long timeout;
    OrderDelay(String orderId, long timeout) {
        this.orderId = orderId;
        this.timeout = timeout + System.nanoTime();
    }

    public int compareTo(Delayed other) {
        if (other == this) {
            return 0;
        }
        OrderDelay t = (OrderDelay) other;
        long d = (getDelay(TimeUnit.NANOSECONDS) - t.getDelay(TimeUnit.NANOSECONDS));
        return (d == 0) ? 0 : ((d &lt; 0) ? -1 : 1);
    }

    // 返回距离你自定义的超时时间还有多少
    public long getDelay(TimeUnit unit) {
        return unit.convert(timeout - System.nanoTime(), TimeUnit.NANOSECONDS);
    }

    void print() {
        System.out.println(orderId + "编号的订单要删除啦。。。。");
    }

    public static void main(String[] args) {
        DelayQueue&lt;OrderDelayed&gt; delayQueue = new DelayQueue&lt;&gt;();
        delayQueue.put(new OrderDelayed("220101001", 8, TimeUnit.SECONDS));
        delayQueue.put(new OrderDelayed("220101002", 4, TimeUnit.SECONDS));  
        while (true) {
            // 取队列头部元素是否过期
            OrderDelayed task = delayQueue.poll();
            if (task != null) {
                System.out.println("订单 </code></pre></div>]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/d4a02ad890b4cf42ab109.png" type="image/png"/>
    </item>
    <item>
      <title>spring</title>
      <link>https://javaguide.cn/interview/spring.html</link>
      <guid>https://javaguide.cn/interview/spring.html</guid>
      <source url="https://javaguide.cn/rss.xml">spring</source>
      <description>1. Spring是什么？特性？ Spring是一个轻量级、非入侵式的控制反转(IoC)和面向切面(AOP)的框架。 IoC和DI的支持:管理对象生命周期和依赖关系 AOP编程的支持：面向切面编程可以实现对程序进行权限拦截、运行监控等切面功能。 声明式事务的支持：支持通过配置就来完成对事务的管理，而不需要通过硬编码的方式。 快捷测试的支持：支持Juni...</description>
      <category>面试</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[
<ul>
<li>Spring是一个轻量级、非入侵式的控制反转(IoC)和面向切面(AOP)的框架。</li>
<li>IoC和DI的支持:管理对象生命周期和依赖关系</li>
<li>AOP编程的支持：面向切面编程可以实现对程序进行权限拦截、运行监控等切面功能。</li>
<li>声明式事务的支持：支持通过配置就来完成对事务的管理，而不需要通过硬编码的方式。</li>
<li>快捷测试的支持：支持Junit注解测试Spring程序。</li>
<li>快速集成功能：方便集成各种优秀框架</li>
<li>复杂API模板封装：对JDBC、JavaMail等提供了模板化的封装，降低应用难度</li>
</ul>
<h1>2. Spring有哪些模块？</h1>
<ul>
<li>Spring Core：Spring 核心，它是框架最基础的部分，提供 IoC 和依赖注入 DI 特性。</li>
<li>Spring Context：Spring 上下文容器，它是 BeanFactory 功能加强的一个子接口。</li>
<li>Spring Web：它提供 Web 应用开发的支持。</li>
<li>Spring MVC：它针对 Web 应用中 MVC 思想的实现。</li>
<li>Spring DAO：提供对 JDBC 抽象层，简化了 JDBC 编码，同时，编码更具有健壮性。</li>
<li>Spring ORM：它支持用于流行的 ORM 框架的整合，比如：Spring + Hibernate、Spring + iBatis、Spring + JDO 的整合等</li>
<li>Spring AOP：即面向切面编程，它提供了与 AOP 联盟兼容的编程实现。</li>
</ul>
<h1>3. Spring常用注解？</h1>
<ul>
<li>Web:
<ul>
<li>@Controller：组合注解（组合了@Component注解），应用在MVC层（控制层）。</li>
<li>@RestController：@Controller和@ResponseBody的组合注解，注解在类上则该Controller的所有方法都默认加上了@ResponseBody。</li>
<li>@RequestMapping：用于映射Web请求，包括访问路径和参数。Restful接口根据请求类型使用不同的注解：@GetMapping、@PostMapping、@PutMapping、@DeleteMapping</li>
<li>@ResponseBody：将返回值放在response内，通常返回json数据。</li>
<li>@RequestBody：将request的参数放在request体中</li>
<li>@PathVariable：用于接收路径参数，比如@RequestMapping(“/hello/{name}”)申明的路径，将注解放在参数中前，即可获取该值，通常作为Restful的接口实现方法。</li>
</ul>
</li>
<li>容器:
<ul>
<li>@Component：将类变为Spring管理的Bean。</li>
<li>@Service：组合注解（组合了@Component注解），应用在service层（业务逻辑层）。</li>
<li>@Repository：组合注解（组合了@Component注解），应用在dao层（数据访问层）。</li>
<li>@Autowired：Spring提供的工具（由Spring的依赖注入工具（BeanPostProcessor、BeanFactoryPostProcessor）自动注入）。</li>
<li>@Qualifier：用于区分两个以上相同类型的Bean</li>
<li>@Configuration：声明当前类是一个配置类（相当于一个Spring配置的xml文件）</li>
<li>@Value：可用在字段，构造器参数跟方法参数指定默认值，支持#{}跟${}方式。一般将SpringbBoot中的application.properties配置的属性值赋值给变量。</li>
<li>@Bean：注解在方法上，声明当前方法的返回值为一个Bean。返回的Bean对应的类中可以定义init()方法和destroy()方法，然后在@Bean(initMethod=”init”,destroyMethod=”destroy”)定义，在构造之后执行init，在销毁之前执行destroy。</li>
<li>@Scope:定义采用什么模式创建Bean（方法上，得有@Bean）包括：Singleton、Prototype、Request、Session、GlobalSession。</li>
</ul>
</li>
<li>AOP:
<ul>
<li>@Aspect:声明一个切面（类上）使用@After、@Before、@Around定义建言（advice），可直接将拦截规则（切点）作为参数。
<ul>
<li>@After：在方法执行之后执行（方法上）。</li>
<li>@Before：在方法执行之前执行（方法上）。</li>
<li>@Around：在方法执行之前与之后执行（方法上）。</li>
<li>@PointCut：声明切点在java配置类中使用@EnableAspectJAutoProxy注解开启Spring对AspectJ代理的支持（类上）。</li>
</ul>
</li>
</ul>
</li>
<li>事务：@Transactional：在要开启事务的方法上使用，即可声明式开启事务。</li>
</ul>
<h1>5. Spring中都用到了哪些设计模式？</h1>
<ul>
<li>工厂模式—使用工厂模式通过BeanFactory、ApplicationContext创建bean对象。</li>
<li>代理模式—SpringAOP功能功能就是通过代理模式来实现的，分为动态代理和静态代理。</li>
<li>单例模式—Spring中定义的Bean默认为单例模式。</li>
<li>模板方法—解决代码重复的问题。比如RestTemplate、JmsTemplate、JdbcTemplate。</li>
<li>观察者模式:Spring事件驱动模型就是观察者模式很经典的一个应用。</li>
<li>适配器模式:SpringAOP的增强或通知(Advice)使用到了适配器模式、SpringMVC中也是用到了适配器模式适配Controller。</li>
<li>策略模式：Spring中有一个Resource接口，它的不同实现类，会根据不同的策略去访问资源。</li>
<li>前端控制器—Spring提供了DispatcherServlet来对请求进行分发。</li>
<li>视图帮助(ViewHelper)—Spring提供了一系列的JSP标签，高效宏来辅助将分散的代码整合在视图里。</li>
<li>依赖注入—贯穿于BeanFactory/ApplicationContext接口的核心理念。</li>
</ul>
<h1>12. 什么是ioc控制反转?好处？</h1>
<ul>
<li>Inverse Of Control反转控制：将对象的生命周期交给spring容器管理</li>
<li>它将最小化应用程序中的代码量</li>
<li>它以最小的影响和最少的侵入机制促进松耦合</li>
<li>支持即时的实例化和延迟加载Bean对象</li>
<li>易于测试，因为不需要单元测试用例中的任何单例或JNDI查找机制。</li>
</ul>
<h1>16. spring的di</h1>
<ul>
<li>dependency Injection依赖注入,是ioc的实现方式
<ul>
<li>注入方式：set/属性方法注入、构造方法注入、字段注入</li>
<li>注入类型：值类型注入（8大基本数据类型）、引用类型注入 将依赖对象注入</li>
</ul>
</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>set方法注入
&lt;bean  name="user" class="cn.itcast.bean.User" &gt;
	&lt;!--值类型注入: 为User对象中名为name的属性注入tom作为值 --&gt;
	&lt;property name="name" value="tom" &gt;&lt;/property&gt;
	&lt;!-- 引用类型注入: 为car属性注入下方配置的car对象 --&gt;
	&lt;property name="car"  ref="car" &gt;&lt;/property&gt;
	&lt;!--数组类型注入: 如果数组中只准备类一个值（对象），直接使用value|ref--&gt;
	&lt;property name="arr" value="tom"&gt;&lt;/property&gt;
	&lt;property name="arr"&gt;
		&lt;array&gt;
			&lt;value&gt;tom&lt;/value&gt;
			&lt;ref bean="user"/&gt;
		&lt;array&gt;
	&lt;/property&gt;
	&lt;!-- List类型注入：如果list中只准备类一个值（对象），直接使用value|ref--&gt;
	&lt;property name="list" value="jack"&gt;&lt;/property&gt;
	&lt;property name="list"&gt;
		&lt;list&gt;
			&lt;value&gt;jack&lt;/value&gt;
			&lt;ref bean="user"/&gt;
		&lt;list&gt;
	&lt;/property&gt;
	&lt;!-- Properties类型注入 --&gt;
	&lt;property name="prop"&gt;
		&lt;props&gt;
			&lt;prop key="driverClass"&gt;com.jdbc.mysql.Driver&lt;/prop&gt;
		&lt;props&gt;
	&lt;/property&gt;
	&lt;!-- Map类型注入 --&gt;
	&lt;property name="map"&gt;
		&lt;map&gt;
			&lt;entry key="url" value="jdbc:mysql:///crm"&gt;&lt;/entry&gt;
		&lt;map&gt;
	&lt;/property&gt;
&lt;/bean&gt;
&lt;!-- 将car对象配置到容器中 --&gt;
&lt;bean name="car" class="cn.itcast.bean.Car" &gt;
	&lt;property name="name" value="兰博基尼" &gt;&lt;/property&gt;
&lt;/bean&gt;


构造函数注入
&lt;bean name="user2" class="cn.itcast.bean.User" &gt;
	&lt;!-- name属性: 构造函数的参数名  index属性: 
	构造函数的参数索引 type属性: 构造函数的参数类型--&gt;
	&lt;constructor-arg name="name" index="0" type="java.lang.Integer" value="999"&gt;&lt;/constructor-arg&gt;
	&lt;constructor-arg name="car" index="1" ref="car"&gt;&lt;/constructor-arg&gt;
&lt;/bean&gt;
</code></pre></div><h1>14. 简述Spring IoC的实现机制？</h1>
<ul>
<li>原理：工厂模式加反射机制</li>
<li>a. 加载配置文件，解析成BeanDefinition放在Map里</li>
<li>b. BeanFactory调用getBean的时候，从BeanDefinition所属的Map里，拿出Class对象进行实例化，如果有依赖关系，将递归调用getBean方法 —— 完成依赖注入。</li>
</ul>
<h1>13. 说说applicationContext&amp;BeanFactory</h1>
<ul>
<li>BeanFactory接口：创建并管理各种类的对象。每次在获得对象时才会创建对象.最常用的是XmlBeanFactory，根据XML文件中内容创建相应Bean</li>
<li>ApplicationContext建立在BeanFactoty基础上。每次容器启动时就会创建容器中配置的所有对象.并提供更多功能
<ul>
<li>1、ClassPathXmlApplicationContext ：从 ClassPath 的 XML 配置文件中读取上下文，并生成上下文定义。应用程序上下文从程序环境变量中取得。</li>
<li>2、FileSystemXmlApplicationContext ：由文件系统中的XML配置文件读取上下文</li>
<li>3、XmlWebApplicationContext ：由Web应用的XML文件读取上下文。在 Spring MVC 使用</li>
<li>4、Spring Boot 的ConfigServletWebServerApplicationContext</li>
</ul>
</li>
</ul>
<h1>17. Spring容器启动阶段会干什么？</h1>
<ul>
<li>IoC容器工作的过程可以划分两个阶段</li>
<li>容器启动阶段：加载配置，分析配置信息，装配到BeanDefinition，其他后处理</li>
<li>Bean实例化阶段：实例化对象，装配依赖， 生命周期回调， 对象其他处理， 注册回调接口</li>
</ul>
<h1>18. Spring Bean在容器的生命周期是什么样的？</h1>
<ul>
<li>实例化Bean对象:
<ul>
<li>根据配置中Bean Definition中实例化Bean对象（通过XML，Java注解或Java Config代码提供）</li>
</ul>
</li>
<li>属性赋值：Aware相关的属性，注入到Bean对象
<ul>
<li>如果Bean实现BeanNameAware接口，则工厂通过传递Bean的beanName调用setBeanName(String name)方法</li>
<li>如果Bean实现BeanFactoryAware接口，工厂通过传递自身的实例来调用setBeanFactory(BeanFactory beanFactory)方法</li>
</ul>
</li>
<li>初始化
<ul>
<li>@PostConstruct</li>
<li>如果存在与Bean关联的任何BeanPostProcessor，则调用#preProcessBeforeInitialization(Object bean, String beanName) 方法。</li>
<li>如果Bean实现InitializingBean接口，则会调用#afterPropertiesSet() 方法。</li>
<li>如果Bean指定init方法（例如 </li>
<li>如果存在与Bean关联的任何 BeanPostProcessor，则调用#postProcessAfterInitialization(Object bean, String beanName) 方法。</li>
</ul>
</li>
<li>销毁：
<ul>
<li>@PreDestroy</li>
<li>如果Bean实现DisposableBean接口，当 spring 容器关闭时，会调用 #destroy() 方法。</li>
<li>如果bean指定destroy方法（例如 </li>
</ul>
</li>
</ul>
<h1>15. Spring有哪些自动装配的方式?</h1>
<ul>
<li>byName根据名称进行自动匹配</li>
<li>byType根据类型进行自动匹配</li>
<li>constructor spring根据bean构造函数入参类型自动装配</li>
<li>autodetect 如果Bean提供了默认的构造函数，则采用byType，否则采用constructor。</li>
</ul>
<h1>4. spring中的bean作用域scope类型√</h1>
<ul>
<li>singleton(默认):被标识为单例的对象，在spring容器中只存在一个实例</li>
<li>prototype:被标识为多例的对象,每次获取都会创建新对象</li>
<li>request:web环境下.对象与request生命周期一致.</li>
<li>session:web环境下,对象与session生命周期一致.</li>
<li>Application:对象与Web Application生命周期一致，只能在同一个webapplication中获取</li>
</ul>
<h1>8. spring框架中的单例bean是线程安全的吗？√</h1>
<ul>
<li>如果单例Bean是无状态的，也就是线程中的操作不会对Bean的成员执行查询以外的操作，那么这个单例Bean是线程安全的。</li>
<li>如果bean有多种状态的话（比如 View Model 对象），就需要自行保证线程安全。解决办法就是将多态bean的作用域由“singleton”变更为“prototype”或者将变量放入ThreadLocal中</li>
</ul>
<h1>6. 如何解决spring bean中的循环依赖？√为何使用三级缓存解决循环依赖而不是二级缓存?</h1>
<ul>
<li>单例模式下Spring可以解决哪些情况的循环依赖
<ul>
<li>多例模式不支持，无限创建对象</li>
<li>AB均采用构造器注入，不支持。直接抛出BeanCurrentlylnCreationException异常。</li>
<li>AB均采用setter注入，支持</li>
<li>AB均采用属性自动注入，支持</li>
<li>A中注入的B为setter注入，B中注入的A为构造器注入，支持</li>
<li>B中注入的A为setter注入，A中注入的B为构造器注入，不支持</li>
<li>第四种可以，第五种不可以的原因是Spring在创建Bean时默认会根据自然排序进行创建，所以A会先于B进行创建。</li>
</ul>
</li>
<li>spring通过三级缓存解决循环依赖，
<ul>
<li>singletonObjects 一级缓存。保存实例化、属性赋值、初始化完成的bean实例</li>
<li>earlySingletonObjects 二级缓存 。保存实例化完成的bean实例</li>
<li>singletonFactories 三级缓存，用于保存bean创建工厂，以便后面有机会创建代理对象</li>
</ul>
</li>
<li>实例化过程
<ul>
<li>A实例化并把A的ObjectFactory加入第三级缓存
<ul>
<li>A填充属性需要注入B -&gt; B实例化并把B的ObjectFactory加入第三级缓存</li>
<li>B填充属性需要注入A -&gt; 从第三级缓存移除A对象，A代理对象加入第二级缓存（此时A还是半成品，B注入的是A代理对象）</li>
<li>B属性注入完成，创建B代理对象（此时B是完成品） -&gt; 从第三级缓存移除B对象，B代理对象加入第一级缓存</li>
<li>A填充属性注入B代理对象，从第二级缓存移除A代理对象，A代理对象加入第一级缓存</li>
</ul>
</li>
</ul>
</li>
<li>如果没有AOP的话确实可以两级缓存就可以解决循环依赖的问题，如果加上AOP，两级缓存是无法解决的，不可能每次执行singleFactory.getObject()方法都给我产生一个新的代理对象，所以还要借助另外一个缓存来保存产生的代理对象</li>
</ul>
<h1>7. @Autowired 的实现原理？</h1>
<ul>
<li>在Bean的初始化阶段，会通过Bean后置处理器来进行前置和后置的处理。@Autowired功能是通过后置处理器<br>
AutowiredAnnotationBeanPostProcessor来完成的</li>
<li>Spring在创建bean的过程中，最终会调用到doCreateBean()方法，在doCreateBean()方法中会调用populateBean()方法，来为bean进行属性填充，完成自动装配等工作。</li>
<li>在populateBean()方法中一共调用了两次后置处理器，第一次是为了判断是否需要属性填充，如果不需要进行属性填充，那么就会直接进行return，如果需要进行属性填充，那么方法就会继续向下执行，后面会进行第二次后置处理器的调用，这个时候，就会调用到AutowiredAnnotationBeanPostProcessor的postProcessPropertyValues()方法，在该方法中就会进行@Autowired注解的解析，然后实现自动装配</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>//属性赋值
protected void populateBean(String beanName, RootBeanDefinition mbd, @Nullable BeanWrapper bw) {
          //…………
          if (hasInstAwareBpps) {
              if (pvs == null) {
                  pvs = mbd.getPropertyValues();
              }

              PropertyValues pvsToUse;
              for(Iterator var9 = this.getBeanPostProcessorCache().instantiationAware.iterator(); var9.hasNext(); pvs = pvsToUse) {
                  InstantiationAwareBeanPostProcessor bp = (InstantiationAwareBeanPostProcessor)var9.next();
                  pvsToUse = bp.postProcessProperties((PropertyValues)pvs, bw.getWrappedInstance(), beanName);
                  if (pvsToUse == null) {
                      if (filteredPds == null) {
                          filteredPds = this.filterPropertyDescriptorsForDependencyCheck(bw, mbd.allowCaching);
                      }
                      //执行后处理器，填充属性，完成自动装配
                      //调用InstantiationAwareBeanPostProcessor的postProcessPropertyValues()方法
                      pvsToUse = bp.postProcessPropertyValues((PropertyValues)pvs, filteredPds, bw.getWrappedInstance(), beanName);
                      if (pvsToUse == null) {
                          return;
                      }
                  }
              }
          }
         //…………
  }

//先调用 findAutowiringMetadata()方法解析出 bean 中带有@Autowired 注解、@Inject 和@Value 注解的属性和方法。然后调用 metadata.inject()方法，进行属性填充。
  public PropertyValues postProcessProperties(PropertyValues pvs, Object bean, String beanName) {
      //@Autowired注解、@Inject和@Value注解的属性和方法
      InjectionMetadata metadata = this.findAutowiringMetadata(beanName, bean.getClass(), pvs);

      try {
          //属性填充
          metadata.inject(bean, beanName, pvs);
          return pvs;
      } catch (BeanCreationException var6) {
          throw var6;
      } catch (Throwable var7) {
          throw new BeanCreationException(beanName, "Injection of autowired dependencies failed", var7);
      }
  }
</code></pre></div><h1>19. spring的AOP以及实现方式,通知类型</h1>
<ul>
<li>AOP(Aspect-Oriented Programming)，面向切面编程:通过动态代理将通知织入目标对象.把一些业务逻辑中的相同代码抽取到一个独立的模块中，提高代码的可重用性。</li>
<li>实现方式
<ul>
<li>动态代理(优先):基于接口，被代理对象必须要实现接口,才能产生代理对象.</li>
<li>cglib代理：基于继承，对目标对象进行继承代理.目标对象不被final修饰。通过ASM读取目标类的字节码，然后修改字节码生成新的类</li>
</ul>
</li>
<li>应用：用于增强方法，权限认证、日志、事务、参数校验</li>
<li>常用术语
<ul>
<li>Joinpoint(连接点)：目标对象中，被拦截到的方法</li>
<li>Poincut(切入点)：目标对象，已经增强的方法。pointcut 的作用就是提供一组规则(使用 AspectJ pointcut expression language 来描述) 来匹配joinpoint, 给满足规则的 joinpoint 添加 Advice</li>
<li>Advice(通知/增强)：指拦截到连接点之后要执行的增强代码
<ul>
<li>前置通知（Before advice）：在某连接点（JoinPoint）之前执行的通知，但这个通知不能阻止连接点前的执行。ApplicationContext 中在 &lt; aop:aspect &gt; 里面使用 &lt; aop:before &gt; 元素进行声明；</li>
<li>后置通知（After advice）：当某连接点退出的时候执行的通知（不论是正常返回还是异常退出）。ApplicationContext 中在 &lt; aop:aspect &gt; 里面使用 &lt; aop:after &gt; 元素进行声明。</li>
<li>返回后通知（After return advice ：在某连接点正常完成后执行的通知，不包括抛出异常的情况。ApplicationContext 中在 &lt; aop:aspect &gt; 里面使用 &lt;&lt; after-returning &gt;&gt; 元素进行声明。</li>
<li>环绕通知（Around advice）：在 join point 前和 joint point 退出后都执行的 advice。ApplicationContext 中在 &lt; aop:aspect &gt; 里面使用 &lt; aop:around &gt; 元素进行声明。</li>
<li>抛出异常后通知（After throwing advice）：在方法抛出异常退出时执行的通知。ApplicationContext 中在 &lt; aop:aspect &gt; 里面使用 &lt; aop:after-throwing &gt; 元素进行声明。</li>
</ul>
</li>
<li>Target(目标对象)：被代理的对象</li>
<li>Weaving(织入)：将 aspect 和其他对象连接起来, 并创建 adviced object 的过程.</li>
<li>Proxy(代理)：将通知织入到目标对象之后，形成代理对象 Advice + Target Object = Advised Object = Proxy 。</li>
<li>aspect(切面)：切入点+通知 可以简单地认为, 使用 @Aspect 注解的类就是切面。</li>
</ul>
</li>
</ul>
<h1>22. spring事务配置，处理方式？</h1>
<ul>
<li>声明式事务：基于AOP，通过使用注解@Transactional或基于XML的配置事务，从而事务管理与业务代码分离。但无法用到代码块级别</li>
<li>编程式事务：通过TransactionTemplate和PlatformTransactionManager编码的方式实现事务管理，需要在代码中显式的调用事务的获得、提交、回滚。灵活性高，但维护困难</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class AccountService {
    private TransactionTemplate transactionTemplate;

    public void setTransactionTemplate(TransactionTemplate transactionTemplate) {
        this.transactionTemplate = transactionTemplate;
    }

    public void transfer(final String out, final String in, final Double money) {
        transactionTemplate.execute(new TransactionCallbackWithoutResult() {
            @Override
            protected void doInTransactionWithoutResult(TransactionStatus status) {
                // 转出
                accountDao.outMoney(out, money);
                // 转入
                accountDao.inMoney(in, money);
            }
        });
    }
}

</code></pre></div><h1>24. Spring 的事务隔离级别？</h1>
<ul>
<li>Spring的接口TransactionDefinition中定义了表示隔离级别的常量，当然其实主要还是对应数据库的事务隔离级别：</li>
<li>ISOLATION_DEFAULT：使用后端数据库默认的隔离界别，MySQL 默认可重复读，Oracle 默认读已提交。</li>
<li>ISOLATION_READ_UNCOMMITTED：读未提交</li>
<li>ISOLATION_READ_COMMITTED：读已提交</li>
<li>ISOLATION_REPEATABLE_READ：可重复读</li>
<li>ISOLATION_SERIALIZABLE：串行化</li>
</ul>
<h1>27. 事务传播行为？有什么用？√</h1>
<ul>
<li>事务的传播行为propagation（service方法调用另外一个service方法的时候，仅限于不同类方法间相互调用）</li>
<li>事务的传播机制是指在一个事务中，对于多个事务性操作之间的关系和协调的处理方式。它决定了在一个事务方法中调用其他事务方法时，事务的范围和属性等。</li>
<li>支持当前事务
<ul>
<li>PROPAGATION_REQUIRED如果当前存在事务，则使用该事务。如果当前没有事务，就新建一个(默认)！！！</li>
<li>PROPAGATION_SUPPORTS如果当前存在事务，则使用该事务。如果当前没有事务，就不使用事务</li>
<li>PROPAGATION_MANDATORY如果当前存在事务，则使用该事务。如果当前没有事务，抛出异常</li>
</ul>
</li>
<li>不支持当前事务的情况
<ul>
<li>PROPAGATION_REQUIRES_NEW创建一个新的事务，如果有事务存在，挂起当前事务，</li>
<li>PROPAGATION_NOT_SUPPORTED以非事务方式运行，如果有事务存在，挂起当前事务</li>
<li>PROPAGATION_NEVER 以非事务方式运行，如果有事务存在，抛出异常</li>
<li>PROPAGATION_NESTED如果当前事务存在，则创建一个事务作为当前事务的嵌套事务来运行，如果当前没有事务，则等价PROPAGATION_REQUIRED</li>
<li>以 PROPAGATION_NESTED 启动的事务内嵌于外部事务中（如果存在外部事务的话），此时，内嵌事务并不是一个独立的事务，它依赖于外部事务的存在，只有通过外部的事务提交，才能引起内部事务的提交，嵌套的子事务不能单独提交。其实嵌套的子事务就是保存点的一个应用，一个事务中可以包括多个保存点，每一个嵌套子事务。另外，外部事务的回滚也会导致嵌套子事务的回滚。</li>
</ul>
</li>
<li>事务传播机制是使用 ThreadLocal 实现的，所以，如果调用的方法是在新线程中的，事务传播会失效。</li>
<li>在 Spring 中，只有通过 Spring 容器的 AOP 代理调用的公开方法（public method）上的@Transactional注解才会生效。Spring 默认使用基于 JDK 的动态代理（当接口存在时）或基于 CGLIB 的代理（当只有类时）来实现事务。这两种代理机制都只能代理公开的方法。</li>
</ul>
<h1>28. 声明式事务实现原理了解吗？</h1>
<ul>
<li>Spring的声明式事务管理是通过AOP（面向切面编程）和代理机制实现的。</li>
<li>第一步，在Bean初始化阶段创建代理对象：
<ul>
<li>Spring容器在初始化单例Bean的时候，会遍历所有的BeanPostProcessor实现类，并执行其postProcessAfterInitialization方法。</li>
<li>在执行postProcessAfterInitialization方法时会遍历容器中所有的切面，查找与当前Bean匹配的切面，这里会获取事务的属性切面，也就是@Transactional注解及其属性值。</li>
<li>然后根据得到的切面创建一个代理对象，默认使用JDK动态代理创建代理，如果目标类是接口，则使用JDK动态代理，否则使用Cglib。</li>
</ul>
</li>
<li>第二步，在执行目标方法时进行事务增强操作：
<ul>
<li>当通过代理对象调用Bean方法的时候，会触发对应的AOP增强拦截器，声明式事务是一种环绕增强，对应接口为MethodInterceptor，事务增强对该接口的实现为TransactionInterceptor</li>
<li>事务拦截器TransactionInterceptor在invoke方法中，通过调用父类TransactionAspectSupport的invokeWithinTransaction方法进行事务处理，包括开启事务、事务提交、异常回滚等。</li>
</ul>
</li>
</ul>
<h1>29. 声明式事务在哪些情况下会失效？</h1>
<ul>
<li>@Transactional应用在非public修饰的方法上。因为在SpringAOP代理时，TransactionInterceptor（事务拦截器）在目标方法执行前后进行拦截，DynamicAdvisedInterceptor（CglibAopProxy的内部类）的intercept方法或JdkDynamicAopProxy的invoke方法会间接调用AbstractFallbackTransactionAttributeSource的computeTransactionAttribute方法，获取Transactional注解的事务配置信息。</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>protectedTransactionAttributecomputeTransactionAttribute(Methodmethod,Class&lt;?&gt;targetClass){
  //Don'tallowno-publicmethodsasrequired.
  if(allowPublicMethodsOnly()&amp;&amp;!Modifier.isPublic(method.getModifiers())){
    return null;
  }
}
</code></pre></div><ul>
<li>@Transactional注解属性propagation设置错误
<ul>
<li>TransactionDefinition.PROPAGATION_SUPPORTS：如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务方式执行；错误使用场景：在业务逻辑必须运行在事务环境下以确保数据一致性的情况下使用SUPPORTS。</li>
<li>TransactionDefinition.PROPAGATION_NOT_SUPPORTED：总是以非事务方式执行，如果当前存在事务，则挂起该事务。错误使用场景：在需要事务支持的操作中使用NOT_SUPPORTED。</li>
<li>TransactionDefinition.PROPAGATION_NEVER：总是以非事务方式执行，如果当前存在事务，则抛出异常。错误使用场景：在应该在事务环境下执行的操作中使用NEVER。</li>
</ul>
</li>
<li>@Transactional注解属性rollbackFor设置错误
<ul>
<li>rollbackFor用来指定能够触发事务回滚的异常类型。Spring默认抛出未检查unchecked异常（继承自RuntimeException的异常）或者Error才回滚事务，其他异常不会触发回滚事务。</li>
</ul>
</li>
<li>同一个类中方法调用，导致@Transactional失效
<ul>
<li>由SpringAOP代理造成的，因为只有事务方法被当前类以外的代码调用时，才会由Spring生成的代理对象来管理。</li>
</ul>
</li>
</ul>
<h1>9. spring注册bean的几种方式</h1>
<ul>
<li>直接编码</li>
<li>配置文件 xml的bean标签</li>
<li>注解
<ul>
<li>@Component、@Service、@Controller</li>
<li>@Bean</li>
</ul>
</li>
<li>java config</li>
</ul>
<h1>10. spring中的@Required、@Autowired、@Qualifier注解的作用？</h1>
<ul>
<li>@Required注解，应用于Bean属性setter方法。表示属性必须注入否则抛出 BeanInitializationException 异常。</li>
<li>@Autowired用于在setter方法，构造函数，具有任意名称或多个参数的属性或方法上自动装配 Bean</li>
<li>@Qualifier指定id自动装配哪个bean</li>
</ul>
<h1>11. 解释什么叫延迟加载？</h1>
<ul>
<li>容器启动之后默认会创建所有作用域为单例的Bean，但是有的业务场景不需要提前创建。此时设置lazy-init="true"。容器启动之后不会默认创建作用域为单例的Bean，而是在获得该Bean时才创建</li>
</ul>
<h1>20. java热部署</h1>
<ul>
<li>spring-boot-devtools、Spring Loaded实现原理，nio的WatchService监听文件夹变化，同时实现classLoader的findclass方法重新将class加载进内存</li>
</ul>
<h1>21. Spring容器创建过程</h1>
<p>AbstractApplicationContext调用refresh()方法通过调用obtainFreshBeanFactory()方法创建Bean工厂AnnotatedBeanDefinitionReader扫描注解doScan方法和XmlBeanDefinitionReader的doLoadBeanDefinitions方法sax方式解析xml将其封装成document对象，使用BeanDefinitionReaderUtils.registerBeanDefinition并注册到BeanDefinitionRegistry缓存中<br>
然后调用postProcessBeanFactory调用子类的BeanFactory的后置处理器，然后调用invokeBeanFactoryPostProcessors()执行后置处理器<br>
第三注册BeanPostProcessors()到BeanFactory中<br>
第四注册监听器<br>
第五实例化所有的Bean放到singletonObjects单例池里面</p>
<h1>23. @Transactional 注解有哪些属性？如何使用？</h1>
<ul>
<li>属性：propagation事务传播行为，isolation事务隔离级别、rollbackFor导致事务回滚的异常类数组、timeout事务超时回滚、readonly读写或只读事务</li>
<li>@Transactional 可用在接口、接口方法、类、类方法上。只被应用到 public 方法上，方法级别注解覆盖类级别的注解。</li>
</ul>
<h1>25. Spring 事务如何和不同的数据持久层框架(Spring JDBC、Hibernate、Spring JPA、MyBatis)做集成？</h1>
<ul>
<li>Spring通过org.springframework.transaction.PlatformTransactionManager进行事务管理管理</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public interface PlatformTransactionManager {
  // 根据事务定义 TransactionDefinition ，获得 TransactionStatus 。 
  //为什么不是创建事务呢？因为如果当前如果已经有事务，则不会进行创建，一般来说会跟当前线程进行绑定。
  //为什么返回TransactionStatus对象？因为TransactionStatus 中包含事务属性和事务的其它信息，例如是否只读、是否为新创建的事务等等
  TransactionStatus getTransaction(@Nullable TransactionDefinition definition) throws TransactionException;
  //为什么根据 TransactionStatus 情况，进行提交？例如说，带@Transactional注解的A方法，会调用 @Transactional 注解的B方法
  //在B方法结束调用后，会执行PlatformTransactionManager#commit(TransactionStatus status) 方法，此处事务是不能、也不会提交的
  //而是在A方法结束调用后，执行PlatformTransactionManager#commit(TransactionStatus status) 方法，提交事务
  void commit(TransactionStatus status) throws TransactionException;
  // 为什么根据 TransactionStatus 情况，进行回滚？原因同上
  void rollback(TransactionStatus status) throws TransactionException;
}
</code></pre></div><ul>
<li>不同的数据持久层框架，会有其对应的PlatformTransactionManager实现类，都基于AbstractPlatformTransactionManager这个骨架类。
<ul>
<li>HibernateTransactionManager，和Hibernate5事务管理做集成。</li>
<li>DataSourceTransactionManager，和JDBC事务管理做集成。也适用于MyBatis、Spring JDBC等等</li>
<li>JpaTransactionManager，和JPA事务管理做集成。</li>
</ul>
</li>
</ul>
<h1>26. 为什么在Spring事务中不能切换数据源？</h1>
<ul>
<li>在Spring的事务管理中，数据库连接会和当前线程所绑定，即使设置了另外一个数据源，使用的还是当前的数据源连接。</li>
<li>而且多个数据源且需要事务的场景会带来多事务一致性的问题</li>
<li>推荐除非了读写分离所带来的多数据源，其它情况下，建议只有一个数据源</li>
</ul>
<h1>30. 拦截器与过滤器区别√</h1>
<ul>
<li>拦截器是基于java的反射机制的，而过滤器是基于函数回调。</li>
<li>拦截器不依赖与servlet容器，过滤器依赖servlet容器。</li>
<li>拦截器只能对action请求起作用，而过滤器则可以对几乎所有的请求起作用。</li>
<li>拦截器可以访问action上下文、值栈里的对象，而过滤器不能访问。</li>
<li>在action的生命周期中，拦截器可以多次被调用，而过滤器只能在容器初始化时被调用一次。</li>
<li>拦截器可以获取IOC容器中的各个bean，而过滤器就不行，这点很重要，在拦截器里注入一个service，可以调用业务逻辑。</li>
</ul>
<h1>31. spring区分环境</h1>
<ul>
<li>spring.profiles.active=dev</li>
</ul>
]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/9d7d1e010e6a298683def.jpg" type="image/jpeg"/>
    </item>
    <item>
      <title>springboot</title>
      <link>https://javaguide.cn/interview/springboot.html</link>
      <guid>https://javaguide.cn/interview/springboot.html</guid>
      <source url="https://javaguide.cn/rss.xml">springboot</source>
      <description>1. springboot优缺点？ √快速构建项目，通过 Intellij IDEA 或者官方的 Spring Initializr 就可以快速创建新项目 √自动配置:提供了一系列的 Starter,对主流框架的无配置集成 √项目独立运行，内嵌servlet容器Tomcat、Jetty 或者 Undertow 提供运行时应用监控。Spring Boot...</description>
      <category>面试</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<!-- TOC -->
<!-- /TOC -->
<h1>1. springboot优缺点？</h1>
<ul>
<li>
<p>√快速构建项目，通过 Intellij IDEA 或者官方的 Spring Initializr 就可以快速创建新项目</p>
</li>
<li>
<p>√自动配置:提供了一系列的 Starter,对主流框架的无配置集成</p>
</li>
<li>
<p>√项目独立运行，内嵌servlet容器Tomcat、Jetty 或者 Undertow</p>
</li>
<li>
<p>提供运行时应用监控。Spring Boot 提供基于 HTTP、JMX、SSH 对运行时的项目进行监控。</p>
</li>
<li>
<p>极大地提高了开发、部署效率</p>
</li>
<li>
<p>因为自动配置 Spring Bean 的功能，我们可能无法知道，哪些 Bean 被进行创建了。这个时候，如果我们想要自定义一些 Bean ，可能存在冲突，或者不知道实际注入的情况。</p>
</li>
</ul>
<h1>2. 如何统一引入Spring Boot版本？</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>方式1.继承 spring-boot-starter-parent 项目，容易与别的项目冲突
&lt;parent&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;
    &lt;version&gt;1.5.1.RELEASE&lt;/version&gt;
&lt;/parent&gt;
方式2.导入 spring-boot-dependencies 项目依赖，比较自由
&lt;dependencyManagement&gt;
    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt;
            &lt;version&gt;1.5.1.RELEASE&lt;/version&gt;
            &lt;type&gt;pom&lt;/type&gt;
            &lt;scope&gt;import&lt;/scope&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;
&lt;/dependencyManagement&gt;
</code></pre></div><h1>3. Spring Boot 有哪些配置方式？</h1>
<ul>
<li>XML 配置文件。<code>&lt;bean&gt;</code></li>
<li>注解配置。@Component</li>
<li>Java Config 配置。使用 @Bean 和 @Configuration</li>
</ul>
<h1>4. Spring Boot 有哪几种读取配置的方式？</h1>
<ul>
<li>@Value注解，读取配置到属性。支持和 @PropertySource注解一起使用，指定使用的配置文件。</li>
<li>@ConfigurationProperties注解，读取配置到类上。支持和@PropertySource注解一起使用，指定使用的配置文件。</li>
</ul>
<h1>5. bootstrap.properties和application.properties有何区别?</h1>
<ul>
<li>bootstrap(.yml/.properties)：由父ApplicationContext加载，比applicaton优先加载，配置在应用程序上下文的引导阶段生效。在SpringCloud Config或者Nacos中会用到。且属性不能被覆盖；</li>
<li>application(.yml/.properties)：由ApplicatonContext加载，用于项目的自动化配置。</li>
</ul>
<h1>6. SpringBoot中如何解决跨域问题 ?</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>@Configuration
public class CorsConfig implements WebMvcConfigurer {
    @Override
    public void addCorsMappings(CorsRegistry registry) {
        registry.addMapping("/**")
                .allowedOrigins("*")
                .allowCredentials(true)
                .allowedMethods("GET", "POST", "PUT", "DELETE", "OPTIONS")
                .maxAge(3600);
    }
}
</code></pre></div><h1>7. springboot配置文件读取顺序？√</h1>
<ul>
<li>
<p>config/application.properties|yml（项目根目录中config目录下）</p>
</li>
<li>
<p>application.properties|yml（项目根目录下）</p>
</li>
<li>
<p>resources/config/application.properties|yml（项目resources目录中config目录下）</p>
</li>
<li>
<p>resources/application.properties|yml（项目的resources目录下）</p>
</li>
<li>
<p>如果同一个目录下，默认先读取application.properties。然后application.yml</p>
</li>
<li>
<p>如果同一个配置属性，默认使用第1个读取到的</p>
</li>
<li>
<p>配置文件放置在项目的resources目录下，因为配置文件的修改，通过热部署不用重新启动项目，热部署作用范围是classpath下</p>
</li>
</ul>
<h1>8. springboot实现将配置文件放到classpath，那么所有的文件将不受所放位置的影响</h1>
<ul>
<li>Xbootclasspath/a:与路径无空格 路径为同jar路径下的config文件，此时所有的配置文件都会像classpath一样加载</li>
<li>java -Xbootclasspath/a:/config/ -jar testspringbootMybaits-0.0.1-SNAPSHOT.jar注意此时的配置文件会覆盖原来的配置！！！！！！</li>
<li>/config/根目录，config/相对当前目录</li>
<li>jar包指定编码启动 java -Dfile.encoding=utf-8 -jar test.jar</li>
</ul>
<h1>9. SpringBoot 自动配置原理、@EnableAutoConfiguration实现原理</h1>
<ul>
<li>@SpringBootApplication注解包含了@EnableAutoConfiguration，@Configuration（指定类是 Bean 定义的配置类），@ComponentScan(扫描指定包下的 Bean),而@EnableAutoConfiguration(打开自动配置功能)使用了@Import({AutoConfigurationImportSelector.class}) 而AutoConfigurationImportSelector，使用ImportSelector接口的selectImports方法加载META-INF/spring.factories文件的信息org.springframework.boot.autoconfigure.EnableAutoConfiguration=，封装成beanName，加载到IOC容器中，实现自动配置功能</li>
<li>SpringBoot在启动时扫描项目所依赖的jar包，寻找包含spring.factories文件的jar</li>
<li>根据spring.factories配置加载AutoConfigure类</li>
<li>根据[@Conditional 等条件注解](Spring Boot 条件注解) 的条件，进行自动配置并将Bean注入Spring IoC中</li>
</ul>
<h1>如何自定义一个SpringBoot Srarter?</h1>
<ul>
<li>引入 SpringBoot 相关依赖</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt;
    &lt;optional&gt;true&lt;/optional&gt;
&lt;/dependency&gt;

</code></pre></div><ul>
<li>编写配置文件:定义了属性配置的前缀</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>@ConfigurationProperties(prefix = "hello")
public class HelloProperties {
    private String name;
    //省略getter、setter
}

</code></pre></div><ul>
<li>自动装配</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>@Configuration
@EnableConfigurationProperties(HelloProperties.class)
public class HelloPropertiesConfigure {
}
</code></pre></div><ul>
<li>配置自动类:在/resources/META-INF/spring.factories文件中添加自动配置类路径</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>org.springframework.boot.autoconfigure.EnableAutoConfiguration=\
    cn.fighter3.demo.starter.configure.HelloPropertiesConfigure

</code></pre></div><h1>Springboot 启动原理？</h1>
<ul>
<li>SpringApplication这个类主要做了以下四件事情：
<ul>
<li>推断应用的类型是普通的项目还是 Web 项目</li>
<li>查找并加载所有可用初始化器 ， 设置到 initializers 属性中</li>
<li>找出所有的应用程序监听器，设置到 listeners 属性中</li>
<li>推断并设置 main 方法的定义类，找到运行的主类<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/4c9e3994321ee4a06a9e5.png" alt="springbootstart.png"></li>
</ul>
</li>
<li>为什么SpringBoot在启动的时候能够找到main方法上的@SpringBootApplication注解？</li>
<li>因为它利用了Java的反射机制和类加载机制，SpringApplication.run(Class&lt;?&gt;primarySource,String...args)方法接收两个参数：第一个是主应用类（即包含main方法的类），第二个是命令行参数。primarySource参数提供了一个起点，SpringBoot通过它来加载应用上下文。</li>
<li>SpringBoot利用Java反射机制来读取传递给run方法的类（MyApplication.class）。它会检查这个类上的注解，包括@SpringBootApplication。</li>
</ul>
<h1>Spring Boot 默认的包扫描路径是什么？</h1>
<ul>
<li>以启动类 @SpringBootApplication 注解所在的包为根目录的，默认情况会扫描启动类所在包及其子包下的所有组件。</li>
</ul>
]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/4c9e3994321ee4a06a9e5.png" type="image/png"/>
    </item>
    <item>
      <title>springcloud</title>
      <link>https://javaguide.cn/interview/springcloud.html</link>
      <guid>https://javaguide.cn/interview/springcloud.html</guid>
      <source url="https://javaguide.cn/rss.xml">springcloud</source>
      <description>什么是微服务？ 微服务（Microservices）是一种软件架构风格，将一个大型应用程序划分为一组小型、自治且松耦合的服务。每个微服务负责执行特定的业务功能，并通过轻量级通信机制（如HTTP）相互协作。每个微服务可以独立开发、部署和扩展，使得应用程序更加灵活、可伸缩和可维护。 在微服务的架构演进方向：单体式--&amp;gt;服务化SOA（Service-Orie...</description>
      <category>面试</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<!-- TOC -->
<!-- /TOC -->
<h1>什么是微服务？</h1>
<ul>
<li>微服务（Microservices）是一种软件架构风格，将一个大型应用程序划分为一组小型、自治且松耦合的服务。每个微服务负责执行特定的业务功能，并通过轻量级通信机制（如HTTP）相互协作。每个微服务可以独立开发、部署和扩展，使得应用程序更加灵活、可伸缩和可维护。</li>
<li>在微服务的架构演进方向：单体式--&gt;服务化SOA（Service-Oriented Architecture，面向服务的架构）--&gt;微服务。</li>
<li>微服务是一种特定的架构风格，而SOA是一种设计原则。微服务可以看作是对SOA思想的一种具体实践方式，但并不等同于SOA。</li>
<li>SOA关注于服务的重用性和组合性，但并没有具体规定服务的大小</li>
</ul>
<h1>微服务组件？</h1>
<ul>
<li>注册中心：用于服务的注册与发现，管理微服务的地址信息。常见的实现包括：
<ul>
<li>Spring Cloud Netflix：Eureka、Consul</li>
<li>Spring Cloud Alibaba：Nacos</li>
</ul>
</li>
<li>配置中心：用于集中管理微服务的配置信息，可以动态修改配置而不需要重启服务。常见的实现包括：
<ul>
<li>Spring Cloud Netflix：Spring Cloud Config</li>
<li>Spring Cloud Alibaba：Nacos Config</li>
</ul>
</li>
<li>远程调用：用于在不同的微服务之间进行通信和协作。常见的实现保包括：
<ul>
<li>RESTful API：如RestTemplate、Feign</li>
<li>RPC（远程过程调用）：如Dubbo、gRPC</li>
</ul>
</li>
<li>API网关：作为微服务架构的入口，统一暴露服务，并提供路由、负载均衡、安全认证等功能。常见的实现包括：
<ul>
<li>Spring Cloud Netflix：Zuul、Gateway</li>
<li>Spring Cloud Alibaba：Gateway、Apisix等</li>
</ul>
</li>
<li>分布式事务：保证跨多个微服务的一致性和原子性操作。常见的实现包括：
<ul>
<li>Spring Cloud Alibaba：Seata</li>
</ul>
</li>
<li>熔断器：用于防止微服务之间的故障扩散，提高系统的容错能力。常见的实现包括：
<ul>
<li>Spring Cloud Netflix：Hystrix</li>
<li>Spring Cloud Alibaba：Sentinel、Resilience4j</li>
</ul>
</li>
<li>限流和降级：用于防止微服务过载，对请求进行限制和降级处理。常见的实现包括：
<ul>
<li>Spring Cloud Netflix：Hystrix</li>
<li>Spring Cloud Alibaba：Sentinel</li>
</ul>
</li>
<li>分布式追踪和监控：用于跟踪和监控微服务的请求流程和性能指标。常见的实现包括：
<ul>
<li>Spring Cloud Netflix：Spring Cloud Sleuth + Zipkin</li>
<li>Spring Cloud Alibaba：SkyWalking、Sentinel Dashboard</li>
</ul>
</li>
</ul>
<h1>注册中心是用来干什么的？</h1>
<ul>
<li>注册中心是用来管理和维护分布式系统中各个服务的地址和元数据的组件。它主要用于实现服务发现和服务注册功能。
<ul>
<li>服务注册：各个服务在启动时向注册中心注册自己的网络地址、服务实例信息和其他相关元数据。这样，其他服务就可以通过注册中心获取到当前可用的服务列表。</li>
<li>服务发现：客户端通过向注册中心查询特定服务的注册信息，获得可用的服务实例列表。这样客户端就可以根据需要选择合适的服务进行调用，实现了服务间的解耦。</li>
<li>负载均衡：对同一服务的多个实例进行负载均衡，将请求分发到不同的实例上，提高整体的系统性能和可用性。</li>
<li>故障恢复：监测和检测服务的状态，当服务实例发生故障或下线时，可以及时更新注册信息，从而保证服务能够正常工作。</li>
<li>服务治理：进行服务的配置管理、动态扩缩容、服务路由、灰度发布等操作，实现对服务的动态管理和控制</li>
</ul>
</li>
</ul>
<h1>说下Eureka、ZooKeeper、Nacos的区别？√</h1>
<table>
<thead>
<tr>
<th>特性</th>
<th>Eureka</th>
<th>ZooKeeper</th>
<th>Nacos</th>
</tr>
</thead>
<tbody>
<tr>
<td>开发公司</td>
<td>Netflix</td>
<td>Apache 基金会</td>
<td>阿里巴巴</td>
</tr>
<tr>
<td>CAP</td>
<td>AP（可用性和分区容忍性）</td>
<td>CP（一致性和分区容忍性）</td>
<td>既支持AP，也支持CP</td>
</tr>
<tr>
<td>功能</td>
<td>服务注册与发现</td>
<td>分布式协调、配置管理、分布式锁</td>
<td>服务注册与发现、配置管理、服务管理</td>
</tr>
<tr>
<td>定位</td>
<td>适用于构建基于 HTTP 的微服务架构</td>
<td>通用的分布式协调服务框架</td>
<td>适用于微服务和云原生应用</td>
</tr>
<tr>
<td>访问协议</td>
<td>HTTP</td>
<td>TCP</td>
<td>HTTP/DNS</td>
</tr>
<tr>
<td>自我保护</td>
<td>支持</td>
<td>-</td>
<td>支持</td>
</tr>
<tr>
<td>数据存储</td>
<td>内嵌数据库、多个实例形成集群</td>
<td>ACID 特性的分布式文件系统 ZAB 协议</td>
<td>内嵌数据库、MySQL 等</td>
</tr>
<tr>
<td>健康检查</td>
<td>Client Beat</td>
<td>Keep Alive</td>
<td>TCP/HTTP/MYSQL/Client Beat</td>
</tr>
<tr>
<td>特点</td>
<td>简单易用、自我保护机制</td>
<td>高性能、强一致性</td>
<td>动态配置管理、流量管理、灰度发布等</td>
</tr>
<tr>
<td>可以看到Eureka和ZooKeeper的最大区别是一个支持AP，一个支持CP，Nacos既支持既支持AP，也支持CP。</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<h1>Eureka实现原理了解吗？</h1>
<ul>
<li>服务注册与发现: 当一个服务实例启动时，它会向Eureka Server发送注册请求，将自己的信息注册到注册中心。Eureka Server会将这些信息保存在内存中，并提供REST接口供其他服务查询。服务消费者可以通过查询服务实例列表来获取可用的服务提供者实例，从而实现服务的发现。</li>
<li>服务健康检查: Eureka通过心跳机制来检测服务实例的健康状态。服务实例会定期向Eureka Server发送心跳，也就是续约，以表明自己的存活状态。如果Eureka Server在一定时间内没有收到某个服务实例的心跳，则会将其标记为不可用，并从服务列表中移除，下线实例。</li>
<li>服务负载均衡: Eureka客户端在调用其他服务时，会从本地缓存中获取服务的注册信息。如果缓存中没有对应的信息，则会向Eureka Server发送查询请求。Eureka Server会返回一个可用的服务实例列表给客户端，客户端可以使用负载均衡算法选择其中一个进行调用。</li>
</ul>
<h1>Eureka Server怎么保证高可用？</h1>
<ul>
<li>多实例部署: 通过将多个Eureka Server实例部署在不同的节点上，可以实现高可用性。当其中一个实例发生故障时，其他实例仍然可以提供服务，并保持注册信息的一致性。</li>
<li>服务注册信息的复制: 当一个服务实例向Eureka Server注册时，每个Eureka Server实例都会复制其他实例的注册信息，以保持数据的一致性。当某个Eureka Server实例发生故障时，其他实例可以接管其工作，保证整个系统的正常运行。</li>
<li>自我保护机制: Eureka还具有自我保护机制。当Eureka Server节点在一定时间内没有接收到心跳时，它会进入自我保护模式。在自我保护模式下，Eureka Server不再剔除注册表中的服务实例，以保护现有的注册信息。这样可以防止由于网络抖动或其他原因导致的误剔除，进一步提高系统的稳定性。</li>
</ul>
<h1>为什么微服务需要配置中心？</h1>
<ul>
<li>微服务架构中的每个服务通常都需要一些配置信息，例如数据库连接地址、服务端口、日志级别等。这些配置可能因为不同环境、不同部署实例或者动态运行时需要进行调整和管理。</li>
<li>微服务的实例一般非常多，如果每个实例都需要一个个地去做这些配置，那么运维成本将会非常大，这时候就需要一个集中化的配置中心，去管理这些配置。</li>
</ul>
<h1>Nacos配置中心的原理</h1>
<ul>
<li>配置信息存储：Nacos默认使用内嵌数据库Derby来存储配置信息，还可以采用MySQL等关系型数据库。</li>
<li>注册配置信息：服务启动时，Nacos Client会向Nacos Server注册自己的配置信息，这个注册过程就是把配置信息写入存储，并生成版本号。</li>
<li>获取配置信息：服务运行期间，Nacos Client通过API从Nacos Server获取配置信息。Server根据键查找对应的配置信息，并返回给Client。</li>
<li>监听配置变化：Nacos Client可以通过注册监听器的方式，实现对配置信息的监听。当配置信息发生变化时，Nacos Server会通知已注册的监听器，并触发相应的回调方法。</li>
</ul>
<h1>Nacos配置中心长轮询机制？</h1>
<ul>
<li>一般来说客户端和服务端的交互分为两种：推（Push）和拉（Pull），Nacos在Pull的基础上，采用了长轮询来进行配置的动态刷新。</li>
<li>客户端发起Pull请求，服务端检查配置是否有变更。如果没有变更，则设置一个定时任务，在一段时间后执行，并将当前的客户端连接加入到等待队列中。</li>
<li>在等待期间，如果配置发生变更，服务端会立即返回结果给客户端，完成一次"推送"操作。<br>
如果在等待期间没有配置变更，等待时间达到预设的超时时间后，服务端会自动返回结果给客户端，即使配置没有变更。</li>
<li>如果在等待期间，通过Nacos Dashboard或API对配置进行了修改，会触发一个事件机制，服务端会遍历等待队列，找到发生变更的配置项对应的客户端连接，并将变更的数据通过连接返回，完成一次"推送"操作。</li>
<li>通过长轮询的方式，Nacos客户端能够实时感知配置的变化，并及时获取最新的配置信息。同时，这种方式也降低了服务端的压力，避免了大量的长连接占用内存资源。</li>
</ul>
<h1>能说下HTTP和RPC的区别吗？</h1>
<ul>
<li>HTTP（Hypertext Transfer Protocol）是一种应用层协议，主要强调的是网络通信；</li>
<li>RPC（Remote Procedure Call，远程过程调用）是一种用于分布式系统之间通信的协议，强调的是服务之间的远程调用。</li>
<li>在微服务体系里，基于HTTP风格的远程调用通常使用框架如Feign来实现，基于RPC的远程调用通常使用框架如Dubbo来实现。</li>
</ul>
<table>
<thead>
<tr>
<th>-</th>
<th>HTTP</th>
<th>RPC</th>
</tr>
</thead>
<tbody>
<tr>
<td>定义</td>
<td>HTTP（超文本传输协议）是一种用于传输超文本的协议。</td>
<td>RPC（远程过程调用）是一种用于实现分布式系统中不同节点之间通信的协议。</td>
</tr>
<tr>
<td>通信方式</td>
<td>基于请求-响应模型，客户端发送请求，服务器返回响应。</td>
<td>基于方法调用模型，客户端调用远程方法并等待结果。</td>
</tr>
<tr>
<td>传输协议</td>
<td>基于TCP协议，可使用其他传输层协议如TLS/SSL进行安全加密。</td>
<td>可以使用多种传输协议，如TCP、UDP等。</td>
</tr>
<tr>
<td>数据格式</td>
<td>基于文本，常用的数据格式有JSON、XML等。</td>
<td>可以使用各种数据格式，如二进制、JSON、Protocol Buffers等。</td>
</tr>
<tr>
<td>接口定义</td>
<td>使用RESTful风格的接口进行定义，常用的方法有GET、POST、PUT、DELETE等。</td>
<td>使用IDL（接口定义语言）进行接口定义，如Protocol Buffers、Thrift等。</td>
</tr>
<tr>
<td>跨语言性</td>
<td>支持跨语言通信，可以使用HTTP作为通信协议实现不同语言之间的通信。</td>
<td>支持跨语言通信，可以使用IDL生成不同语言的客户端和服务端代码。</td>
</tr>
<tr>
<td>灵活性</td>
<td>更加灵活，适用于不同类型的应用场景，如Web开发、API调用等。</td>
<td>更加高效，适用于需要高性能和低延迟的分布式系统。</td>
</tr>
</tbody>
</table>
<h1>Feign和Dubbo的区别？</h1>
<table>
<thead>
<tr>
<th>-</th>
<th>Feign</th>
<th>Dubbo</th>
</tr>
</thead>
<tbody>
<tr>
<td>定义</td>
<td>Feign是一个声明式的Web服务客户端，用于简化HTTP API的调用。</td>
<td>Dubbo是一个分布式服务框架，用于构建面向服务的微服务架构。</td>
</tr>
<tr>
<td>通信方式</td>
<td>基于HTTP协议，使用RESTful风格的接口进行定义和调用。</td>
<td>基于RPC协议，支持多种序列化协议如gRPC、Hessian等。</td>
</tr>
<tr>
<td>服务发现</td>
<td>通常结合服务注册中心（如Eureka、Consul）进行服务发现和负载均衡。</td>
<td>通过ZooKeeper、Nacos等进行服务注册和发现，并提供负载均衡功能。</td>
</tr>
<tr>
<td>服务治理</td>
<td>不直接提供服务治理功能，需要结合其他组件或框架进行服务治理。</td>
<td>提供服务注册与发现、负载均衡、容错机制、服务降级等服务治理功能。</td>
</tr>
<tr>
<td>跨语言性</td>
<td>支持跨语言通信，可以使用HTTP作为通信协议实现不同语言之间的通信。</td>
<td>支持跨语言通信，通过Dubbo的IDL生成不同语言的客户端和服务端代码。</td>
</tr>
<tr>
<td>生态系统</td>
<td>集成了Spring Cloud生态系统，与Spring Boot无缝集成。</td>
<td>拥有完整的生态系统，包括注册中心、配置中心、监控中心等组件。</td>
</tr>
<tr>
<td>适用场景</td>
<td>适用于构建RESTful风格的微服务架构，特别适合基于HTTP的微服务调用。</td>
<td>适用于构建面向服务的微服务架构，提供更全面的服务治理和容错机制。</td>
</tr>
</tbody>
</table>
<ul>
<li>Dubbo可以使用HTTP协议作为通信方式，而Feign也可以集成RPC协议进行远程调用。选择使用哪种远程调用方式取决于具体的业务需求和技术栈的选择</li>
</ul>
<h1>说一下Fegin?</h1>
<ul>
<li>Feign是一个声明式的Web服务客户端，它简化了使用基于HTTP的远程服务的开发。Feign使用RestTemplate实现Http调用，使用Ribbon实现负载均衡。</li>
<li>Feign的主要特点和功能包括：
<ul>
<li>声明式API：Feign允许开发者使用简单的注解来定义和描述对远程服务的访问。通过使用注解，开发者可以轻松地指定URL、HTTP方法、请求参数、请求头等信息，使得远程调用变得非常直观和易于理解。</li>
</ul>
</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>@FeignClient(name = "example", url = "https://api.example.com") 
 public interface ExampleService { 
     @GetMapping("/endpoint") 
     String getEndpointData(); 
 }
</code></pre></div><ul>
<li>集成负载均衡：Feign集成了Ribbon负载均衡器，可以自动实现客户端的负载均衡。它可以根据服务名和可用实例进行动态路由，并分发请求到不同的服务实例上，提高系统的可用性和可伸缩性。</li>
<li>容错机制：Feign支持集成Hystrix容错框架，可以在调用远程服务时提供容错和断路器功能。当远程服务不可用或响应时间过长时，Feign可以快速失败并返回预设的响应结果，避免对整个系统造成级联故障。</li>
</ul>
<h1>为什么Feign第一次调用耗时很长？</h1>
<ul>
<li>主要原因是由于Ribbon的懒加载机制，当第一次调用发生时，Feign会触发Ribbon的加载过程，包括从服务注册中心获取服务列表、建立连接池等操作，这个加载过程会增加首次调用的耗时。</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>ribbon: 
   eager-load: 
     enabled: true 
       clients: service-1
</code></pre></div><ul>
<li>解决方法：在应用启动时预热Feign客户端，自动触发一次无关紧要的调用，来提前加载Ribbon和其他相关组件。相当于提前进行了第一次调用。</li>
</ul>
<h1>Feign怎么实现认证传递？</h1>
<ul>
<li>使用拦截器传递认证信息。可以通过实现RequestInterceptor接口来定义拦截器，在拦截器里，把认证信息添加到请求头中，然后将其注册到Feign的配置中。</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>@Configuration 
 public class FeignClientConfig { 
  
     @Bean 
     public RequestInterceptor requestInterceptor() { 
         return new RequestInterceptor() { 
             @Override 
             public void apply(RequestTemplate template) { 
                 // 添加认证信息到请求头中 
                 template.header("Authorization", "Bearer " + getToken()); 
             } 
         }; 
     } 
  
     private String getToken() { 
         // 获取认证信息的逻辑，可以从SecurityContext或其他地方获取 
         // 返回认证信息的字符串形式 
         return "your_token"; 
     } 
 }
</code></pre></div><h1>Fegin怎么做负载均衡？Ribbon?</h1>
<ul>
<li>在Feign中，负载均衡是通过集成Ribbon来实现的。Ribbon是Netflix开源的一个客户端负载均衡器.Ribbon通过从服务注册中心获取可用服务列表，并通过负载均衡算法选择合适的服务实例进行请求转发，实现客户端的负载均衡。</li>
</ul>
<h1>负载均衡算法？</h1>
<h1>1. springcloud组件有哪些？ √</h1>
<ul>
<li>服务发现与注册ZooKeeper、Eureka、consoul、Nacos</li>
<li>服务间调用Feign</li>
<li>断路器Hystrix、Sentinel</li>
<li>网关Zuul、gatyway</li>
<li>分布式配置consul</li>
<li>负载均衡Ribbon、spring-cloud-loadbalancer</li>
</ul>
<h1>2. 微服务的优缺点？</h1>
<ul>
<li>优点
<ul>
<li>每一个服务足够内聚,代码容易理解</li>
<li>开发效率提高，一个服务只做一件事</li>
<li>微服务能够被小团队单独开发</li>
<li>微服务是松耦合的，是有功能意义的服务</li>
<li>可以用不同的语言开发,面向接口编程</li>
<li>易于与第三方集成</li>
<li>微服务只是业务逻辑的代码，不会和 HTML、CSS 或者其他界面组合</li>
</ul>
</li>
<li>缺点
<ul>
<li>分布式系统的复杂性</li>
<li>多服务运维难度，随着服务的增加，运维的压力也在增大</li>
<li>系统部署依赖</li>
<li>服务间通信成本</li>
<li>数据一致性和事务管理</li>
<li>系统集成测试</li>
<li>性能监控</li>
<li>团队沟通和协作成本</li>
</ul>
</li>
</ul>
<h1>流行的微服务解决方案及区别</h1>
<table>
<thead>
<tr>
<th>特点</th>
<th>Dubbo</th>
<th>Spring Cloud Netflix</th>
<th>Spring Cloud Alibaba</th>
</tr>
</thead>
<tbody>
<tr>
<td>开发语言</td>
<td>Java</td>
<td>Java</td>
<td>Java</td>
</tr>
<tr>
<td>服务治理</td>
<td>提供完整的服务治理功能</td>
<td>提供部分服务治理功能</td>
<td>提供完整的服务治理功能</td>
</tr>
<tr>
<td>服务注册与发现</td>
<td>ZooKeeper/Nacos</td>
<td>Eureka/Consul</td>
<td>Nacos</td>
</tr>
<tr>
<td>负载均衡</td>
<td>自带负载均衡策略</td>
<td>Ribbon</td>
<td>Ribbon\Dubbo负载均衡策略</td>
</tr>
<tr>
<td>服务调用</td>
<td>RPC方式</td>
<td>RestTemplate/Feign</td>
<td>Feign/RestTemplate/Dubbo</td>
</tr>
<tr>
<td>熔断器</td>
<td>Sentinel</td>
<td>Hystrix</td>
<td>Sentinel/Resilience4j</td>
</tr>
<tr>
<td>配置中心</td>
<td>Apollo</td>
<td>Spring Cloud Config</td>
<td>Nacos Config</td>
</tr>
<tr>
<td>API网关</td>
<td>Higress/APISIX</td>
<td>Zuul/Gateway</td>
<td>Spring Cloud Gateway</td>
</tr>
<tr>
<td>分布式事务</td>
<td>Seata</td>
<td>不支持分布式事务</td>
<td>Seata</td>
</tr>
<tr>
<td>限流和降级</td>
<td>Sentinel</td>
<td>Hystrix</td>
<td>Sentinel</td>
</tr>
<tr>
<td>分布式追踪和监控</td>
<td>Skywalking</td>
<td>Spring Cloud Sleuth + Zipkin</td>
<td>SkyWalking或Sentinel Dashboard</td>
</tr>
<tr>
<td>微服务网格</td>
<td>Dubbo Mesh</td>
<td>不支持微服务网格</td>
<td>Service Mesh（Nacos+Dubbo Mesh）</td>
</tr>
<tr>
<td>社区活跃度</td>
<td>相对较高</td>
<td>目前较低</td>
<td>相对较高</td>
</tr>
<tr>
<td>孵化和成熟度</td>
<td>孵化较早，成熟度较高</td>
<td>成熟度较高</td>
<td>孵化较新，但迅速发展</td>
</tr>
</tbody>
</table>
<h1>3. 服务注册与发现</h1>
<ul>
<li>基于spring-cloud-commons的discovery的DiscoveryClient接口，实现统一的客户端的注册发现。</li>
<li>spring-cloud-netflix-eureka-server和spring-cloud-netflix-eureka-client ，基于Eureka实现。</li>
<li>spring-cloud-alibaba-nacos-discovery，基于Nacos实现。</li>
<li>spring-cloud-zookeeper-discovery，基于Zookeeper实现。</li>
</ul>
<h2>3.1. 为什么要有服务注册与发现？</h2>
<ul>
<li>屏蔽、解耦服务之间相互依赖的细节。服务之间的远程调用必须要知道IP、端口信息。调用方直接配置被调用方的IP、端口，这种调用直接依赖IP、端口的方式存在依赖，如被调用的IP、端口变化后，调用方也要同步修改。通过服务发现，将服务的IP、端口转化成服务名来调用。</li>
<li>对微服务进行动态配置。微服务架构中，服务众多、服务之间的相互依赖错综复杂，无论是服务主动停止、意外挂掉，还是因为流量增加对服务实现扩容，这些服务或状态上的动态变化，都需要尽快的通知到被调用方，被调用方采取相应的策略。对于服务注册与发现要实时管理者服务的数据和状态，包括服务的注册上线、服务主动下线，异常服务的踢出。服务发现将服务IP、端口等细节通过一个服务名抽象给调用者，并动态管理者各个微服务的状态检测、状态更新，服务上线，下线等，这些都是微服务治理的基础，包括，负载均衡，链路跟踪。</li>
<li>服务发现有两大模式：
<ul>
<li>客户端发现模式：客户端决定相应服务实例的网络位置，并且对请求实现负载均衡。客户端查询服务注册表，后者是一个可用服务实例的数据库；然后使用负载均衡算法从中选择一个实例，并发出请求</li>
<li>服务端发现模式：客户端通过负载均衡器向某个服务提出请求，负载均衡器查询服务注册表，并将请求转发到可用的服务实例。如同客户端发现，服务实例在服务注册表中注册或注销。</li>
</ul>
</li>
</ul>
<h2>3.2. Eureka介绍</h2>
<ul>
<li>由两个组件组成：Eureka服务端，服务注册中心，支持集群部署；Eureka 客户端，Java客户端，用来处理服务注册与发现。</li>
<li>在应用启动时，Eureka客户端向服务端注册自己的服务信息，同时将服务端的服务信息缓存到本地。客户端会和服务端周期性的进行心跳交互，以更新服务租约和服务信息。</li>
</ul>
<h2>3.3. Eureka缓存机制？</h2>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/d8e1d1b5769a399ef1bb8.png" alt="eurekacache.png" tabindex="0"><figcaption>eurekacache.png</figcaption></figure>
<h2>3.4. Eureka自我保护模式？解决方法</h2>
<ul>
<li>当Eureka Server节点在短时间内丢失了过多实例的连接时（比如网络故障或频繁的启动关闭客户端）就会进入自我保护模式，保护服务注册表中的信息，不再删除服务注册表中的数据（即不会注销任何微服务），当网络故障恢复后，就会自动退出自我保护模式</li>
<li>解决方法
<ul>
<li>等待Eureka Server自动恢复等待网络恢复（或者没有频繁的启动与关闭实例）</li>
<li>重启Eureka Server生产环境建议对Eureka Server做负载均衡，这样在依次重启Eureka Server后，无效的实例会被清除。</li>
<li>关闭Eureka自我保护模式。yml配置文件：</li>
</ul>
</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>eureka:
  server:
    enable-self-preservation: false
    eviction-interval-timer-in-ms: 4000 # This is not required
</code></pre></div><h2>3.5. eureka的注册中心怎么知道最近的服务，就近机房？</h2>
<ul>
<li>通过属性prefer-same-zone-eureka
<ul>
<li>如果false则按照service-url的第一个注册中心来注册，并和其维持心跳检测，不再向其它注册中心注册和维持心跳。只有在第一个注册失败的情况下，才会依次向其它的注册中心注册，总共重试3次，注册失败后每隔一个心跳时间，会再次尝试。</li>
<li>如果true，先通过region取availability-zones内的第一个zone的service-url下的第一个注册中心进行注册和维持心跳，不再向其它的注册中心注册和维持心跳。只有在第一个注册失败的情况下，才会依次向其它的注册中心注册，总共重试3次，注册失败后每隔一个心跳时间，会再次尝试。为了保证服务注册到同一个 zone 的注册中心，一定要注意 availability-zones 的顺序，必须把同一zone写在最前面</li>
</ul>
</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>eureka:
  client:
    # 尽量向同一区域的 eureka 注册,默认为true
    prefer-same-zone-eureka: true
    #地区
    region: tianjin
    availability-zones:
      tianjin: zone-1,zone-2
    service-url:
      zone-1: http://IP1:port/eureka/,http://IP2:port/eureka/,http://IP3:port/eureka/
      zone-2: http://IP1:port/eureka/,http://IP2:port/eureka/,http://IP3:port/eureka/
</code></pre></div><h2>3.6. ZooKeeper，eureka，nacos原理？</h2>
<ul>
<li>基于spring-cloud-commons的discovery的DiscoveryClient接口，实现统一的客户端的注册发现。</li>
<li>ZooKeeper(CP)：leader+follower，leader写，同步到follower，follower读，保证顺序一致性，主动推送，leader崩溃的时候，为了保证数据一致性，尽量不要读到不一致的数据，此时要重新选举leader以及做数据同步，此时集群会短暂的不可用</li>
<li>Eureka(AP)：peer-to-peer，各节点都能写也都能读，每个节点通过异步复同步给其他节点，所以可能数据不一致，任何一个节点宕机，其他节点正常工作，可用性高</li>
<li>Nacos(CP/AP)：基于raft算法。还提供了配置管理、元数据管理和流量管理等功能，并且提供了一个可视化的控制台管理界面。</li>
</ul>
<h1>4. 在 Spring Cloud 中的负载均衡</h1>
<ul>
<li>基于spring-cloud-commons的loadbalancer的ServiceInstanceChooser接口实现统一的服务的选择。并且，负载均衡组件在选择需要调用的服务之后，还提供调用该服务的功能，具体方法见LoadBalancerClient接口的execute方法。
<ul>
<li>spring-cloud-netflix-ribbon，基于Ribbon实现。</li>
<li>spring-cloud-loadbalancer，提供简单的负载均衡功能。</li>
</ul>
</li>
</ul>
<h2>4.1. 负载均衡的两种模式</h2>
<ul>
<li>客户端模式：客户端节点有一份服务端清单，从Eureka服务注册中心获取。在Spring Cloud中使用@LoadBalanced注解开启客户端模式</li>
<li>服务端模式（nginx）：维护一个可用的服务端清单，然后通过心跳机制来删除故障的服务端节点以保证清单中都是可以正常访问的服务端节点。负载均衡服务器按照某种配置好的规则从可用服务端清单中选出一台服务器去处理客户端的请求。</li>
</ul>
<h2>4.2. 负载均衡作用</h2>
<ul>
<li>优化资源使用，最大化吞吐量，最小化响应时间并避免任何单一资源的过载。使用多个组件进行负载平衡而不是单个组件可能会通过冗余来提高可靠性和可用性。负载平衡通常涉及专用软件或硬件，例如多层交换机或域名系统服务器进程。</li>
</ul>
<h2>4.3. ribbon介绍？核心组件？</h2>
<ul>
<li>作用：主要提供客户端的软件负载均衡算法。</li>
<li>核心组件
<ul>
<li>Server封装了服务实例的ip和端口之类</li>
<li>ServerList获取服务实例列表的</li>
<li>ServerListUpdater是用来更新服务注册表的数据</li>
<li>IRule负责负载均衡的算法的</li>
<li>IClientConfig获取到一些配置Ribbon的一些配置</li>
<li>ILoadBalancer主要是用来协调上面提到的各个核心组件的，使得他们能够协调工作</li>
</ul>
</li>
</ul>
<h2>4.4. ribbon实现原理？</h2>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/7324515938c59a3c405b2.jpg" alt="ribbonprinciple.png" tabindex="0"><figcaption>ribbonprinciple.png</figcaption></figure>
<h2>4.5. ribbon负载均衡算法？√</h2>
<ul>
<li>Round Robin轮询</li>
<li>Random 随机</li>
<li>AvailabilityFilteringRule会优先过滤掉由于多次访问故障而处于断路器跳闸状态被标记为circuit tripped的服务，还有并发的连接数（active connections 超过配置的阈值）超过临界值的服务，然后对剩余的服务列表按照轮训策略进行访问</li>
<li>WeightedResponseTimeRule根据平均响应时间计算所有服务的权重，响应时间越快服务权重越大被选中的机率越大，刚启动时如果统计信息不足，则使用RoundRobinRule 策略，等统计信息足，会切换到WeightedResponseTimeRule</li>
<li>RetryRule先按照RoundRobinRule策略获取服务，如果获取服务失败则在制定时间内进行重试</li>
<li>BestAvailableRule会优先过滤掉由于多次访问故障而处于断路器跳闸状态的服务，选择一个最小的并发请求的server.逐个考察Server，如果Server被tripped则忽略，在选择ActiveRequestsCount最小的server</li>
<li>ZoneAvoidanceRule复合判断server所在区域的性能和server的可用性选择服务器</li>
</ul>
<h2>4.6. Ribbon 缓存机制？</h2>
<h2>4.7. Ribbon 重试机制？</h2>
<h2>4.8. Ribbon 是怎么和 Eureka 整合的？</h2>
<ul>
<li>首先，Ribbon 会从 Eureka Client 里获取到对应的服务列表。</li>
<li>然后，Ribbon 使用负载均衡算法获得使用的服务。</li>
<li>最后，Ribbon 调用对应的服务。</li>
</ul>
<h1>5. 声明式调用fegin？实现原理？</h1>
<ul>
<li>spring-cloud-openfeign ，基于 Feign 实现。</li>
<li>Feign 实现原理
<ul>
<li>如果接口定义了@FeignClient注解，Feign会对这个接口创建一个动态代理。用那个接口本质就是会调用 Feign 创建的动态代理，</li>
<li>Feign的动态代理会根据接口上@RequestMapping 等注解，来动态构造出你要请求的服务的地址。</li>
<li>最后针对这个地址，发起请求、解析响应。</li>
<li>通过@EnableFeignClients和FeignClient注解 通过动态代理在本地实例化远程接口-&gt;封装Request对象并进行编码-&gt;使用restTemplate发起http请求并对获取结果进行解码。<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/0895bad5dd977f581dd19.jpg" alt="feginprinciple.png"></li>
</ul>
</li>
</ul>
<h2>5.1. Feign 和 Ribbon 的区别？</h2>
<ul>
<li>Ribbon和Feign都是使用于调用用其余服务的，不过方式不同。
<ul>
<li>启动类用的注解不同。Ribbon使用的是@RibbonClient ；Feign 使用的是 @EnableFeignClients 。</li>
<li>服务的指定位置不同。Ribbon是在@RibbonClient注解上设置；Feign则是在定义声明方法的接口中用@FeignClient注解上设置</li>
</ul>
</li>
<li>调使用方式不同
<ul>
<li>Ribbon需要构建Http请求，模拟Http请求而后用RestTemplate发送给其余服务，步骤相当繁琐。</li>
<li>Feign采使用接口的方式，将需要调使用的其余服务的方法定义成声明方法就可，不需要构建Http请求。不过要注意的是声明方法的注解、方法签名要和提供服务的方法完全一致。</li>
</ul>
</li>
</ul>
<h2>5.2. Feign 是怎么和 Ribbon、Eureka 整合的?</h2>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/0520ffe60397bffac0eb3.jpg" alt="feginribboneureka.png" tabindex="0"><figcaption>feginribboneureka.png</figcaption></figure>
<ul>
<li>首先，用户调用 Feign 创建的动态代理。</li>
<li>然后，Feign 调用 Ribbon 发起调用流程。
<ul>
<li>首先，Ribbon 会从 Eureka Client 里获取到对应的服务列表。</li>
<li>然后，Ribbon 使用负载均衡算法获得使用的服务。</li>
<li>ribbon调用对应的服务，调用 Feign ，而 Feign 调用 HTTP 库最终调用使用的服务。</li>
<li>因为 Feign 和 Ribbon 都存在使用 HTTP 库调用指定的服务，两者集成后保留Feign的调用，而Ribbon只负责负载均衡功能</li>
</ul>
</li>
</ul>
<h2>5.3. Feign 重试机制？</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>//Ribbon+RestTemplate的重试
@Bean
@LoadBalanced
public RestTemplate restTemplate() {
  SimpleClientHttpRequestFactory simpleClientHttpRequestFactory = new   SimpleClientHttpRequestFactory();
  simpleClientHttpRequestFactory.setConnectTimeout(1000);
  simpleClientHttpRequestFactory.setReadTimeout(1000);
  return new RestTemplate(simpleClientHttpRequestFactory);
}
在此基础上，使用如下配置，即可实现重试：
spring.cloud.loadbalancer.retry.enabled=true
ribbon:
  # 同一实例最大重试次数，不包括首次调用
  MaxAutoRetries: 1
  # 重试其他实例的最大重试次数，不包括首次所选的server
  MaxAutoRetriesNextServer: 2
  # 是否所有操作都进行重试
  OkToRetryOnAllOperations: false

因为 Ribbon 和 Feign 都有重试机制，在整合 Ribbon 的情况下，不使用 Feign 重试，而是使用 Ribbon 的重试。
ribbon:
  MaxAutoRetries: 1
  MaxAutoRetriesNextServer: 2
  OkToRetryOnAllOperations: false
相关Issue可参考：https://github.com/spring-cloud/spring-cloud-netflix/issues/467

Zuul的重试
# 开启了重试
zuul.retryable: true
ribbon:
  MaxAutoRetries: 1
  MaxAutoRetriesNextServer: 2
  OkToRetryOnAllOperations: false
# 指定局部路由开启重试，局部配置优先级更高。
zuul.routes.&lt;routename&gt;.retryable=true

基于HTTP响应码重试
clientName.ribbon.retryableStatusCodes: 404,502
Hystrix的超时时间必须大于超时的时间，否则，一旦Hystrix超时，就没办法继续重试了。
不建议将ribbon.OkToRetryOnAllOperations 设为true。因为一旦启用该配置，则表示重试任何操作，包括POST请求，而由于缓存了请求体，此时可能会影响服务器的资源。
</code></pre></div><h1>6. 服务保障？</h1>
<ul>
<li>spring-cloud-netflix-hystrix基于 Hystrix 实现。</li>
<li>spring-cloud-alibaba-sentinel基于 Sentinel 实现。</li>
</ul>
<h2>什么是服务雪崩？</h2>
<ul>
<li>在微服务中，假如一个或者多个服务出现故障，如果这时候，依赖的服务还在不断发起请求，或者重试，那么这些请求的压力会不断在下游堆积，导致下游服务的负载急剧增加。不断累计之下，可能会导致故障的进一步加剧，可能会导致级联式的失败，甚至导致整个系统崩溃，这就叫服务雪崩。</li>
<li>防止方法
<ul>
<li>服务高可用部署：确保各个服务都具备高可用性，通过冗余部署、故障转移等方式来减少单点故障的影响。</li>
<li>限流和熔断：对服务之间的请求进行限流和熔断，以防止过多的请求涌入导致后端服务不可用。</li>
<li>缓存和降级：合理使用缓存来减轻后端服务的负载压力，并在必要时进行服务降级，保证核心功能的可用性。</li>
</ul>
</li>
</ul>
<h2>6.1. 为什么要使用服务保障？</h2>
<ul>
<li>在微服务架构中，我们将业务拆分成一个个的服务，服务与服务之间可以相互调用（RPC）。为了保证其高可用，单个服务又必须集群部署。由于网络原因或者自身的原因，服务并不能保证服务的 100% 可用，如果单个服务出现问题，调用这个服务就会出现网络延迟，此时若有大量的网络涌入，会形成任务累积，导致服务瘫痪，甚至导致服务“雪崩”。为了解决这个问题，就出现断路器模型。</li>
</ul>
<h2>6.2. hystrix作用，原理√</h2>
<ul>
<li>断路器，保护系统，控制故障范围。</li>
<li>简介：Hystrix 是一个延迟和容错库，旨在隔离远程系统，服务和第三方库的访问点，当出现故障是不可避免的故障时，停止级联故障并在复杂的分布式系统中实现弹性。</li>
<li>旨在通过添加延迟容错和容错逻辑来提高分布式系统的弹性，防止雪崩效应的发生。它通过隔离服务之间的依赖关系、限制并发线程池的大小、实现熔断机制等方式来实现容错。</li>
<li>旨在隔离远程系统，服务和第三方库的访问点，当出现故障是不可避免的故障时，停止级联故障并在复杂的分布式系统中实现弹性。</li>
</ul>
<h2>6.3. Hystrix隔离策略</h2>
<ul>
<li>线程池隔离(支持超时)。tomcat线程会将请求任务交给服务内部线程池的线程处理，线程完成后将调用结果返回给tomcat。从而实现资源隔离，服务内部的线程池的数量就决定了整个服务并发度；当请求的服务网络开销比较大的时候，或者是请求比较耗时的时候使用，因为，可以保证大量的容器(tomcat)线程可用，不会由于服务原因，一直处于阻塞或等待状态，快速失败返回</li>
<li>信号量隔离。限制tomcat访问服务的线程数达到限流目的。请求缓存服务时使用，因为这类服务的返回通常会非常的快，不会占用容器线程太长时间，而且也减少了线程切换的一些开销，提高了缓存服务的效率<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/62d5d0137dc8127da398a.jpg" alt="hystrixprinciple.png"></li>
</ul>
<h2>6.4. Hystrix 缓存机制？作用？</h2>
<ul>
<li>减少重复的请求数。降低依赖服务的返回数据始终保持一致。</li>
<li>在同一个用户请求的上下文中，相同依赖服务的返回数据始终保持一致。</li>
<li>请求缓存在run()和construct()执行之前生效，所以可以有效减少不必要的线程开销</li>
</ul>
<h2>7. 什么是服务熔断？</h2>
<ul>
<li>服务熔断是微服务架构中的容错机制，用于保护系统免受服务故障或异常的影响。当某个服务出现故障或异常时，服务熔断可以快速隔离该服务，确保系统稳定可用。</li>
<li>它通过监控服务的调用情况，当错误率或响应时间超过阈值时，触发熔断机制，后续请求将返回默认值或错误信息，避免资源浪费和系统崩溃。</li>
<li>服务熔断还支持自动恢复，重新尝试对故障服务的请求，确保服务恢复正常后继续使用。</li>
</ul>
<h2>什么是服务降级？</h2>
<ul>
<li>服务降级是一种微服务架构中的容错机制，用于在系统资源紧张或服务故障时保证核心功能的可用性。</li>
<li>当系统出现异常情况时，服务降级会主动屏蔽一些非核心或可选的功能，而只提供最基本的功能，以确保系统的稳定运行。通过减少对资源的依赖，服务降级可以保证系统的可用性和性能。</li>
<li>它可以根据业务需求和系统状况来制定策略，例如替换耗时操作、返回默认响应、返回静态错误页面等。</li>
</ul>
<h2>熔断降级方案实现？</h2>
<table>
<thead>
<tr>
<th>框架</th>
<th>实现方案</th>
<th>特点</th>
</tr>
</thead>
<tbody>
<tr>
<td>Spring Cloud	Netflix</td>
<td>Hystrix</td>
<td>提供线程隔离、服务降级、请求缓存、请求合并等功能可与Spring Cloud其他组件无缝集成.官方已宣布停止维护，推荐使用Resilience4j代替</td>
</tr>
<tr>
<td>Spring Cloud</td>
<td>Resilience4j</td>
<td>轻量级服务熔断库 提供类似于Hystrix的功能 具有更好的性能和更简洁的API 可与Spring Cloud其他组件无缝集成</td>
</tr>
<tr>
<td>Spring Cloud Alibaba</td>
<td>Sentinel</td>
<td>阿里巴巴开源的流量控制和熔断降级组件提供实时监控、流量控制、熔断降级等功能与Spring Cloud Alibaba生态系统紧密集成</td>
</tr>
<tr>
<td>Dubbo</td>
<td>Dubbo自带熔断降级机制</td>
<td>Dubbo框架本身提供的熔断降级机制可通过配置实现服务熔断和降级与Dubbo的RPC框架紧密集成</td>
</tr>
</tbody>
</table>
<h1>Hystrix怎么实现服务容错？</h1>
<ul>
<li>服务熔断（Circuit Breaker）：Hystrix通过设置阈值来监控服务的错误率或响应时间。当错误率或响应时间超过预设的阈值时，熔断器将会打开，后续的请求将不再发送到实际的服务提供方，而是返回预设的默认值或错误信息。这样可以快速隔离故障服务，防止故障扩散，提高系统的稳定性和可用性。</li>
<li>服务降级（Fallback）：当服务熔断打开时，Hystrix可以提供一个备用的降级方法或返回默认值，以保证系统继续正常运行。开发者可以定义降级逻辑，例如返回缓存数据、执行简化的逻辑或调用其他可靠的服务，以提供有限但可用的功能。</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>import com.netflix.hystrix.contrib.javanica.annotation.HystrixCommand; 
  
 /** 
 * 服务降级示例 
 **/ 
 @Service 
 public class MyService { 
  
     @HystrixCommand(fallbackMethod = "fallbackMethod") 
     public String myServiceMethod() { 
         // 实际的服务调用逻辑 
         // ... 
     } 
  
     public String fallbackMethod() { 
         // 降级方法的逻辑，当服务调用失败时会执行此方法 
         // 可以返回默认值或执行其他备用逻辑 
         // ... 
     } 
 }
</code></pre></div><ul>
<li>请求缓存（Request Caching）：Hystrix可以缓存对同一请求的响应结果，当下次请求相同的数据时，直接从缓存中获取，避免重复的网络请求，提高系统的性能和响应速度。</li>
<li>请求合并（Request Collapsing）：Hystrix可以将多个并发的请求合并为一个批量请求，减少网络开销和资源占用。这对于一些高并发的场景可以有效地减少请求次数，提高系统的性能。</li>
<li>实时监控和度量（Real-time Monitoring and Metrics）：Hystrix提供了实时监控和度量功能，可以对服务的执行情况进行监控和统计，包括错误率、响应时间、并发量等指标。通过监控数据，可以及时发现和解决服务故障或性能问题。</li>
<li>线程池隔离（Thread Pool Isolation）：Hystrix将每个依赖服务的请求都放在独立的线程池中执行，避免因某个服务的故障导致整个系统的线程资源耗尽。通过线程池隔离，可以提高系统的稳定性和可用性。</li>
</ul>
<h2>6.5. Hystrix 熔断机制？实现？</h2>
<ul>
<li>Hystrix的熔断机制通过监控服务调用的状态来实现。当服务调用失败率达到一定阈值时，Hystrix会自动开启熔断器，将后续的请求快速失败，避免对服务的进一步压力。</li>
<li>Hystrix的熔断方式有以下几种：
<ul>
<li>强制熔断：在某些情况下，比如服务提供方宕机等情况下，直接强制熔断，不再进行服务调用。</li>
<li>根据阈值熔断：当服务调用失败率达到一定阈值时，自动开启熔断器，将后续请求快速失败。</li>
<li>半开状态熔断：在熔断器开启一段时间后，尝试发送一个测试请求到服务提供方，如果请求成功，则熔断器进入半开状态，否则继续保持开启状态。</li>
<li>降级：当服务调用失败或超时时，可以通过返回默认值或者调用备用服务的方式进行降级，保证系统的可用性。</li>
</ul>
</li>
<li>Hystrix断路器通过HystrixCircuitBreaker实现。有三种状态:CLOSED-关闭；OPEN-打开；HALF_OPEN-半开
<ul>
<li>断路器处于OPEN状态时，链路处于非健康状态，命令执行时，直接调用回退逻辑，跳过正常逻辑。</li>
<li>红线:初始时断路器处于CLOSED状态，链路处于健康状态。当满足如下条件，断路器从CLOSED变成OPEN状态
<ul>
<li>周期(可配，HystrixCommandProperties.default_metricsRollingStatisticalWindow = 10000 ms)内，总请求数超过一定量(可配，HystrixCommandProperties.circuitBreakerRequestVolumeThreshold = 20 ) 。错误请求占总请求数超过一定比例( 可配，HystrixCommandProperties.circuitBreakerErrorThresholdPercentage = 50% ) 。</li>
</ul>
</li>
<li>绿线:断路器处于OPEN状态，命令执行时，若当前时间超过断路器开启时间一定时间(HystrixCommandProperties.circuitBreakerSleepWindowInMilliseconds = 5000ms)，断路器变成HALF_OPEN状态，尝试调用正常逻辑，根据执行是否成功，打开或关闭熔断器【蓝线】。<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/7aa4fa0667258f4190419.jpg" alt="hystrixcircuitbreakerstatuschange.png"></li>
</ul>
</li>
</ul>
<h2>6.6. 什么是 Hystrix服务降级？</h2>
<ul>
<li>在 Hystrix 断路器熔断时，可以调用一个降级方法(需要配置和编码，也可以不写，也就是不会有服务降级的功能)，返回相应的结果。</li>
</ul>
<h2>8. 服务熔断和服务降级的区别</h2>
<ul>
<li>服务熔断一般是某个服务（下游服务）故障引起，而服务降级一般是从整体负荷考虑；熔断其实是一个框架级的处理，每个微服务都需要（无层级之分），而降级一般需要对业务有层级之分（比如降级一般是从最外围服务开始）实现方式不太一样；服务降级具有代码侵入性(由控制器完成/或自动降级)，熔断一般称为自我熔断。</li>
</ul>
<h2>9. 服务限流</h2>
<ul>
<li>限流的目的是通过对并发访问/请求进行限速或者一个时间窗口内的的请求进行限速来保护系统，一旦达到限制速率则可以拒绝服务（定向到错误页或告知资源没有了）、排队或等待（比如秒杀、评论、下单）、降级（返回兜底数据或默认数据，如商品详情页库存默认有货）。</li>
</ul>
<h2>Sentinel怎么实现限流的？</h2>
<ul>
<li>Sentinel通过动态管理限流规则，根据定义的规则对请求进行限流控制。具体实现步骤如下：</li>
<li>定义资源：在Sentinel中，资源可以是URL、方法等，用于标识需要进行限流的请求。</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>// 原本的业务方法. 
 @SentinelResource(blockHandler = "blockHandlerForGetUser") 
 public User getUserById(String id) { 
     throw new RuntimeException("getUserById command failed"); 
 } 
  
 // blockHandler 函数，原方法调用被限流/降级/系统保护的时候调用 
 public User blockHandlerForGetUser(String id, BlockException ex) { 
     return new User("admin"); 
 }
</code></pre></div><ul>
<li>配置限流规则：在Sentinel的配置文件中定义资源的限流规则。规则可以包括资源名称、限流阈值、限流模式（令牌桶或漏桶）等。</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>private static void initFlowQpsRule() { 
     List&lt;FlowRule&gt; rules = new ArrayList&lt;&gt;(); 
     FlowRule rule1 = new FlowRule(); 
     rule1.setResource(resource); 
     // Set max qps to 20 
     rule1.setCount(20); 
     rule1.setGrade(RuleConstant.FLOW_GRADE_QPS); 
     rule1.setLimitApp("default"); 
     rules.add(rule1); 
     FlowRuleManager.loadRules(rules); 
 }
</code></pre></div><ul>
<li>监控流量：Sentinel会监控每个资源的流量情况，包括请求的QPS（每秒请求数）、线程数、响应时间等。</li>
<li>限流控制：当请求到达时，Sentinel会根据资源的限流规则判断是否需要进行限流控制。如果请求超过了限流阈值，则可以进行限制、拒绝或进行其他降级处理。</li>
</ul>
<h1>Sentinel采用的什么限流算法？</h1>
<ul>
<li>Sentinel使用滑动窗口限流算法来实现限流。滑动窗口限流算法是一种基于时间窗口的限流算法。它将一段时间划分为多个时间窗口，并在每个时间窗口内统计请求的数量。通过动态地调整时间窗口的大小和滑动步长，可以更精确地控制请求的通过速率。</li>
</ul>
<h2>6.7. Sentinel有哪些流程控制规则？√</h2>
<ul>
<li>流量控制，其原理是监控应用流量的QPS或并发线程数等指标，当达到指定的阈值时对流量进行控制，以避免被瞬时的流量高峰冲垮，从而保障应用的高可用性</li>
<li>1.QPS(Queries Per Second)：当调用相关url对应的资源时，QPS达到单机阈值时，就会限流。</li>
<li>2.线程数：当调用相关url对应的资源时，线程数达到单机阈值时，就会限流。</li>
<li>设置限流模式
<ul>
<li>直连模式 sentinel默认的流控处理就是(直连--&gt;快速失败);</li>
<li>关联模式 当关联的资源达到阈值，就限流自己。</li>
<li>链路模式 只针对从指定链路访问到本资源的请求做统计，判断是否超过阈值。直接拒绝直接拒绝（RuleConstant.CONTROL_BEHAVIOR_DEFAULT）方式是默认的流量控制方式，当QPS超过任意规则的阈值后，新的请求就会被立即拒绝，拒绝方式为抛出FlowException。</li>
</ul>
</li>
</ul>
<h1>Sentinel怎么实现集群限流？</h1>
<p>Sentinel利用了Token Server和Token Client的机制来实现集群限流。开启集群限流后，Client向Token Server发送请求，Token Server根据配置的规则决定是否限流。</p>
<h1>10. 网关服务</h1>
<ul>
<li>spring-cloud-netflix-zuul，基于Zuul1实现。Netflix最新开源的网关服务是Zuul2 ，基于响应式的网关服务。</li>
<li>spring-cloud-gateway ，基于Spring Webflux实现</li>
</ul>
<h2>10.1. 为什么要有网关？</h2>
<ul>
<li>
<p>动态路由：反向代理</p>
</li>
<li>
<p>安全控制：统一认证（支持 HMAC, JWT, Basic, OAuth 2.0等常用协议）和鉴权（权限控制、IP 黑白名单）</p>
</li>
<li>
<p>协议转换</p>
</li>
<li>
<p>熔断、限流</p>
</li>
<li>
<p>灰度发布</p>
</li>
<li>
<p>api组合：可以调用一次网关实现调用两次微服务的功能</p>
</li>
<li>
<p>请求分析，记录日志</p>
</li>
<li>
<p>缓存</p>
</li>
<li>
<p>健康检查</p>
</li>
<li>
<p>可用性</p>
</li>
<li>
<p>高性能</p>
</li>
<li>
<p>API版本管理</p>
</li>
</ul>
<h2>10.2. zuul原理？</h2>
<ul>
<li>作用：API 网关，路由，负载均衡等多种作用。</li>
<li>简介：类似Nginx反向代理的功能</li>
<li>在微服务架构中，后端服务往往不直接开放给调用端，而是通过一个 API网关根据请求的 url ，路由到相应的服务。当添加API网关后，在第三方调用端和服务提供方之间就创建了一面墙，这面墙直接与调用方通信进行权限控制，后将请求均衡分发给后台服务端。<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/c5e5a6603d8d79d4509d3.jpg" alt="zuulprinciple.png"></li>
</ul>
<h2>10.3. Spring Cloud Gateway</h2>
<ul>
<li>Route（路由）：路由是Spring Cloud Gateway的基本构建块，它定义了请求的匹配规则和转发目标。通过配置路由，可以将请求映射到后端的服务实例或URL上。路由规则可以根据请求的路径、方法、请求头等条件进行匹配，并指定转发的目标URI。</li>
<li>Predicate（断言）：断言用于匹配请求的条件，如果请求满足断言的条件，则会应用所配置的过滤器。Spring Cloud Gateway提供了多种内置的断言，如Path（路径匹配）、Method（请求方法匹配）、Header（请求头匹配）等，同时也支持自定义断言。</li>
<li>Filter（过滤器）：过滤器用于对请求进行处理和转换，可以修改请求、响应以及执行其他自定义逻辑。Spring Cloud Gateway提供了多个内置的过滤器，如请求转发、请求重试、请求限流等。同时也支持自定义过滤器，可以根据需求编写自己的过滤器逻辑。</li>
</ul>
<h2>Spring Cloud Gateway的具体工作流程</h2>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/eff7e956169c3396d6691.png" alt="springcloudgateway.png" tabindex="0"><figcaption>springcloudgateway.png</figcaption></figure>
<ul>
<li>Gateway Handler（网关处理器）：网关处理器是Spring Cloud Gateway的核心组件，负责将请求转发到匹配的路由上。它根据路由配置和断言条件进行路由匹配，选择合适的路由进行请求转发。网关处理器还会依次应用配置的过滤器链，对请求进行处理和转换。</li>
<li>Gateway Filter Chain（网关过滤器链）：网关过滤器链由一系列过滤器组成，按照配置的顺序依次执行。每个过滤器可以在请求前、请求后或请求发生错误时进行处理。过滤器链的执行过程可以修改请求、响应以及执行其他自定义逻辑。</li>
</ul>
<h1>11. 配置中心</h1>
<ul>
<li>spring-cloud-config基于Git、SVN作为存储。</li>
<li>spring-cloud-alibaba-nacos-config基于Nacos实现。</li>
<li>Apollo携程开源的配置中心。Spring Cloud最成熟的配置中心的选择。</li>
</ul>
<h2>11.1. Spring Cloud Config</h2>
<ul>
<li>作用：配置管理</li>
<li>简介：Spring Cloud Config 提供服务器端和客户端。服务器存储后端的默认实现使用 Git ，因此它轻松支持标签版本的配置环境，以及可以访问用于管理内容的各种工具。</li>
<li>这个还是静态的，得配合 Spring Cloud Bus 实现动态的配置更新。</li>
</ul>
<h2>Apollo</h2>
<h1>12. 链路追踪</h1>
<ul>
<li>skywalking已经进入Apache监控链路和JVM等</li>
<li>spring-cloud-sleuth基于Zipkin实现</li>
</ul>
<h2>为什么要链路追踪</h2>
<ul>
<li>链路追踪，可以可视化地追踪请求从一个微服务到另一个微服务的调用情况。除了排查问题，链路追踪黑还可以帮助优化性能，可视化依赖关系、服务监控和告警</li>
</ul>
<h2>SkyWalking</h2>
<h2>12.1. Spring Cloud Sleuth原理</h2>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/bc82ce3be04420eac161e.jpg" alt="sleuthprinciple.png" tabindex="0"><figcaption>sleuthprinciple.png</figcaption></figure>
<h1>13. springcloud整合图</h1>
<ul>
<li>Eureka + Ribbon + Feign + Hystrix + Zuul<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/b39958ef6196ab3a7d5c3.jpg" alt="springcloud.png"></li>
</ul>
<h1>如何实现灰度发布？</h1>
<ul>
<li>灰度发布（Gray Release，也称为金丝雀发布）是指在软件或服务发布过程中，将新版本的功能或服务以较小的比例引入到生产环境中，仅向部分用户或节点提供新功能的一种发布策略。</li>
</ul>
<h2>为什么要使用灰度发布？</h2>
<ul>
<li>在传统的全量发布中，新版本的功能会一次性全部部署到所有的用户或节点上。如果新版本存在缺陷或问题，可能会对所有用户或节点产生严重的影响，导致系统崩溃或服务不可用。灰度发布采用较小的规模，并逐步将新版本的功能引入到生产环境中，仅向一小部分用户或节点提供新功能。通过持续监测和评估，可以在发现问题时及时回滚或修复。这种逐步引入新版本的方式可以降低风险，并提高系统的稳定性和可靠性。</li>
</ul>
<h2>灰度实现方法？</h2>
<ul>
<li>根据用户划分：根据用户标识或用户组进行划分，在整个用户群体中只选择一小部分用户获得新功能。（常用）</li>
<li>根据地域划分：在不同地区或不同节点上进行划分，在其中的一小部分地区或节点进行新功能的发布。</li>
<li>根据流量划分：根据流量的百分比或请求次数进行划分，只将一部分请求流量引导到新功能上。</li>
</ul>
<h2>Spring Cloud 全链路灰色发布具体实现</h2>
<ul>
<li>前端程序在灰度测试的用户 Header 头中打上标签，例如在 Header 中添加“grap-tag: true”，其表示要进行灰常测试（访问灰度服务），而其他则为访问正式服务。</li>
<li>在负载均衡器 Spring Cloud LoadBalancer 中，拿到 Header 中的“grap-tag”进行判断，如果此标签不为空，并等于“true”的话，表示要访问灰度发布的服务，否则只访问正式的服务。</li>
<li>在网关 Spring Cloud Gateway 中，将 Header 标签“grap-tag: true”继续往下一个调用服务中传递。</li>
<li>在后续的调用服务中，需要实现以下两个关键功能：
<ul>
<li>在负载均衡器 Spring Cloud LoadBalancer 中，判断灰度发布标签，将请求分发到对应服务。</li>
<li>将灰度发布标签（如果存在），继续传递给下一个调用的服务。</li>
</ul>
</li>
<li>经过第四步的反复传递之后，整个 Spring Cloud 全链路的灰度发布就完成了。</li>
<li>关键思路
<ul>
<li>1、注册中心区分正常服务和灰度服务；</li>
<li>2、负载均衡正确转发正常服务和灰度服务；</li>
<li>3、网关和 HTTP 工具传递灰度标签。</li>
</ul>
</li>
</ul>
<h2>核心实现思路和代码</h2>
<h3>3.1 区分正式服务和灰度服务</h3>
<ul>
<li>在灰度服务既注册中心的MetaData（元数据）中标识为灰度服务，而元数据中没有标识（灰度服务）的则为正式服务，以Nacos为例</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>spring:
  application:
    name: canary-user-service
  cloud:
    nacos:
      discovery:
        username: nacos
        password: nacos
        server-addr: localhost:8848
        namespace: public
        register-enabled: true 
        metadata: { "grap-tag":"true" } # 标识自己为灰度服务
</code></pre></div><h3>3.2 负载均衡调用灰度服务</h3>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>// Spring Cloud LoadBalancer 判断并调用灰度服务：
//自定义负载均衡器，并使用了轮询算法。如果 Header 中有灰度标签，则只查询灰度服务的节点实例，否则则查询出所有的正式节点实例（以供服务调用或服务转发）
private Response&lt;ServiceInstance&gt; getInstanceResponse(List&lt;ServiceInstance&gt; instances,Request request) {
    // 实例为空
    if (instances.isEmpty()) {
        if (log.isWarnEnabled()) {
            log.warn("No servers available for service: " + this.serviceId);
        }
        return new EmptyResponse();
    } else { // 服务不为空
        RequestDataContext dataContext = (RequestDataContext) request.getContext();
        HttpHeaders headers = dataContext.getClientRequest().getHeaders();
        // 判断是否为灰度发布（请求）
        if (headers.get(GlobalVariables.GRAY_KEY) != null &amp;&amp;
                headers.get(GlobalVariables.GRAY_KEY).get(0).equals("true")) {
            // 灰度发布请求，得到新服务实例列表
            List&lt;ServiceInstance&gt; findInstances = instances.stream().
                    filter(s -&gt; s.getMetadata().get(GlobalVariables.GRAY_KEY) != null &amp;&amp;
                            s.getMetadata().get(GlobalVariables.GRAY_KEY).equals("true"))
                    .toList();
            if (findInstances.size() &gt; 0) { // 存在灰度发布节点
                instances = findInstances;
            }
        } else { // 查询非灰度发布节点
            // 灰度发布测试请求，得到新服务实例列表
            instances = instances.stream().
                    filter(s -&gt; s.getMetadata().get(GlobalVariables.GRAY_KEY) == null ||
                            !s.getMetadata().get(GlobalVariables.GRAY_KEY).equals("true"))
                    .toList();
        }
        // 随机正数值 ++i（ &amp; 去负数）
        int pos = this.position.incrementAndGet() &amp; Integer.MAX_VALUE;
        // ++i 数值 % 实例数 取模 -&gt; 轮询算法
        int index = pos % instances.size();
        // 得到服务实例方法
        ServiceInstance instance = (ServiceInstance) instances.get(index);
        return new DefaultResponse(instance);
    }
}
</code></pre></div><h3>3.3 网关传递灰度标识</h3>
<ul>
<li>要在网关 Spring Cloud Gateway 中传递灰度标识，只需要在 Gateway 的全局自定义过滤器中设置 Response 的 Header 即可，具体实现代码如下：package com.example.gateway.config;</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>import com.loadbalancer.canary.common.GlobalVariables;
import org.springframework.cloud.gateway.filter.GatewayFilterChain;
import org.springframework.cloud.gateway.filter.GlobalFilter;
import org.springframework.core.Ordered;
import org.springframework.http.HttpStatus;
import org.springframework.http.server.reactive.ServerHttpRequest;
import org.springframework.http.server.reactive.ServerHttpResponse;
import org.springframework.stereotype.Component;
import org.springframework.web.server.ServerWebExchange;
import reactor.core.publisher.Mono;

@Component
public class LoadBalancerFilter implements GlobalFilter {
    @Override
    public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) {
        // 得到 request、response 对象
        ServerHttpRequest request = exchange.getRequest();
        ServerHttpResponse response = exchange.getResponse();
        if (request.getQueryParams().getFirst(GlobalVariables.GRAY_KEY) != null) {
            // 设置金丝雀标识
            response.getHeaders().set(GlobalVariables.GRAY_KEY,
                    "true");
        }
        // 此步骤正常，执行下一步
        return chain.filter(exchange);
    }
}
</code></pre></div><h1>3.4 Openfeign 传递灰度标签HTTP</h1>
<ul>
<li>调用工具 Openfeign 传递灰度标签的实现代码如下：</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>import feign.RequestInterceptor;
import feign.RequestTemplate;
import jakarta.servlet.http.HttpServletRequest;
import org.springframework.stereotype.Component;
import org.springframework.web.context.request.RequestContextHolder;
import org.springframework.web.context.request.ServletRequestAttributes;

import java.util.Enumeration;
import java.util.LinkedHashMap;
import java.util.Map;

@Component
public class FeignRequestInterceptor implements RequestInterceptor {
    @Override
    public void apply(RequestTemplate template) {
        // 从 RequestContextHolder 中获取 HttpServletRequest
        ServletRequestAttributes attributes = (ServletRequestAttributes)
                RequestContextHolder.getRequestAttributes();
        // 获取 RequestContextHolder 中的信息
        Map&lt;String, String&gt; headers = getHeaders(attributes.getRequest());
        // 放入 openfeign 的 RequestTemplate 中
        for (Map.Entry&lt;String, String&gt; entry : headers.entrySet()) {
            template.header(entry.getKey(), entry.getValue());
        }
    }

    /**
     * 获取原请求头
     */
    private Map&lt;String, String&gt; getHeaders(HttpServletRequest request) {
        Map&lt;String, String&gt; map = new LinkedHashMap&lt;&gt;();
        Enumeration&lt;String&gt; enumeration = request.getHeaderNames();
        if (enumeration != null) {
            while (enumeration.hasMoreElements()) {
                String key = enumeration.nextElement();
                String value = request.getHeader(key);
                map.put(key, value);
            }
        }
        return map;
    }
}
</code></pre></div><h1>Seata支持哪些模式的分布式事务？</h1>
<ul>
<li>Seata以下几种模式的分布式事务：
<ul>
<li>AT（Atomikos）模式：Seata默认支持的模式，最常用的。在AT模式下，Seata通过在业务代码中嵌入事务上下文，实现对分布式事务的管理。Seata会拦截并解析业务代码中的SQL语句，通过对数据库连接进行拦截和代理，实现事务的管理和协调。<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/e0a2b3f17439791ef0e97.png" alt="seataat1.png"><br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/f1c2597a611a4bcf6a468.png" alt="seataat2.png"></li>
<li>TCC（Try-Confirm-Cancel）模式：TCC模式是一种基于补偿机制的分布式事务模式。在TCC模式中，业务逻辑需要实现Try、Confirm和Cancel三个阶段的操作。Seata通过调用业务代码中的Try、Confirm和Cancel方法，并在每个阶段记录相关的操作日志，来实现分布式事务的一致性。<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/e3a492135cfb1b9a68369.png" alt="seatatcc.png"></li>
<li>SAGA模式：SAGA模式是一种基于事件驱动的分布式事务模式。在SAGA模式中，每个服务都可以发布和订阅事件，通过事件的传递和处理来实现分布式事务的一致性。Seata提供了与SAGA模式兼容的Saga框架，用于管理和协调分布式事务的各个阶段。<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/264d940d050468301c1fa.png" alt="seatasaga.png"></li>
<li>XA模式：XA模式是一种基于两阶段提交（Two-Phase Commit）协议的分布式事务模式。在XA模式中，Seata通过与数据库的XA事务协议进行交互，实现对分布式事务的管理和协调。XA模式需要数据库本身支持XA事务，并且需要在应用程序中配置相应的XA数据源。<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/dbae39b1c21075990c42e.png" alt="seataxa.png"></li>
</ul>
</li>
</ul>
<h1>了解Seata的实现原理吗？</h1>
<ul>
<li>Seata的实现原理主要包括三个核心组件：事务协调器（Transaction Coordinator）、事务管理器（Transaction Manager）和资源管理器（Resource Manager）。
<ul>
<li>事务协调器（Transaction Coordinator）：事务协调器负责协调和管理分布式事务的整个过程。它接收事务的开始和结束请求，并根据事务的状态进行协调和处理。事务协调器还负责记录和管理事务的全局事务 ID（Global Transaction ID）和分支事务 ID（Branch Transaction ID）。</li>
<li>事务管理器（Transaction Manager）：事务管理器负责全局事务的管理和控制。它协调各个分支事务的提交或回滚，并保证分布式事务的一致性和隔离性。事务管理器还负责与事务协调器进行通信，并将事务的状态变更进行持久化。</li>
<li>资源管理器（Resource Manager）：资源管理器负责管理和控制各个参与者（Participant）的事务操作。它与事务管理器进行通信，并根据事务管理器的指令执行相应的事务操作，包括提交和回滚。<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/0456accaa69ce5192fac9.png" alt="seatamodel.png"></li>
</ul>
</li>
<li>Seata的实现原理基于两阶段提交（Two-Phase Commit）协议，具体的机制如下：
<ul>
<li>一阶段：在事务提交的过程中，首先进行预提交阶段。事务协调器向各个资源管理器发送预提交请求，资源管理器执行相应的事务操作并返回执行结果。在此阶段，业务数据和回滚日志记录在同一个本地事务中提交，并释放本地锁和连接资源。</li>
<li>二阶段：在预提交阶段成功后，进入真正的提交阶段。此阶段主要包括提交异步化和回滚反向补偿两个步骤：</li>
<li>提交异步化：事务协调器发出真正的提交请求，各个资源管理器执行最终的提交操作。这个阶段的操作是非常快速的，以确保事务的提交效率。</li>
<li>回滚反向补偿：如果在预提交阶段中有任何一个资源管理器返回失败结果，事务协调器发出回滚请求，各个资源管理器执行回滚操作，利用一阶段的回滚日志进行反向补偿。</li>
</ul>
</li>
</ul>
<h1>Seata的事务执行流程是什么样的？</h1>
<ul>
<li>事务发起方（Transaction Starter）发起全局事务：事务发起方是指发起分布式事务的应用程序或服务。它向Seata的事务协调器发送全局事务的开始请求，生成全局事务ID（Global Transaction ID）。</li>
<li>事务协调器创建全局事务记录：事务协调器接收到全局事务的开始请求后，会为该事务创建相应的全局事务记录，并生成分支事务ID（Branch Transaction ID）。</li>
<li>分支事务注册：事务发起方将全局事务ID和分支事务ID发送给各个参与者（Participant），即资源管理器。参与者将分支事务ID注册到本地事务管理器，并将事务的执行结果反馈给事务协调器。</li>
<li>执行业务逻辑：在分布式事务的上下文中，各个参与者执行各自的本地事务，即执行业务逻辑和数据库操作。</li>
<li>预提交阶段：事务发起方向事务协调器发送预提交请求，事务协调器将预提交请求发送给各个参与者。</li>
<li>执行本地事务确认：参与者接收到预提交请求后，执行本地事务的确认操作，并将本地事务的执行结果反馈给事务协调器。</li>
<li>全局事务提交或回滚：事务协调器根据参与者反馈的结果进行判断，如果所有参与者的本地事务都执行成功，事务协调器发送真正的提交请求给参与者，参与者执行最终的提交操作；如果有任何一个参与者的本地事务执行失败，事务协调器发送回滚请求给参与者，参与者执行回滚操作。</li>
<li>完成全局事务：事务协调器接收到参与者的提交或回滚结果后，根据结果更新全局事务的状态，并通知事务发起方全局事务的最终结果。</li>
</ul>
<h1>全局事务ID和分支事务ID是怎么传递的？</h1>
<ul>
<li>全局事务ID和分支事务ID在分布式事务中通过上下文传递的方式进行传递。常见的传递方式包括参数传递、线程上下文传递和消息中间件传递。具体的传递方式可以根据业务场景和技术选型进行选择和调整。</li>
</ul>
<h1>Seata的事务回滚是怎么实现的？</h1>
<ul>
<li>Seata的事务回滚是通过回滚日志实现的。每个参与者在执行本地事务期间生成回滚日志，记录了对数据的修改操作。</li>
<li>当需要回滚事务时，事务协调器向参与者发送回滚请求，参与者根据回滚日志中的信息执行撤销操作，将数据恢复到事务开始前的状态。</li>
<li>回滚日志的管理和存储是Seata的核心机制，可以选择将日志存储在不同的介质中。通过回滚日志的持久化和恢复，Seata确保了事务的一致性和恢复性。</li>
</ul>
<h1>服务监控</h1>
<h2>32.你们的服务怎么做监控和告警？</h2>
<ul>
<li>Prometheus：Prometheus 是一个开源的监控系统，具有灵活的数据模型和强大的查询语言，能够收集和存储时间序列数据。它可以通过HTTP协议定期拉取微服务的指标数据，并提供可扩展的存储和查询功能。</li>
<li>Grafana：Grafana 是一个开源的可视化仪表板工具，与 Prometheus 结合使用，创建实时和历史数据的仪表板。Grafana 提供了丰富的图表和可视化选项，可以帮助用户更好地理解和分析微服务的性能和状态。</li>
</ul>
<h2>33.你们的服务怎么做日志收集？</h2>
<ul>
<li>ELK：
<ul>
<li>Elasticsearch：Elasticsearch是一个分布式搜索和分析引擎，用于存储和索引大量的日志数据。它提供了快速的搜索和聚合功能，可以高效地处理大规模的日志数据。</li>
<li>Logstash：Logstash是一个用于收集、过滤和转发日志数据的工具。它可以从各种来源（如文件、网络、消息队列等）收集日志数据，并对数据进行处理和转换，然后将其发送到Elasticsearch进行存储和索引。</li>
<li>Kibana：Kibana是一个用于日志数据可视化和分析的工具。它提供了丰富的图表、仪表盘和搜索功能，可以帮助用户实时监控和分析日志数据，发现潜在的问题和趋势。</li>
</ul>
</li>
<li>这三者里Elasticsearch提供数据存储和检索能力，Logstash负责将日志收集到ES，Kibana负责日志数据的可视化分析。</li>
<li>使用ELK进行微服务日志收集的一般流程如下：</li>
</ul>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/3f959676d10750e5c8902.png" alt="elk.png" tabindex="0"><figcaption>elk.png</figcaption></figure>
<ul>
<li>在每个微服务中配置日志输出：将微服务的日志输出到标准输出（stdout）或日志文件。</li>
<li>使用Logstash收集日志：配置Logstash收集器，通过配置输入插件（如文件输入、网络输入等）监听微服务的日志输出，并进行过滤和处理。</li>
<li>将日志数据发送到Elasticsearch：配置Logstash的输出插件，将经过处理的日志数据发送到Elasticsearch进行存储和索引。</li>
<li>使用Kibana进行可视化和分析：通过Kibana连接到Elasticsearch，创建仪表盘、图表和搜索查询，实时监控和分析微服务的日志数据。</li>
<li>除了应用最广泛的ELK，还有一些其它的方案比如Fluentd、Graylog、Loki、Filebeat，一些云厂商也提供了付费方案，比如阿里云的sls。</li>
</ul>
]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/d8e1d1b5769a399ef1bb8.png" type="image/png"/>
    </item>
    <item>
      <title>springmvc</title>
      <link>https://javaguide.cn/interview/springmvc.html</link>
      <guid>https://javaguide.cn/interview/springmvc.html</guid>
      <source url="https://javaguide.cn/rss.xml">springmvc</source>
      <description>1. 谈谈你对 MVC 模式的理解？√ MVC是Model—View—Controller简称，它是一种架构模式，它分离了表现与交互。它被分为三个核心部件：模型、视图、控制器 Model（模型）：指javaBean 是程序的主体部分，主要包含业务数据和逻辑。在模型层，还会涉及到用户发布的服务，在服务中会根据不同的业务需求，更新业务模型中的数据。 Vie...</description>
      <category>面试</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<!-- TOC -->
<!-- /TOC -->
<h1>1. 谈谈你对 MVC 模式的理解？√</h1>
<ul>
<li>MVC是Model—View—Controller简称，它是一种架构模式，它分离了表现与交互。它被分为三个核心部件：模型、视图、控制器</li>
<li>Model（模型）：指javaBean 是程序的主体部分，主要包含业务数据和逻辑。在模型层，还会涉及到用户发布的服务，在服务中会根据不同的业务需求，更新业务模型中的数据。</li>
<li>View（视图）：指JSP或者HTML 是程序呈现给用户的部分，是用户和程序交互的接口，用户会根据具体的业务需求，在View视图层输入自己特定的业务数据，并通过界面的事件交互，将对应的输入参数提交给后台控制器进行处理</li>
<li>Controller（控制器）：指servlet或者Filter Controller用来处理用户输入数据，以及更新业务模型的部分。控制器中接收了用户与界面交互时传递过来的数据，并根据数据业务逻辑来执行服务的调用和更新业务模型的数据和状态</li>
</ul>
<h1>3. springMVC执行流程？√SpringMVC 的核心组件有哪些？HandlerAdapter作用？√</h1>
<ul>
<li>架构流程
<ul>
<li>用户发送请求至前端控制器DispatcherServlet</li>
<li>DispatcherServlet收到请求调用HandlerMapping处理器映射器。处理器映射器根据请求url找到具体的处理器，生成处理器对象及处理器拦截器(如果有则生成)以 HandlerExecutionChain 对象的形式返回给DispatcherServlet</li>
<li>DispatcherServlet调用HandlerAdapter处理器适配器调用处理器。中途调用拦截器的preHandle和postHandle方法，HandlerAdapter将controller执行结果ModelAndView返回给DispatcherServlet</li>
<li>DispatcherServlet将ModelAndView传给ViewReslover视图解析器ViewReslover解析后返回具体View</li>
<li>DispatcherServlet对View进行渲染视图（即将模型数据填充至视图中）</li>
<li>DispatcherServlet响应用户</li>
</ul>
</li>
<li>组件说明
<ul>
<li>DispatcherServlet：前端控制器，相当于mvc模式中的c，流程控制中心，由它调用其它组件处理用户的请求，降低了组件之间的耦合性。</li>
<li>HandlerMapping：处理器映射器。负责根据用户请求url找到Handler即处理器，提供配置文件方式，实现接口方式，注解方式等映射方式</li>
<li>Handler：处理器，后端控制器，具体的用户请求进行处理。涉及到具体的用户业务请求，需要程序员根据业务需求开发Handler</li>
<li>HandlAdapter：处理器适配器，适配器模式的应用，通过扩展适配器可以对更多类型的处理器进行执行。DispatcherServlet会根据controller对应的controller类型来调用相应的HandlerAdapter来进行处理，负责表单数据的验证、数据类型的转换、将表单数据封装到 JavaBean 等</li>
<li>ViewResolver：视图解析器。首先根据逻辑视图名解析成物理视图名即具体的页面地址，再生成View视图对象，最后对View进行渲染将处理结果通过页面展示给用户</li>
<li>ModelAndView：装载了模型数据和视图信息，作为Handler处理结果返回给DispatcherServlet。</li>
<li>View：支持View视图类型：jstlView、freemarkerView、pdfView等</li>
<li>HandlerInterceptor：处理器拦截器，是一个接口，如果需要完成一些拦截处理，可以实现该接口。</li>
<li>HandlerExecutionChain：处理器执行链，包括两部分内容：Handler 和 HandlerInterceptor（系统会有一个默认的 HandlerInterceptor，如果需要额外设置拦截，可以添加拦截器）。</li>
</ul>
</li>
<li>三大组件：处理器映射器、处理器适配器、视图解析器称为springmvc的三大组件。需要用户开发的组件有handler、view<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/4e64fa261b3306be5d57d.png" alt="springmvcexecutionflow.png"><br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/a4dbc7ba97069479b942b.jpg" alt="springmvcexecutionflow2.png"></li>
</ul>
<h1>SpringMVC Restful风格的接口的流程是什么样的呢？</h1>
<ul>
<li>客户端向服务端发送一次请求，这个请求会先到前端控制器DispatcherServlet</li>
<li>DispatcherServlet接收到请求后会调用HandlerMapping处理器映射器。由此得知，该请求该由哪个Controller来处理</li>
<li>DispatcherServlet调用HandlerAdapter处理器适配器，告诉处理器适配器应该要去执行哪个Controller</li>
<li>Controller被封装成了ServletInvocableHandlerMethod，HandlerAdapter处理器适配器去执行invokeAndHandle方法，完成对Controller的请求处理</li>
<li>HandlerAdapter执行完对Controller的请求，会调用HandlerMethodReturnValueHandler去处理返回值，主要的过程：
<ul>
<li>调用RequestResponseBodyMethodProcessor，创建ServletServerHttpResponse（Spring对原生ServerHttpResponse的封装）实例</li>
<li>使用HttpMessageConverter的write方法，将返回值写入ServletServerHttpResponse的OutputStream输出流中</li>
<li>在写入的过程中，会使用JsonGenerator（默认使用Jackson框架）对返回值进行Json序列化</li>
</ul>
</li>
<li>执行完请求后，返回的ModealAndView为null，ServletServerHttpResponse里也已经写入了响应，所以不用关心View的处理<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/0630239e8e2b0b062ba02.png" alt="springmvcrestful.png"></li>
</ul>
<h1>4. 简述SpringMVC中使用的设计模式以及在SpringMVC中的应用场景(1-2个)</h1>
<ul>
<li>单例模式：springmvc的controller默认是单例的</li>
<li>代理模式：springmvc的controller是通过代理产生的</li>
</ul>
<h1>5. SpringMVC 常用的注解有哪些？</h1>
<ul>
<li>@RequestMapping：用于处理请求url映射的注解，可用于类或方法上。用于类上，则表示类中的所有响应请求的方法都是以该地址作为父路径；方法上则映射url和http请求方法</li>
<li>@RequestBody：注解实现接收 HTTP 请求的 json 数据，将 json 转换为 Java 对象；</li>
<li>@ResponseBody：注解实现将 Controller 方法返回对象转化为 json 对象响应给客户。需要配合相应的支持 JSON 格式化的 HttpMessageConverter 实现类</li>
<li>@Controller，它将一个类标记为 Spring Web MVC 控制器 Controller</li>
<li>@RestController，在 @Controller 基础上，增加了 @ResponseBody，提供Restful API ，返回例如 JSON 数据格式。当然，返回什么样的数据格式，根据客户端的 "ACCEPT" 请求头决定。</li>
<li>@PathVariable从 URI 读取值，比如查询参数</li>
</ul>
<h1>6. @RequestMapping 和 @GetMapping 注解的不同之处在哪里？</h1>
<ul>
<li>@RequestMapping可注解在类和方法上；@GetMapping 仅可注册在方法上</li>
<li>@RequestMapping可进行GET、POST、PUT、DELETE等请求方法；@GetMapping是@RequestMapping的GET请求方法的特例</li>
</ul>
<h1>7. 如何解决POST、GET请求中文乱码问题？</h1>
<ul>
<li>POST：web.xml中配置一个 CharacterEncodingFilter 过滤器，设置成 utf-8；</li>
<li>GET：
<ul>
<li>方法1：修改tomcat配置文件添加编码与工程编码一致，&lt;ConnectorURIEncoding="utf-8" connectionTimeout="20000" port="8080" protocol="HTTP/1.1" redirectPort&gt;</li>
<li>方法2：对参数进行重新编码：String userName = new String(request.getParamter("userName").getBytes("ISO8859-1"),"utf-8")</li>
</ul>
</li>
</ul>
<h1>8. springmvc异常处理</h1>
<ul>
<li>Spring MVC提供了异常解析器HandlerExceptionResolver接口，将处理器(handler)执行时发生的异常，解析(转换)成对应的ModelAndView结果</li>
</ul>
<h1>9. Spring MVC 拦截器有哪些方法？作用？</h1>
<ul>
<li>preHandle方法，调用Controller方法前执行。按拦截器定义顺序调用。若任一拦截器返回false ，则Controller方法不再调用。</li>
<li>postHandle方法，调用Controller方法后执行。按拦截器定义逆序调用</li>
<li>afterCompletion方法，处理完Controller方法返回结果后执行.按拦截器定义逆序调用.只要preHandle方法返回true时就会执行.无视异常</li>
<li>记录访问日志。记录异常日志。需要登陆的请求操作，拦截未登陆的用户。</li>
</ul>
<h1>10. Spring MVC 的拦截器和 Filter 过滤器有什么差别？</h1>
<ul>
<li>功能相同：拦截器和 Filter都能实现相应的功能，谁也不比谁强。</li>
<li>容器不同：拦截器构建在 Spring MVC 体系中；Filter 构建在 Servlet 容器之上。</li>
<li>使用便利性不同：拦截器提供了三个方法，分别在不同的时机执行；过滤器仅提供一个方法，当然也能实现拦截器的执行时机的效果，就是麻烦一些。</li>
</ul>
<h1>11. 什么是安全的REST操作?</h1>
<ul>
<li>REST接口是否安全的界限，在于是否修改服务端的资源。因此GET和HEAD是安全的，PUT,POST 和 DELETE是不安全的</li>
</ul>
<h1>12. 什么是幂等操作? 为什么幂等操作如此重要?</h1>
<ul>
<li>用户对于同一操作发起的一次请求或者多次请求的结果是一致的，不会因为多次点击而产生了副作用。</li>
<li>POST方法不是幂等操作 ，因为如果发送多个 POST 请求，它将在服务端创建不同的资源。但是PUT更新资源是幂等操作。甚至多个PUT请求被用来更新服务端资源，将得到相同的结果。</li>
</ul>
<h1>13. REST 用哪种 HTTP 方法呢?</h1>
<ul>
<li>GET检索服务端资源</li>
<li>POST创建服务端资源</li>
<li>PUT更新服务端资源</li>
<li>DELETE删除服务端资源</li>
</ul>
<h1>14. REST API是无状态的吗?</h1>
<ul>
<li>REST API是无状态的，因为基于HTTP也是无状态。</li>
<li>REST API请求应该包含处理它所需的所有细节。它不应该依赖于以前或下一个请求或服务器端维护的一些数据，例如会话。</li>
</ul>
<h1>15. 如何创建 HttpMessageConverter 的自定义实现来支持一种新的请求/响应？</h1>
<ul>
<li>自定义的AbstractHttpMessageConverter实现，并使用WebMvcConfigurerAdapter的#extendMessageConverters(List&lt;HttpMessageConverter&lt;?&gt;&gt; converters) 方法注册</li>
</ul>
]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/4e64fa261b3306be5d57d.png" type="image/png"/>
    </item>
    <item>
      <title>sql宝典</title>
      <link>https://javaguide.cn/interview/sql.html</link>
      <guid>https://javaguide.cn/interview/sql.html</guid>
      <source url="https://javaguide.cn/rss.xml">sql宝典</source>
      <description>t_grade成绩表 1. case when使用 分数等级：每门课成绩的等级划分为三个，分数小于80为及格，大于等于80低于90分为中等；大于等于90分为优秀，结果如下 2. 分组及其组内比较 如：查出每个学科低于其平均分的学生等。首先查询出每条记录对应的分组函数值select * from table t1 left join (select 分组...</description>
      <category>面试</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<!-- TOC -->
<!-- /TOC -->
<ul>
<li>t_grade成绩表</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align:center">name</th>
<th style="text-align:center">kemu</th>
<th style="text-align:center">fenshu</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">张三</td>
<td style="text-align:center">语文</td>
<td style="text-align:center">81</td>
</tr>
<tr>
<td style="text-align:center">张三</td>
<td style="text-align:center">数学</td>
<td style="text-align:center">72</td>
</tr>
<tr>
<td style="text-align:center">李四</td>
<td style="text-align:center">语文</td>
<td style="text-align:center">76</td>
</tr>
<tr>
<td style="text-align:center">李四</td>
<td style="text-align:center">数学</td>
<td style="text-align:center">90</td>
</tr>
<tr>
<td style="text-align:center">王五</td>
<td style="text-align:center">语文</td>
<td style="text-align:center">81</td>
</tr>
<tr>
<td style="text-align:center">王五</td>
<td style="text-align:center">数学</td>
<td style="text-align:center">100</td>
</tr>
<tr>
<td style="text-align:center">...</td>
<td style="text-align:center">...</td>
<td style="text-align:center">...</td>
</tr>
</tbody>
</table>
<h1>1. case when使用</h1>
<ul>
<li>分数等级：每门课成绩的等级划分为三个，分数小于80为及格，大于等于80低于90分为中等；大于等于90分为优秀，结果如下</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align:center">name</th>
<th style="text-align:center">kemu</th>
<th style="text-align:center">fenshu</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">张三</td>
<td style="text-align:center">语文</td>
<td style="text-align:center">中等</td>
</tr>
<tr>
<td style="text-align:center">张三</td>
<td style="text-align:center">数学</td>
<td style="text-align:center">合格</td>
</tr>
<tr>
<td style="text-align:center">李四</td>
<td style="text-align:center">语文</td>
<td style="text-align:center">合格</td>
</tr>
<tr>
<td style="text-align:center">李四</td>
<td style="text-align:center">数学</td>
<td style="text-align:center">优秀</td>
</tr>
<tr>
<td style="text-align:center">王五</td>
<td style="text-align:center">语文</td>
<td style="text-align:center">中等</td>
</tr>
<tr>
<td style="text-align:center">王五</td>
<td style="text-align:center">数学</td>
<td style="text-align:center">优秀</td>
</tr>
</tbody>
</table>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>select name,kemu,case when fenshu&gt;=90 then  '优秀' when  fenshu&lt;90 and fenshu&gt;=80 then '中等'when  fenshu&lt;80 then '合格' end  as fenshu from t_grade
</code></pre></div><h1>2. 分组及其组内比较</h1>
<ul>
<li>如：查出每个学科低于其平均分的学生等。首先查询出每条记录对应的分组函数值select * from table t1 left join (select 分组函数(统计字段) as 比较字段 from table group by 分组字段) t2 on 唯一条件 where 比较条件</li>
<li>用一条sql语句查询出每个学科低于其平均分的学生/平均分低于60的学生(查询结果表头名为：姓名、学科、分数、学科平均分)</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>Select 
	a.name,a.kemu,a.fenshu,(Select avg(b.fenshu) From score b where a.kemu=b.kemu GROUP BY b.kemu )
From 
	score a Where a.fenshu&lt;(Select avg(b.fenshu) From score b where a.kemu=b.kemu GROUP BY b.kemu ) 
GROUP BY 
	a.kemu

SELECT 
	a.name,a.kemu,a.fenshu,b.aa
FROM 
	test a,(SELECT kemu,AVG(fenshu) aa FROM test GROUP BY kemu) b
WHERE a.kemu=b.kemu AND a.fenshu&lt;b.aa
</code></pre></div><h1>3. 都大于问题</h1>
<ul>
<li>查出某条件下都大于都小于的数据（not in）</li>
<li>用一条sql语句查询出每门课都大于80分的学生姓名</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>SELECT 
	name,kemu,fenshu 
from 
	t_grade 
where name not in(select name from t_grade where fenshu&lt;=80)
</code></pre></div><h1>4. 行转列</h1>
<ul>
<li>如：把表中特定行的数据去重后做为列名;将同一个人的科目显示出来</li>
<li>利用max(case when then)或者sum(case when then)或者sum(IF()) 或者max(IF())：先将数据按某个条件分组，然后通过sum或者max将行转列，但是问题是，行转列有限制</li>
<li>用一条sql语句写出如下的查询结果</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align:center">姓名</th>
<th style="text-align:center">语文</th>
<th style="text-align:center">数学</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">张三</td>
<td style="text-align:center">81</td>
<td style="text-align:center">72</td>
</tr>
<tr>
<td style="text-align:center">李四</td>
<td style="text-align:center">76</td>
<td style="text-align:center">90</td>
</tr>
<tr>
<td style="text-align:center">王五</td>
<td style="text-align:center">81</td>
<td style="text-align:center">100</td>
</tr>
</tbody>
</table>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>SELECT 
	a.name '分数',a.fenshu '语文',b.fenshu '数学'
FROM 
	(SELECT NAME,fenshu FROM test WHERE kemu='语文') a,
	(SELECT NAME,fenshu FROM test WHERE kemu='数学') b
WHERE 
	a.name=b.name;

SELECT
	name as 姓名,
	MAX(
		CASE 
		WHEN  kemu='语文' THEN
			fenshu
		END
	) AS 语文,
	MAX(
		CASE 
		WHEN kemu='数学' THEN
			fenshu
		END
	) AS 数学 
FROM
	t_grade
GROUP BY name
</code></pre></div><h1>5. 列转行</h1>
<ul>
<li>如：把表中特定列做为每一行数据对应行的值（union）</li>
<li>将上面的结果变回例子的样子</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>select name, '语文' kemu , 语文 as SCORE from t_grade
union select name, '数学' kemu, 数学 as SCORE from t_grade
union select name, '英语' kemu, 英语 as SCORE from t_grade
order by name,kemu;
</code></pre></div><h1>6. top-n问题</h1>
<ul>
<li>
<p>如：求出第二(n)高/低的薪水</p>
</li>
<li>
<p>如果是找第二高之类的问题：select max(distinct 字段) from table where 字段&lt; (select max(distinct 字段) from table group by 分组字段) where 条件</p>
</li>
<li>
<p>如果是找第n高的问题：select distinct 字段 FROM table t1 where (SELECT count(distinct 字段) from table t2 WHERE t2.字段 &gt; t1.字段) = n-1</p>
</li>
<li>
<p>如果是找前n高的问题：select distinct 字段 from table t1 where (select count(distinct 字段) from table t2 where t2.字段 &gt; t1.字段)&lt; n</p>
</li>
<li>
<p>如果是找当前记录处于第几的问题：select 字段,(select count(distinct 字段) from table t2 where t2.字段 &gt;= t1.字段) from Scores t1 order by 字段 DESC</p>
</li>
<li>
<p>Employee 表包含所有员工信息，每个员工有其对应的工号 Id，姓名 Name，工资 Salary 和部门编号 DepartmentId</p>
</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align:center">Id</th>
<th style="text-align:center">Name</th>
<th style="text-align:center">Salary</th>
<th style="text-align:center">DepartmentId</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">Joe</td>
<td style="text-align:center">85000</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">Henry</td>
<td style="text-align:center">80000</td>
<td style="text-align:center">2</td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center">Sam</td>
<td style="text-align:center">60000</td>
<td style="text-align:center">2</td>
</tr>
<tr>
<td style="text-align:center">4</td>
<td style="text-align:center">Max</td>
<td style="text-align:center">90000</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">5</td>
<td style="text-align:center">Janet</td>
<td style="text-align:center">69000</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">6</td>
<td style="text-align:center">Randy</td>
<td style="text-align:center">85000</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">7</td>
<td style="text-align:center">Will</td>
<td style="text-align:center">70000</td>
<td style="text-align:center">1</td>
</tr>
</tbody>
</table>
<ul>
<li>Department 表包含公司所有部门的信息。</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align:center">Id</th>
<th style="text-align:center">Name</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">IT</td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">Sales</td>
</tr>
</tbody>
</table>
<ul>
<li>编写一个 SQL 查询，找出每个部门获得前三高工资的所有员工</li>
</ul>
<p>|Department|Employee|Salary|<br>
|:-😐:-😐:-😐:-😐<br>
|IT|Max|90000|<br>
|IT|Randy|85000|<br>
|IT|Joe|85000|<br>
|IT|Will|70000|<br>
|Sales|Henry|80000|<br>
|Sales|Sam| 60000|</p>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>SELECT
	d.NAME AS Department,
	e.NAME AS Employee,
	e.Salary AS Salary 
FROM
	employee e
	LEFT JOIN Department d ON d.id = e.DepartmentId 
WHERE
	e.id IN (
	SELECT
		e1.id 
	FROM
		Employee e1
		LEFT JOIN Employee e2 ON e2.DepartmentId = e1.DepartmentId 
		AND e2.Salary &gt; e1.Salary 
	GROUP BY
		e1.Id 
	HAVING
		count( DISTINCT e2.Salary ) &lt;= 2 --选取top几
	) 
and e.DepartmentId in (select Id from Department) 补全数据，不用补全的话不用加上这句
ORDER BY
	d.Id ASC,
	e.Salary DESC
</code></pre></div><ul>
<li>编写一个 SQL 查询，获取 Employee 表中第二高的薪水（Salary）</li>
<li>例如上述 Employee 表，SQL查询应该返回 200 作为第二高的薪水。如果不存在第二高的薪水，那么查询应返回 null</li>
</ul>
<h1>7. 删除重复数据</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>-- 删除多余的重复记录(多个字段)，只保留最小id的记录
DELETE FROM student WHERE id IN (
    SELECT * FROM (
        SELECT id FROM student WHERE (stuno,stuname) -- 注意：此处一定要加括号，当成联合字段来处理
        IN (
            -- 查找学号和姓名均重复的学生信息
            SELECT stuno,stuname FROM student GROUP BY stuno,stuname HAVING COUNT(1) &gt; 1
        ) AND id NOT IN (
            -- 查询最小id的记录
            SELECT MIN(id) FROM student GROUP BY stuno,stuname HAVING COUNT(1) &gt; 1
        )
    ) AS stu_repeat_copy

);
</code></pre></div><h1>8. 查找每个学科分数低于60的人数</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>CREATE TABLE `xueke`  (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `tid` int(11) NULL DEFAULT NULL,
  `sid` int(11) NULL DEFAULT NULL,
  `name` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `score` int(11) NULL DEFAULT NULL,
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 8 CHARACTER SET = latin1 COLLATE = latin1_swedish_ci ROW_FORMAT = Compact;

-- </code></pre></div>]]></content:encoded>
    </item>
    <item>
      <title>网址收藏</title>
      <link>https://javaguide.cn/resource/%E7%BD%91%E5%9D%80%E6%94%B6%E8%97%8F.html</link>
      <guid>https://javaguide.cn/resource/%E7%BD%91%E5%9D%80%E6%94%B6%E8%97%8F.html</guid>
      <source url="https://javaguide.cn/rss.xml">网址收藏</source>
      <description>网址收藏 网址收藏</description>
      <category>网址收藏</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>网址收藏</p>
<!--more-->
<h1>网址收藏</h1>
<pre><code>前端技术:
jquery官网:https://jquery.com/
boostrap官网:http://v3.bootcss.com/
boostrap教程:https://www.runoob.com/bootstrap/bootstrap-grid-system.html
jquery的ztree下载:http://www.treejs.cn/v3/main.php#_zTreeInfo
jquery的ztree文档:http://www.treejs.cn/v3/api.php
vue.js的官网:https://cn.vuejs.org/
vuex的官网:https://vuex.vuejs.org/zh/guide/
node.js官网:https://nodejs.org/en/
knockout.js官网:http://knockoutjs.com/
es5官方文档:http://lzw.me/pages/ecmascript/#356
webpack(前端自动化构建的工具)官网:https://webpack.github.io/
Vue-Router官网:https://router.vuejs.org/
animate.css官网:https://daneden.github.io/animate.css/
npm官网:https://www.npmjs.com/
cnpm（淘宝镜像）官网:http://npm.taobao.org/
MintUI官网:http://mint-ui.github.io/#!/zh-cn
MUI官网:http://www.dcloud.io/mui.html
highcharts官网:http://www.hcharts.cn/
easy-ui(简易ui实现)官网:http://www.jeasyui.com/
easy-ui教程:http://www.jeasyui.net/tutorial/
electron官网:https://electronjs.org/docs
jquery模板:http://www.17sucai.com/
模板引擎art-template官网:http://aui.github.io/art-template/
express（node.js的web框架）官网:http://expressjs.com/和http://www.expressjs.com.cn/

富文本编辑器KindEditor:http://kindeditor.net
CKEditor:http://ckeditor.com/
百度编辑器UEditor:http://ueditor.baidu.com/website/

ant-desgin: https://ant.design/index-cn
图片服务器:
模板引擎:https://freemarker.apache.org/


技术社区:
CSDN官网:https://www.csdn.net/
慕课网:https://www.imooc.com/
牛客网:https://www.nowcoder.com/
java开源软件:http://www.oschina.net/project/lang/19/java/
it面试网:http://www.itmian4.com/
LeetCode:https://leetcode.com/

Java
jdk1.8下载:http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html
tomcat官网:http://tomcat.apache.org/
maven官网:http://maven.apache.org/
spring官网:https://spring.io/
swagger官网:https://swagger.io/
commons-io操作文件:http://commons.apache.org/proper/commons-io/
C3p0官网:https://www.mchange.com/projects/c3p0/
DBCP官网:http://commons.apache.org/proper/commons-dbcp/index.html
DBUtils:https://commons.apache.org/proper/commons-dbutils/examples.html
dom4j官网(解析xml):https://dom4j.github.io/
ssms官网:https://download.microsoft.com/download/C/3/D/C3DBFF11-C72E-429A-A861-4C316524368F/SSMS-Setup-CHS.exe
shiro官网:http://shiro.apache.org/
jFinal官网:https://www.jfinal.com/doc

pinyin4j官网:http://pinyin4j.sourceforge.net/
lucene官网:https://lucene.apache.org/
ehcache缓存官网:http://www.ehcache.org/
POI(office文件读写)官网:http://poi.apache.org/
quartz官网:http://www.quartz-scheduler.org/
jd-gui官网:http://jd.benow.ca/
apache cxf：http://cxf.apache.org/
webservice官网:http://ws.apache.org/
hibernate官网:http://hibernate.org/
zookeeper官网:https://zookeeper.apache.org/


数据库:
mysql下载:https://www.mysql.com/downloads/
oracle下载:https://www.oracle.com/index.html
sql server官网:https://www.microsoft.com/en-us/sql-server/sql-server-downloads-free-trial
mongodb官网:https://www.mongodb.com/
monggoose官网:http://mongoosejs.com/
mycat官网:http://www.mycat.io/
oracle官网:https://www.oracle.com/index.html

中间件:
activemq官网:http://activemq.apache.org/
emq官网:https://www.emqx.com/zh
Nginx官网:http://nginx.org/
dubbo官网:http://dubbo.apache.org

版本管理:
Git官网:https://git-scm.com/
maven私服搭建:https://www.cnblogs.com/likehua/p/4552620.html

linux:
centos官网:https://www.centos.org
java的jsch连接linux工具:http://www.jcraft.com/jsch/

帮助文档:
菜鸟教程:http://www.runoob.com
在线api文档:http://tool.oschina.net/apidocs/
springboot官网:https://spring.io/projects/spring-boot
在线http接口测试工具http://www.atool.org/httptest.php
jdk的版本区别文档:https://docs.oracle.com/javase/specs/
html转义字符对照表:https://tool.oschina.net/commons?type=2
javase官网:https://docs.oracle.com/javase/specs/

工具:
winscp官网:https://winscp.net/eng/docs/lang:chs
putty官网:https://www.chiark.greenend.org.uk/~sgtatham/putty/
百度网盘无限制下载:http://pandownload.com/
everything下载:http://www.voidtools.com/
eclipse官网:https://www.eclipse.org/

Spring文档
整合Struts2.x:https://struts.apache.org/plugins/spring/
整合hibernate以及Spring4.0文档:https://docs.spring.io/autorepo/docs/spring-framework/4.1.8.RELEASE/spring-framework-reference/pdf/spring-framework-reference.pdf
整合mybatis:http://www.mybatis.org/spring/zh/getting-started.html
springboot整合mybatis:http://www.mybatis.org/spring-boot-starter/mybatis-spring-boot-autoconfigure/(两个mybatis整合包不能同时使用!)

书籍查询
码农网:http://www.codeceo.com/
</code></pre>
]]></content:encoded>
    </item>
    <item>
      <title>Swagger</title>
      <link>https://javaguide.cn/backend/apidocumentation/swagger.html</link>
      <guid>https://javaguide.cn/backend/apidocumentation/swagger.html</guid>
      <source url="https://javaguide.cn/rss.xml">Swagger</source>
      <description>最好的API使用Swagger工具构建 1. springboot整合swagger2 2. swagger主要注解的说明</description>
      <category>后端</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>最好的API使用Swagger工具构建</p>
<!--more-->
<h1>1. springboot整合swagger2</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>导入swagger依赖（在maven项目pom.xml中添加以下依赖）
&lt;dependency&gt;
    &lt;groupId&gt;io.springfox&lt;/groupId&gt;
    &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt;
    &lt;version&gt;2.9.2&lt;/version&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;io.springfox&lt;/groupId&gt;
    &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt;
    &lt;version&gt;2.9.2&lt;/version&gt;
&lt;/dependency&gt;
在主程序中添加@EnableSwagger2
@SpringBootApplication
@EnableSwagger2
public class MainApplication {
	public static void main(String[] args) {
		SpringApplication.run(MainApplication.class, args);
	}
}

在需要api的类上面添加注解
@RestController
@Api(tags = "UserinfoCtrl", description = "用户信息相关")  
public class testswaggercontroller {
	@RequestMapping("/testswagger")
	@ApiOperation(value = "获取用户信息", httpMethod = "GET", notes = "显示用户信息")  
	public Map&lt;String, Object&gt; fun() {
		Map&lt;String , Object&gt; result=new HashMap&lt;String,Object&gt;();
		result.put("test", "test");
		Demo demo=new Demo("junye", "1");
		result.put("Demo", demo);
		System.out.println("chenggong");
		return result;
	}
}
测试是否生成了api：浏览器访问：localhost:8080/swagger-ui.html#
</code></pre></div><h1>2. swagger主要注解的说明</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>@Api用在类上，说明该类的作用。可以标记一个Controller类做为swagger文档资源
@Api(value = "/user", description = "Operations about user")
value:url的路径值
tags:如果设置这个值、value的值会被覆盖
description:对api资源的描述
basePath:基本路径可以不配置
position:如果配置多个Api 想改变显示的顺序位置
produces:For example, "application/json, application/xml"
consumes:For example, "application/json, application/xml"
authorizations:高级特性认证时配置
hidden:配置为true 将在文档中隐藏

ApiOperation：用在方法上，说明方法的作用，每一个url资源的定义,与Controller中的方法并列使用。
@ApiOperation(
value = "Find purchase order by ID",
notes = "",
response = Order,
tags = {"Pet Store"})
value:url的路径值
tags:如果设置这个值、value的值会被覆盖
description:对api资源的描述
position:如果配置多个Api 想改变显示的顺序位置
produces:For example, "application/json, application/xml"
consumes:For example, "application/json, application/xml"
protocols:Possible values: http, https, ws, wss.
authorizations:高级特性认证时配置
hidden:配置为true 将在文档中隐藏
response:返回的对象
responseContainer:这些对象是有效的 "List", "Set" or "Map".，其他无效
httpMethod:"GET", "HEAD", "POST", "PUT", "DELETE", "OPTIONS" and "PATCH"
code:http的状态码 默认 200
extensions:扩展属性

ApiParam请求属性,与Controller中的方法并列使用。
public ResponseEntity&lt;User&gt; createUser(@RequestBody @ApiParam(value = "Created user object")
name:属性名称
value:属性值
defaultValue:默认属性值
allowableValues:可以不配置
required:是否属性必填
access	:不过多描述
allowMultiple:	默认为false
hidden:隐藏该属性
example:举例子

ApiResponse：响应配置，与Controller中的方法并列使用
@ApiResponse(code = 400, message = "Invalid user supplied")
code:http的状态码
message:描述
response:默认响应类 Void
reference:参考ApiOperation中配置
responseHeaders:参考 ResponseHeader 属性配置说明
responseContainer:参考ApiOperation中配置

ApiResponses 与Controller中的方法并列使用ApiResponses：响应集配置，使用方式：只有value属性
@ApiResponses({ @ApiResponse(code = 400, message = "Invalid Order") })

ResponseHeader 与Controller中的方法并列使用响应头设置
@ResponseHeader(name="head1",description="response head conf")
name:响应头名称
description:头描述
response:默认响应类 Void
responseContainer:参考ApiOperation中配置

其他
@ApiImplicitParams：用在方法上包含一组参数说明；
@ApiImplicitParam：用在@ApiImplicitParams注解中，指定一个请求参数的各个方面
paramType：参数放在哪个地方
name：参数代表的含义
value：参数名称
dataType： 参数类型，有String/int，无用
required ： 是否必要
defaultValue：参数的默认值
@ApiResponses：用于表示一组响应；
@ApiResponse：用在@ApiResponses中，一般用于表达一个错误的响应信息；
code： 响应码(int型)，可自定义
message：状态码对应的响应信息
@ApiModel：描述一个Model的信息（这种一般用在post创建的时候，
使用@RequestBody这样的场景，请求参数无法使用@ApiImplicitParam注解进行描述的时候；
@ApiModelProperty：描述一个model的属性。
</code></pre></div>]]></content:encoded>
    </item>
    <item>
      <title>nginx</title>
      <link>https://javaguide.cn/backend/apigateway/nginx.html</link>
      <guid>https://javaguide.cn/backend/apigateway/nginx.html</guid>
      <source url="https://javaguide.cn/rss.xml">nginx</source>
      <description>1. 什么是nginx? Nginx是一款高性能的http 服务器/反向代理服务器及电子邮件（IMAP/POP3）代理服务器。 由俄罗斯的程序设计师Igor Sysoev所开发，官方测试nginx能够支支撑5万并发链接，并且cpu、内存等资源消耗却非常低，运行非常稳定。而且可以负载均衡 2. 应用场景 http服务器。Nginx是一个http服务可以独...</description>
      <category>后端</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[
<ul>
<li>Nginx是一款高性能的http 服务器/反向代理服务器及电子邮件（IMAP/POP3）代理服务器。</li>
<li>由俄罗斯的程序设计师Igor Sysoev所开发，官方测试nginx能够支支撑5万并发链接，并且cpu、内存等资源消耗却非常低，运行非常稳定。而且可以负载均衡</li>
</ul>
<h1>2. 应用场景</h1>
<ul>
<li>http服务器。Nginx是一个http服务可以独立提供http服务。可以做网页静态服务器。</li>
<li>虚拟主机。可以实现在一台服务器虚拟出多个网站。例如个人网站使用的虚拟主机。</li>
<li>反向代理，负载均衡。当网站的访问量达到一定程度后，单台服务器不能满足用户的请求时，需要用多台服务器集群可以使用nginx做反向代理。并且多台服务器可以平均分担负载，不会因为某台服务器负载高宕机而某台服务器闲置的情况。</li>
</ul>
<h1>3. nginx安装</h1>
<ul>
<li>下载nginx：官方网站：<a href="http://nginx.org/,1.8.0%E7%89%88%E6%9C%AC%E3%80%82Nginx%E6%8F%90%E4%BE%9B%E7%9A%84%E6%BA%90%E7%A0%81%E5%AE%89%E8%A3%85" target="_blank" rel="noopener noreferrer">http://nginx.org/,1.8.0版本。Nginx提供的源码安装</a></li>
<li>环境安装
<ul>
<li>gcc环境:yum install gcc-c++</li>
<li>PCRE(Perl Compatible Regular Expressions)是一个Perl库，包括 perl 兼容的正则表达式库。nginx的http模块使用pcre来解析正则表达式，所以需要在linux上安装pcre库。pcre-devel是使用pcre开发的一个二次开发库。nginx也需要此库。yum install -y pcre pcre-devel</li>
<li>zlib库:提供了很多种压缩和解压缩的方式，nginx使用zlib对http包的内容进行gzip，所以需要在linux上安装zlib库。yum install -y zlib zlib-devel</li>
<li>OpenSSL 是一个强大的安全套接字层密码库，囊括主要的密码算法、常用的密钥和证书封装管理功能及SSL协议，并提供丰富的应用程序供测试或其它目的使用。nginx不仅支持http协议，还支持https（即在ssl协议上传输http），所以需要在linux安装openssl库。yum install -y openssl openssl-devel</li>
</ul>
</li>
<li>正式安装
<ul>
<li>第一步：把nginx的源码包上传到linux系统</li>
<li>第二步：解压缩[root@localhost ~]# tar zxf nginx-1.8.0.tar.gz</li>
<li>第三步：使用configure命令创建makeFile文件，执行下面一大行</li>
</ul>
</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>	./configure \
	--prefix=/usr/local/nginx \
	--pid-path=/var/run/nginx/nginx.pid \
	--lock-path=/var/lock/nginx.lock \
	--error-log-path=/var/log/nginx/error.log \
	--http-log-path=/var/log/nginx/access.log \
	--with-http_gzip_static_module \
	--http-client-body-temp-path=/var/temp/nginx/client \
	--http-proxy-temp-path=/var/temp/nginx/proxy \
	--http-fastcgi-temp-path=/var/temp/nginx/fastcgi \
	--http-uwsgi-temp-path=/var/temp/nginx/uwsgi \
	--http-scgi-temp-path=/var/temp/nginx/scgi
	注意：启动nginx之前，上边将临时文件目录指定为/var/temp/nginx，需要在/var下创建temp及nginx目录
	mkdir /var/temp/nginx/client -p
</code></pre></div><pre><code>- 第四步：make
- 第五步：make install
- 启动nginx 进入/usr/local/nginx/sbin目录[root@localhost sbin]# ./nginx -c /nginx.conf
- 指定配置文件启动:/usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf
- 查找nginx是否存在ps aux|grep nginx
- 关闭nginx：[root@localhost sbin]# ./nginx -s stop
- 推荐使用：[root@localhost sbin]# ./nginx -s quit
- 重启nginx：1、先关闭后启动。2、刷新配置文件：[root@localhost sbin]# ./nginx -s reload
</code></pre>
<ul>
<li>访问nginx:<a href="http://192.168.25.135:80/" target="_blank" rel="noopener noreferrer">http://192.168.25.135:80/</a> 默认是80端口。注意：是否关闭防火墙。</li>
<li>查看nginx配置文件：nginx -t</li>
</ul>
<h1>4. nginx.conf配置</h1>
<h2>配置虚拟主机(server节点)</h2>
<ul>
<li>在一台服务器启动多个网站。如何区分不同的网站?:1域名不同2端口不同</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>通过端口listen区分不同虚拟机
http {	
	server {//一个server节点就是一个虚拟主机
		listen       
		server_name  localhost;
		location / {
			root   html;//Html是nginx安装目录下的html目录
			index  index.html index.htm;
		}
	}
	/*server {
		listen       81;
		server_name  localhost;
		location / {
			root   html-81;
			index  index.html index.htm;
		}
	}*/
}
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>通过域名server_name区分虚拟主机
http {
	server {
		listen       80;
		server_name  www.taobao.com;
		location / {
			root   html-taobao;
			index  index.html index.htm;
		}
	}
	/*server {
		listen       80;
		server_name  www.baidu.com;
		location / {
			root   html-baidu;
			index  index.html index.htm;
		}
	}*/
}
</code></pre></div><h2>5. nginx反向代理配置</h2>
<ul>
<li>正向代理(客户端转发请求和响应)</li>
<li>反向代理：(服务端转发请求和响应)</li>
<li>反向代理服务器决定哪台服务器提供服务。返回代理服务器不提供服务器。也是请求的转发。</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>	upstream tomcat1 {
		server 192.168.25.148:8080;
	}
	server {
		listen       80;
		server_name  www.sina.com.cn;
		location / {
			proxy_pass   http://tomcat1;//代理配置
			index  index.html index.htm;
		}
	}
	upstream tomcat2 {
		server 192.168.25.148:8081;
	}
	server {
		listen       80;
		server_name  www.sohu.com;
		location / {
			proxy_pass   http://tomcat2;//代理配置
			index  index.html index.htm;
		}
	}
</code></pre></div><h2>6. 负载均衡/集群配置</h2>
<ul>
<li>如果一个服务由多条服务器提供，需要把负载分配到不同的服务器处理，需要负载均衡。</li>
<li>可以根据服务器的实际情况调整服务器权重。权重越高分配的请求越多，权重越低，请求越少。默认是都是1</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>	upstream tomcat2 {
		server 192.168.25.148:8081;//集群配置
		server 192.168.25.148:8082 weight=2;
		server 192.168.25.148:8083;
	}
</code></pre></div><h2>6.1. Nginx的高可用配置</h2>
<ul>
<li>要实现nginx的高可用，需要实现备份机。主服务器和备份机上都运行高可用（High Availability）监控程序，通过传送诸如“I am alive”这样的信息来监控对方的运行状况。当备份机不能在一定的时间内收到这样的信息时，它就接管主服务器的服务IP并继续提供负载均衡服务；当备份管理器又从主管理器收到“I am alive”这样的信息时，它就释放服务IP地址，这样的主服务器就开始再次提供负载均衡服务。</li>
<li>keepalived是集群管理中保证集群高可用的一个服务软件，用来防止单点故障。Keepalived的作用是检测web服务器的状态，如果有一台web服务器死机，或工作出现故障，Keepalived将检测到，并将有故障的web服务器从系统中剔除，当web服务器工作正常后Keepalived自动将web服务器加入到服务器群中，这些工作全部自动完成，不需要人工干涉，需要人工做的只是修复故障的web服务器。<br>
-keepalived工作原理：keepalived是以VRRP协议为实现基础的，VRRP全称Virtual Router Redundancy Protocol，即虚拟路由冗余协议。可以认为是实现路由器高可用的协议，即将N台提供相同功能的路由器组成一个路由器组，这个组里面有一个master和多个backup，master上面有一个对外提供服务的vip（VIP = Virtual IP Address，虚拟IP地址，该路由器所在局域网内其他机器的默认路由为该vip），master会发组播，当backup收不到VRRP包时就认为master宕掉了，这时就需要根据VRRP的优先级来选举一个backup当master。这样的话就可以保证路由器的高可用了。</li>
<li>keepalived主要有三个模块，分别是core、check和VRRP。core模块为keepalived的核心，负责主进程的启动、维护以及全局配置文件的加载和解析。check负责健康检查，包括常见的各种检查方式。VRRP模块是来实现VRRP协议的。</li>
<li>keepalived+nginx实现主备过程<br>
初始状态<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/68448aa3db9eda659080a.png" alt="图片8.png"><br>
主机宕机<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/2139793d9471132befa39.png" alt="图片9.png"><br>
主机恢复<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/cf3135d3956bb4bcab747.png" alt="图片10.png"></li>
</ul>
<h2>11. vue页面部署到nginx</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>	带子路由
	server{
		location /newmatch/ {           
			proxy_pass  http://localhost:11001/;
			proxy_redirect   off;
			proxy_set_header Host $host;
			proxy_set_header X-Real-IP $remote_addr;
			proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
		}
	}
	server {
        listen       11001;
        location / {
            root   html\test;
            index  index.html index.htm;
			expires 1s;
        }
    }
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>	或者不带子路由
	server {
        listen       9999;
		location / {
			root   html\test;
		}
		#location = /index.html {
        #    root   html;
        #}
	}
</code></pre></div><h2>12. nginx的websocket配置</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>	server {
        listen       8083;
		location / {
			proxy_pass http://wx.bio-match.com:8083/;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;//websocket配置1
            proxy_set_header Connection "upgrade";//websocket配置2
		}
       error_page   500 502 503 504  /50x.html;
        location = /50x.html {
            root   html;
        }
    }
</code></pre></div><h1>13. 使用winws.exe注册成windows服务</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>	winws.xml配置
	&lt;?xml version="1.0" encoding="UTF-8" ?&gt;
	&lt;service&gt;
		&lt;id&gt;nginx&lt;/id&gt;
		&lt;name&gt;nginx&lt;/name&gt;
		&lt;description&gt;nginx&lt;/description&gt;
		&lt;executable&gt;D:\tools\nginx-1.14.2\nginx.exe&lt;/executable&gt;
		&lt;logpath&gt;D:\tools\nginx-1.14.2\&lt;/logpath&gt;
		&lt;logmode&gt;roll&lt;/logmode&gt;
		&lt;depend&gt;&lt;/depend&gt;
		&lt;startargument&gt;-p D:\tools\nginx-1.14.2&lt;/startargument&gt;
		&lt;stopargument&gt;-p D:\tools\nginx-1.14.2 -s stop&lt;/stopargument&gt;
	&lt;/service&gt;
</code></pre></div>]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/68448aa3db9eda659080a.png" type="image/png"/>
    </item>
    <item>
      <title>DOS</title>
      <link>https://javaguide.cn/backend/containerservice/DOS.html</link>
      <guid>https://javaguide.cn/backend/containerservice/DOS.html</guid>
      <source url="https://javaguide.cn/rss.xml">DOS</source>
      <description>DOS 1. 配置环境变量(快速运行exe程序) 2. 常用DOS命令 1. 配置环境变量(快速运行exe程序) 当我们在DOS控制台中使用的程序只给出程序名称，而没有给出完整路径时，那么Windows系统会到Path变量保存的路径中去查找程序。 配置步骤：鼠标右键点击计算机→属性→高级系统设置→点击环境变量→找到系统变量中的PATH→点击编辑按钮 2...</description>
      <category>运维</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>DOS</p>
<!--more-->
<!-- TOC -->
<ul>
<li><a href="#1-%E9%85%8D%E7%BD%AE%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E5%BF%AB%E9%80%9F%E8%BF%90%E8%A1%8Cexe%E7%A8%8B%E5%BA%8F">1. 配置环境变量(快速运行exe程序)</a></li>
<li><a href="#2-%E5%B8%B8%E7%94%A8dos%E5%91%BD%E4%BB%A4">2. 常用DOS命令</a></li>
</ul>
<!-- /TOC -->
<h1>1. 配置环境变量(快速运行exe程序)</h1>
<ul>
<li>当我们在DOS控制台中使用的程序只给出程序名称，而没有给出完整路径时，那么Windows系统会到Path变量保存的路径中去查找程序。</li>
<li>配置步骤：鼠标右键点击计算机→属性→高级系统设置→点击环境变量→找到系统变量中的PATH→点击编辑按钮</li>
</ul>
<h1>2. 常用DOS命令</h1>
<ul>
<li>弹出DOS控制台:win+R，然后输入cmd</li>
</ul>
<p>|操作|dos命令|操作|<br>
|:-😐:-😐<br>
|清屏|cls| C:\ &gt;cls|<br>
|切换盘符(必须在盘符根目录使用)|:|C:\ &gt;E:|<br>
|进入指定目录|cd|D:&gt;cd develop或D:&gt;cd develop\Java|<br>
|返回上一级目录|cd..|D:\develop\Java&gt;cd..|<br>
|返回盘符根目录|cd|D:\develop\Java&gt;cd|<br>
|显示当前目录下的文件和子目录信息|dir;||<br>
|运行应用程序|程序完整名称 参数|D:&gt;C:\windows\notepad.exe D:&gt;C:\windows\notepad[.exe]|<br>
|删除进程|taskkill /f /im 进程名|taskkill /f /im "chrome.exe"|<br>
|复制文件夹|xcopy /Y 原始目录名 目标目录名 /e|xcopy /Y "D:/Match" "D:/MatchBackup" /e"|<br>
|winrar解压|unrar x -y 压缩文件 目标目录|unrar x -y "D:/update/Match.rar" "D:/Match"|<br>
|利用putty上传文件|"C:\Program Files\PuTTY\pscp.exe" -pw 密码 文件名 <a href="mailto:root@127.0.0.1">root@127.0.0.1</a>:|"C:\Program Files\PuTTY\pscp.exe" -pw 密码 文件名 <a href="mailto:root@127.0.0.1">root@127.0.0.1</a>:|</p>
]]></content:encoded>
    </item>
    <item>
      <title>CICD</title>
      <link>https://javaguide.cn/backend/containerservice/cicd.html</link>
      <guid>https://javaguide.cn/backend/containerservice/cicd.html</guid>
      <source url="https://javaguide.cn/rss.xml">CICD</source>
      <description>DevOps Development（开发）和 Operations（运维）的组合，是⼀种⽅法论，是⼀组过程、⽅法与系统的统称，⽤于促进应⽤开发DEV、应⽤运维OPS和质量保障（QA）部⻔之间的沟通、协作与整合，以期打破传统开发和运营之间的壁垒和鸿沟； 通过⾃动化软件交付和架构变更的流程，来使得构建、测试、发布软件能够更加地快捷、频繁和可靠；具体来说，...</description>
      <category>运维</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<!--more-->
<!-- TOC -->
<h2>DevOps</h2>
<p>Development（开发）和 Operations（运维）的组合，是⼀种⽅法论，是⼀组过程、⽅法与系统的统称，⽤于促进应⽤开发DEV、应⽤运维OPS和质量保障（QA）部⻔之间的沟通、协作与整合，以期打破传统开发和运营之间的壁垒和鸿沟；<br>
通过⾃动化软件交付和架构变更的流程，来使得构建、测试、发布软件能够更加地快捷、频繁和可靠；具体来说，就是在软件交付和部署过程中提⾼沟通与协作的效率，旨在更快、更可靠的的发布更⾼质量的产品；<br>
DevOps并不指代某⼀特定的软件⼯具或软件⼯具组合；各种⼯具软件或软件组合可以实现 DevOps 的概念⽅法，与软件开发中设计到的 OOP、AOP、IOC（或DI）等类似，是⼀种理论或过程或⽅法的抽象或代称。当下容器化技术与K8S是DevOps的核⼼</p>
<h2>CI/CD</h2>
<p>通过将⾃动化引⼊应⽤程序开发阶段来频繁向客户交付应⽤程序的⽅法。主要概念是持续集成、持续交付和持续部署。<br>
解决集成新代码可能给开发和运营团队带来的问题（⼜名“集成地狱”）的解决⽅案。<br>
CI指持续集成，开发⼈员的⾃动化过程。成功的CI指对应⽤程序的新代码更改会定期构建、测试并合并到共享存储库。解决同时开发的应⽤程序有太多分⽀可能相互冲突的问题的解决⽅案。<br>
CD指持续交付(Continuous Delivery)/持续部署(Continuous Deployment)，两者都是关于⾃动化流⽔线的进⼀步阶段，但有时会单独使⽤它们来说明正在发⽣的⾃动化程度。持续交付意味着开发⼈员对应⽤程序的更改会⾃动进⾏错误测试并上传到存储库（如 GitHub 或容器注册表），然后运维团队可以将它们部署到实时⽣产环境中。这是对开发团队和业务团队之间可⻅性和沟通不佳问题的解决⽅案。⽬的是确保以最少的努⼒部署<br>
新代码。<br>
持续部署指⾃动将开发⼈员的更改从存储库发布到⽣产环境，供客户使⽤。减少⼈⼯部署。通过⾃动化管道中的下⼀阶段来构建持续交付的优势。</p>
<p>持续集成 (CI) 帮助开发⼈员更频繁地将他们的代码更改合并回共享分⽀或“主⼲”。合并开发⼈员对应⽤程序的更改后，将通过⾃动构建应⽤程序并运⾏不同级别的⾃动化测试（通常是单元测试和集成测试）来验证这些更改，以确保更改不会破坏应⽤程序。这意味着测试从类和函数到构成整个应⽤程序的不同模块的所有内容。如果⾃动化测试发现新代码和现有代码之间存在冲突，CI可以更轻松地快速、频繁地修复这些错误。</p>
<p>持续交付CD：⾃动将经过验证的代码发布到存储库。⽬标是拥有⼀个始终准备好部署到⽣产环境的代码库。在持续交付中，从合并代码更改到交付⽣产就绪版本的每个阶段都涉及测试⾃动化和代码发布⾃动化。在该过程结束时，运营团队能够快速轻松地将应⽤程序部署到⽣产环境。</p>
<p>持续部署CD：⾃动将⽣产就绪的构建发布到代码存储库，⾃动将应⽤程序发布到⽣产环境。因为在⽣产前的流⽔线阶段没有⼈⼯⻔，依赖于精⼼设计的测试⾃动化。<br>
持续部署意味着开发⼈员对云应⽤程序的更改可以在编写后⼏分钟内⽣效（假设通过了⾃动化测试）。使得持续接收和整合⽤户反馈变得更容易。降低了应⽤程序部署的⻛险，从⽽更容易以⼩块的形式发布对应⽤程序的更改，⽽不是⼀次全部发布。</p>
<p>代码上传gitlab --&gt; 触发jenkins构建--&gt; 拉取项目、maven构建jar包、基于项目内的dockerfile进行docker build</p>
]]></content:encoded>
      <enclosure url="https://b.bdstatic.com/comment/Y_bZHaS27NSYIAE9PqRzMw6b453f16568a9dcfabe40633c508c6d0.png" type="image/png"/>
    </item>
    <item>
      <title>Docker</title>
      <link>https://javaguide.cn/backend/containerservice/docker.html</link>
      <guid>https://javaguide.cn/backend/containerservice/docker.html</guid>
      <source url="https://javaguide.cn/rss.xml">Docker</source>
      <description>docker Docker概述？场景？优点？ 开源的应用容器引擎，基于 Go 语言 通过容器实现快速打包，测试和部署程序、管理基础架构(快速交付) 容器安全、轻量、可移植、松耦合、可扩展直接在内核运行(同一硬件上可运行多个容器) Web应用的自动化打包和发布。√ 自动化测试和持续集成、发布。√ 在服务型环境中部署和调整数据库或其他的后台应用。 快速，一...</description>
      <category>运维</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>docker</p>
<!--more-->
<h2>Docker概述？场景？优点？</h2>
<p>开源的应用容器引擎，基于 Go 语言<br>
通过容器实现快速打包，测试和部署程序、管理基础架构(快速交付)<br>
容器安全、轻量、可移植、松耦合、可扩展直接在内核运行(同一硬件上可运行多个容器)</p>
<p>Web应用的自动化打包和发布。√<br>
自动化测试和持续集成、发布。√<br>
在服务型环境中部署和调整数据库或其他的后台应用。</p>
<p>快速，一致地交付您的应用程序<br>
响应式部署和扩展<br>
在同一硬件上运行更多工作负载</p>
<h2>Docker架构？组件？</h2>
<figure><img src="https://b.bdstatic.com/comment/Y_bZHaS27NSYIAE9PqRzMwfd2c5c7d4bb799eaeb7e9adbba3e3694.png" alt="1.png" tabindex="0"><figcaption>1.png</figcaption></figure>
<p>工作流程<br>
构建镜像：使用 Dockerfile 创建镜像。<br>
推送镜像到注册表：将镜像上传到 Docker Hub 或私有注册表中。<br>
拉取镜像：通过 docker pull 从注册表中拉取镜像。<br>
运行容器：使用镜像创建并启动容器。<br>
管理容器：使用 Docker 客户端命令管理正在运行的容器（例如查看日志、停止容器、查看资源使用情况等）。<br>
网络与存储：容器之间通过 Docker 网络连接，数据通过 Docker 卷或绑定挂载进行持久化。</p>
<ul>
<li>Docker客户端（Docker Client）：用户与Docker守护进程交互的命令行界面（CLI）。用户通过Docker CLI发送命令到Docker守护进程执行相应的操作。<br>
功能：允许用户使用命令与 Docker 守护进程通信，如创建容器、构建镜像、查看容器状态等。<br>
交互方式：Docker客户端与Docker守护进程通过REST API或Unix套接字通信<br>
常用命令：<br>
docker run：运行容器。<br>
docker ps：列出正在运行的容器。<br>
docker build：构建 Docker 镜像。<br>
docker exec：在容器中执行命令。</li>
<li>Docker 守护进程（Docker Daemon）：负责管理容器生命周期、构建镜像、分发镜像等任务。监听来自Docker客户端的请求，并且通过Docker API执行请求<br>
启动和停止容器。<br>
构建、拉取和推送镜像。<br>
管理容器的网络和存储。<br>
启动、停止、查看容器日志等。<br>
与 Docker 注册表进行通信，管理镜像的存储与分发。<br>
启动 Docker 守护进程（通常是自动启动的）：sudo systemctl start docker</li>
<li>Docker 引擎 API（Docker Engine API）：Docker提供的RESTful接口，允许客户端与Docker守护进程通信。通过这个API，用户可以执行各种操作，支持跨平台调用。<br>
功能：向 Docker 守护进程发送 HTTP 请求，实现容器、镜像的管理。<br>
提供 RESTful 接口，允许通过编程与 Docker 进行交互。<br>
通过 curl 或其他 HTTP 客户端访问 Docker 引擎 API<br>
查询当前 Docker 守护进程的版本：curl --unix-socket /var/run/docker.sock <a href="http://localhost/version" target="_blank" rel="noopener noreferrer">http://localhost/version</a></li>
<li>Docker 容器（Docker Containers）<br>
执行环境，轻量级、独立且可执行的软件包。容器是从Docker镜像启动的，包含了运行某个应用程序所需的一切——从操作系统库到应用程序代码。容器在运行时与其他容器和宿主机共享操作系统内核，但容器之间的文件系统和进程是隔离的。<br>
功能：<br>
提供独立的运行环境，确保应用程序在不同的环境中具有一致的行为。<br>
容器是临时的，通常在任务完成后被销毁。<br>
容器的生命周期是由 Docker 守护进程管理的。容器可以在任何地方运行，因为它们不依赖于底层操作系统的配置，所有的运行时依赖已经封装在镜像中。<br>
启动容器：docker run -d ubuntu</li>
<li>Docker 镜像（Docker Images）：容器的只读模板。包含了应用程序运行所需的操作系统、运行时、库、环境变量和应用代码等。镜像是静态的，用户可以根据镜像启动容器。<br>
功能：<br>
构建容器<br>
镜像是只读的，不同容器使用同一个镜像时，容器中的文件系统层是独立的。<br>
Docker 镜像可以通过 docker pull 从 Docker Hub 或私有注册表拉取，也可以通过 docker build 从 Dockerfile 构建。<br>
拉取 Ubuntu 镜像：docker pull ubuntu</li>
<li>Docker 仓库（Docker Registries）：存储 Docker 镜像，公共仓库Docker Hub。Docker Hub下载上传镜像也可以部署自己的私有 Docker 仓库来管理企业内部的镜像。<br>
功能：<br>
存储 Docker 镜像。<br>
提供镜像的上传和下载功能。<br>
Docker Hub 提供了大量官方和社区维护的镜像，如 Ubuntu、Nginx、MySQL 等。<br>
推送镜像到 Docker Hub：docker push username/image_name</li>
<li>Docker Compose：定义和运行多容器Docker应用的工具。用一个 docker-compose.yml 配置文件定义多个容器（服务），并可以通过一个命令启动这些容器。用于开发、测试和部署多容器的应用。<br>
功能：<br>
定义和运行多个容器组成的应用。<br>
通过 YAML 文件来配置应用的服务、网络和卷等。</li>
<li>Docker Swarm：集群管理和调度工具。将多个 Docker 主机（节点）组织成集群，并通过Swarm 集群管理工具来调度和管理容器。可以实现容器的负载均衡、高可用性和自动扩展等功能。<br>
功能：<br>
管理多节点 Docker 集群。<br>
通过调度器管理容器的部署和扩展。</li>
<li>Docker 网络（Docker Networks）：并与外部世界进行连接<br>
功能：<br>
管理容器间的网络通信。<br>
支持不同的网络模式，以适应不同场景下的需求。<br>
创建一个自定义网络并将容器连接到该网络：</li>
<li>Docker 卷（Docker Volumes）：数据持久化机制，适用于数据库等需要持久存储的应用。<br>
功能：<br>
允许容器间共享数据。<br>
保证数据持久化，独立于容器的生命周期。与容器文件系统不同，卷的内容不会随着容器销毁而丢失</li>
</ul>
<h2>Docker安装</h2>
<ul>
<li>手动安装</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>
# 更改centos源
curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo
yum -y remove docker docker-client docker-client-latest docker-common docker-latest docker-latest-logrotate docker-logrotate docker-engine
# 更新yum。防止找不到docker
yum update -y
# yum clean all
# yum makecache
#安装一些必备工具 java-11-openjdk-headless java-11-openjdk java-11-openjdk-devel
yum -y install lrzsz net-tools wget vim python3 keyutils unzip lvm2 yum-utils
# 安装docker
yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
#yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
yum -y install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin

systemctl start docker
systemctl enable docker
</code></pre></div>]]></content:encoded>
      <enclosure url="https://b.bdstatic.com/comment/Y_bZHaS27NSYIAE9PqRzMwfd2c5c7d4bb799eaeb7e9adbba3e3694.png" type="image/png"/>
    </item>
    <item>
      <title>Kubernetes</title>
      <link>https://javaguide.cn/backend/containerservice/kubernetes.html</link>
      <guid>https://javaguide.cn/backend/containerservice/kubernetes.html</guid>
      <source url="https://javaguide.cn/rss.xml">Kubernetes</source>
      <description>k8s介绍 Kubernetes舵手。8替代K和s中的8个字母，Google开源基于Go Kubernetes和Docker两个互补。Docker侧重于容器化应用，Kubernetes专注于容器编排。Docker开发应用、打包、测试和交付，Kubernetes在生产、测试环境中编排应用的运行 k8s类似云上的操作系统对资源进行抽象，并对多种云原生微服务...</description>
      <category>运维</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<!--more-->
<!-- TOC -->
<h2>k8s介绍</h2>
<ul>
<li>Kubernetes舵手。8替代K和s中的8个字母，Google开源基于Go</li>
<li>Kubernetes和Docker两个互补。Docker侧重于容器化应用，Kubernetes专注于容器编排。Docker开发应用、打包、测试和交付，Kubernetes在生产、测试环境中编排应用的运行</li>
<li>k8s类似云上的操作系统对资源进行抽象，并对多种云原生微服务应用进行调度</li>
</ul>
<h2>k8s架构</h2>
<p>Kubernetes集群由主节点（master）与工作节点（node）组成。这些节点都是Linux主机<br>
<img src="https://b.bdstatic.com/comment/Y_bZHaS27NSYIAE9PqRzMwc1af6a79492ff1fec2341d5f59ee453a.png" alt="k8s.png"></p>
<ul>
<li>主节点（master控制平面）：组成集群的控制平面的系统服务的集合。3-5个副本保证高可用</li>
<li>API Server（API服务）：负责所有组件(系统内置组件以及外部用户组件)之间的通信。对外通过HTTPS的方式提供了RESTful风格的API接口。访问API Server的全部请求都必须经过授权与认证</li>
<li>Controller Manager：管理和执行各种控制器(如 ReplicaSet、Deployment、StatefulSet等)。实现了全部的后台控制循环，完成对集群的监控并对事件作出响应</li>
<li>Controller(Deployment、DaemonSet以及StatefulSet)：每个controller都在后台启动了独立的监控循环功能，负责监控API Server的变更。每个控制循环都只关心与自己相关的逻辑。保证集群的当前状态（current state）与期望状态（desired state）相匹配。每个控制循环的基础逻辑如下。1获取期望状态2观察当前状态3判断两者间的差异。4变更当前状态来消除差异点</li>
<li>Scheduler：通过监听API Server来启动新的工作任务，并将其分配到适合的且处于正常运行状态的节点中。调度器过滤掉不能运行指定任务的工作节点并排序。选择分数最高的节点来运行指定的任务。然后进行多种前置校验包括：节点是否仍然存在、是否有affinity或者anti-affinity规则、任务所依赖的端口在当前工作节点是否可以访问、工作节点是否有足够的资源等。过滤不满足任务执行条件的工作节点，最后根据规则计算得分并排序，包括：工作节点上是否已经包含任务所需的镜像、剩余资源是否满足任务执行条件，正在执行多少任务。得分最高的工作节点执行任务。如果调度器没找到合适的工作节点，那么任务会被标记为暂停状态</li>
<li>ETCD：在整个控制层中，只有集群存储是有状态（stateful）的部分，持久化地存储了整个集群的配置与状态。底层用分布式数据库etcd。运行3～5个副本保证高可用。etcd认为一致性比可用性更重要。在出现脑裂时会停止为集群提供更新能力来保证存储数据的一致性。etcd不可用时应用仍然可以在集群性持续运行，只不过无法更新任何内容而已。etcd用RAFT一致性算法</li>
<li>工作节点：集群的工作者。负责1. 监听API Server分派的新任务。2. 执行新分派的任务。3. 通过API Server向控制平面回复任务执行的结果。</li>
<li>Kubelet：工作节点核心，每个工作节点上都有部署。负责将当前工作节点注册到集群当中，集群的资源池就会获取到当前工作节点的CPU、内存以及存储信息，并将工作节点加入当前资源池。负责监听API Server新分配的任务并执行，维护与控制平面之间的一个通信频道，准备将执行结果反馈回去。如果Kuberlet无法运行指定任务，就会将这个信息反馈给控制平面，并由控制平面决定接下来要采取什么措施</li>
<li>容器运行时 (Docker、Containerd、...)：Kubelet需要容器运行时（container runtime）来执行依赖容器才能执行的任务，例如拉取镜像并启动或停止容器。k8s通过运⾏时接⼝（CRI）的模块支持不同的容器运行时</li>
<li>Kube-proxy：运行在每个工作节点，负责本地集群网络。例如保证每个工作节点都可以获取到唯一的IP地址，并且实现了本地IPTABLE以及IPVS来保障Pod间的网络路由与负载均衡</li>
</ul>
<h2>POD、Pause容器、yaml定义pod(了解)，POD生命周期与重启、拉取策略，利用探针实现POD健康检查，对外暴露，Pod调度与节点亲和性，污点（Taint）与容忍度（Toleration）.LimitRange与ResourceQuota</h2>
<ul>
<li>Docker中调度的原子单位是容器；K8s中最小调度的原子单位是Pod。每个Pod中运行一个或一组容器，称为多容器Pod（multi-container Pod）</li>
<li>同一个Pod中运行多个容器会共享相同的Pod环境。包括了IPC命名空间，内存，磁盘、网络以及其他资源，如IP地址。容器之间可以用localhost接口通信。</li>
<li>多容器Pod适用于存在强绑定关系的多个容器，比如需要共享内存与存储。如果容器间并不存在如此紧密的关系，最好将容器封装到不同的Pod，通过网络以松耦合的方式来运行。在任务级别实现容器间的隔离，降低相互之间的影响。但会导致大量的未加密的网络流量产生。</li>
<li>Pause容器：infrastucture container（infra）基础容器，</li>
<li>每个Pod运行一个Pause的容器，其他容器（业务容器）都从pause容器中fork出来，共享Pause容器的网络栈和Volume挂载卷。因此他们之间通信和数据交换更为高效</li>
<li>Pause容器为每个业务容器提供以下功能：<br>
PID命名空间：Pod中的不同应用程序可以看到其他应用程序的进程ID。<br>
网络命名空间：Pod中的多个容器能够访问同一个IP和端口范围。<br>
IPC命名空间：Pod中的多个容器能够使用SystemV IPC或POSIX消息队列进行通信。<br>
UTS命名空间：Pod中的多个容器共享一个主机名<br>
Volumes（共享存储卷）：Pod中的各个容器可以访问Pod级别的Volumes</li>
<li>扩容或缩容应用时通过添加或删除Pod来实现。不要向已经存在的Pod中增加容器来扩容</li>
<li>Pod的部署是一个原子操作。只有当Pod中的<strong>所有容器都启动成功且处于运行状态</strong>时，Pod提供的服务才是可用的，一个Pod（即使包含多容器）只会被唯一的工作节点调度</li>
<li>如果Pod出现预期外的销毁时会启动新Pod来取代有问题的Pod。有全新的ID与IP地址。不要在设计程序的时依赖特定的Pod</li>
</ul>
<details>
<summary>yaml定义pod</summary>
<div class="language-bash" data-ext="sh" data-title="sh"><pre class="language-bash"><code><span class="token comment"># 编写yaml</span>
<span class="token function">mkdir</span> /etc/k8s
<span class="token function">cat</span> <span class="token operator">&gt;</span> /etc/k8s/nginx-pod.yaml <span class="token operator">&lt;&lt;-</span><span class="token string">'EOF'
# API版本号，固定写v1即可
apiVersion: v1 
# 创建对象类型
kind: Pod 
# 元数据，描述pod的辅助信息
metadata: 
	# pod名称
  name: pod-nginx
# 设置容器、镜像等关键选项
spec:
  # 重启策略
  restartPolicy: Never
  containers: 
    # 容器名称
    - name: container-nginx
    # 镜像名称
      image: nginx:1.20.2-alpine
      # 镜像拉取策略
      imagePullPolicy: IfNotPresent
      # 容器内部暴露的端口号，即expose
      ports: 
      # nginx容器默认对外暴露80端口
      - containerPort: 80 
      # 配置存活探针,每五秒钟执⾏⼀次探测容器80端⼝是否准备就绪
      # ⽽第⼀次探测执⾏前先等待10秒，留出必要的初始化时间
      livenessProbe:
        tcpSocket:
          port: 80
        initialDelaySeconds: 10
        periodSeconds: 5
      readinessProbe:
        httpGet:
          path: /abcde
          port: 80
          httpHeaders:
            - name: Custom-Header
              value: Awesome
        initialDelaySeconds: 3
        periodSeconds: 3
EOF</span>

kubectl apply <span class="token parameter variable">-f</span> /etc/k8s/nginx-pod.yaml
<span class="token comment">#移除</span>
kubectl delete <span class="token parameter variable">-f</span> /etc/k8s/nginx-pod.yaml

<span class="token comment"># 查看已部署的Nginx节点</span>
kubectl get pods <span class="token parameter variable">-A</span> <span class="token parameter variable">-o</span> wide

<span class="token comment"># 查看指定pod明细</span>
kubectl describe pod pod-nginx
<span class="token comment"># 查看输出的日志</span>
kubectl logs <span class="token parameter variable">-f</span> pod-nginx
<span class="token comment"># 查看运行时命令</span>
crictl <span class="token function">ps</span>
</code></pre></div></details>
<p>Pod生命周期五个阶段</p>
<ul>
<li>运行中（Running）：Pod已经绑定到了一个节点上，所有的容器都已被创建。至少有一个容器正在运行，或者正处于启动或重启状态。</li>
<li>等待中（Pending）: 创建Pod请求已被接受，但有一个或者多个容器镜像尚未创建</li>
<li>正常终止（Succeeded）：pod中的所有的容器已经正常退出，并且永远不会自动重启这些容器，一般在部署job时出现</li>
<li>异常停止（Failed）：Pod中的所有容器都已终止了，并且至少有一个容器是因为失败终止。容器以非0状态退出或者被系统终止</li>
<li>未知状态（PodUnkonwn）：出于某种原因，无法获得Pod的状态，通常是与Pod主机通信出错</li>
</ul>
<p>Pod详细状态</p>
<ul>
<li>CrashLoopBackOff：容器退出，正在重启，建议增加内存、CPU等资源</li>
<li>InvalidImageName： 无法解析镜像名称</li>
<li>ImageInspectError： 无法校验镜像</li>
<li>ErrImageNeverPull： 策略禁止拉取镜像</li>
<li>ImagePullBackOff： 正在重试拉取，建议更换镜像仓库</li>
<li>RegistryUnavailable： 连接不到镜像中心</li>
<li>ErrImagePull： 通用的拉取镜像出错</li>
<li>CreateContainerConfigError： 不能创建kubelet使用的容器配置</li>
<li>CreateContainerError： 创建容器失败</li>
<li>m.internalLifecycle.PreStartContainer  执行hook报错</li>
<li>RunContainerError： 启动容器失败</li>
<li>PostStartHookError： 执行hook报错</li>
<li>ContainersNotInitialized： 容器没有初始化完毕</li>
<li>ContainersNotReady： 容器没有准备完毕</li>
<li>ContainerCreating：容器创建中，长时间卡死要decribe与logs查看日志分析内容</li>
<li>PodInitializing：pod初始化中</li>
<li>DockerDaemonNotReady：docker还没有完全启动</li>
<li>NetworkPluginNotReady：网络插件还没有完全启动</li>
</ul>
<p>POD重启策略spec.restartPolicy：适用于pod中的所有首次需要重启的容器，随后再次需要重启将延迟一段时间后进行，时长为10，20，40，80，160，300s</p>
<ul>
<li>Always(默认)：容器失效时，自动重启该容器</li>
<li>OnFailure：容器停止运行且退出码不为0时重启</li>
<li>Never：任何状态都不重启容器<br>
POD镜像拉取策略spec.containers[i].imagePullPolicy</li>
<li>IfNotPresent(默认)，镜像不存在时拉取（面对稳定版本）</li>
<li>Always：每次创建Pod都重新拉取镜像（面对不断变更版本）</li>
<li>Never：永远不会拉取镜像</li>
</ul>
<p>Pod实现健康检查三种探针类型spec.containers[i].StartupProbe：</p>
<ul>
<li>StartupProbe：用于判断容器内应用程序是否已经启动。会先禁止其他的探测直到成功为止，成功后将不再进行探测。适用于容器启动时间长的场景</li>
<li>LivenessProbe（存活探针）：用于探测容器是否运行，探测失败会根据配置的重启策略进行处理。没有配置则默认success。</li>
<li>ReadinessProbe（就绪探针）：用于探测容器内的程序是否健康，返回值为success代表容器完成启动，并且程序是可以接受流量的状态<br>
三者区别</li>
<li>存活探针用于确定重启容器时机。例如探测到死锁。提高应用的可用性，即使其中存在缺陷</li>
<li>就绪探针可以确定容器准备好接受请求流量时机，当所有容器都就绪时，才能认为该Pod就绪。用于控制Pod作为Service的后端。Pod尚未就绪会被从Service的负载均衡器中剔除</li>
</ul>
<p>Pod探针的四种检测方式spec.containers[i].StartupProbe.httpGet：</p>
<ul>
<li>exec：在容器内执行命令返回值为0，则认为容器健康。</li>
<li>tcpSocket：通过TCP连接检查容器内的端口是否连通，连通则容器健康</li>
<li>httpGet（常用）：通过程序暴露的API地址检查程序是否正常，如果状态码为200~400，则容器健康</li>
<li>grpc：用gRPC执行远程过程调用。如果响应的状态是"SERVING"，则认为诊断成功。<br>
探测结果</li>
<li>Success（成功）：容器通过了诊断。</li>
<li>Failure（失败）：容器未通过诊断。</li>
<li>Unknown（未知）：诊断失败，因此不会采取任何行动。<br>
配置范本：</li>
<li>容器启动5秒后发送第一个存活探针。尝试连接nginx容器的80端口。如果探测成功，Pod会被标记为就绪状态，每隔10秒运行一次探测</li>
<li>就绪探针periodSeconds字段指定每隔3秒执行一次存活探测</li>
<li>initialDelaySeconds 字段在执行第一次探测前等待3秒。向容器内运行的服务（服务监听8080端口）发送HTTP GET请求来探测。如果服务器上/healthz路径下的处理程序返回成功代码，则认为容器是健康存活的。如果返回失败代码，则会杀死容器并重启。返回200-400的任何代码都表示成功，其它表示失败</li>
</ul>
<p>对外暴露端口</p>
<table>
<thead>
<tr>
<th>方法</th>
<th>优点</th>
<th>缺点</th>
</tr>
</thead>
<tbody>
<tr>
<td>NodePort</td>
<td>简单、适合测试环境</td>
<td>端口范围受限，暴露到所有节点</td>
</tr>
<tr>
<td>LoadBalancer</td>
<td>云环境原生支持，外部访问简单</td>
<td>仅支持云环境，可能有额外成本</td>
</tr>
<tr>
<td>Ingress</td>
<td>强大的路由和域名支持，生产环境</td>
<td>要额外部署 Ingress Controller</td>
</tr>
<tr>
<td>直接暴露(HostPort)</td>
<td>配置简单</td>
<td>不推荐，破坏抽象，难以扩展和管理</td>
</tr>
</tbody>
</table>
<p>调度是指将Pod放置到合适的节点上，以便对应节点上运⾏Pod<br>
调度器通过K8s的监测Watch机制来发现集群中新创建且尚未被调度到节点上的Pod。调度器会将发现的每个未调度的Pod调度到合适的节点上运⾏</p>
<p>kube-scheduler是默认调度器，在设计上允许你⾃⼰编写⼀个调度组件并替换原有的kube-scheduler<br>
Kube-scheduler选择⼀个最佳节点来运⾏新建或尚未调度（unscheduled）的Pod。由于Pod中的容器和Pod本身可能有不同的要求，调度程序会过滤掉任何不满⾜Pod特定调度需求的节点。API允许在创建Pod时指定节点<br>
满⾜Pod调度请求的所有节点称之为可调度节点。如果没有节点能满⾜Pod的资源请求，那么Pod将⼀直停留在未调度状态直到调度器找到合适节点<br>
调度器先找到⼀个Pod的所有可调度节点，然后对可调度节点打分，选出其中得分最⾼的节点来运⾏Pod。调度器将调度决定通知给kube-apiserver，这个过程叫做绑定<br>
做调度决定时要考虑的因素：单独和整体的资源请求、硬件/软件/策略限制、亲和以及反亲和要求、数据局部性、负载间的⼲扰等等。</p>
<p>kube-scheduler给Pod做调度选择时包含两个步骤<br>
过滤阶段：将所有满⾜Pod调度需求的节点选出来。例如PodFitsResources过滤函数会检查候选节点的可⽤资源能否满⾜Pod的资源请求。过滤后得出所有可调度节点的节点列表；通常包含不⽌⼀个节点。如果这个列表是空的，代表Pod不可调度<br>
打分阶段：为Pod从所有可调度节点中选取最合适的节点。根据打分规则给每⼀个可调度节点打分。最后将Pod调度到得分最⾼的节点上。如果存在多个得分最⾼的节点，则从中随机选取⼀个</p>
<p>过滤和打分配置<br>
调度策略：配置过滤所⽤的断⾔（Predicates）和打分优先级（Priorities）<br>
调度配置：配置实现不同调度阶段的插件，包括QueueSort、Filter、Score、Bind、Reserve、Permit等</p>
<p>Affinity亲和性：当满⾜了某些条件就把Pod调度到集群上。Anti-Affinity相反，~不把Pod调度到集群上.<br>
Taint污点和Toleration容忍，Taint提供Node的标记，但标记不是Label，当设置好Taint后，满⾜Toleration的Pod将可以部署到该Node上。</p>
<p>Node Selector和Label可以实现精确筛选</p>
<div class="language-bash" data-ext="sh" data-title="sh"><pre class="language-bash"><code><span class="token comment"># 新增有nodeSelector的Pod</span>
mkdir/etc/k8s
cd/etc/k8s
cat<span class="token operator">&gt;</span> pod-nginx.yaml <span class="token operator">&lt;&lt;-</span><span class="token string">'EOF'
apiVersion: v1
kind: Pod
metadata:
  name: pod-nginx
spec:
  containers:
    - name: container-nginx
      image: nginx:1.20.2-alpine
      ports:
        - containerPort: 80
  nodeSelector:
    disk: ssd # 放置到具有 "disk=ssd" 标签的节点上
EOF</span>
kubectl delete <span class="token parameter variable">-f</span> pod-nginx.yaml
kubectl apply <span class="token parameter variable">-f</span> pod-nginx.yaml

<span class="token comment"># 检查集群的Node状态，包含Labels，处于Pending状态，describe也提示⽆法匹配</span>
kubectl get po
NAME READY STATUS RESTARTS AGE
pod-nginx <span class="token number">0</span>/1 Pending <span class="token number">0</span> 24s

kubectl get no --show-labels
kubectl describe po pod-nginx
Warning  FailedScheduling  6s    default-scheduler  <span class="token number">0</span>/1 nodes are available: <span class="token number">1</span> node<span class="token punctuation">(</span>s<span class="token punctuation">)</span> didn<span class="token string">'t match Pod'</span>s <span class="token function">node</span> affinity/selector. preemption: <span class="token number">0</span>/1 nodes are available: <span class="token number">1</span> Preemption is not helpful <span class="token keyword">for</span> scheduling.
<span class="token comment"># 新增disk=ssd的Label并检查</span>
kubectl label nodes node1 <span class="token assign-left variable">disk</span><span class="token operator">=</span>ssd
kubectl get no --show-labels

<span class="token comment"># ⼜开始跑了，如果再度检查describe的讯息中的Event会发现：</span>
kubectl describe po pod-nginx
<span class="token comment"># 要删除标签，需要的key后⾯增加减号即可</span>
kubectl label <span class="token function">node</span> node1 disk-
</code></pre></div><p>Affinity分类<br>
1、Node Affinity：和Node Selector不同的是，它会有更多细緻的操作，NodeSelector看成是简易版的NodeAffinity，<br>
两种策略：<br>
preferredDuringSchedulingIgnoredDuringExecution：软策略，可以不满⾜<br>
requiredDuringSchedulingIgnoredDuringExecution：硬策略，⼀定要满⾜</p>
<p>matchExpressions的key<br>
<a href="http://kubernetes.io/hostname" target="_blank" rel="noopener noreferrer">kubernetes.io/hostname</a><br>
<a href="http://failure-domain.beta.kubernetes.io/zone" target="_blank" rel="noopener noreferrer">failure-domain.beta.kubernetes.io/zone</a><br>
<a href="http://failure-domain.beta.kubernetes.io/region" target="_blank" rel="noopener noreferrer">failure-domain.beta.kubernetes.io/region</a><br>
<a href="http://beta.kubernetes.io/instance-type" target="_blank" rel="noopener noreferrer">beta.kubernetes.io/instance-type</a><br>
<a href="http://beta.kubernetes.io/os" target="_blank" rel="noopener noreferrer">beta.kubernetes.io/os</a><br>
<a href="http://beta.kubernetes.io/arch" target="_blank" rel="noopener noreferrer">beta.kubernetes.io/arch</a></p>
<p>operator操作符<br>
In：Label的值在某个列表中<br>
NotIn：Label的值不在某个列表中<br>
Gt：Label的值⼤于某个值<br>
Lt：Label的值⼩于某个值<br>
Exists：某个Label存在<br>
DoesNotExist：某个Label不存在</p>
<p>weight权重1~100，越⾼越优先考虑</p>
<div class="language-bash" data-ext="sh" data-title="sh"><pre class="language-bash"><code><span class="token comment"># 新的Pod不允许部署在Node0上，在剩余节点中优先部署在disk=ssd的Node上</span>
<span class="token function">mkdir</span> /etc/k8s
<span class="token builtin class-name">cd</span> /etc/k8s
<span class="token function">cat</span> <span class="token operator">&gt;</span> pod-nginx.yaml <span class="token operator">&lt;&lt;-</span><span class="token string">'EOF'
apiVersion: v1
kind: Pod
metadata:
  name: pod-nginx
spec:
  containers:
    - name: container-nginx
      image: nginx:1.20.2-alpine
      ports:
        - containerPort: 80
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
              - key: kubernetes.io/hostname
                operator: NotIn
                values:
                  - node0
      preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 1
          preference:
            matchExpressions:
              - key: disk
                operator: In
                values:
                  - ssd
EOF</span>
kubectl delete <span class="token parameter variable">-f</span> pod-nginx.yaml
kubectl apply <span class="token parameter variable">-f</span> pod-nginx.yaml

kubectl get po <span class="token parameter variable">-o</span> wide
NAME READY STATUS RESTARTS AGE IP NODE NOMI
pod-nginx <span class="token number">1</span>/1 Running <span class="token number">0</span> 6s <span class="token number">10.244</span>.0.147 minikube <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span> <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>

</code></pre></div><p>2、Pod Affinity<br>
也有两种类型：<br>
requiredDuringSchedulingIgnoredDuringExecution<br>
preferredDuringSchedulingIgnoredDuringExecution<br>
Pod间亲和性，⽤Pod规约中的.affinity.podAffinity字段<br>
Pod间反亲和性，⽤Pod规约中的.affinity.podAntiAffinity字段</p>
<figure><img src="https://b.bdstatic.com/comment/Y_bZHaS27NSYIAE9PqRzMwe93f41f0fe17e1e3a3bf470704ee8ff5.png" alt="affinity.png" tabindex="0"><figcaption>affinity.png</figcaption></figure>
<p>亲和性规则：仅当节点和⾄少⼀个已运⾏且有security=S1的标签的Pod处于同⼀区域时，才可以将该Pod调度到节点上。更确切说，<a href="http://xn--Podtopology-rb7re9edv2ddiictew32bed3lxr0b.kubernetes.io/zone=V%E6%A0%87%E7%AD%BE%E7%9A%84%E8%8A%82%E7%82%B9%E4%B8%8A%EF%BC%8C%E5%B9%B6%E4%B8%94%E9%9B%86%E7%BE%A4%E4%B8%AD%E2%BE%84%E5%B0%91%E6%9C%89%E2%BC%80%E4%B8%AA%E4%BD%8D%E4%BA%8E%E8%AF%A5%E5%8F%AF%E2%BD%A4%E5%8C%BA%E7%9A%84%E8%8A%82%E7%82%B9%E4%B8%8A%E8%BF%90%E2%BE%8F%E7%9D%80%E5%B8%A6%E6%9C%89security=S1%E6%A0%87%E7%AD%BE%E7%9A%84Pod%E3%80%82" target="_blank" rel="noopener noreferrer">必须将Pod调度到具有topology.kubernetes.io/zone=V标签的节点上，并且集群中⾄少有⼀个位于该可⽤区的节点上运⾏着带有security=S1标签的Pod。</a><br>
反亲和性规则：如果节点处于Pod所在的同⼀可⽤区且⾄少⼀个Pod具有security=S2标签，则该Pod不应被调度到该节点上。更确切说，如果同⼀可⽤区中存在其他运⾏着带有security=S2标签的Pod节点，<a href="http://xn--topology-459lv3zuj1bwrvm4cl47bx07a5px.kubernetes.io/zone=R%EF%BC%8CPod%E4%B8%8D%E8%83%BD%E8%A2%AB%E8%B0%83%E5%BA%A6%E5%88%B0%E8%AF%A5%E8%8A%82%E7%82%B9%E4%B8%8A" target="_blank" rel="noopener noreferrer">并且节点具有标签topology.kubernetes.io/zone=R，Pod不能被调度到该节点上</a></p>
<div class="language-yaml" data-ext="yml" data-title="yml"><pre class="language-yaml"><code><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> v1
<span class="token key atrule">kind</span><span class="token punctuation">:</span> Pod
<span class="token key atrule">metadata</span><span class="token punctuation">:</span>
  <span class="token key atrule">name</span><span class="token punctuation">:</span> with<span class="token punctuation">-</span>pod<span class="token punctuation">-</span>affinity
<span class="token key atrule">spec</span><span class="token punctuation">:</span>
  <span class="token key atrule">affinity</span><span class="token punctuation">:</span>
    <span class="token key atrule">podAffinity</span><span class="token punctuation">:</span>
      <span class="token key atrule">requiredDuringSchedulingIgnoredDuringExecution</span><span class="token punctuation">:</span>
        <span class="token punctuation">-</span> <span class="token key atrule">labelSelector</span><span class="token punctuation">:</span>
            <span class="token key atrule">matchExpressions</span><span class="token punctuation">:</span>
              <span class="token punctuation">-</span> <span class="token key atrule">key</span><span class="token punctuation">:</span> security
                <span class="token key atrule">operator</span><span class="token punctuation">:</span> In
                <span class="token key atrule">values</span><span class="token punctuation">:</span>
                  <span class="token punctuation">-</span> S1
          <span class="token key atrule">topologyKey</span><span class="token punctuation">:</span> topology.kubernetes.io/zone
    <span class="token key atrule">podAntiAffinity</span><span class="token punctuation">:</span>
      <span class="token key atrule">preferredDuringSchedulingIgnoredDuringExecution</span><span class="token punctuation">:</span>
        <span class="token punctuation">-</span> <span class="token key atrule">weight</span><span class="token punctuation">:</span> <span class="token number">100</span>
          <span class="token key atrule">podAffinityTerm</span><span class="token punctuation">:</span>
            <span class="token key atrule">labelSelector</span><span class="token punctuation">:</span>
              <span class="token key atrule">matchExpressions</span><span class="token punctuation">:</span>
                <span class="token punctuation">-</span> <span class="token key atrule">key</span><span class="token punctuation">:</span> security
                  <span class="token key atrule">operator</span><span class="token punctuation">:</span> In
                  <span class="token key atrule">values</span><span class="token punctuation">:</span>
                    <span class="token punctuation">-</span> S2
            <span class="token key atrule">topologyKey</span><span class="token punctuation">:</span> topology.kubernetes.io/zone
  <span class="token key atrule">containers</span><span class="token punctuation">:</span>
    <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> with<span class="token punctuation">-</span>pod<span class="token punctuation">-</span>affinity
      <span class="token key atrule">image</span><span class="token punctuation">:</span> registry.k8s.io/pause<span class="token punctuation">:</span><span class="token number">2.0</span>
</code></pre></div><p>污点（Taint）与容忍度（Toleration）<br>
节点亲和性是Pod的属性，使Pod被吸引到特定的节点（出于偏好或硬性要求）<br>
污点（Taint）相反，使节点排斥特定的Pod<br>
容忍度（Toleration）⽤于Pod。允许调度器调度带有对应污点的Pod。但并不保证调度<br>
污点和容忍度配合⽤来避免Pod被分配到不合适的节点上</p>
<p>Taint的策略：<br>
NoSchedule：POD不会被调度到标记为taints节点。<br>
PreferNoSchedule：NoSchedule的软策略版本。<br>
NoExecute：⼀旦Taint⽣效，如该节点内正在运⾏的POD没有对应Tolerate设置会被逐出</p>
<div class="language-bash" data-ext="sh" data-title="sh"><pre class="language-bash"><code><span class="token comment"># 设置污点</span>
kubectl taint nodes node0 <span class="token assign-left variable">app</span><span class="token operator">=</span>nginx:NoSchedule

<span class="token comment"># 去除污点</span>
kubectl taint nodes node0 <span class="token assign-left variable">app</span><span class="token operator">=</span>nginx:NoSchedule-

<span class="token function">cat</span> <span class="token operator">&gt;</span> deploy-nginx.yaml <span class="token operator">&lt;&lt;-</span><span class="token string">'EOF'
apiVersion: v1
kind: Pod
metadata:
  name: nginx
  labels:
    app: nginx
spec:
  containers:
    - name: nginx
      image: nginx:1.20.2-alpine
      imagePullPolicy: IfNotPresent
      ports:
        - containerPort: 80
EOF</span>
kubectl delete <span class="token parameter variable">-f</span> deploy-nginx.yaml
kubectl apply <span class="token parameter variable">-f</span> deploy-nginx.yaml

<span class="token comment"># 没有任何⼀台服务器可以部署，因为所有node认为app=nginx是污点，不予部署</span>
kubectl get po
nginx <span class="token number">0</span>/1 Pending <span class="token number">0</span> 2m9s

<span class="token comment"># 设置容忍度，允许app=nginx部署在app=nginx:NoSchedule的节点上</span>

<span class="token function">cat</span> <span class="token operator">&gt;</span> deploy-nginx.yaml <span class="token operator">&lt;&lt;-</span><span class="token string">'EOF'
apiVersion: v1
kind: Pod
metadata:
  name: nginx
  labels:
    app: nginx
spec:
  containers:
    - name: nginx
      image: nginx:1.20.2-alpine
      imagePullPolicy: IfNotPresent
      ports:
        - containerPort: 80
  tolerations:
    - key: "app"
      operator: "Equal"
      value: "nginx"
      effect: "NoSchedule"
EOF</span>
kubectl delete <span class="token parameter variable">-f</span> deploy-nginx.yaml
kubectl apply <span class="token parameter variable">-f</span> deploy-nginx.yaml

<span class="token comment"># 有了</span>
kubectl get po <span class="token parameter variable">-o</span> wide
nginx <span class="token number">1</span>/1 Running <span class="token number">0</span> 2m9s
</code></pre></div><p>LimitRange与ResourceQuota<br>
LimitRange（限制范围）<br>
默认情况下，K8s集群上的容器运⾏使⽤的计算资源没有限制<br>
使⽤资源配额可以在⼀个指定的命名空间内限制集群资源的使⽤与创建<br>
⼀个Pod最多能够使⽤命名空间的资源配额所定义的CPU和内存⽤量<br>
LimitRange是限制命名空间内每个适⽤的对象类别（例如Pod或PersistentVolumeClaim）指定的资源分配量（限制和请求）的策略对象</p>
<p>LimitRange对象能够限制在⼀个命名空间中实施：<br>
对每个Pod或Container最⼩和最⼤的资源使⽤量的限制。<br>
对每个PersistentVolumeClaim能申请的最⼩和最⼤的存储空间⼤⼩的限制。<br>
对⼀种资源的申请值和限制值的⽐值的控制。<br>
对计算资源的默认申请/限制值，并且⾃动的在运⾏时注⼊到多个Container中。</p>
<p>LimitRange默认值可能⼩于客户端提交给API服务器的规约中为容器指定的request值导致Pod将⽆法调度</p>
<div class="language-bash" data-ext="sh" data-title="sh"><pre class="language-bash"><code><span class="token function">cat</span> <span class="token operator">&gt;</span> myRange.yml <span class="token operator">&lt;&lt;-</span><span class="token string">'EOF'
apiVersion: v1
kind: LimitRange
metadata:
  name: cpu-resource-constraint
spec:
  limits:
  - default: 
      cpu: "500m" # 默认限制值
    defaultRequest: 
      cpu: "500m" # 默认请求值
    max: 
      cpu: "1" # 最大值
    min: 
      cpu: "100m" # 最小值
    type: Container # 限制类型为容器
EOF</span>
kubectl delete <span class="token parameter variable">-f</span> myRange.yml
kubectl apply <span class="token parameter variable">-f</span> myRange.yml

<span class="token comment"># K8s允许将CPU的限额设置为分数，⽐如CPU.limits=500m，500milliCPU，0.5个CPU，Pod就会被分到⼀个CPU⼀半计算能⼒。等价于cpu=0.5，不过官⽅推荐500m</span>
<span class="token comment"># 内存资源的单位是bytes，⽀持使⽤Ei，Pi，Ti，Gi，Mi，Ki的⽅式作为bytes的值，要注意Mi和M的区别（1Mi=10241024，1M=10001000）。</span>

<span class="token comment"># 声明CPU资源请求为700m但未声明limit的Pod：Pod将不会被调度，失败并出现类似以下的错误：</span>
<span class="token function">cat</span> <span class="token operator">&gt;</span> conflict.yml <span class="token operator">&lt;&lt;-</span><span class="token string">'EOF'
apiVersion: v1
kind: Pod
metadata:
  name: example-conflict-with-limitrange-cpu
spec:
  containers:
  - name: demo
    image: registry.k8s.io/pause:2.0
    resources:
      requests:
        cpu: "700m"
EOF</span>
kubectl delete <span class="token parameter variable">-f</span> conflict.yml
kubectl apply <span class="token parameter variable">-f</span> conflict.yml
Pod <span class="token string">"example-conflict-with-limitrange-cpu"</span> is invalid: spec.containers<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>.resources.requests: Invalid value: <span class="token string">"700m"</span><span class="token builtin class-name">:</span> must be <span class="token function">less</span> than or equal to cpu limit

<span class="token comment"># 如果你同时设置了request和limit，即使相同的LimitRange，新Pod也会被成功调度：</span>
<span class="token function">cat</span> <span class="token operator">&gt;</span> conflict.yml <span class="token operator">&lt;&lt;-</span><span class="token string">'EOF'
apiVersion: v1
kind: Pod
metadata:
  name: example-no-conflict-with-limitrange-cpu
spec:
  containers:
  - name: demo
    image: registry.k8s.io/pause:2.0
    resources:
      requests:
        cpu: "700m"
      limits:
        cpu: "700m"
EOF</span>
kubectl delete <span class="token parameter variable">-f</span> conflict.yml
kubectl apply <span class="token parameter variable">-f</span> conflict.yml
</code></pre></div><p>Resource Quota（资源配额）<br>
资源配额，通过ResourceQuota对象来定义，对每个命名空间的资源消耗总量、某种类型的对象的总数⽬、Pod可以使⽤的计算资源提供限制<br>
配额机制所⽀持的资源类型：</p>
<figure><img src="https://b.bdstatic.com/comment/Y_bZHaS27NSYIAE9PqRzMwee6ca4ddffd533cb55dd4b91337023be.png" alt="limits.png" tabindex="0"><figcaption>limits.png</figcaption></figure>
<p>不同的团队可以在不同的命名空间下⼯作。通过RBAC强制执⾏。集群管理员可为每个命名空间创建⼀个或多个ResourceQuota对象。<br>
当⽤户在命名空间下创建资源（如Pod、Service等）时，配额系统会跟踪集群的资源使⽤情况，确保使⽤的资源⽤量不超过ResourceQuota中定义的硬性资源限额。<br>
如果资源创建或者更新请求违反了配额约束，那么该请求会报错（HTTP403FORBIDDEN），并在消息中给出有可能违反的约束。<br>
如果命名空间下的计算资源cpu和memory的配额被启⽤，则必须设定请求值（request）和约束值（limit），否则配额系统将拒绝Pod的创建。可⽤LimitRanger准⼊控制器来为没有设置计算资源需求的Pod设置默认值<br>
对于其他资源：⽆需为该资源设置限制或请求。如果资源配额限制了此命名空间的临时存储，则可以创建没有限制/请求临时存储的新Pod。可⽤限制范围⾃动设置对这些资源的默认请求</p>
<p>在具有32GiB内存和16核CPU资源的集群中，允许A团队⽤20GiB内存和10核的CPU资源，B团队⽤10GiB内存和4核的CPU资源，预留2GiB内存和2核的CPU资源供将来分配。限制"testing"命名空间使⽤1核CPU资源和1GiB内存。允许"production"命名空间使⽤任意数量</p>
<div class="language-bash" data-ext="sh" data-title="sh"><pre class="language-bash"><code><span class="token comment"># 查看是否支持</span>
kubectl api-resources <span class="token operator">|</span> <span class="token function">grep</span> resourcequota
resourcequotas <span class="token function">quota</span>  v1 <span class="token boolean">true</span> ResourceQuota

<span class="token function">cat</span> <span class="token operator">&gt;</span> helloworld.yml <span class="token operator">&lt;&lt;-</span><span class="token string">'EOF'
apiVersion: apps/v1
kind: Deployment
metadata:
  name: helloworld-deployment
  namespace: myspace
spec:
  replicas: 3
  selector:
    matchLabels:
      app: helloworld
  template:
    metadata:
      labels:
        app: helloworld
    spec:
      containers:
      - name: k8s-demo
        image: 105552010/k8s-demo
        ports:
        - name: nodejs-port
          containerPort: 3000
        resources:
          requests:
            cpu: "200m"
            memory: "512Mi"
          limits:
            cpu: "400m"
            memory: "1Gi"
EOF</span>
kubectl delete <span class="token parameter variable">-f</span> helloworld.yml
kubectl apply <span class="token parameter variable">-f</span> helloworld.yml
</code></pre></div><p>存储资源配额</p>
<figure><img src="https://b.bdstatic.com/comment/Y_bZHaS27NSYIAE9PqRzMwe87568c263d25e19b2d136c7594e72c0.png" alt="storagelimits.png" tabindex="0"><figcaption>storagelimits.png</figcaption></figure>
<p>如果针对"gold"storageclass与"bronze"storageclass设置配额可以定义如下配额：<br>
<a href="http://gold.storageclass.storage.k8s.io/requests.storage:500Gi" target="_blank" rel="noopener noreferrer">gold.storageclass.storage.k8s.io/requests.storage:500Gi</a><br>
<a href="http://bronze.storageclass.storage.k8s.io/requests.storage:100Gi" target="_blank" rel="noopener noreferrer">bronze.storageclass.storage.k8s.io/requests.storage:100Gi</a></p>
<p>对象数量限定</p>
<div class="language-bash" data-ext="sh" data-title="sh"><pre class="language-bash"><code><span class="token function">cat</span> <span class="token operator">&gt;</span> namespace-quota.yml <span class="token operator">&lt;&lt;-</span><span class="token string">'EOF'</span>
apiVersion: v1
kind: Namespace
metadata:
  name: myspace
</code></pre></div>]]></content:encoded>
      <enclosure url="https://b.bdstatic.com/comment/Y_bZHaS27NSYIAE9PqRzMwc1af6a79492ff1fec2341d5f59ee453a.png" type="image/png"/>
    </item>
    <item>
      <title>linux服务器搭建</title>
      <link>https://javaguide.cn/backend/containerservice/linux%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA.html</link>
      <guid>https://javaguide.cn/backend/containerservice/linux%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA.html</guid>
      <source url="https://javaguide.cn/rss.xml">linux服务器搭建</source>
      <description>记录linux安装各种服务器的方法 linux7的安装 1.png 2.png 3.png 4.png 5.png 6.png 7.png 8.png 9.png 10.png 11.png 12.png 13.png 14.png centos查看ip: ip addr jdk1.7安装 安装JDK17 安装tomcat yum安装mysql 安装M...</description>
      <category>运维</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>记录linux安装各种服务器的方法</p>
<!--more-->
<h2>linux7的安装</h2>
<p><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/71c1796efe37e96e0628b.png" alt="1.png"><br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/6e44053497d2ef56f4534.png" alt="2.png"><br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/1e0c79462792d22eacc18.png" alt="3.png"><br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/0e340472b9b2523467702.png" alt="4.png"><br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/4a8f5d63c6d02c4466d4c.png" alt="5.png"><br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/1e22b257b346f674fb850.png" alt="6.png"><br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/986d71aa592cea3f3c998.png" alt="7.png"><br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/12da83371510377bf3ba8.png" alt="8.png"><br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/c4b6234550cc8e1bd2268.png" alt="9.png"><br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/0d2a0b6967800c5f9be2a.png" alt="10.png"><br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/f5113dbb606a51484f5bb.png" alt="11.png"><br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/b18714b9fa515816e1433.png" alt="12.png"><br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/ce31ccbf61b3e9bd91be0.png" alt="13.png"><br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/e33b59a7d062218650ec8.png" alt="14.png"></p>
<p>centos查看ip: ip addr</p>
<h2>jdk1.7安装</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>jdk的解压
在usr目录下sudo mkdir java新建/usr/java目录
将jdk-7u55-linux-i586.tar.gz放到/usr/java目录下(putty按tab键能快速补全)
tar -zxvf jdk-7u55-linux-i586.tar.gz -C /usr/java/解压到/usr/java/目录
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>配置jdk环境变量
vim /etc/profile如果找不到vim命令就yum install vim
输入G到文件末尾，输入i在文件尾部添加：
JAVA_HOME=/usr/java/jdk1.7.0_55/
export PATH=$JAVA_HOME/bin:$PATH
按esc退出编辑，:wq保存并退出
重新加载一下文件:source /etc/profile
查看jdk版本：java -version
报错-bash: /usr/java/jdk1.7.0_55//bin/java: /lib/ld-linux.so.2: bad ELF interpreter: 没有那个文件或目录
则sudo yum install glibc.i686
再查看jdk版本：java -version
</code></pre></div><h2>安装JDK17</h2>
<div class="language-bash" data-ext="sh" data-title="sh"><pre class="language-bash"><code><span class="token number">1</span>. 下载安装包
<span class="token function">mkdir</span> /home/jdk17
<span class="token function">wget</span> https://download.oracle.com/java/17/latest/jdk-17_linux-x64_bin.tar.gz <span class="token parameter variable">-P</span> /home/jdk17/openjdk-17.0.0.1+2_linux-x64_bin.tar.gz
<span class="token number">2</span>. 解压
<span class="token function">tar</span> xf /home/jdk17/openjdk-17.0.0.1+2_linux-x64_bin.tar.gz <span class="token parameter variable">-C</span> /home/jdk17/
 
<span class="token number">3</span>. 配置环境变量
<span class="token function">vim</span> /etc/profile　　<span class="token comment">#末尾添加如下位置</span>
<span class="token builtin class-name">export</span> <span class="token assign-left variable">JAVA_HOME</span><span class="token operator">=</span>/home/jdk17/jdk-17.0.0.1
<span class="token builtin class-name">export</span> <span class="token assign-left variable">CLASSPATH</span><span class="token operator">=</span>.:<span class="token variable">$JAVA_HOME</span>/lib/tools.jar:<span class="token variable">$JAVA_HOME</span>/lib/dt.jar
<span class="token builtin class-name">export</span> <span class="token assign-left variable"><span class="token environment constant">PATH</span></span><span class="token operator">=</span><span class="token variable">$JAVA_HOME</span>/bin:<span class="token environment constant">$PATH</span>
 
<span class="token number">4</span>. 使环境变量生效
<span class="token builtin class-name">source</span> /etc/profile
 
<span class="token number">5</span>. 验证
<span class="token function">java</span>
javac
<span class="token function">java</span> <span class="token parameter variable">-version</span>
</code></pre></div><h2>安装tomcat</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>tomcat的解压
将apache-tomcat-7.0.47.tar.gz放到/usr/java目录下
tar -zxvf apache-tomcat-7.0.47.tar.gz -C /usr/java/将tomcat解压到/usr/java目录下
到tomcat的bin目录下执行： ./startup.sh 启动tomcat
到tomcat的logs文件夹下执行 cat catalina.out查看执行情况
关闭防火墙:servive iptables stop（centos7以前）
关闭防火墙:sudo systemctl stop firewalld.service &amp;&amp; sudo systemctl disable firewalld.service（centos7）
查看是否启动成功： 执行jps 访问http://192.168.13.123:8080/
</code></pre></div><h2>yum安装mysql</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>安装带有可用的mysql5系列社区版资源的rpm包rpm -Uvh http://dev.mysql.com/get/mysql-community-release-el7-5.noarch.rpm
查看当前可用的mysql安装资源：yum repolist enabled | grep "mysql.*-community.*"
yum的方式安装MySQL:yum -y install mysql-community-server
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>加入开机启动:systemctl enable mysqld
启动mysql服务进程:systemctl start mysqld
重置密码:mysql_secure_installation   然后按回车就行，接着做按提示做一系列的事情
</code></pre></div><h2>安装MySQL</h2>
<p>1.创建mysql文件夹并切换路径<br>
local是linux上安装文件的目录<br>
cd /usr/local<br>
mkdir mysql<br>
cd mysql<br>
2.下载mysql<br>
wget <a href="https://dev.mysql.com/get/Downloads/MySQL-8.0/mysql-8.0.30-linux-glibc2.12-x86_64.tar.xz" target="_blank" rel="noopener noreferrer">https://dev.mysql.com/get/Downloads/MySQL-8.0/mysql-8.0.30-linux-glibc2.12-x86_64.tar.xz</a><br>
3.解压mysql<br>
tar xvJf mysql-8.0.30-linux-glibc2.12-x86_64.tar.xz<br>
4.重命名文件夹并删除压缩包<br>
mv mysql-8.0.30-linux-glibc2.12-x86_64 mysql-8.0<br>
rm -rf mysql-8.0.30-linux-glibc2.12-x86_64<br>
5.创建用户组以及用户和密码<br>
groupadd mysql<br>
useradd -g mysql mysql<br>
编译安装时候创建mysql组和mysql用户，并把datadir和安装目录属主改为mysql，启动时，mysqld进程的属主是mysql，即便mysql服务被黑掉，得到了mysql用户权限，也不会影响系统安全</p>
<p>6.授权用户<br>
chown -R mysql.mysql /usr/local/mysql/mysql-8.0<br>
7.切换到bin目录下，初始化基础信息得到临时密码<br>
cd bin<br>
./mysqld --user=mysql --basedir=/usr/local/mysql/mysql-8.0 --datadir=/usr/local/mysql/mysql-8.0/data/ --initialize<br>
8.编辑配置文件my.cnf<br>
如果没有 my.cnf 文件就通过命令 touch /etc/my.cnf 创建一个</p>
<p>vi /etc/my.cnf<br>
内容如下：</p>
<p>[mysql]<br>
#MySQL 提示符配置</p>
<p>#用户名@主机名+数据库名<br>
#prompt="\u@\h [\d]&gt;"</p>
<p>#用户名@主机名+mysql版本号+数据库名<br>
prompt=\u@\h \v [\d]&gt;\_</p>
<p>#用户名@主机名+当前时间+mysql版本号+数据库名<br>
#prompt="(\u@\h) \R:\m:\s \v [\d] \n&gt;"</p>
<p>[mysqld]<br>
#mysql安装根目录<br>
basedir = /usr/local/mysql/mysql-8.0/</p>
<p>#mysql数据文件所在位置<br>
datadir = /usr/local/mysql/mysql-8.0/data/</p>
<p>#设置socke文件所在目录<br>
socket = /tmp/mysql.sock</p>
<p>#数据库默认字符集, 主流字符集支持一些特殊表情符号（特殊表情符占用4个字节）<br>
character-set-server = utf8mb4</p>
<p>#数据库字符集对应一些排序等规则，注意要和character-set-server对应<br>
collation-server = utf8mb4_general_ci</p>
<p>#设置client连接mysql时的字符集,防止乱码<br>
init_connect='SET NAMES utf8mb4'<br>
9.切换到mysql-8.0目录下，添加mysqld服务到系统<br>
cd /usr/local/mysql/mysql-8.0<br>
cp -a ./support-files/mysql.server /etc/init.d/mysql<br>
10.授权以及添加服务<br>
chmod +x /etc/init.d/mysql<br>
chkconfig --add mysql<br>
11.启动mysql<br>
service mysql start<br>
12.查看启动状态<br>
service mysql status<br>
13.将mysql命令添加到系统指令<br>
ln -s /usr/local/mysql/mysql-8.0/bin/mysql /usr/bin</p>
<p>现在任何目录下执行 mysql -uroot -p 就可以进行登录</p>
<p>14.登录mysql，密码使用之前随机生成的密码<br>
mysql -uroot -p</p>
<p>15.修改root密码<br>
ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY '123456';<br>
修改root用户密码为 123456 ，也可以换成别的</p>
<p>16.执行 flush privileges 使密码生效<br>
flush privileges;<br>
17.选择mysql数据库<br>
use mysql;<br>
18.修改远程连接并生效，%表示开启远程权限<br>
update user set host='%' where user='root';<br>
flush privileges;<br>
19.退出MySQL：<br>
\q<br>
20.查看mysql是否开机启动<br>
chkconfig --list<br>
如果 mysql服务的 第3、4、5项都是开着的，则已经开启了开机启动，反之则没有。</p>
<p>如果没有，可以用命令设置开机自启动：</p>
<p>systemctl enable mysqld.service<br>
再次查看mysql是否开机启动：</p>
<p>chkconfig --list</p>
<p>1.查看3306端口状态<br>
firewall-cmd --zone=public --query-port=3306/tcp<br>
2、如果是no，表示关闭，打开3306端口<br>
firewall-cmd --zone=public --add-port=3306/tcp --permanent<br>
3、防火墙重载<br>
firewall-cmd --reload<br>
4、再次查看3306端口状态<br>
firewall-cmd --zone=public --query-port=3306/tcp<br>
应该是yes，说明端口已经打开，去navicat测试连接，输入ip和root账户密码，即可成功！<br>
执行下面命令一键登录：<br>
mysql -uroot -hlocalhost -p123456</p>
<h2>Dubbo的注册中心Zookeeper的安装</h2>
<pre><code>Zookeeper是java开发的可以运行在windows、linux环境。需要先安装jdk。
安装环境：Linux：centos6.4 Jdk:1.7以上版本

安装步骤：
第一步：安装jdk
第二步：把zookeeper的压缩包上传到linux系统（目录随意）
第三步：解压缩压缩包tar -zxvf zookeeper-3.4.6.tar.gz
第四步：进入zookeeper-3.4.6目录，创建data文件夹。
第五步：把zookeeper-3.4.6目录下的conf目录将zoo_sample.cfg改名为zoo.cfg ：mv zoo_sample.cfg zoo.cfg
第六步：修改zoo.cfg的data属性设置为data所在的目录：vim zoo.cfg然后输入i编辑
dataDir=/usr/zookeeper-3.4.6/data 然后Esc，然后:wq保存并退出
第七步：进入bin目录启动zookeeper ./zkServer.sh start
关闭：./zkServer.sh stop
查看状态：./zkServer.sh status
注意：需要关闭防火墙。
service iptables stop
永久关闭修改配置开机不启动防火墙：
chkconfig iptables off
如果不能成功启动zookeeper，需要删除data目录下的zookeeper_server.pid文件。
</code></pre>
<h2>Dubbo监控中心的安装</h2>
<pre><code>需要安装tomcat，然后部署监控中心即可。

部署监控中心：
cp dubbo-admin-2.5.4.war apache-tomcat-7.0.47/webapps/dubbo-admin.war 
进入tomcat的bin目录下启动tomcat
访问http://192.168.25.167:8080/dubbo-admin/
用户名：root密码：root

如果监控中心和注册中心在同一台服务器上，可以不需要任何配置。
如果不在同一台服务器，需要修改配置文件dubbo.properties：
/root/apache-tomcat-7.0.47/webapps/dubbo-admin/WEB-INF/dubbo.properties
dubbo.registry.address=zookeeper://127.0.0.1:2181注册中心地址
dubbo.admin.root.password=root root用户的密码
dubbo.admin.guest.password=guest
</code></pre>
<h2>redis安装</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>Redis是c语言开发的。
输入gcc；如果找不到命令的话就要安装
安装redis需要c语言的编译环境。如果没有gcc需要在线安装。yum install gcc-c++

安装步骤：
第一步：redis的源码包上传到linux系统。
第二步：解压缩redis。tar -zxvf redis-3.0.0.tar.gz
第三步：编译。进入redis源码目录redis-3.0.0。make 
第四步：安装。make install PREFIX=/usr/java/redis install命令安装redis到/usr/local/redis中
PREFIX参数指定redis的安装目录。一般软件安装到/usr目录下
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>redis的启动：
前端启动：在redis的安装目录bin下直接启动redis-server  ./redis-server 

后台启动：
把redis-3.0.0/redis.conf复制到/usr/java/redis/bin/目录下
cp redis.conf /usr/java/redis/bin/
修改配置文件：daemonize no 为yes
在/usr/java/redis/bin/中执行 ./redis-server redis.conf
查看redis进程：ps aux|grep redis
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>Redis-cli
在redis的安装目录下的bin
[root@localhost bin]# ./redis-cli 
默认连接localhost运行在6379端口的redis服务。
[root@localhost bin]# ./redis-cli -h 192.168.25.153 -p 6379
-h：连接的服务器的地址
-p：服务的端口号

关闭redis：[root@localhost bin]# ./redis-cli shutdown
</code></pre></div><h2>solr服务器的安装</h2>
<h3>Solr的环境</h3>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>Solr是java开发。
需要安装jdk。安装环境Linux。需要安装Tomcat。
</code></pre></div><h3>搭建步骤</h3>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>第一步：把solr 的压缩包上传到Linux系统
第二步：解压solr。tar -zxvf solr-4.10.3.tgz.tgz
第三步：安装Tomcat，解压缩即可。 tar -zxvf apache-tomcat-7.0.47.tar.gz
第四步：把solr复制到Tomcat下webapps 
第五步：解压缩war包。进入bin目录下./startup.bat启动Tomcat解压。关闭tomcat
第六步：把/root/solr-4.10.3/example/lib/ext目录下的所有的jar包，添加到solr工程中。
cp * /usr/java/solr/tomcat/webapps/solr/WEB-INF/lib/
第七步：创建一个solrhome。/usr/java/solr-4.10.3/example/solr目录就是一个solrhome。复制此目录到/usr/java/solr/solrhome
cp -r solr /usr/java/solr/solrhome
第八步：关联solr及solrhome。需要修改tomcat下的solr工程的web.xml文件。
把这个注释打开并配置好solrhome地址
&lt;env-entry&gt;
   &lt;env-entry-name&gt;solr/home&lt;/env-entry-name&gt;
   &lt;env-entry-value&gt;/usr/java/solr/solrhome/&lt;/env-entry-value&gt;
   &lt;env-entry-type&gt;java.lang.String&lt;/env-entry-type&gt;
&lt;/env-entry&gt;
第九步：启动Tomcat
http://192.168.25.154:8080/solr/
和windows下的配置完全一样。
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>配置业务域
1、把/usr/java/IK Analyzer 2012FF_hf1/IKAnalyzer2012FF_u1.jar添加到tomcat/webappps/solr/lib目录下
2、把/usr/java/IK Analyzer 2012FF_hf1/ext_stopword.dic、IKAnalyzer.cfg.xml、mydict.dic放到tomcat/webappps/solr/WEB-INF/classes目录下。
配置一个FieldType，制定使用IKAnalyzer
3、修改/usr/java/solr/solrhome/collection1/conf/schema.xml,添加
&lt;fieldType name="text_ik" class="solr.TextField"&gt;
  &lt;analyzer class="org.wltea.analyzer.lucene.IKAnalyzer"/&gt;
&lt;/fieldType&gt;
配置业务域，type制定使用自定义的FieldType。设置业务系统Field,添加
&lt;field name="item_title" type="text_ik" indexed="true" stored="true"/&gt;
&lt;field name="item_sell_point" type="text_ik" indexed="true" stored="true"/&gt;
&lt;field name="item_price"  type="long" indexed="true" stored="true"/&gt;
&lt;field name="item_image" type="string" indexed="false" stored="true" /&gt;
&lt;field name="item_category_name" type="string" indexed="true" stored="true" /&gt;

&lt;field name="item_keywords" type="text_ik" indexed="true" stored="false" multiValued="true"/&gt;
&lt;copyField source="item_title" dest="item_keywords"/&gt;
&lt;copyField source="item_sell_point" dest="item_keywords"/&gt;
&lt;copyField source="item_category_name" dest="item_keywords"/&gt;
4、重启tomcat
</code></pre></div><h2>solr-cloud搭建</h2>
<h3>Zookeeper集群搭建</h3>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>第一步：需要安装jdk环境。
第二步：把zookeeper的压缩包上传到服务器。
第三步：解压缩。tar -zxvf zookeeper-3.4.6.tar.gz
第四步：把zookeeper复制三份。
[root@localhost ~]# mkdir /usr/java/solr-cloud
[root@localhost ~]# cp -r zookeeper-3.4.6 /usr/java/solr-cloud/zookeeper01
[root@localhost ~]# cp -r zookeeper-3.4.6 /usr/java/solr-cloud/zookeeper02
[root@localhost ~]# cp -r zookeeper-3.4.6 /usr/java/solr-cloud/zookeeper03
第五步：在每个zookeeper目录下创建一个data目录。
mkdir data
第六步：在data目录下创建一个myid文件，文件名就叫做“myid”。内容就是每个实例的id。例如1、2、3
vim data 然后输入i 输入1 输入esc 输入：wq
cat myid //检查myid的内容1
第七步：修改配置文件。把conf目录下的zoo_sample.cfg文件改名为zoo.cfg
每个一样配置！
cp zoo_sample.cfg zoo.cfg
将datadir=改成data文件夹的地址
保证clientPort三个不冲突
然后在最后一行配置
server.1=192.168.25.135:2881:3881
server.2=192.168.25.135:2882:3882
server.3=192.168.25.135:2883:3883
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>创建全部启动的脚本 start-all.sh :vim start-all.sh
cd zookeeper01/bin
./zkServer.sh start
cd ../../
cd zookeeper02/bin
./zkServer.sh start
cd ../../
cd zookeeper03/bin
./zkServer.sh start
cd ../../
使用以下命令授权
chmod u+x start-all.sh 
查看zookeeper的状态
一个leader其他都是follower
zookeeper01/bin/zkServer.sh status
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>Using config: /usr/java/solr-cloud/zookeeper01/bin/../conf/zoo.cfg
Stopping zookeeper ... bin/zkServer.sh: 第 143 行:kill: (26838) - 没有那个进程
STOPPED
如果关闭zookeeper的时候有这句话 说明端口占用

查看占用2181端口的程序pid：
[root@localhost local]# lsof -i:5432

kill掉该进程
[root@localhost local]# kill -9 7035
重新启动即可
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>创建全部关闭的脚本 start-all.sh :vim shutdown-all.sh
cd zookeeper01/bin
./zkServer.sh stop
cd ../../
cd zookeeper02/bin
./zkServer.sh stop
cd ../../
cd zookeeper03/bin
./zkServer.sh stop
cd ../../
使用以下命令授权
chmod u+x shutdown-all.sh 
查看zookeeper的状态
一个leader其他都是follower
zookeeper01/bin/zkServer.sh status
</code></pre></div><h3>Solr集群的搭建</h3>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>第一步：创建四个tomcat实例。每个tomcat运行在不同的端口。8180、8280、8380、8480
在/usr/java目录下tar -zxvf apache-tomcat-7.0.47解压tomcat
复制四个tomcat到/usr/java/solr-cloud目录下
cp -r apache-tomcat-7.0.47 /usr/java/solr-cloud/tomcat04
vim /usr/java/solr/tomcat/conf/server.xml 将8080改成8180，其他端口号同时加1
第二步：部署solr的war包。把单机版的/usr/java/solr/tomcat/webapps/solr复制到集群中的tomcat01234中。
cp -r /usr/java/solr/tomcat/webapps/solr /usr/java/solr-cloud/tomcat01/webapps/solr
第三步：为每个solr实例创建一个对应的solrhome。使用单机版的solrhome复制四份
cp -r /usr/java/solr/solrhome /usr/java/solr-cloud/solrhome01
第四步：需要修改solr的web.xml文件。把solrhome关联起来。
vim /usr/java/solr/tomcat/webapps/solr/WEB-INF/web.xml
&lt;env-entry&gt;
   &lt;env-entry-name&gt;solr/home&lt;/env-entry-name&gt;
   &lt;env-entry-value&gt;/usr/java/solr-cloud/solrhome01/&lt;/env-entry-value&gt;
   &lt;env-entry-type&gt;java.lang.String&lt;/env-entry-type&gt;
&lt;/env-entry&gt;

第五步：配置solrCloud相关的配置。每个solrhome下都有一个solr.xml，把其中的ip及端口号配置好。
vim /usr/java/solr-cloud/solrhome01/solr.xml
&lt;solrcloud&gt;
	&lt;str name="host"&gt;192.168.25.135&lt;/str&gt;
	&lt;int name="hostPort"&gt;8180&lt;/int&gt;
	&lt;str name="hostContext"&gt;${hostContext:solr}&lt;/str&gt;
	&lt;int name="zkClientTimeout"&gt;${zkClientTimeout:30000}&lt;/int&gt;
	&lt;bool name="genericCoreNodeNames"&gt;${genericCoreNodeNames:true}&lt;/bool&gt;
&lt;/solrcloud&gt;
第六步：让zookeeper统一管理配置文件。需要把solrhome/collection1/conf目录上传到zookeeper。上传任意solrhome中的配置文件即可。
使用工具上传配置文件：/root/solr-4.10.3/example/scripts/cloud-scripts/zkcli.sh
./zkcli.sh -zkhost 192.168.25.135:2181,192.168.25.135:2182,192.168.25.135:2183 -cmd upconfig -confdir /usr/local/solr-cloud/solrhome01/collection1/conf -confname myconf
第七步：修改tomcat/bin目录下的catalina.sh 文件，关联solr和zookeeper。
把此配置添加到配置文件中：
JAVA_OPTS="-DzkHost=192.168.25.135:2181,192.168.25.135:2182,192.168.25.135:2183"
第八步：启动每个tomcat实例。要包装zookeeper集群是启动状态。
第九步：访问集群
第十步：创建新的Collection进行分片处理。
http://192.168.25.135:8180/solr/admin/collections?action=CREATE&amp;name=collection2&amp;numShards=2&amp;replicationFactor=2
第十一步：删除不用的Collection。
http://192.168.25.135:8180/solr/admin/collections?action=DELETE&amp;name=collection1
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>查看第六步的zookeeper上的配置文件：
使用zookeeper目录下的bin/zkCli.sh命令查看zookeeper上的配置文件：
[root@localhost bin]# ./zkCli.sh 
[zk: localhost:2181(CONNECTED) 0] ls /
[configs, zookeeper]
[zk: localhost:2181(CONNECTED) 1] ls /configs
[myconf]
[zk: localhost:2181(CONNECTED) 2] ls /configs/myconf
[admin-extra.menu-top.html, protwords.txt, mapping-FoldToASCIIenglish.enu-bottom.html, clustering, schema.xml..]
[zk: localhost:2181(CONNECTED) 3] 
退出：
[zk: localhost:2181(CONNECTED) 3] quit
使用以下命令连接指定的zookeeper服务：
./zkCli.sh -server 192.168.25.154:2183
</code></pre></div><h2>ActiveMQ的安装</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>进入http://activemq.apache.org/下载ActiveMQ 使用的版本是5.12.0
安装环境：
1、需要jdk、Linux系统。生产环境都是Linux系统。
安装步骤
第一步： 把ActiveMQ 的压缩包上传到Linux系统。
第二步：解压缩。
第三步：启动。
使用bin目录下的activemq命令启动：./activemq start 
关闭：./activemq stop
查看状态：./activemq status
注意：如果ActiveMQ整合spring使用不要使用activemq-all-5.12.0.jar包。建议使用5.11.2
进入管理后台：http://192.168.25.168:8161/admin用户名：admin密码：admin
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>11.3.解决405问题：
修改hosts文件，配置机器名和127.0.0.1的映射关系。
机器名：/etc/sysconfig/network文件中定义了机器名：
</code></pre></div><figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/bfd35cb9434cac5a500fe.png" alt="15.png" tabindex="0"><figcaption>15.png</figcaption></figure>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>Host文件的配置：
</code></pre></div><figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/ca5682c10b4ee9f1c9a6f.png" alt="16.png" tabindex="0"><figcaption>16.png</figcaption></figure>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>重新启动Activemq的服务
</code></pre></div><h2>mycat安装</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>第一步：把MyCat的压缩包上传到linux服务器
第二步：解压缩，得到mycat目录
第三步：进入mycat/bin，启动MyCat
启动命令：./mycat start
停止命令：./mycat stop
重启命令：./mycat restart
注意：可以使用mysql的客户端直接连接mycat服务。默认服务端口为8066
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>配置schema.xml
Schema.xml作为MyCat中重要的配置文件之一，管理着MyCat的逻辑库、表、分片规则、DataNode以及DataSource。

schema 标签用于定义MyCat实例中的逻辑库
Table 标签定义了MyCat中的逻辑表
dataNode 标签定义了MyCat中的数据节点，也就是我们通常说所的数据分片。
dataHost标签在mycat逻辑库中也是作为最底层的标签存在，直接定义了具体的数据库实例、读写分离配置和心跳语句。
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>注意：若是LINUX版本的MYSQL，则需要设置为Mysql大小写不敏感，否则可能会发生表找不到的问题。
在MySQL的配置文件中my.ini [mysqld] 中增加一行
　　lower_case_table_names = 1
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>&lt;?xml version="1.0"?&gt;
&lt;!DOCTYPE mycat:schema SYSTEM "schema.dtd"&gt;
&lt;mycat:schema xmlns:mycat="http://org.opencloudb/"&gt;
	&lt;!--TESTDB是用程序连的数据库名字--&gt;
	&lt;schema name="TESTDB" checkSQLschema="false" sqlMaxLimit="100"&gt;
		&lt;!-- TB_ITEM是TESTDB中含有的表，dataNode指定存到那几个真正的数据库上 --&gt;
		&lt;!-- auto sharding by id (long) --&gt;
		&lt;table name="TB_ITEM" dataNode="dn1,dn2,dn3" rule="auto-sharding-long" /&gt;
		&lt;table name="TB_USER" dataNode="dn1,dn2" primaryKey="ID" type="global"  /&gt;
	&lt;/schema&gt;
	&lt;!--配置节点真正的数据库地址--&gt;
	&lt;dataNode name="dn1" dataHost="localhost1" database="db1" /&gt;
	&lt;dataNode name="dn2" dataHost="localhost2" database="db2" /&gt;
	&lt;dataNode name="dn3" dataHost="localhost1" database="db3" /&gt;
	&lt;dataHost name="localhost1" maxCon="1000" minCon="10" balance="0"
		writeType="0" dbType="mysql" dbDriver="native" switchType="1"  slaveThreshold="100"&gt;
		&lt;!--检查心跳包健康检查--&gt;
		&lt;heartbeat&gt;select user()&lt;/heartbeat&gt;
		&lt;!-- can have multi write hosts --&gt;
		&lt;writeHost host="hostM1" url="192.168.25.134:3306" user="root" password="root"&gt;
		&lt;!-- can have multi read hosts --&gt;
		&lt;/writeHost&gt;
	&lt;/dataHost&gt;
	&lt;dataHost name="localhost2" maxCon="1000" minCon="10" balance="0"
		writeType="0" dbType="mysql" dbDriver="native" switchType="1"  slaveThreshold="100"&gt;
		&lt;heartbeat&gt;select user()&lt;/heartbeat&gt;
		&lt;!-- can have multi write hosts --&gt;
		&lt;writeHost host="hostM1" url="192.168.25.166:3306" user="root" password="root"&gt;
		&lt;!-- can have multi read hosts --&gt;
		&lt;/writeHost&gt;
	&lt;/dataHost&gt;
&lt;/mycat:schema&gt;
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>配置server.xml
server.xml几乎保存了所有mycat需要的系统配置信息。最常用的是在此配置用户名、密码及权限。
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>&lt;!--TESTDB是用程序连的数据库名字，test是账号和密码--&gt;
&lt;user name="test"&gt;
    &lt;property name="password"&gt;test&lt;/property&gt;
    &lt;property name="schemas"&gt;TESTDB&lt;/property&gt;
    &lt;property name="readOnly"&gt;true&lt;/property&gt;
&lt;/user&gt;
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>配置rule.xml
rule.xml里面就定义了我们对表进行拆分所涉及到的规则定义。我们可以灵活的对表使用不同的分片算法，
或者对表使用相同的算法但具体的参数不同。这个文件里面主要有tableRule和function这两个标签。
在具体使用过程中可以按照需求添加tableRule和function。
此配置文件可以不用修改，使用默认即可。
</code></pre></div><h2>在CentOS7上安装SQL Server 2017</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>系统需求：
CentOS7.3以上，我目前用的是CenOS7.4
服务器至少3.25GB内存
好像对CPU没有什么要求，我在虚拟机中配置的CPU为一核
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>安装 SQL Server
下载 Microsoft SQL Server Red Hat 存储库配置文件：
[root@CentOS7~]#curl -o /etc/yum.repos.d/mssql-server.repo https://packages.microsoft.com/config/rhel/7/mssql-server-2017.repo
运行以下命令，安装 SQL Server：
[root@CentOS7 ~]# yum update
[root@CentOS7 ~]# yum install -y mssql-server
运行包安装完成后mssql-conf 安装并按照提示操作以设置 SA 密码，并选择你的版本、语言、设置sql密码
[root@CentOS7 ~]# /opt/mssql/bin/mssql-conf setup
确认 SQL Server 系统管理员密码:
在安装的最后，系统会提示如下：
正在配置 SQL Server...
Created symlink from 
/etc/systemd/system/multi-user.target.wants/mssql-server.service to /usr/lib/systemd/system/mssql-server.service.
安装程序已成功完成。SQL Server 正在启动。
配置完成后，请验证服务是否正在运行：
[root@CentOS7 ~]# systemctl status mssql-server
● mssql-server.service - Microsoft SQL Server Database Engine
   Loaded: loaded (/usr/lib/systemd/system/mssql-server.service; enabled; vendor preset: disabled)
   Active: active (running) since 四 2017-10-05 14:19:18 CST; 21s ago
	 Docs: https://docs.microsoft.com/en-us/sql/linux
 Main PID: 1208 (sqlservr)
   CGroup: /system.slice/mssql-server.service
		   ├─1208 /opt/mssql/bin/sqlservr
		   └─1228 /opt/mssql/bin/sqlservr
............
（以下进行省略）
如果运行结果如上（●正常是绿颜色的）就是服务正常运行了。
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>若要允许远程连接，请打开防火墙上的 SQL Server 端口。
默认的 SQL Server 端口为 TCP 1433。 如果你使用FirewallD防火墙，可以使用以下命令添加规则：
[root@CentOS7 ~]# firewall-cmd --zone=public --add-port=1433/tcp --permanent
[root@CentOS7 ~]# firewall-cmd --reload

当然如果你的服务器前端是有防火墙进行保护的，
也可以不用运行上述命令，而是直接将系统的防火墙关闭。
使用如下命令关闭firewallD防火墙并设置为开机不自动启动：
[root@CentOS7 ~]# systemctl stop firewalld
[root@CentOS7 ~]# systemctl disable firewalld
Removed symlink /etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service.
Removed symlink /etc/systemd/system/multi-user.target.wants/firewalld.service.
以上就完成了SQL Server 2017的安装
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>安装 SQL Server 命令行工具（sqlcmd和bcp）
下载安装源。[root@CentOS7 ~]# curl -o /etc/yum.repos.d/msprod.repo https://packages.microsoft.com/config/rhel/7/prod.repo
安装mssql 工具与 unixODBC 开发人员包，安装之前系统会提示你必须同意相关许可，注意：需要输入大写的YES
[root@CentOS7 ~]# yum update
[root@CentOS7 ~]# yum install -y mssql-tools unixODBC-devel
添加/opt/mssql-tools/bin/到环境变量
[root@CentOS7 ~]# echo 'export PATH="$PATH:/opt/mssql-tools/bin"' &gt;&gt; ~/.bash_profile
[root@CentOS7 ~]# echo 'export PATH="$PATH:/opt/mssql-tools/bin"' &gt;&gt; ~/.bashrc
[root@CentOS7 ~]# source ~/.bashrc
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>使用sqlcmd进行本地连接
[root@CentOS7 ~]# sqlcmd -S localhost -U SA
Password:
这时系统会提示你输入sa密码，输入后回车
如果成功，应会显示 sqlcmd 命令提示符：1&gt;

</code></pre></div><h1>一键Trojan搭建(CentOS 7)</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>

# 查看日志
journalctl -u trojan -f

# 查看端口占用
netstat -tunlp | grep 端口号

# 连接端口
telnet 38.47.108.105  81

junye54231535@gmail.com
https://www.namesilo.com/
junye54231535@gmail.com Junye54231535@gmail.com


admin
2fEfpDxB




03事务隔离的实现结合08
06 和05问题时间
10 问题时间
15 ask
38.47.108.105




</code></pre></div><h1>在Linux下开启指定端口号</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>1、查看某个端口是否已开启，如果提示no表示未开启
firewall-cmd --query-port=8888/tcp

2、永久开启端口号，提示 success 表示成功
firewall-cmd --add-port=8888/tcp --permanent

3、开启端口后要重载配置
firewall-cmd --reload
 
4、移除端口
firewall-cmd --permanent --remove-port=8888/tcp
</code></pre></div><h2>代理</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>编辑 /etc/profile 文件，添加以下内容：
export HTTP_PROXY=http://192.168.1.141:7890/
export HTTPS_PROXY=http://192.168.1.141:7890/
export NO_PROXY=localhost,127.0.0.1,10.0.0.0/8,172.16.0.0/12,192.168.0.0/16,169.254.0.0/16

保存后，执行以下命令使更改生效：
source /etc/profile
检查
curl -I https://www.google.com
</code></pre></div><h2>虚拟机磁盘扩容</h2>
<p>使用 fdisk 创建新分区<br>
执行以下命令为未分配的磁盘空间创建新分区：</p>
<p>fdisk /dev/sda<br>
按以下步骤操作：</p>
<p>输入 n 创建一个新分区。<br>
选择分区类型为 primary（主分区）。<br>
提供起始和结束位置（直接按回车键默认使用剩余空间）。<br>
输入 t 修改分区类型为 8e（Linux LVM）。<br>
输入 w 保存更改并退出。<br>
partprobe /dev/sda<br>
运行 fdisk -l 再次查看，新分区应该显示为 /dev/sda3。</p>
<ol start="3">
<li>将新分区添加为物理卷<br>
将新创建的分区 /dev/sda3 初始化为 LVM 的物理卷：<br>
pvcreate /dev/sda3<br>
Physical volume "/dev/sda3" successfully created</li>
</ol>
<p>扩展卷组<br>
将新创建的物理卷 /dev/sda3 添加到现有卷组 centos：<br>
vgextend centos /dev/sda3<br>
验证卷组是否扩展成功：<br>
vgs<br>
此时应该能看到 VFree 显示有了新的空闲空间。<br>
lvextend -l +100%FREE /dev/mapper/centos-root<br>
报错lvextend -l +100%FREE /dev/mapper/centos-root<br>
就 rm -rf /etc/lvm/archive/*<br>
rm -rf /tmp/*清除后重新执行<br>
文件系统扩容sudo xfs_growfs /dev/mapper/centos-root</p>
]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/71c1796efe37e96e0628b.png" type="image/png"/>
    </item>
    <item>
      <title>UML</title>
      <link>https://javaguide.cn/backend/cs/uml.html</link>
      <guid>https://javaguide.cn/backend/cs/uml.html</guid>
      <source url="https://javaguide.cn/rss.xml">UML</source>
      <description>uml 1. UML——Unified modeling language UML (统一建模语言) 2. UML图例 3. UML图分类 4. 依赖关系 1. UML——Unified modeling language UML (统一建模语言) UML是一种用于软件系统分析和设计的语言工具，它用于帮助软件开发人员进行思考和记录思路的结果 UML本身...</description>
      <category>理论</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>uml</p>
<!--more-->
<!-- TOC -->
<ul>
<li><a href="#1-umlunified-modeling-language-uml-%E7%BB%9F%E4%B8%80%E5%BB%BA%E6%A8%A1%E8%AF%AD%E8%A8%80">1. UML——Unified modeling language UML (统一建模语言)</a></li>
<li><a href="#2-uml%E5%9B%BE%E4%BE%8B">2. UML图例</a></li>
<li><a href="#3-uml%E5%9B%BE%E5%88%86%E7%B1%BB">3. UML图分类</a></li>
<li><a href="#4-%E4%BE%9D%E8%B5%96%E5%85%B3%E7%B3%BB">4. 依赖关系</a></li>
</ul>
<!-- /TOC -->
<h1>1. UML——Unified modeling language UML (统一建模语言)</h1>
<ul>
<li>UML是一种用于软件系统分析和设计的语言工具，它用于帮助软件开发人员进行思考和记录思路的结果</li>
<li>UML本身是一套符号的规定，用于描述软件模型中的各个元素和他们之间的关系，比如类、接口、实现、泛化、依赖、组合、聚合等</li>
<li>使用UML来建模，常用的工具有 Rational Rose , 也可以使用一些插件来建模</li>
<li>用于描述系统中的类(对象)本身的组成和类(对象)之间的各种静态关系。</li>
<li>类之间的关系：依赖、泛化（继承）、实现、关联、聚合与组合</li>
</ul>
<h1>2. UML图例</h1>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/6195768fe18cf19f843db.png" alt="1.png" tabindex="0"><figcaption>1.png</figcaption></figure>
<h1>3. UML图分类</h1>
<ul>
<li>用例图(use case)</li>
<li>静态结构图：类图(类图是描述类与类之间的关系的，是UML图中最核心的)、对象图、包图、组件图、部署图</li>
<li>动态行为图：交互图（时序图与协作图）、状态图、活动图</li>
</ul>
<h1>4. 依赖关系</h1>
<ul>
<li>
<p>类图—依赖关系（Dependence） 类中用到了对方\类的成员属性\方法的返回类型\方法接收的参数类型\方法中使用到</p>
</li>
<li>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/7708aae05861181588a42.png" alt="2.png" tabindex="0"><figcaption>2.png</figcaption></figure>
</li>
<li>
<p>类图—泛化关系(generalization) 泛化关系实际上就是继承关系，他是依赖关系的特例 如果A类继承了B类，我们就说A和B存在泛化关系</p>
</li>
<li>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/ca768a81e42990feb878d.png" alt="3.png" tabindex="0"><figcaption>3.png</figcaption></figure>
</li>
<li>
<p>类图—实现关系（Implementation） 实现关系实际上就是A类实现B接口，他是依赖关系的特例<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/a9fc5d4edbe85d76da51a.png" alt="4.png"></p>
</li>
<li>
<p>类图—关联关系（Association） 类与类之间的联系，他是依赖关系的特例、关联具有导航性：即双向关系或单向关系</p>
</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>    单向一对一关系
    public class Person {
        private IDCard card;
    }
    public class IDCard{}
    
    双向一对一关系
    public class Person {
        private IDCard card;
    }
    public class IDCard{
        private Person person
    }
</code></pre></div><figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/6e369a8ab9c2ba242a992.png" alt="5.png" tabindex="0"><figcaption>5.png</figcaption></figure>
<ul>
<li>类图—聚合关系（Aggregation） 表示的是整体和部分的关系，整体与部分可以分开</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>    public class Computer {
        private Mouse mouse; //鼠标可以和computer分离
        private Moniter moniter;//显示器可以和Computer分离
        public void setMouse(Mouse mouse) {
            this.mouse = mouse;
        }
        public void setMoniter(Moniter moniter) {
            this.moniter = moniter;
        }
        
    }
</code></pre></div><figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/7a5b0e2215fb163368219.png" alt="6.png" tabindex="0"><figcaption>6.png</figcaption></figure>
<ul>
<li>类图—组合关系（Composition） 也是整体与部分的关系，但是整体与部分不可以分开<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/22e5d55432836886fc309.png" alt="1.png"></li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>    public class Person{
    private IDCard card;
    private Head head = new Head();
    }
    public class IDCard{}
    public class Head{}
</code></pre></div><figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/cdd20c73318764930990c.png" alt="7.png" tabindex="0"><figcaption>7.png</figcaption></figure>
]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/6195768fe18cf19f843db.png" type="image/png"/>
    </item>
    <item>
      <title>操作系统</title>
      <link>https://javaguide.cn/backend/cs/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.html</link>
      <guid>https://javaguide.cn/backend/cs/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.html</guid>
      <source url="https://javaguide.cn/rss.xml">操作系统</source>
      <description>操作系统 1. 操作系统的概念和作用 2. 操作系统的发展过程 3. 操作系统的基本特性 4. 操作系统主要功能 5. 操作系统的运行环境 6. 进程描述与控制 6.1. 前趋图(DAG Directed Acyclic Graph): 6.2. 程序执行方式 6.3. 进程 6.4. 线程 6.5. 进程控制 6.6. 进程同步 6.7. 进程通信 ...</description>
      <category>理论</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>操作系统</p>
<!--more-->
<!-- TOC -->
<ul>
<li><a href="#1-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%A6%82%E5%BF%B5%E5%92%8C%E4%BD%9C%E7%94%A8">1. 操作系统的概念和作用</a></li>
<li><a href="#2-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%8F%91%E5%B1%95%E8%BF%87%E7%A8%8B">2. 操作系统的发展过程</a></li>
<li><a href="#3-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%89%B9%E6%80%A7">3. 操作系统的基本特性</a></li>
<li><a href="#4-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%B8%BB%E8%A6%81%E5%8A%9F%E8%83%BD">4. 操作系统主要功能</a></li>
<li><a href="#5-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83">5. 操作系统的运行环境</a></li>
<li><a href="#6-%E8%BF%9B%E7%A8%8B%E6%8F%8F%E8%BF%B0%E4%B8%8E%E6%8E%A7%E5%88%B6">6. 进程描述与控制</a>
<ul>
<li><a href="#61-%E5%89%8D%E8%B6%8B%E5%9B%BEdag-directed-acyclic-graph">6.1. 前趋图(DAG Directed Acyclic Graph):</a></li>
<li><a href="#62-%E7%A8%8B%E5%BA%8F%E6%89%A7%E8%A1%8C%E6%96%B9%E5%BC%8F">6.2. 程序执行方式</a></li>
<li><a href="#63-%E8%BF%9B%E7%A8%8B">6.3. 进程</a></li>
<li><a href="#64-%E7%BA%BF%E7%A8%8B">6.4. 线程</a></li>
<li><a href="#65-%E8%BF%9B%E7%A8%8B%E6%8E%A7%E5%88%B6">6.5. 进程控制</a></li>
<li><a href="#66-%E8%BF%9B%E7%A8%8B%E5%90%8C%E6%AD%A5">6.6. 进程同步</a></li>
<li><a href="#67-%E8%BF%9B%E7%A8%8B%E9%80%9A%E4%BF%A1">6.7. 进程通信</a></li>
<li><a href="#68-%E5%A4%84%E7%90%86%E5%99%A8%E8%B0%83%E5%BA%A6">6.8. 处理器调度</a></li>
<li><a href="#69-%E6%AD%BB%E9%94%81">6.9. 死锁</a></li>
</ul>
</li>
<li><a href="#7-linux%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86">7. linux进程管理</a>
<ul>
<li><a href="#71-%E8%BF%9B%E7%A8%8B%E7%9A%84%E7%B1%BB%E5%9E%8B">7.1. 进程的类型</a></li>
<li><a href="#72-%E8%BF%9B%E7%A8%8B%E7%9A%84%E6%A0%87%E8%AE%B0">7.2. 进程的标记</a></li>
<li><a href="#73-%E6%93%8D%E4%BD%9Clinux%E8%BF%9B%E7%A8%8B%E7%9A%84%E7%9B%B8%E5%85%B3%E5%91%BD%E4%BB%A4">7.3. 操作linux进程的相关命令</a></li>
</ul>
</li>
<li><a href="#8-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E6%A6%82%E8%BF%B0">8. 内存管理概述</a></li>
<li><a href="#9-%E5%AD%98%E5%82%A8%E7%AE%A1%E7%90%86%E6%96%B9%E5%BC%8F">9. 存储管理方式</a>
<ul>
<li><a href="#91-%E5%A4%9A%E9%81%93%E7%A8%8B%E5%BA%8F%E7%8E%AF%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AF%B9%E6%8D%A2%E6%8A%80%E6%9C%AFswapping">9.1. 多道程序环境下的对换技术(Swapping)</a></li>
</ul>
</li>
<li><a href="#10-linux%E7%9A%84%E5%AD%98%E5%82%A8%E7%AE%A1%E7%90%86">10. linux的存储管理</a></li>
<li><a href="#11-%E8%99%9A%E6%8B%9F%E5%AD%98%E5%82%A8%E5%99%A8">11. 虚拟存储器</a>
<ul>
<li><a href="#111-%E8%99%9A%E6%8B%9F%E5%AD%98%E5%82%A8%E5%99%A8%E6%A6%82%E8%BF%B0">11.1. 虚拟存储器概述</a></li>
<li><a href="#112-%E8%99%9A%E6%8B%9F%E5%AD%98%E5%82%A8%E7%AE%A1%E7%90%86%E6%96%B9%E5%BC%8F">11.2. 虚拟存储管理方式</a></li>
<li><a href="#113-%E9%A1%B5%E9%9D%A2%E8%B0%83%E5%85%A5%E7%AD%96%E7%95%A5">11.3. 页面调入策略</a></li>
<li><a href="#%E7%89%A9%E7%90%86%E5%9D%97%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5">物理块分配策略</a></li>
<li><a href="#114-%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5">11.4. 内存分配策略</a></li>
<li><a href="#115-%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95page-replacement-algorithms">11.5. 页面置换算法(Page-Replacement Algorithms)</a></li>
<li><a href="#116-%E6%8A%96%E5%8A%A8%E4%B8%8E%E5%B7%A5%E4%BD%9C%E9%9B%86">11.6. 抖动与工作集</a></li>
<li><a href="#117-%E8%AF%B7%E6%B1%82%E5%88%86%E6%AE%B5%E5%AD%98%E5%82%A8%E7%AE%A1%E7%90%86%E6%96%B9%E5%BC%8F">11.7. 请求分段存储管理方式</a></li>
</ul>
</li>
<li><a href="#12-%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E7%B3%BB%E7%BB%9F">12. 输入输出系统</a>
<ul>
<li><a href="#121-io%E8%AE%BE%E5%A4%87%E5%88%86%E7%B1%BB">12.1. I/O设备分类</a></li>
<li><a href="#122-io%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%8A%9F%E8%83%BD">12.2. I/O系统的基本功能</a></li>
<li><a href="#123-io%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84%E5%92%8C%E6%A8%A1%E5%9E%8B">12.3. I/O系统的层次结构和模型</a></li>
</ul>
</li>
<li><a href="#13-io%E8%AE%BE%E5%A4%87%E5%92%8C%E8%AE%BE%E5%A4%87%E6%8E%A7%E5%88%B6%E5%99%A8%E6%A6%82%E8%BF%B0">13. I/O设备和设备控制器概述</a>
<ul>
<li><a href="#131-%E8%AE%BE%E5%A4%87%E5%AF%BB%E5%9D%80%E6%96%B9%E5%BC%8F">13.1. 设备寻址方式</a></li>
<li><a href="#132-%E8%AE%BE%E5%A4%87%E6%8E%A7%E5%88%B6%E5%99%A8%E5%88%86%E6%88%90%E6%8E%A7%E5%88%B6%E5%AD%97%E7%AC%A6%E8%AE%BE%E5%A4%87%E7%9A%84%E6%8E%A7%E5%88%B6%E5%99%A8%E5%92%8C%E6%8E%A7%E5%88%B6%E5%9D%97%E8%AE%BE%E5%A4%87%E7%9A%84%E6%8E%A7%E5%88%B6%E5%99%A8">13.2. 设备控制器（分成控制字符设备的控制器和控制块设备的控制器）</a></li>
<li><a href="#133-io%E9%80%9A%E9%81%93">13.3. I/O通道</a></li>
</ul>
</li>
<li><a href="#14-%E4%B8%AD%E6%96%AD%E6%9C%BA%E6%9E%84%E5%92%8C%E8%AE%BE%E5%A4%87%E9%A9%B1%E5%8A%A8%E7%A8%8B%E5%BA%8F">14. 中断机构和设备驱动程序</a>
<ul>
<li><a href="#141-%E4%B8%AD%E6%96%AD%E6%9C%BA%E6%9E%84">14.1. 中断机构</a></li>
<li><a href="#142-%E8%AE%BE%E5%A4%87%E9%A9%B1%E5%8A%A8%E7%A8%8B%E5%BA%8F">14.2. 设备驱动程序</a></li>
<li><a href="#143-%E4%B8%8E%E8%AE%BE%E5%A4%87%E6%97%A0%E5%85%B3%E7%9A%84io%E8%BD%AF%E4%BB%B6">14.3. 与设备无关的I/O软件</a></li>
<li><a href="#144-%E7%94%A8%E6%88%B7%E5%B1%82%E7%9A%84io%E8%BD%AF%E4%BB%B6">14.4. 用户层的I/O软件</a></li>
<li><a href="#145-%E5%81%87%E8%84%B1%E6%9C%BAspooling%E7%B3%BB%E7%BB%9F%E8%99%9A%E6%8B%9F%E8%AE%BE%E5%A4%87%E6%8A%80%E6%9C%AF%E5%B0%86%E7%8B%AC%E5%8D%A0%E8%AE%BE%E5%A4%87%E6%94%B9%E6%88%90%E5%85%B1%E4%BA%AB%E8%AE%BE%E5%A4%87%E7%9A%84%E6%8A%80%E6%9C%AF">14.5. 假脱机（Spooling）系统（虚拟设备技术）：将独占设备改成共享设备的技术</a></li>
<li><a href="#146-%E7%BC%93%E5%86%B2%E5%8C%BA%E7%AE%A1%E7%90%86">14.6. 缓冲区管理</a></li>
</ul>
</li>
<li><a href="#15-%E6%96%87%E4%BB%B6%E5%92%8C%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F">15. 文件和文件系统</a>
<ul>
<li><a href="#151-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F">15.1. linux文件系统</a></li>
</ul>
</li>
<li><a href="#16-%E6%96%87%E4%BB%B6%E7%9A%84%E9%80%BB%E8%BE%91%E7%BB%93%E6%9E%84">16. 文件的逻辑结构</a></li>
<li><a href="#17-%E6%96%87%E4%BB%B6%E7%9B%AE%E5%BD%95">17. 文件目录</a></li>
<li><a href="#18-%E6%96%87%E4%BB%B6%E5%85%B1%E4%BA%AB">18. 文件共享</a></li>
<li><a href="#19-%E6%96%87%E4%BB%B6%E4%BF%9D%E6%8A%A4">19. 文件保护</a></li>
<li><a href="#20-%E5%A4%96%E5%AD%98%E7%9A%84%E7%BB%84%E7%BB%87%E6%96%B9%E5%BC%8F%E8%BE%85%E5%AD%98%E7%9A%84%E5%AD%98%E5%82%A8%E7%A9%BA%E9%97%B4%E5%88%86%E9%85%8D">20. 外存的组织方式(辅存的存储空间分配)</a></li>
<li><a href="#21-%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E7%A9%BA%E9%97%B4%E7%9A%84%E7%AE%A1%E7%90%86">21. 文件存储空间的管理</a></li>
<li><a href="#22-%E6%8F%90%E9%AB%98%E7%A3%81%E7%9B%98io%E9%80%9F%E5%BA%A6%E7%9A%84%E9%80%94%E5%BE%84">22. 提高磁盘I/O速度的途径</a></li>
<li><a href="#23-%E6%8F%90%E9%AB%98%E7%A3%81%E7%9B%98%E5%8F%AF%E9%9D%A0%E6%80%A7%E7%9A%84%E6%8A%80%E6%9C%AF">23. 提高磁盘可靠性的技术</a></li>
<li><a href="#24-%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7%E6%8E%A7%E5%88%B6">24. 数据一致性控制</a></li>
</ul>
<!-- /TOC -->
<h1>1. 操作系统的概念和作用</h1>
<ul>
<li>操作系统概念：一组能有效组织和管理计算机硬件和软件资源并对各类作业进行调度的程序的集合/操作系统是指管理计算机硬件和软件资源的计算机程序（是软件）</li>
<li>原子操作:一个不可分割的基本单位，在执行过程中不允许被中断。在系统态下执行，常驻内存</li>
<li>原语操作:由若干条指令组成的，用于完成一定功能的过程，是一个原子操作</li>
<li>操作系统作用
<ul>
<li>提供用户与计算机硬件之间的接口（用户通过命令、系统调用、和图标一窗口方式与系统通信并取得它的服务）</li>
<li>管理系统资源（管理处理机、存储器、I/O设备和文件(数据和程序)等资源、协调用户对共享资源的使用）</li>
<li>计算机资源的抽象（隐藏对硬件操作的具体细节，增强系统功能）</li>
</ul>
</li>
<li>操作系统内核
<ul>
<li>支撑功能：中断处理、时钟管理、原语操作</li>
<li>资源管理功能：进程管理、存储器管理、设备管理</li>
</ul>
</li>
</ul>
<h1>2. 操作系统的发展过程</h1>
<ul>
<li>操作系统发展历程
<ul>
<li>人工操作方式</li>
<li>脱机输入/输出(Off-Line I/O)方式</li>
<li>单道批处理系统(Simple Batch Processing System)</li>
<li>多道批处理系统(Multiprogrammed Batch Processing System)</li>
<li>分时系统（人机交互）(Time Sharing System)</li>
<li>实时系统(工业控制系统等)(Real Time System)</li>
<li>微机操作系统
<ul>
<li>单用户单任务操作系统(CP/M、MS-DOS)</li>
<li>单用户多任务操作系统windows</li>
<li>多用户多任务操作系统Linux</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1>3. 操作系统的基本特性</h1>
<ul>
<li>并发(Concurrence)
<ul>
<li>并行:多个事件在同一时刻发生、并发:多个事件在同一个时间发生、串行:多个事件按顺序执行</li>
<li>并发性：一段时间内宏观上有多个程序同时运行，微观上多个程序分时运行</li>
</ul>
</li>
<li>共享(Sharing)
<ul>
<li>资源共享/复用:系统中的资源可供内存中多个并发进程共同使用</li>
<li>互斥共享方式：一定时间内，只允许一个进程访问临界资源</li>
</ul>
</li>
</ul>
]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/5882cbd92d95d868467a2.png" type="image/png"/>
    </item>
    <item>
      <title>算法</title>
      <link>https://javaguide.cn/backend/cs/%E7%AE%97%E6%B3%95.html</link>
      <guid>https://javaguide.cn/backend/cs/%E7%AE%97%E6%B3%95.html</guid>
      <source url="https://javaguide.cn/rss.xml">算法</source>
      <description>数据结构和算法 1. 概述 数据data结构(structure)是一门研究组织数据方式的学科，有了编程语言也就有了数据结构.学好数据结构可以编写更加有效率的代码 程序 = 数据结构 + 算法 1.1. 数据结构的分类 线性结构：特点是数据元素之间存在一对一的线性关系：常见的有：数组、队列、链表和栈.有两种不同的存储结构，即顺序存储结构(数组)和链式存...</description>
      <category>算法</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>数据结构和算法</p>
<!--more-->
<h1>1. 概述</h1>
<ul>
<li>数据data结构(structure)是一门研究组织数据方式的学科，有了编程语言也就有了数据结构.学好数据结构可以编写更加有效率的代码</li>
<li>程序 = 数据结构 + 算法</li>
</ul>
<h2>1.1. 数据结构的分类</h2>
<ul>
<li>线性结构：特点是数据元素之间存在一对一的线性关系：常见的有：数组、队列、链表和栈.有两种不同的存储结构，即顺序存储结构(数组)和链式存储结构(链表)
<ul>
<li>顺序存储的线性表称为顺序表，顺序表中的存储元素是连续的</li>
<li>链式存储的线性表称为链表，链表中的存储元素不一定是连续的，元素节点中存放数据元素以及相邻元素的地址信息</li>
</ul>
</li>
<li>非线性结构包括：二维数组，多维数组，广义表，树结构，图结构</li>
</ul>
<h2>1.2. 算法的时间复杂度</h2>
<ul>
<li>度量一个程序(算法)执行时间的两种方法
<ul>
<li>事后统计的方法
<ul>
<li>要想对设计的算法的运行性能进行评测，需要实际运行该程序；</li>
<li>所得时间的统计量依赖于计算机的硬件、软件等环境因素,要在同一台计算机的相同状态下运行，才能比较算法速度</li>
</ul>
</li>
<li>事前估算的方法：通过分析某个算法的时间复杂度来判断哪个算法更优.</li>
</ul>
</li>
<li>时间频度
<ul>
<li>一个算法花费的时间与算法中语句的执行次数成正比例，哪个算法中语句执行次数多，它花费时间就多。</li>
<li>一个算法中的语句执行次数称为语句频度或时间频度。记为T(n)。</li>
</ul>
</li>
<li>时间复杂度
<ul>
<li>一般情况下，算法中的基本操作语句的重复执行次数是问题规模n的某个函数，用T(n)表示，</li>
<li>若有某个辅助函数f(n)，使得当n趋近于无穷大时，<code>T(n) / f(n)</code> 的极限值为不等于零的常数，则称f(n)是T(n)的同数量级函数。</li>
<li>记作 <code>T(n)=Ｏ( f(n) )，称Ｏ( f(n) )</code>&nbsp; 为算法的渐进时间复杂度，简称时间复杂度。</li>
<li>T(n) 不同，但时间复杂度可能相同。 如：T(n)=n²+7n+6 与 T(n)=3n²+2n+2 它们的T(n)&nbsp;不同，但时间复杂度相同，都为O(n²)</li>
<li>计算时间复杂度的方法：
<ul>
<li>常数1代替运行时间中的所有加法常数&nbsp; <code>T(n)=n²+7n+6  =&gt; T(n)=n²+7n+1</code></li>
<li>修改后的运行次数函数中，只保留最高阶项&nbsp; <code>T(n)=n²+7n+1 =&gt; T(n) = n²</code></li>
<li>去除最高阶项的系数 <code>T(n) = 4n² =&gt; T(n) = n² =&gt; O(n²)</code></li>
</ul>
</li>
<li>常见的时间复杂度
<ul>
<li>常数阶O(1):无论代码执行了多少行，只要是没有循环等复杂结构，代码的时间复杂度就都是O(1)</li>
<li>对数阶O(log2n) <code>int i = 1 ; while(i&lt;n){ i = i*2 } </code></li>
<li>线性阶O(n) <code>for(int i=0;i&lt;n;i++){System.out.print(i)}</code></li>
<li>线性对数阶O(nlog2n) <code>for(int m=0;m&lt;n;m++){ int 1 = 1 ; while(i&lt;n){ i = i*2 } }</code></li>
<li>平方阶O(n^2) <code>for(int i=0;i&lt;n;i++){for(int j=0;j&lt;n;j++){System.out.print(j)}}</code></li>
<li>立方阶O(n^3)</li>
<li>k次方阶O(n^k)</li>
<li>指数阶O(2^n)</li>
<li>常见的算法时间复杂度由小到大依次为：<code>Ο(1)＜Ο(log2n)＜Ο(n)＜Ο(nlog2n)＜Ο(n2)＜Ο(n3)＜Ο(nk)＜Ο(2n)</code>,尽可能避免使用指数阶的算法</li>
</ul>
</li>
<li>平均时间复杂度：所有可能的输入实例均以等概率出现的情况下，该算法的运行时间。</li>
<li>最坏时间复杂度：最坏情况下的时间复杂度。一般讨论的时间复杂度均是最坏情况下的时间复杂度。保证算法运行时间不会比最坏情况更长</li>
</ul>
</li>
</ul>
<h2>1.3. 算法的空间复杂度</h2>
<ul>
<li>算法的空间复杂度(Space Complexity)定义为该算法所耗费的存储空间，它也是问题规模n的函数。是对一个算法在运行过程中临时占用存储空间大小的量度</li>
<li>有的算法需要占用的临时工作单元数与解决问题的规模n有关，它随着n的增大而增大，当n较大时，将占用较多的存储单元，例如快速排序和归并排序算法就属于这种情况</li>
<li>在做算法分析时，主要讨论的是时间复杂度。从用户使用体验上看，更看重的程序执行的速度。一些缓存产品(redis, memcache)和算法(基数排序)本质就是用空间换时间.</li>
</ul>
<h2>1.4. 算法框架</h2>
<h3>1.4.1. 数据结构的存储方式</h3>
<ul>
<li>数据结构的存储方式只有两种：数组（顺序存储:查找块，索引访问，增删快，需要扩容）和链表（链式存储：增删快，只需操作尾结点，查找慢，遍历）
<ul>
<li>「队列(先进先出)」、「栈(先进先出)」这两种数据结构既可以使用链表也可以使用数组实现。用数组实现，就要处理扩容缩容的问题；用链表实现，没有这个问题，但需要更多的内存空间存储节点指针。</li>
<li>「图」的两种表示方法，邻接表就是链表，邻接矩阵就是二维数组。邻接矩阵判断连通性迅速，并可以进行矩阵运算解决一些问题，但是如果图比较稀疏的话很耗费空间。邻接表比较节省空间，但是很多操作的效率上肯定比不过邻接矩阵。</li>
<li>「散列表」就是通过散列函数把键映射到一个大数组里。而且对于解决散列冲突的方法，拉链法需要链表特性，操作简单，但需要额外的空间存储指针；线性探查法就需要数组特性，以便连续寻址，不需要指针的存储空间，但操作稍微复杂些。</li>
<li>「树」，用数组实现就是「堆」，因为「堆」是一个完全二叉树，用数组存储不需要节点指针，操作也比较简单；用链表实现就是很常见的那种「树」，因为不一定是完全二叉树，所以不适合用数组存储。为此，在这种链表「树」结构之上，又衍生出各种巧妙的设计，比如二叉搜索树、AVL 树、红黑树、区间树、B 树等等，以应对不同的问题</li>
</ul>
</li>
<li>数组由于是紧凑连续存储,可以随机访问，通过索引快速找到对应元素，而且相对节约存储空间。但正因为连续存储，内存空间必须一次性分配够，所以说数组如果要扩容，需要重新分配一块更大的空间，再把数据全部复制过去，时间复杂度 O(N)；而且你如果想在数组中间进行插入和删除，每次必须搬移后面的所有数据以保持连续，时间复杂度 O(N)。</li>
<li>链表因为元素不连续，而是靠指针指向下一个元素的位置，所以不存在数组的扩容问题；如果知道某一元素的前驱和后驱，操作指针即可删除该元素或者插入新元素，时间复杂度 O(1)。但是正因为存储空间不连续，你无法根据一个索引算出对应元素的地址，所以不能随机访问；而且由于每个元素必须存储指向前后元素位置的指针，会消耗相对更多的储存空间。</li>
</ul>
<h3>1.4.2. 数据结构的基本操作框架(遍历+访问=&gt;树=&gt;二叉树=&gt;前中后序遍历)</h3>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>数组遍历框架，典型的线性迭代结构
void traverse(int[] arr) {
    for (int i = 0; i &lt; arr.length; i++) {
        // 迭代访问 arr[i]
    }
}
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>链表遍历框架，兼具迭代和递归结构
/* 基本的单链表节点 */
class ListNode {
    int val;
    ListNode next;
}

void traverse(ListNode head) {
    for (ListNode p = head; p != null; p = p.next) {
        // 迭代访问 p.val
    }
}

void traverse(ListNode head) {
    // 递归访问 head.val
    traverse(head.next);
}
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>二叉树遍历框架，典型的非线性递归遍历结构
/* 基本的二叉树节点 */
class TreeNode {
    int val;
    TreeNode left, right;
}

void traverse(TreeNode root) {
    traverse(root.left);
    traverse(root.right);
}
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>二叉树框架可以扩展为 N 叉树的遍历框架
/* 基本的 N 叉树节点 */
class TreeNode {
    int val;
    TreeNode[] children;
}

void traverse(TreeNode root) {
    for (TreeNode child : root.children)
        traverse(child);
}
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>大部分算法技巧，本质上都是树的遍历问题
void traverse(TreeNode root) {
    // 前序遍历
    traverse(root.left)
    // 中序遍历
    traverse(root.right)
    // 后序遍历
}
</code></pre></div><h1>2. 稀疏数组sparsearray</h1>
<ul>
<li>稀疏数组：当保存一个数组中大部分元素为0或者同一个值的时，节省存储空间，如果写入磁盘则减少I/O，提升性能</li>
<li>问题:五子棋程序存盘退出和续上盘功能，二维数组的棋盘、地图等</li>
<li>思路:
<ul>
<li>二维数组 -&gt; 稀疏数组
<ul>
<li>遍历二维数组得到有效数据的个数sum</li>
<li>根据sum 创建稀疏数组<code>sparseArr int[sum + 1][3]</code>(留个一维数组数组一共有几行几列，有多少个不同的值)</li>
<li>第1个一维数组记录数组的一维数组个数、二维数组的个数、有效数据个数sum</li>
<li>从第2个一维数组开始记录数组的有效数据<code>（int[?][1]和int[?][2]记录有效数据的位置int[?][3]记录有效数据的值）</code>直到所有数组记录完</li>
</ul>
</li>
<li>稀疏数组 转 二维数组思路
<ul>
<li>先根据读取稀疏数组的第一个一维数组数据建立二维数组</li>
<li>从第2个一维数组开始将给二维数组一一赋值</li>
</ul>
</li>
</ul>
</li>
</ul>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/fe862b3b8a9644e8f5035.png" alt="稀疏数组2.png" tabindex="0"><figcaption>稀疏数组2.png</figcaption></figure>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>    public class SparseArray {
        public static void main(String[] args) {
            int[][] testarray = new int[5][6];
            testarray[2][1] = 3;
            testarray[0][3] = 10;
            testarray[4][5] = 4;
            System.out.println("原来数组~~");
            printArray(testarray);
            System.out.println("稀疏数组~~");
            printArray(getSpaseArray(testarray));
            System.out.println("原来数组~~");
            printArray(getOldArray(getSpaseArray(testarray)));
        }
        
        public static int[][] getSpaseArray(int[][] oldArray){
            //1.求出有效数据的个数
            int sum = 0;
            for(int i=0;i&lt;oldArray.length;i++){
                for(int j=0;j&lt;oldArray[i].length;j++){
                    if(oldArray[i][j]!=0){
                        sum++;
                    }
                }
            }
            //2.创建稀疏数组
            int[][] result= new int[sum+1][3];
            result[0][0] = oldArray.length;//每个赋值
            result[0][1] = oldArray[0].length;
            result[0][2] = sum;
            int index = 0;//用于记录是第几个非0数据,稀疏数组的"第几行"
            for(int i=0;i&lt;oldArray.length;i++){
                for(int j=0;j&lt;oldArray[i].length;j++){
                    if(oldArray[i][j]!=0){
                        index++;
                        result[index][0] = i;
                        result[index][1] = j;
                        result[index][2] = oldArray[i][j];
                    }
                }
            }
            return result;
        }
        
        public static int[][] getOldArray(int[][] spaseArray){
            int[][] result = new int[spaseArray[0][0]][spaseArray[0][1]];
            for(int i=1;i&lt;spaseArray.length;i++){//将后面几行读取完就行了
                result[spaseArray[i][0]][spaseArray[i][1]] = spaseArray[i][2];
            }
            return result;
        }
        
        public static void printArray(int[][] printarray){
            for(int i=0;i&lt;printarray.length;i++){
                for(int j=0;j&lt;printarray[i].length;j++){
                    System.out.printf("%d\t",printarray[i][j]);
                }
                System.out.println();
            }
        }
    }
</code></pre></div><h1>3. 队列</h1>
<ul>
<li>队列是一个有序列表，可以用数组或是链表来实现。遵循先入先出的原则。即：先存入队列的数据，要先取出。后存入的要后取出</li>
<li>使用条件/应用实例:银行排队</li>
<li>单向队列(数组结构)
<ul>
<li>指针front指向第一个元素前一个位置默认为-1</li>
<li>指针rear指向最后一个元素默认为-1</li>
<li>队列的最大容量为maxSize</li>
<li>队列满的条件为rear = maxSize - 1</li>
<li>队列null的条件为front == rear</li>
<li>给队列添加元素时,先判断满,先rear++然后arr[rear]赋值</li>
<li>出队列时，先判断null，先front++并返回arr[front]</li>
<li>队列头数据为arr[front+1];</li>
<li>存在的问题:数组不能复用,使用算法改成环形队列取模解决</li>
</ul>
</li>
<li>循环队列(数组结构)
<ul>
<li>指针front指向队列的第一个元素,默认为0</li>
<li>指针rear指向队列的最后一个元素的后一个位置,默认为0</li>
<li>队列的最大数量为maxSize</li>
<li>队列满的条件<code>(rear+1)%maxSize==front</code></li>
<li>队列为null条件rear==front</li>
<li>有效数字的个数<code>size = (rear+maxSize-front)%maxSize</code>,推导过程
<ul>
<li>当<code>rear&gt;=front,size = rear - front = rear - front + 0 = (rear - front) % maxSize + maxSize % maxSize = (rear - front + maxSize ) % maxSize  (注：rear - front &lt; maxSize)</code></li>
<li>当<code>rear&lt;front,size = (rear-0) + (maxSize - front) = rear - front + maxSize = (rear - front + maxSize ) % maxSize (注：rear - front &lt; maxSize)</code></li>
</ul>
</li>
<li>为了区分循环队列中队列为满时和队列为空时的情况，可以有至少2种方法
<ul>
<li>浪费一个空间，来区分队列为满时和队列为空时的情况，也就是当 <code>( rear + 1 ) % maxSize == front</code>的时候，表示队列已经满了，当front == tail的时候，表示队列为空。rear永远指向"空元素".（本例子）</li>
<li>附加一个标志位tag，当head赶上tail，队列空，则令tag=0,当tail赶上head，队列满，则令tag=1</li>
</ul>
</li>
</ul>
</li>
</ul>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/1e004863e3a952a2c7ac8.png" alt="队列.png" tabindex="0"><figcaption>队列.png</figcaption></figure>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>    //使用数组模拟单向队列 -编写一个ArrayQueue类
    class ArrayQueue {
        private int maxSize; // 表示数组的最大容量
        private int front = -1; // 指向队列头部，指向队列头的前一个位置
        private int rear = -1; // 指向队列尾，指向队列尾的数据
        private int[] arr; // 该数组用于存放数据, 模拟队列
        public ArrayQueue(int arrMaxSize) {
            maxSize = arrMaxSize;
            arr = new int[maxSize];
        }
        public boolean isFull() {return rear == maxSize - 1;}// 判断队列是否满
        public boolean isEmpty() {return rear == front;}// 判断队列是否为空
        public void addQueue(int n) {
            if (isFull()) System.out.println("队列满，不能加入数据~~");return;
            rear++; // 让rear 后移
            arr[rear] = n;
        }
        public int getQueue() {
            if (isEmpty()) System.out.println("队列空的，没有数据~~");return;
            front++; // front后移
            return arr[front];
        }
        public void showQueue() {
            if (isEmpty()) System.out.println("队列空的，没有数据~~");return;
            for (int i = 0; i &lt; arr.length; i++) {
                System.out.printf("arr[%d]=%d\n", i, arr[i]);
            }
        }
        public int headQueue() {// 显示队列的头数据， 注意不是取出数据
            if (isEmpty()) throw new RuntimeException("队列空的，没有数据~~");
            return arr[front + 1];
        }
    } 
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>    class CircleArray {
        private int maxSize;// 表示数组的最大容量
        private int front = 0;//指向队列的第一个元素
        private int rear = 0;//指向队列的最后一个元素的后一个位置. 因为空出一个空间做为约定.
        private int[] arr; // 该数据用于存放数据, 模拟队列
        
        public CircleArray(int arrMaxSize) {
            maxSize = arrMaxSize;
            arr = new int[maxSize];
        }
        public boolean isFull() {return (rear  + 1) % maxSize == front;}
        public boolean isEmpty() {return rear == front;}
        public void addQueue(int n) {
            if (isFull()) System.out.println("队列满，不能加入数据~");return;
            arr[rear] = n;
            rear = (rear + 1) % maxSize; //将 rear 后移, 这里必须考虑取模
        }
        public int getQueue() {// 获取队列的数据, 出队列
            if (isEmpty()) throw new RuntimeException("队列空，不能取数据);
            int value = arr[front];
            front = (front + 1) % maxSize;
            return value;
        }
        public void showQueue() {
            if (isEmpty()) System.out.println("队列空的，没有数据~~");return;
            for (int i = front; i &lt; front + size() ; i++) {
                System.out.printf("arr[%d]=%d\n", i % maxSize, arr[i % maxSize]);
            }
        }
        public int size() {
            return (rear + maxSize - front) % maxSize;   
        }
        public int headQueue() {// 显示队列的头数据， 注意不是取出数据
            if (isEmpty()) throw new RuntimeException("队列空的，没有数据~~");
            return arr[front];
        }
    }  
</code></pre></div><h1>4. 链表</h1>
<ul>
<li>链表是有序的列表，是以节点的方式来存储,是链式存储，每个节点包含data域，next 域：指向下一个节点.</li>
<li>链表的各个节点不一定是连续存储.链表分带头节点的链表和没有头节点的链表</li>
</ul>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/954fffe0ef1d2c2cbd746.png" alt="链表.png" tabindex="0"><figcaption>链表.png</figcaption></figure>
<h2>4.1. 单链表</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>    class SingleLinkedList {
        private HeroNode head = new HeroNode(0, "", "");//先初始化一个头节点, 头节点不要动, 不存放具体的数据
        public HeroNode getHead() {return head;}
        //不考虑编号顺序时添加节点到单向链表时，找到当前链表的最后节点，将这个节点的next指向新节点
        public void add(HeroNode heroNode) {
            HeroNode temp = head;
            while(true) {
                if(temp.next == null) break;
                temp = temp.next;
            }
            temp.next = heroNode;
        }
        //根据条件将元素插入到指定位置(如果有这元素，则添加失败，并给出提示)
        public void addByOrder(HeroNode heroNode) {
            HeroNode temp = head;
            boolean flag = false;
            while(true) {
                if(temp.next == null) break;
                if(temp.next.no &gt; heroNode.no) break;
                if (temp.next.no == heroNode.no) {flag = true;break;}
                temp = temp.next;
            }
            if(flag) {
                System.out.printf("准备插入的英雄的编号 %d 已经存在了, 不能加入\n", heroNode.no);
            } else {
                heroNode.next = temp.next;
                temp.next = heroNode;
            }
        }
        //修改节点的信息, 根据no编号来修改，即no编号不能改.
        public void update(HeroNode newHeroNode) {
            HeroNode temp = head;
            boolean flag = false;
            while(true) {
                if (temp == null) break;
                if(temp.no == newHeroNode.no) {flag = true;break;}
                temp = temp.next;
            }
            if(flag) {
                temp.name = newHeroNode.name;
                temp.nickname = newHeroNode.nickname;
            } else {
                System.out.printf("没有找到 编号 %d 的节点，不能修改\n", newHeroNode.no);
            }
        }
        //删除节点
        public void del(int no) {
            HeroNode temp = head;
            boolean flag = false; 
            while(true) {
                if(temp.next == null) break; 
                if(temp.next.no == no) {flag = true;break;}
                temp = temp.next;
            }
            if(flag) {
                temp.next = temp.next.next;
            }else {
                System.out.printf("要删除的 %d 节点不存在\n", no);
            }
        }
        //显示链表[遍历]
        public void list() {
            if(head.next == null) return;
            HeroNode temp = head.next;
            while(true) {
                if(temp == null) break;
                temp = temp.next;
            }
        }
    }
    //定义HeroNode，每个HeroNode 对象就是一个节点
    class HeroNode {
        public int no;
        public String name;
        public String nickname;
        public HeroNode next; //指向下一个节点
        public HeroNode(int no, String name, String nickname) {
            this.no = no;
            this.name = name;
            this.nickname = nickname;
        }
        //toString
    }
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>    /**
	* 1.获取到单链表的节点的个数(如果是带头结点的链表，需求不统计头节点)
    * @param head 链表的头节点
    * @return 返回的就是有效节点的个数
    */
    public static int getLength(HeroNode head) {
        if(head.next == null) return 0;
        int length = 0;//定义一个辅助的变量, 这里我们没有统计头节点
        HeroNode cur = head.next;
        while(cur != null) {
            length++;
            cur = cur.next;
        }
        return length;
    }
	/**
	 * 2.查找单链表中的倒数第k个结点 【新浪面试】
	 *  先把链表从头到尾遍历，得到链表的总的长度size 从链表的第一个开始遍历 (size-index)个，就可以得到
	 * @param head head节点
	 * @param index 表示是倒数第index个节点
	 * @return
	 */
	public static HeroNode findLastIndexNode(HeroNode head, int index) {
		if(head.next == null) return null;
		int size = getLength(head);
		if(index &lt;=0 || index &gt; size) {
			return null; 
		}
		HeroNode cur = head.next;
		for(int i =0; i&lt; size - index; i++) {
			cur = cur.next;
		}
		return cur;
	}
	/**
	 * 将旧链表的数据取出并将其放到新链表的最前端
	 * 单链表反转 【腾讯面试】
	 * @param head
	 */
	public static void reversetList(HeroNode head) {
		if(head.next == null || head.next.next == null) return ;
		HeroNode cur = head.next;
		HeroNode next = null;// 指向当前节点[cur]的下一个节点，方便循环的时候指向当前节点
		HeroNode reverseHead = new HeroNode(0, "", "");
		//遍历原来的链表，每遍历一个节点，就将其取出，并放在新的链表reverseHead 的最前端
		while(cur != null) { 
			next = cur.next;//先暂时保存当前节点的下一个节点，因为后面需要使用
			//</code></pre></div>]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/fe862b3b8a9644e8f5035.png" type="image/png"/>
    </item>
    <item>
      <title>计算机常识</title>
      <link>https://javaguide.cn/backend/cs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%B8%B8%E8%AF%86.html</link>
      <guid>https://javaguide.cn/backend/cs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%B8%B8%E8%AF%86.html</guid>
      <source url="https://javaguide.cn/rss.xml">计算机常识</source>
      <description>计算机的常识 1. 内存图 2. 字符编码表及字符与编码解码 3. ASCII码 4. 循环冗余校验CRC(Cyclic Redundancy Check) 5. 哈希算法 6. 位运算 7. 浮点数在计算机中的存储 1. 内存图 内存.png内存.png 2. 字符编码表及字符与编码解码 ASCII表。定长，单字节7位编码。各种英文字符对应的编码。 ...</description>
      <category>理论</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>计算机的常识</p>
<!--more-->
<!-- TOC -->
<ul>
<li><a href="#1-%E5%86%85%E5%AD%98%E5%9B%BE">1. 内存图</a></li>
<li><a href="#2-%E5%AD%97%E7%AC%A6%E7%BC%96%E7%A0%81%E8%A1%A8%E5%8F%8A%E5%AD%97%E7%AC%A6%E4%B8%8E%E7%BC%96%E7%A0%81%E8%A7%A3%E7%A0%81">2. 字符编码表及字符与编码解码</a></li>
<li><a href="#3-ascii%E7%A0%81">3. ASCII码</a></li>
<li><a href="#4-%E5%BE%AA%E7%8E%AF%E5%86%97%E4%BD%99%E6%A0%A1%E9%AA%8Ccrccyclic-redundancy-check">4. 循环冗余校验CRC(Cyclic Redundancy Check)</a></li>
<li><a href="#5-%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95">5. 哈希算法</a></li>
<li><a href="#6-%E4%BD%8D%E8%BF%90%E7%AE%97">6. 位运算</a></li>
<li><a href="#7-%E6%B5%AE%E7%82%B9%E6%95%B0%E5%9C%A8%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%AD%E7%9A%84%E5%AD%98%E5%82%A8">7. 浮点数在计算机中的存储</a></li>
</ul>
<!-- /TOC -->
<h1>1. 内存图</h1>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/8dd3fad59c299b802ad94.png" alt="内存.png" tabindex="0"><figcaption>内存.png</figcaption></figure>
<h1>2. 字符编码表及字符与编码解码</h1>
<pre><code>生活中字符和计算机二进制的对应关系表
</code></pre>
<ul>
<li>ASCII表。定长，单字节7位编码。各种英文字符对应的编码。</li>
<li>iso-8859-1/latin1:拉丁码表，定长单字节8位编码，1-xxxxxxx  负数。</li>
<li>GB2312:简体中文码表（汉字编码字符基本集）。定长，双字节编码。</li>
<li>GBK:（汉字内码扩展规范）向下兼容GB2312、定长。双字节编码，</li>
<li>unicode：兼容全球的字符集。国际标准码表:双字节编码。</li>
<li>UTF-8(unicode字符集)，非定长，以1-4字节为单位对Unicode进行编码
<ul>
<li>编程推荐使用UTF-8、windows默认GBK编码<br>
Java中的char类型用的就是这个码表。char c = 'a';占两个字节。<br>
Java中的字符串是按照系统默认码表来解析的。<br>
简体中文版 字符串默认的码表是GBK。<br>
UTF-8:基于unicode，一个字节就可以存储数据，不要用两个字节存储，<br>
而且这个码表更加的标准化，在每一个字节头加入了编码信息(后期到api中查找)。<br>
文字</li>
</ul>
</li>
</ul>
]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/8dd3fad59c299b802ad94.png" type="image/png"/>
    </item>
    <item>
      <title>计算机组成原理</title>
      <link>https://javaguide.cn/backend/cs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86.html</link>
      <guid>https://javaguide.cn/backend/cs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86.html</guid>
      <source url="https://javaguide.cn/rss.xml">计算机组成原理</source>
      <description>计算机组成原理 1. 计算机系统概论 1.1. 计算机系统组成-&amp;gt;计算机性能的好坏取决于软硬件功能的总和 1.2. 现代计算机的解题过程 1.3. 计算机系统的层次结构 1.4. 计算机基本组成 2. 计算机发展简史 3. 系统总线 3.1. 总线的基本概念 3.2. 总线分类 3.3. 总线性能指标 3.4. 总线标准 3.5. 总线控制 4. 存储...</description>
      <category>理论</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>计算机组成原理</p>
<!--more-->
<!-- TOC -->
<ul>
<li><a href="#1-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%AE%BA">1. 计算机系统概论</a>
<ul>
<li><a href="#11-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E7%BB%84%E6%88%90-%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%80%A7%E8%83%BD%E7%9A%84%E5%A5%BD%E5%9D%8F%E5%8F%96%E5%86%B3%E4%BA%8E%E8%BD%AF%E7%A1%AC%E4%BB%B6%E5%8A%9F%E8%83%BD%E7%9A%84%E6%80%BB%E5%92%8C">1.1. 计算机系统组成-&gt;计算机性能的好坏取决于软硬件功能的总和</a></li>
<li><a href="#12-%E7%8E%B0%E4%BB%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%9A%84%E8%A7%A3%E9%A2%98%E8%BF%87%E7%A8%8B">1.2. 现代计算机的解题过程</a></li>
<li><a href="#13-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84">1.3. 计算机系统的层次结构</a></li>
<li><a href="#14-%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E6%9C%AC%E7%BB%84%E6%88%90">1.4. 计算机基本组成</a></li>
</ul>
</li>
<li><a href="#2-%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8F%91%E5%B1%95%E7%AE%80%E5%8F%B2">2. 计算机发展简史</a></li>
<li><a href="#3-%E7%B3%BB%E7%BB%9F%E6%80%BB%E7%BA%BF">3. 系统总线</a>
<ul>
<li><a href="#31-%E6%80%BB%E7%BA%BF%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5">3.1. 总线的基本概念</a></li>
<li><a href="#32-%E6%80%BB%E7%BA%BF%E5%88%86%E7%B1%BB">3.2. 总线分类</a></li>
<li><a href="#33-%E6%80%BB%E7%BA%BF%E6%80%A7%E8%83%BD%E6%8C%87%E6%A0%87">3.3. 总线性能指标</a></li>
<li><a href="#34-%E6%80%BB%E7%BA%BF%E6%A0%87%E5%87%86">3.4. 总线标准</a></li>
<li><a href="#35-%E6%80%BB%E7%BA%BF%E6%8E%A7%E5%88%B6">3.5. 总线控制</a></li>
</ul>
</li>
<li><a href="#4-%E5%AD%98%E5%82%A8%E5%99%A8">4. 存储器</a>
<ul>
<li><a href="#41-%E5%AD%98%E5%82%A8%E4%BB%8B%E8%B4%A8">4.1. 存储介质</a></li>
<li><a href="#42-%E5%AD%98%E5%82%A8%E5%99%A8%E7%9A%84%E5%88%86%E7%B1%BB">4.2. 存储器的分类</a></li>
<li><a href="#43-%E5%AD%98%E5%82%A8%E5%99%A8%E7%9A%84%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84">4.3. 存储器的层次结构</a></li>
<li><a href="#44-%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84">4.4. 存储系统层次结构</a></li>
<li><a href="#45-%E4%B8%BB%E5%AD%98%E5%82%A8%E5%99%A8">4.5. 主存储器</a></li>
<li><a href="#46-%E5%AD%98%E5%82%A8%E5%99%A8%E7%9A%84%E6%A0%A1%E9%AA%8C%E6%B1%89%E6%98%8E%E7%A0%81">4.6. 存储器的校验(汉明码)</a></li>
<li><a href="#47-%E9%AB%98%E9%80%9F%E7%BC%93%E5%86%B2%E5%AD%98%E5%82%A8%E5%99%A8">4.7. 高速缓冲存储器</a></li>
<li><a href="#48-%E7%BC%93%E5%AD%98-%E4%B8%BB%E5%AD%98%E5%9C%B0%E5%9D%80%E6%98%A0%E5%B0%84%E6%96%B9%E5%BC%8F%E4%B8%BB%E5%AD%98%E5%9C%B0%E5%9D%80%E6%98%A0%E5%B0%84%E5%88%B0cache%E5%9C%B0%E5%9D%80%E7%A7%B0%E4%B8%BA%E5%9C%B0%E5%9D%80%E6%98%A0%E5%B0%84">4.8. ？？？？缓存-主存地址映射方式（主存地址映射到Cache地址称为地址映射）</a></li>
<li><a href="#49-%E6%9B%BF%E6%8D%A2%E7%AD%96%E7%95%A5">4.9. 替换策略</a></li>
<li><a href="#410-%E8%BE%85%E5%8A%A9%E5%AD%98%E5%82%A8%E5%99%A8">4.10. 辅助存储器</a></li>
</ul>
</li>
<li><a href="#5-%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E7%B3%BB%E7%BB%9F">5. 输入输出系统</a>
<ul>
<li><a href="#51-%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E7%B3%BB%E7%BB%9F%E5%8F%91%E5%B1%95%E6%A6%82%E5%86%B5">5.1. 输入输出系统发展概况</a></li>
<li><a href="#52-%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%BB%84%E6%88%90">5.2. 输入输出系统的组成</a></li>
<li><a href="#53-io%E8%AE%BE%E5%A4%87%E4%B8%8E%E4%B8%BB%E6%9C%BA%E7%9A%84%E8%81%94%E7%B3%BB%E6%96%B9%E5%BC%8F">5.3. I/O设备与主机的联系方式</a></li>
<li><a href="#54-io%E8%AE%BE%E5%A4%87%E4%B8%8E%E4%B8%BB%E6%9C%BA%E4%BF%A1%E6%81%AF%E4%BC%A0%E9%80%81%E7%9A%84%E6%8E%A7%E5%88%B6%E6%96%B9%E5%BC%8F">5.4. I/O设备与主机信息传送的控制方式</a></li>
<li><a href="#55-io%E6%8E%A5%E5%8F%A3">5.5. I/O接口</a></li>
<li><a href="#56-%E6%8E%A5%E5%8F%A3%E7%9A%84%E5%8A%9F%E8%83%BD%E5%92%8C%E7%BB%84%E6%88%90">5.6. 接口的功能和组成</a></li>
<li><a href="#57-%E7%A8%8B%E5%BA%8F%E4%B8%AD%E6%96%AD%E6%96%B9%E5%BC%8F">5.7. 程序中断方式</a></li>
<li><a href="#58-%E4%B8%AD%E6%96%AD%E6%9C%8D%E5%8A%A1%E7%A8%8B%E5%BA%8F%E7%9A%84%E6%B5%81%E7%A8%8B">5.8. 中断服务程序的流程</a></li>
<li><a href="#59-dma%E6%96%B9%E5%BC%8F">5.9. DMA方式</a></li>
</ul>
</li>
<li><a href="#6-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%9A%84%E8%BF%90%E7%AE%97%E6%96%B9%E6%B3%95">6. 计算机的运算方法</a>
<ul>
<li><a href="#61-%E8%BF%9B%E5%88%B6%E7%9A%84%E6%A6%82%E8%BF%B0">6.1. 进制的概述</a></li>
<li><a href="#62-%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%AD%E7%9A%84%E6%95%B0">6.2. 计算机中的数</a></li>
<li><a href="#63-%E6%95%B0%E7%9A%84%E5%AE%9A%E7%82%B9%E8%A1%A8%E7%A4%BA%E5%92%8C%E6%B5%AE%E7%82%B9%E8%A1%A8%E7%A4%BA">6.3. 数的定点表示和浮点表示</a></li>
<li><a href="#64-%E5%AE%9A%E7%82%B9%E6%95%B0%E7%9A%84%E5%8A%A0%E5%87%8F%E6%B3%95">6.4. 定点数的加减法</a></li>
<li><a href="#65-%E5%AE%9A%E7%82%B9%E6%95%B0%E4%B9%98%E6%B3%95%E8%BF%90%E7%AE%97">6.5. 定点数乘法运算</a></li>
<li><a href="#66-%E5%AE%9A%E7%82%B9%E6%95%B0%E9%99%A4%E6%B3%95%E8%BF%90%E7%AE%97">6.6. 定点数除法运算</a></li>
<li><a href="#67-%E6%B5%AE%E7%82%B9%E6%95%B0%E7%9A%84%E5%8A%A0%E5%87%8F%E6%B3%95">6.7. 浮点数的加减法</a></li>
</ul>
</li>
<li><a href="#7-%E6%8C%87%E4%BB%A4%E7%B3%BB%E7%BB%9F">7. 指令系统</a>
<ul>
<li><a href="#71-%E6%9C%BA%E5%99%A8%E6%8C%87%E4%BB%A4">7.1. 机器指令</a></li>
<li><a href="#72-%E6%93%8D%E4%BD%9C%E6%95%B0%E7%B1%BB%E5%9E%8B">7.2. 操作数类型</a></li>
<li><a href="#73-%E6%93%8D%E4%BD%9C%E7%B1%BB%E5%9E%8B">7.3. 操作类型</a></li>
<li><a href="#74-%E5%AF%BB%E5%9D%80%E6%96%B9%E5%BC%8F">7.4. 寻址方式</a></li>
</ul>
</li>
<li><a href="#8-cpu%E7%9A%84%E7%BB%93%E6%9E%84%E5%92%8C%E5%8A%9F%E8%83%BD">8. CPU的结构和功能</a>
<ul>
<li><a href="#81-%E6%8E%A7%E5%88%B6%E5%99%A8%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%8A%9F%E8%83%BD">8.1. 控制器的基本功能</a></li>
<li><a href="#82-cpu%E7%BB%93%E6%9E%84%E6%A1%86%E5%9B%BE">8.2. CPU结构框图</a></li>
</ul>
</li>
<li><a href="#9-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%9A%84%E6%8E%A7%E5%88%B6%E5%99%A8">9. 计算机的控制器</a></li>
<li><a href="#10-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%9A%84%E8%BF%90%E7%AE%97%E5%99%A8">10. 计算机的运算器</a>
<ul>
<li><a href="#101-cpu%E7%9A%84%E5%AF%84%E5%AD%98%E5%99%A8">10.1. CPU的寄存器</a></li>
<li><a href="#102-%E6%8E%A7%E5%88%B6%E5%8D%95%E5%85%83%E5%92%8C%E4%B8%AD%E6%96%AD%E7%B3%BB%E7%BB%9F">10.2. 控制单元和中断系统</a></li>
<li><a href="#103-%E6%8C%87%E4%BB%A4%E5%91%A8%E6%9C%9F">10.3. 指令周期</a></li>
</ul>
</li>
<li><a href="#11-%E4%B8%AD%E6%96%AD%E7%B3%BB%E7%BB%9F">11. 中断系统</a>
<ul>
<li><a href="#111-%E6%A6%82%E8%BF%B0">11.1. 概述</a></li>
<li><a href="#112-%E4%B8%AD%E6%96%AD%E5%88%A4%E4%BC%98%E9%80%BB%E8%BE%91">11.2. 中断判优逻辑</a></li>
<li><a href="#113-%E4%B8%AD%E6%96%AD%E6%9C%8D%E5%8A%A1%E7%A8%8B%E5%BA%8F%E5%85%A5%E5%8F%A3%E5%9C%B0%E5%9D%80%E7%9A%84%E5%AF%BB%E6%89%BE">11.3. 中断服务程序入口地址的寻找</a></li>
<li><a href="#114-%E4%B8%AD%E6%96%AD%E5%93%8D%E5%BA%94">11.4. 中断响应</a></li>
<li><a href="#115-%E4%B8%AD%E6%96%AD%E5%B1%8F%E8%94%BD%E6%8A%80%E6%9C%AF%E7%94%A8%E4%BA%8E%E5%A4%9A%E9%87%8D%E4%B8%AD%E6%96%AD">11.5. 中断屏蔽技术(用于多重中断)</a></li>
</ul>
</li>
<li><a href="#12-%E6%8E%A7%E5%88%B6%E5%8D%95%E5%85%83%E7%9A%84%E5%8A%9F%E8%83%BD">12. 控制单元的功能</a>
<ul>
<li><a href="#121-%E5%BE%AE%E6%93%8D%E4%BD%9C%E5%91%BD%E4%BB%A4%E7%9A%84%E5%88%86%E6%9E%90">12.1. 微操作命令的分析</a></li>
<li><a href="#122-%E4%B8%AD%E6%96%AD%E5%91%A8%E6%9C%9F">12.2. 中断周期</a></li>
</ul>
</li>
<li><a href="#13-%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8C%87%E4%BB%A4%E7%9A%84%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B">13. 计算机指令的执行过程</a></li>
<li><a href="#cpu%E5%AE%9E%E7%8E%B0%E5%8E%9F%E5%AD%90%E6%80%A7">CPU实现原子性</a></li>
</ul>
<!-- /TOC -->
<h1>1. 计算机系统概论</h1>
<h2>1.1. 计算机系统组成-&gt;计算机性能的好坏取决于软硬件功能的总和</h2>
<ul>
<li>硬件：计算机实体部分，由各种电子元器件，各类光、电、机设备的实物组成</li>
<li>软件：由人们事先编制的具有各类特殊功能的程序组成，常存放在计算机的主存或辅存内，分为系统软件和应用软件
<ul>
<li>系统软件/程序：管理整个计算机系统，监视服务，使系统资源得到合理调度，高效运行，包括标准程序库、语言处理程序（如将汇编语言翻译成机器语言的汇编程序或者将高级语言翻译成机器语言的编译程序）、操作系统（如批处理系统、分时系统、实时系统）、服务程序（如诊断程序、调试程序、连接程序等）数据库管理系统、网络软件等</li>
<li>应用软件/程序：根据任务需要编制的各种程序，如科学计算程序，数据处理程序，过程控制程序，事务管理程序等</li>
</ul>
</li>
</ul>
<h2>1.2. 现代计算机的解题过程</h2>
<ul>
<li>由用户用高级语言编写程序（源程序），然后将它和数据一起送入计算机内，再由计算机将其翻译成机器能识别的机器语言程序（目标程序），机器自动运行该机器语言程序，并将结果输出</li>
</ul>
<h2>1.3. 计算机系统的层次结构</h2>
<ul>
<li>
<p>机器语言机器：用户必须用二进制代码来编写程序（机器语言程序），可以直接在机器上执行，直接执行机器语言的机器称为实际机器M1</p>
</li>
<li>
<p>汇编语言机器：汇编语言使用符号表示指令或数据所在存储单元的地址，使程序员可以不再使用繁杂而又易错的二进制代码编写程序；汇编程序将汇编语言程序翻译成机器语言程序</p>
</li>
<li>
<p>高级语言机器：程序员不必了解、掌握实际机器M1的机型、内部的具体组成及其指令系统，只需掌握高级语言的语法和语义，便可直接编程。在进入机器语言机器运行前，由翻译程序将高级语言程序翻译成机器语言程序。翻译程序分为编译程序和解释程序</p>
<ul>
<li>编译程序：将高级语言程序的全部语句一次全部翻译成机器语言程序，而后再执行机器语言程序。只要源程序不变，无需再次进行翻译。产生新的程序（C\C++\Golang）</li>
<li>解析程序：逐条翻译源程序的语句并执行，直至完成源程序的全部翻译任务，翻译一次执行一次，即使下一次重复执行该语句时，也必须重新翻译。不产生新的程序（Python\Php\Javascript）</li>
</ul>
</li>
<li>
<p>微程序机器：将机器语言机器中的每一条机器指令翻译成一组微指令，构成一个微程序。机器语言机器每执行完对应于一条机器指令的微程序后，便由机器语言机器中的下一条指令使微程序机器自动进入与其相对应的另一个微程序的执行。微程序机器可以看做是对机器语言机器的分解，即用微程序机器的微程序解释并执行每一条机器指令</p>
</li>
<li>
<p>操作系统机器：由操作系统软件构成。提供汇编语言和高级语言在使用和实现过程中所需的某些基本操作，还起到控制并管理计算机系统全部硬件和软件资源的作用，为用户使用计算机系统提供极为方便的条件，操作系统的功能是通过其控制语言来实现的</p>
</li>
<li>
<p>硬件研究的主要对象归结为传统机器M1和微程序机器M0，软件的研究对象主要是操作系统及以上的各级虚拟机<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/2b1b1bc7cd4defb97dd4a.png" alt="9.PNG"></p>
</li>
<li>
<p>计算机系统的属性：程序员看到的传统机器的属性：包括指令集、数据类型、存储器寻址技术、i/o机理等大多数是抽象属性</p>
</li>
<li>
<p>计算机体系结构：指那些能够被程序员所见到的计算机系统的属性，即概念性的结构与功能特性</p>
</li>
<li>
<p>计算机组成：指如何实现计算机体系结构所体现的属性（指令系统属于计算机结构问题，而指令的实现、如何取指令、分析指令、取操作数、运算、送结果等属于计算机组成问题，结构相同的计算机，组成（结构实现）不一定相同）</p>
</li>
</ul>
<h2>1.4. 计算机基本组成</h2>
<ul>
<li>冯诺依曼计算机:1945年，数学家冯诺依曼提出存储程序的概念，以此概念为基础的计算机都称为冯诺依曼机。特点如下
<ul>
<li>计算机是由运算器、存储器、控制器、输入设备和输出设备五大部件组成</li>
<li>指令和数据均以二进制表示，存放在存储器内，并可按地址寻访</li>
<li>指令由操作码和地址码组成，操作码用来表示操作的性质，地址码用来表示操作数在存储器中的位置</li>
<li>指令在存储器内按顺序存放。通常指令是顺序执行的，在特性条件下，可根据运算结果或根据设定条件改变执行顺序</li>
<li>机器以运算器为中心，输入输出设备与存储器间的数据传送通过运算器完成</li>
<li>冯诺依曼瓶颈-&gt;运算器运算速度比存储器访问速度快（CPU经常空转等待数据传输）</li>
</ul>
</li>
<li>计算机的硬件框图
<ul>
<li>经典的冯诺依曼计算机以运算器为中心</li>
<li>现代的计算机以存储器为中心</li>
<li>运算器：完成算术运算和逻辑运算，并将运算的中间结果暂存在运算器内</li>
<li>存储器：存放数据和程序</li>
<li>控制器：控制、指挥程序和数据的输入、运行以及处理运算结果，解释存储器中的指令，并发出各种操作命令来执行指令</li>
<li>输入设备：将人们熟悉的信息形式转换为机器能识别的信息形式</li>
<li>输出设备：将机器运算结果转换为人么熟悉的信息形式</li>
</ul>
</li>
<li>现代计算机组成
<ul>
<li>主机
<ul>
<li>中央处理器CPU(Central Processing Unit)=运算器（算术逻辑单元Arithmetic Logic Unit,ALU）+控制器（控制单元Control Unit,CU）</li>
<li>主存储器(Main Memory,MM)</li>
</ul>
</li>
<li>I/O设备(外部设备) = 输入设备 + 输出设备</li>
</ul>
</li>
</ul>
<p><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/f1eaf30bbe80adb74a1a8.png" alt="1.png"><br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/ffd9f676eecdaf2d46b96.png" alt="2.png"></p>
<ul>
<li>计算机的工作步骤（待补充）</li>
<li>计算机硬件的主要技术指标
<ul>
<li>机器字长：CPU一次能处理数据的位数，与CPU寄存器位数有关，字长越长，数的表示范围越大，精度越高</li>
<li>存储容量：包括了主存容量和辅存容量，主存容量指主存中存放二进制代码的总位数
<ul>
<li>存储容量 = 存储单元个数 x 存储字长（存储单元个数 = 2^MAR的位数，存储字长 = MDR的位数）</li>
<li>计算机存储设备的最小信息单元叫“位（bit）”或“比特位”，用b表示。</li>
<li>计算机最小的存储单元叫“字节（byte）”，用B表示，字节是由连续的8个位组成</li>
<li>当程序需要使用存储空间时，操作系统最小会分派给程序1个字节，而不是1个位</li>
<li>1个字节（8位）存储的最大数据是11111111的二进制数</li>
<li>1B（字节） = 8bit、1KB = 1024B(寄存器)、1MB = 1024KB(高速缓存)、1GB = 1024MB(内存/硬盘) 1TB = 1024GB(硬盘)、1PB = 1024TB(云硬盘)，1EB=1024PB(数据仓库)</li>
</ul>
</li>
<li>运算速度
<ul>
<li>MIPS（Million Instruction Per Second 百万条指令每秒）：单位时间内执行指令的平均条数</li>
<li>CPI（Cycle Per Instruction）：执行一条指令所需的时钟周期（机器主频的倒数）</li>
<li>FLOPS（Floating Point Operation Per Second 浮点数运算次数每秒）</li>
</ul>
</li>
<li>CPU速度：
<ul>
<li>CPU的时钟频率。单位赫兹Hz：秒分之一。每秒中的周期性变动重复次数的计量。高低电平每秒钟变动的频率</li>
<li>1Hz = 1/s，即在单位时间内完成振动的次数，单位为赫兹（1赫兹=1次/秒）。2GHz=2*1000^3Hz=每秒20亿次变动高低电平</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1>2. 计算机发展简史</h1>
<ul>
<li>第一代电子管计算机（1946-1957）:第二次世界大战中由电子管组成的电子数字积分机和计算机（Electronic Numerical Integerator And Computer,ENIAC），采用十进制运算，电路结构复杂，耗电量大，体积大，操作复杂</li>
<li>第二代晶体管计算机（1957-1964）：贝尔实验室发明用半导体组成的晶体管。集成度相对较高，空间占用相对小，功耗相对较低，运行速度较快，操作相对简单。交互更加方便</li>
<li>第三代集成电路计算机（1964-1980）：（德州仪器发明了集成电路IC）计算机变得更小，功耗变得更低，计算速度变得更快</li>
<li>超大规模集成电路计算机（1980-现在）： 一个芯片集成了上百万的晶体管，速度更快，体积更小，价格更低，更能被大众接受，用途丰富：文本处理、表格处理、高交互的游戏与应用</li>
</ul>
<h1>3. 系统总线</h1>
<h2>3.1. 总线的基本概念</h2>
<ul>
<li>总线连接：计算机将各部件连到一组公共信息传输线上</li>
<li>总线: 多个部件的信息传输线，各部件共享的传输介质。由许多传输线和通路组成，每条线可一位一位地传输二进制代码，16条传输线组成的总线可以同时传输16位二进制代码</li>
<li>当多个部件同时向总线发送信息，势必导致信号冲突，传输无效。因此在某一个时刻，只允许有一个部件向总线发送信息，而多个部件可以同时从总线上接收相同的信息</li>
<li>各类总线结构</li>
</ul>
<p><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/89cf6bfb02d7fb5b3fd3d.png" alt="10.png"><br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/e8201c19b05063373ad5f.png" alt="11.png"></p>
<h2>3.2. 总线分类</h2>
<ul>
<li>按数据传输方式分：并行传输总线(8位、16位、32位、64位传输总线)、串行传输总线</li>
<li>按使用范围分：外设总线、测控总线、网络通信总线等</li>
<li>按连接部件不同
<ul>
<li>片内总线：芯片内部的总线，寄存器与寄存器之间、寄存器与控制器、运算器之间都由片内总线连接</li>
<li>系统总线：CPU、主存、I/O设备（通过I/O接口）各大部件之间的信息传输线，按传输信息不同分
<ul>
<li>数据总线（双向传输总线）：传输各功能部件之间的数据信息。数据总线的位数称为数据总线宽度，与机器字长，存储字长有关</li>
<li>地址总线（单向输出总线）：用来指出数据总线上源数据或目的数据在内存中的地址或I/O设备的地址，地址总线的位数和存储单元个数有关，地址线20根，则对应的存储单元个数为2^20</li>
<li>控制总线：发出各种控制信号的传输线，任一控制线的传输都是单向的，可以监视不同组件之间的状态（就绪、未就绪）。控制信号经由控制总线从一个组件发送给另外一个组件，常见控制信号如下：
<ul>
<li>时钟：同步各种操作</li>
<li>复位：初始化所有部件</li>
<li>总线请求：表示某部件需要获得总线使用权</li>
<li>总线允许：表示需要获得总线使用权的部件已获得了控制权</li>
<li>中断请求：表示某部件提出中断请求</li>
<li>存储器写：将数据总线上的数据写至存储器的指定地址单元内</li>
<li>存储器读：将指定存储单元中的数据读到数据总线上</li>
<li>I/O读：从指定的I/O端口将数据读到数据总线上</li>
<li>I/O写：将数据总线上的数据输出到指定的I/O端口内</li>
<li>传输响应：表示数据已被接收，或已将数据传送至数据总线上</li>
</ul>
</li>
</ul>
</li>
<li>通信总线：用于计算机系统之间或计算机系统与其他系统之间（控制仪表、移动通信等）的通信。按传输方式分
<ul>
<li>串行通信：数据在单条1位宽的传输线上，一位一位地按顺序分时传送，如1字节的数据，在串行传送中，需要通过一条传输线分8次由地位到高位按顺序逐位传送，适宜于远距离传送，从几米到达数千公里</li>
<li>并行通信：数据在多条一位宽的传输线上，同时有源传送到目的地，如1字节的数据，在并行传送中，要通过8条并行传输线同时由源传送到目的地。适宜近距离数据传输，小于30m</li>
<li>都与距离成反比，串行通信费用低</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2>3.3. 总线性能指标</h2>
<ul>
<li>总线宽度：总线的根数，用bit（位）表示，8、16、32、64位（即8、16、32、64根）</li>
<li>总线带宽：总线的传输速率，单位时间内总线上传输数据的位数，通常用每秒传输的字节数MBps（兆字节每秒）表示，例如，总线工作频率为33MHz，总线宽度为32位（4B），则总线带宽为33 x （32）÷ 8 = 132MBps</li>
<li>时钟同步/异步：总线上的数据与时钟同步工作的总线称为同步总线，与时钟不同步工作的总线称为异步总线</li>
<li>总线复用：一条信号线上分时传送两种信号，物理上将地址总线和数据总线共用一组物理线路。分时传输地址信号和数据信号</li>
<li>信号线数：地址、数据、控制总线三种总线数总和</li>
<li>总线控制方式:包括突发工作，自动配置，仲裁方式，逻辑方式，计数方式等</li>
<li>负载能力：当总线接上负载后，总线输入输出的逻辑电平是否能保持在正常的额定范围内，通常用可连接扩增电路板数反应总线的负载能力</li>
<li>其他指标：电源电压、总线宽度是否能扩展等<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/60609ac2bc8b113115b76.png" alt="13.png"></li>
</ul>
<h2>3.4. 总线标准</h2>
<ul>
<li>系统与各模块、模块与模块之间的一个互连的标准界面。界面对它两端的模块都是透明的，界面的任一方只需根据总线标准的要求完成自身一方的功能要求， 无需了解对方接口与总线的连接要求，按总线设计的接口可视为通用接口</li>
<li>流行的总线标准：ISA总线、EISA总线、VESA总线、PCI总线常用、AGP总线（显卡）、RS-232C总线、USB总线(Universal Serial Bus)</li>
</ul>
<h2>3.5. 总线控制</h2>
<ul>
<li>
<p>总线判优控制：</p>
<ul>
<li>总线上所连接的设备，按其对总线有无控制能力可分为主设备（模块）和从设备（设备）</li>
<li>主设备对总线有控制权，从设备只能响应从主设备发过来的总线命令，对总线无控制权</li>
<li>总线上的信息传送是由主设备启动的，由主设备发送总线请求信号</li>
<li>若多个主设备同时使用总线，则由总线控制器的判优、仲裁逻辑按一定的优先等级顺序确定哪个设备能使用总线，只有获得总线使用权的主设备才能开始传送数据</li>
</ul>
</li>
<li>
<p>总线判优控制分类</p>
<ul>
<li>集中控制优先权仲裁方式：将控制逻辑集中在一处（如CPU）
<ul>
<li>链式查询：
<ul>
<li>用三根线总线控制（BS总线忙、BR总线请求、BG总线同意），其中总线同意信号BG是串行地从一个I/O接口送到下一个I/接口。如果BG到达的接口有总线请求，BG信号就不再往下传，该接口获得总线使用权，并建立总线忙BS信号，表示它占用了总线。离总线控制部件最近的设备具有最高的优先级。</li>
<li>电路复杂度低，控制线少，仲裁方式简单，容易扩充设备。</li>
<li>优先级低的设备难以获得总线使用权，对电路故障敏感</li>
<li>仅用2根线确定总线使用权属于哪个设备(n为允许接纳的最大设备数)</li>
</ul>
</li>
<li>计时器定时查询
<ul>
<li>相比链式查询多了设备地址线，少了总线同意线BG</li>
<li>总线控制器接收到BR送来的总线请求信号后，在总线未被使用（BS=0）的情况下，总线控制部件中的计数器开始计数，并通过设备地址总线，向各设备发出一组地址信号。当某个请求的占用的设备地址与计数值一致时，便获得总线使用权，此时终止计数查询</li>
<li>计数可以从0开始，此时一旦设备的优先次序被固定，设备的优先级就按0-n顺序排序，固定不变；计数可以从上一次计数的终止点开始，是一种循环的方法，此时设备使用总线的优先级相等；计数的初始值可以由程序设置，故优先次序可以改变</li>
<li>设备的优先级可以改变。电路故障敏感性降低</li>
<li>控制复杂，增加了控制线数</li>
<li>使用log2n根线确定总线使用权属于哪个设备(n为允许接纳的最大设备数)</li>
</ul>
</li>
<li>独立请求
<ul>
<li>每台设备均有一对总线请求线BR和总线同意线BG。总线控制部件中有一排队电路，可根据优先次序确定响应那一台设备的请求。</li>
<li>好处：响应速度快，优先顺序控制灵活、</li>
<li>坏处：控制线数量多，总线控制复杂</li>
<li>使用2n根线确定总线使用权属于哪个设备(n为允许接纳的最大设备数)</li>
</ul>
</li>
</ul>
</li>
<li>分布式：将控制逻辑分散在与总线连接的各个部件或设备上<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/1bb119fee9de6648cc32e.png" alt="22.png"></li>
</ul>
</li>
<li>
<p>总线通信控制</p>
<ul>
<li>总线通信控制解决通信双方如何获知传输开始和传输结束，以及通信双方如何协调配合</li>
<li>总线周期:完成一次总线操作的时间
<ul>
<li>申请分配阶段：由需要使用总线的主设备发出申请，经总线仲裁记过决定下一传输周期的总线使用权授予某一申请者</li>
<li>寻址阶段：取得了使用权的主模块通过总线发出本次要访问的从模块的地址及有关命令，启动参与本次传输的从模块</li>
<li>传数阶段：主模块和从模块进行数据交换，数据有源模块发出，经数据总线流入目的模块</li>
<li>结束阶段：主模块的有关信息从系统总线上撤除，让出总线使用权</li>
</ul>
</li>
<li>通信方式
<ul>
<li>同步通信：通信双方由统一时标控制数据传送，时标通常由CPU的总线控制部件发出，送到总线上的所有部件，也可以由每个部件各自的时序发送器发出，但必须由总线控制部件发出的时钟信号对他们进行同步
<ul>
<li>优缺点：规定明确、统一，各模块的配合简单一一致；对不同速度的部件而言，必须按最慢的速度的部件设计公共时钟，严重影响总线工作效率，缺乏灵活性</li>
<li>适用于总线长度短、各部件存取时间比较一致的场合</li>
</ul>
</li>
<li>异步通信
<ul>
<li>允许各模块速度不一致，没有公共的时钟标准，不要求所有部件严格的同一操作时间</li>
<li>采用应答（握手）的方式，当主模块发出请求信号时，一直等待从模块反馈回来的响应信号后才开始通信，要求主从模块之间增加两条应答线（握手交互信号线）</li>
<li>异步通信应答方式(并行或串行传送)
<ul>
<li>不互锁（CPU向主存写信息）：主模块发出信号后，不必等待接到从模块的回答信号，而是经过一段时间，确认从模块已收到请求信号后，便撤销其请求信号，从模块接收到请求信号后，在条件允许时发出回答信号，并且经过一段时间确认主模块收到回答信号后，自动撤销回答信号</li>
<li>半互锁（多机系统中CPU访问共享存储器）：主模块发出请求信号后必须接到从模块的回答信号才撤销其请求信号。从模块接收到请求信号后，不必确认主模块收到回答信号后，经过一段时间后自动撤销回答信号</li>
<li>全互锁（网络通信）：主模块发出请求信号后必须接到从模块的回答信号才撤销其请求信号。从模块发出应答信号待主模块请求信号撤销后，再撤销请求信号<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/25a073dfb1519b145a517.png" alt="23.png"></li>
</ul>
</li>
</ul>
</li>
<li>半同步通信
<ul>
<li>保留了同步通信的基本特点，如所有的地址、命令、数据信号的发出时间，都严格参照系统时钟的某个前沿开始。而接收方都采用系统时间后沿时刻来进行判断识别，同时像异步通信，允许不同速度的模块和谐工作、增设一条WAIT响应信号线，采用插入时钟（等待）周期的措施来协调通信双方的配合问题</li>
<li>优缺点：比异步通信简单。全系统内各模块在统一系统时钟控制下同步工作，可靠性高，同步结构方便</li>
<li>缺点：对系统时钟频率不能要求太高，系统工作速度不高</li>
</ul>
</li>
<li>分离式通信（大型计算机）
<ul>
<li>将一个传输周期/总线周期分解为两个子周期；第一个子周期，主模块A申请并获得总线使用权后，将数据传输到总线上，并放弃总线使用权；第二个子周期，从模块B接收到主模块发来的信号后，准备好传输数据后才申请并获得总线使用权，将数据传输给主模块A，并放弃总线使用权</li>
<li>特点
<ul>
<li>各模块都变成主模块都要提出申请占用总线使用权</li>
<li>在得到总线使用权后，主模块在限定的时间内想对方传送信息，采用同步方式传送，不再等待对方的应答信号</li>
<li>各模块在准备数据的过程中不占用总线，使总线可接受其他模块的请求</li>
<li>总线被占用时不存在空闲等待时间，充分利用了总线的有效占用，实现了总线在多个主、从模块之间信息交叉重叠并行式传送<br>
-缺点：控制复杂，普通微型计算机系统很少采用</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1>4. 存储器</h1>
<h2>4.1. 存储介质</h2>
<ul>
<li>能寄存"0"、"1"两种代码并能区别两种状态的物质或元器件，存储介质主要有半导体器件、磁性材料和光盘等</li>
</ul>
<h2>4.2. 存储器的分类</h2>
<ul>
<li>按存储介质分类
<ul>
<li>半导体存储器：存储元件由半导体器件组成的存储器，优点：体积小、功耗低、存取时间短；缺点：易失性存储器（电源消失时，所存信息随即丢失）内存、U盘、固态硬盘</li>
<li>磁表面存储器：在金属或塑料表面上涂一层磁性材料作为记录介质，工作时磁层随载磁体高速运转，用磁头在磁层上进行读/写操作。按载磁体形状不同分：磁盘、磁带、磁鼓（少用），具有矩形磁滞回线特性的材料作表面物质，它们按其剩磁的状态不同区分0或者1，而且剩磁状态不会轻易丢失，属于非易失性存储器</li>
<li>磁芯存储器：由硬磁材料做成的环状元件，在磁芯中穿有驱动线和读出线，便可以进行读/写操作(永久记忆存储器)，因为体积太大，工艺复杂、功耗太大不用了</li>
<li>光盘存储器：应用激光在记录介质（磁光材料上）进行读/写的存储器，非易失性存储器；耐用性好、记录密度高、可互换性强特点，常用</li>
</ul>
</li>
<li>按存储方式分类
<ul>
<li>随机存储器（RAM Random Access Memory主存）:可读写，任何一个存储单元的内容都可随机存取，存取时间与存储单元的物理位置无关，分为静态RAM（以触发器原理寄存信息）和动态RAM(以电容放电原理寄存信息，每隔一段时间刷新一次)</li>
<li>只读存储器（ROM Read Only Memory）：只能对存储的内容读出，不能对其重新写入的存储器。通常存放固定不变的程序、常数和汉字字库，甚至用于操作系统的固化。与随机存储器可共同作为主存一部分，统一构成主存的地址域</li>
<li>串行访问存储器（顺序存储器-磁带存储器）：对存储器读写时，只能按物理位置先后顺序寻址；信息位置不同，读写时间不同，如磁带、磁盘</li>
<li>直接存储器：部分串行访问的存储器（磁盘）：在对磁盘读/写时，首先直接指出该存储器中的某个小区域（磁道），然后再顺序寻访，直至找到位置。故前段是直接访问，后端是串行访问</li>
</ul>
</li>
<li>按在计算机中的作用分类
<ul>
<li>主存储器（主存）：和CPU直接交换信息，速度快，容量小，每位价格高</li>
<li>辅助存储器（磁盘、U盘、光盘、磁带等）：存放当前暂时不用的程序和数据，不能和CPU直接交换信息，速度慢，容量大，每位价格低</li>
<li>缓冲存储器（L1、L2、L3缓存，CPU寄存器等）：用在速度不同的部件之中，如CPU与主存之间可设置一个快速缓存<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/bc75707d79485b2dbb8b4.png" alt="24.png"></li>
</ul>
</li>
</ul>
<h2>4.3. 存储器的层次结构</h2>
<ul>
<li>存储器的性能指标：速度、容量和每位价格（位价）</li>
<li>存储器速度、容量和位价的关系
<ul>
<li>位价和速度:辅存（磁盘、磁带）&lt;主存&lt;缓存&lt;寄存器</li>
<li>容量:辅存（磁盘、磁带）&gt;主存&gt;缓存&gt;寄存器</li>
</ul>
</li>
<li>寄存器和缓存Cache通常放在CPU中，寄存器中的数直接在CPU内部参与运算，主存存放将要参与运行的程序和数据</li>
<li>CPU，缓存，主存能直接交信息，CPU不能直接访问辅存</li>
</ul>
<h2>4.4. 存储系统层次结构</h2>
<ul>
<li>缓存-主存层次：利用局部性原理解决CPU和主存速度不匹配问题，速度接近于缓存，容量和位价接近主存
<ul>
<li>在CPU与主存之间增加一层速度快（容量小）的Cache</li>
<li>由于缓存的速度比主存的速度高，只要将CPU近期要用的信息调入缓存，CPU便可以直接从缓存中获取信息，从而提高访存速度，但由于缓存容量小，因此需不断地将主存的内容调入缓存，使缓存中原来的信息被替换；主存和缓存之间数据调动是由硬件自动完成的，对程序员透明</li>
</ul>
</li>
<li>主存-辅存层次（虚拟存储系统）利用局部性原理解决存储系统的容量问题，速度接近主存，容量和位价接近辅存
<ul>
<li>主存之外增加辅助存储器（磁盘、sd卡、U盘等）</li>
<li>辅存的速度比主存低，但是容量比主存大，可以暂时存放大量未用到的信息。当CPU需要用到这些信息时，将辅存的内容调入主存，供CPI直接访问。主存和辅存之间的数据调动是由硬件和操作系统共同完成的<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/345cff6c6aca5673b559d.png" alt="25.png"></li>
</ul>
</li>
</ul>
<h2>4.5. 主存储器</h2>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/487b251954b6e04569b6e.png" alt="36.PNG" tabindex="0"><figcaption>36.PNG</figcaption></figure>
<ul>
<li>主存由半导体集成电路构成，驱动器、译码器和读写电路均制作于存储芯片中，而MAR和MDR制作在CPU芯片内。存储芯片和COU芯片可通过总线连接</li>
<li>根据MAR中的地址访问某个存储单元时，还需经过地址译码、驱动等电路，才能找到所需访问的单元。读出时需要经过读出放大器，才能将被选中的单元的存储字送到MDR。写入时，MDR中的数据也必须经过写入电路才囊真正写入到被选中的单元中</li>
<li>读写过程
<ul>
<li>当要从存储器读出某一信息字时，首先由CPU将该字的地址送到MAR。经地址总线送至主存，然后发出读命令。主存接到读命令后，得知需将该地址单元的内容读出，便完成读操作，将该单元的内容读至数据总线上，由CPU决定由MDR送到什么地方</li>
<li>当要向主存中存入一个信息字时，首先CPU将该字所在存储单元的地址经MAR送到地址总线，并将信息字送入MDR，然后向主存发出写命令，主存接到写命令后，便将数据线上的信息写入到对应地址先指出的主存单元中</li>
</ul>
</li>
<li>主存中存储单元地址的分配
<ul>
<li>主存各存储单元的空间位置是由单元地址号来表示的，而地址总线是用来指出存储单元地址号的，根据该地址可读出或写入一个存储字。计算机系统可以按字寻址，也可以按字节寻址</li>
</ul>
</li>
<li>存储体：由许多存储单元组成</li>
<li>存储单元：由许多存储元件组成,以8位二进制作为一个存储单元，也就是一个字节。存储单元有编号，这些编号称为存储单元的地址号。存储单元按地址寻访。这些地址都是二进制的形式。</li>
<li>存储元件：可以寄存一位二进制代码0/1</li>
<li>字/存储字/存储字长：一个存储单元存储的二进制代码组合/位数（8、16、32位），8位2进制数表示一个字节，因此存储字长取8的倍数，主要看计算机位数</li>
<li>字块：存储在连续的存储单元中而被看作是一个单元的一组字（包含多个字）</li>
<li>大小关系：存储体包括多个存储单元，一个存储单元包括多个存储元件，一个存储元件能寄存一位二进制码</li>
<li>字节地址：每个存储单元的地址。</li>
<li>字地址：一个存储字长的存储单元地址，可以是高位字节地址或者地位字节地址。一个字有n位（8、16、32位），一个字块共B个字，主存共M个字块，主存总字数 = B<em>M，主存总容量 = B</em>M*32（bits），字的地址：前m位指定字块的地址，后b位指定字在字块中的地址，则 2^m = M 、2^b=B</li>
<li>主存的技术指标
<ul>
<li>存储容量：主存能存放二进制代码的总位数/字节总数
<ul>
<li>存储容量 = 存储单元个数 x 存储字长 = 存储单元个数 x 存储字长 /8</li>
<li>地址线为n根，那么存储单元个数为2^n根</li>
</ul>
</li>
<li>存储速度：用存取时间和存取周期表示
<ul>
<li>存取时间(Memory Access Time)：启动一次存储器读/写操作到完成该操作所需的全部时间
<ul>
<li>读出时间：从存储器收到有效地址开始，到产生有效输出所需的全部时间</li>
<li>写入时间：从存储器收到有效地址开始，到数据写入被选中单元为止所需的全部时间</li>
</ul>
</li>
<li>存取周期(Memory Cycle Time)：存储器进行连续两次独立的存储器操作所需的最小时间间隔，通常存取周期大于存取时间</li>
</ul>
</li>
<li>存储器带宽：单位时间内存储器存取的信息量，单位用字/秒或字节/秒或单位/秒表示.提高存储带宽措施：缩短存取周期、增加存储字长、增加存储体</li>
</ul>
</li>
</ul>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/6a4bdf735fe6b9defaff1.png" alt="46.PNG" tabindex="0"><figcaption>46.PNG</figcaption></figure>
<h2>4.6. 存储器的校验(汉明码)</h2>
<ul>
<li>汉明码：使用偶校验、分组校验，只有一位纠错能力
<ul>
<li>奇校验：这串序列1的个数如果为偶数则在前面加个1，使1的个数变成奇数，否则加0。</li>
<li>偶校验：这串序列1的个数如果为奇数则在前面加个1，使1的个数变成偶数，否则加0。</li>
<li>设需要检测的二进制代码为n位，添加K位检测位，组成n+k位的代码，</li>
<li>其中k满足：2^k &gt;= n+k+1</li>
<li>n+k位代码从左到右依次为1,2,3,4,5...,n+k位</li>
<li>校验位安插位置编号：1,2,4,8,...,2^(k-1)</li>
<li>分组依据：p1 xxx1 p2 xx1x p3 x1xx p4 1xxx，同一样格式的位数的数分成一组</li>
<li>检错依据：每组里面“1”的个数为偶数</li>
<li>出错位置: 分组从大到小从左到右排序，失败的组为1，成功的组为0，则组成的二进制数即为出错的位置</li>
</ul>
</li>
<li>举例：序列为1100
<ol>
<li>二进制代码为n=4位,根据2^k &gt;= n+k+1算出k=3</li>
<li>校验位安插位置为1,2,4三个位置</li>
<li>4+3位代码第1-7位从左到右依次为 x1,x2,1,x3,1,0,0 其中x1,x2,x3为需要添加的检测位，暂时没算出来是多少</li>
<li>将同样格式的第几位放一起分成三组：<br>
4.1 第一组(<strong>1)=&gt;第1,3,5,7(x1,1,1,0)位 1的个数为奇数，因此x1=0<br>
4.2 第二组(<em>1</em>)=&gt;第2,3,6,7(x2,1,0,0)位,1的个数为偶数，因此x2=1<br>
4.3 第三组(1</strong>)=&gt;第4,5,6,7(x3,1,0,0)位,1的个数为偶数，因此x3=1</li>
<li>得出最终数据0,1,1,1,0,0</li>
<li>出错位置:假如2和3组出错,将分组从大到小排列，则出错位数为第6位(二进制为110)</li>
</ol>
</li>
</ul>
<h2>4.7. 高速缓冲存储器</h2>
<ul>
<li>产生原因
<ul>
<li>由于I/O设备向主存请求的级别高于CPU访存，这就出现了CPU等待I/O设备访存的现象，致使CPU空等一段时间，甚至可能等待几个主存周期，从而降低了CPU的工作效率。为了避免CPU与I/O设备争抢访存，可在CPU与主存加一级缓存，主存可以将CPU要取的信息提前送至缓存。一旦主存在与I/O设备交换时，CPU可直接从缓存中读取所需信息，不必空等而影响效率。</li>
<li>为了解决主存与CPU速度不匹配的问题</li>
</ul>
</li>
<li>局部性原理：指CPU访问存储器时，无论是存取指令还是存取数据，所访问的存储单元都趋于聚集在一个较小的连续区域中</li>
<li>工作原理：任何时刻都有一些主存块在缓存块中，CPU读取主存某字时，若所需的字已在缓存中，即可直接访问Cache(CPU与Cache之间通常一次传送一个字) 缓存命中；若所需的字不在缓存中，需将该字所在的主存的整个字块一次调入缓存中（缓存与主存之间是字块传送）缓存不命中；如果主存块已调入缓存块，则称该主存块与缓存块建立了对应关系。</li>
<li>由于缓存的块数远小于主存的块数。因此，缓存块不能唯一地、永久地只对应一个主存块，故每个缓存快需设一个标记，用来表示当前存放的是哪一个主存块，该标记的内容相当于主存块的编号。CPU读信息时，要将主存地址的高m位（或m位中的一部分）与缓存块比较，判断所读信息是否已在缓存中</li>
<li>在一个程序执行期间，设Ne为访问Cache的总命中次数，Nm为访问主存的总次数，则命中率h=Ne/(Ne+Nm)</li>
<li>设tc为命中时Cache访问时间，tm为未命中时的主存访问时间，1-h表示未命中率，则Cache-主存系统的平均时间ta=htc+(1-h)tm，访问效率e = tc/ta x 100% = tc/(htc+(1-h)tm)x100%</li>
<li>Cache容量越大，其CPU命中率越高，当Cache到达一定值时，命中率已不因容量的增大而有明显的提高</li>
<li>块长与命中率关系：取决于各程序的局部特性，当块由小到大增长时，起初会因局部性原理使命中率有所提高，由局部性原理指出，在已被访问字的附近，近期也可能被访问，因此，增大块长，可将更多有用字存入缓存，提高命中率；当块继续增大时，命中率可能下降，因为装入缓存的有用数据反而少于被替换掉的有用数据。由于块长的增大，导致缓存中块数的减少，而新装入的块要覆盖旧块，很可能出现少数块刚刚装入就被覆盖，因此命中率反而下降。再者，块增大后，追加上的字距离已被访问的字更远，故近期被访问的可能性会更少</li>
</ul>
<h2>4.8. ？？？？缓存-主存地址映射方式（主存地址映射到Cache地址称为地址映射）</h2>
<pre><code>- 直接映射（固定的映射关系）
    - 设C为缓存块数，m为主存块数，i为缓存块号，j为主存块号，标记t = m-c C = 2^c
    - 映射关系 i = j mod C 或 i = j mod 2^c 即 缓存快C对应主存块C,2C,...,2^m
    - 每个缓存块 i 可以和若干个主存块对应，主存块号mod结果相同的都对应同一个缓存块号。每个主存块 j 只能和一个缓冲块对应
    - 先根据中间C位字段找到Cache字块号对应的字块，根据字块的“标记”是否与主存地址的高t位相符判断。若符合且有效位为“1”，表示该Cache块与主存模块建立了对应关系（命中）可根据b位地址从Cache中获得信息；若不符合或有效位为“0”(不命中)，则从主存读入新的字块来替代旧的字块，同时将信息送往CPU，并修改Cache“标记”。如果原来有效位为“0”，则改为“1”
    - 优点：实现简单，只需利用主存地址的某些位置直接判断，即可确定所需字块是否在缓存中
    - 缺点：不够灵活，每个主存块只能对应米一个缓存块，即使缓存内还空着许多位置也不能占用，缓存空间利用率低。如果程序恰好重复访问对应同一缓存位置的不同主存块，就要不停地替换，从而降低命中率
- 全相联映射（灵活性大的映射关系）
    - 将主存标记从t位增加到t+c位，访问Cache时主存字块标记需要和Cache全部标记进行比较，才能判断出所访问的主存地址是否存在
    - 允许主存中每一字块映射到Cache的任何一块位置上，可以从已被占满的Cache中替换出任一旧字块，
    - 灵活，命中率高，缩小了块冲突率;逻辑电路多，成本高，实际的Cache还要采用各种措施减少地址的比较次数
- 组相联映射（上述两种映射的折中）
    - 把Cache分为Q组，每组R块 主存块号mod结果相同的都对应同一组
    - 设i为缓存组号，j为主存块号 i = j mod Q
    - 当r = 0时是直接映射方式，当r = c时是全相联映射方式
</code></pre>
<p><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/82f12111d9760fa948119.png" alt="30.PNG"><br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/44ea13005fa8dace3b384.png" alt="31.PNG"><br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/5915ee0d665aa75dca8e8.png" alt="32.PNG"></p>
<h2>4.9. 替换策略</h2>
<ul>
<li>替换时机：当新的主存块需要调入Cache并且可用空闲位置又被占满，需要替换数据</li>
<li>随机算法：可采用一个随机数产生器产生一个随机被替换的块，没有局部性原理，不能提高缓存命中率</li>
<li>先进先出算法（FIFO）优先替换最先进入队列的字块，淘汰最先进入队列的字块；容易实现，开销小，没有使用访存的局部性原理，不能提高缓存命中率</li>
<li>最近最少使用算法（Least Recently Used,LRU）：优先淘汰一段时间内没有使用的字块。一般只记录每个块最近一次使用的时间。利用访存局部性原理，平均命中率比FIFO高。一般使用双向链表实现。把当前访问节点置于链表前面（保证链表头部节点是最近使用的）</li>
</ul>
<h2>4.10. 辅助存储器</h2>
<ul>
<li>辅存具有容量大、速度慢、价格低、可脱机保存信息等特点，属"非易失性"存储器</li>
<li>主存具有速度快、成本高、容量小等特点，而大多数由半导体芯片构成，所存信息无法永久保存，属"易失性"存储器</li>
<li>辅存存储器有硬磁盘、软磁盘、磁带、光盘等，前三种属于磁表面存储器</li>
<li>磁表面存储器的主要技术指标
<ul>
<li>记录密度：单位长度内所存储的二进制信息量</li>
<li>存储容量：外存所能存储的二进制信息总数量，一般以位或字节为单位</li>
<li>平均寻址时间</li>
<li>数据传输率：单位时间内磁存储器向主机传送数据的位数或字节数</li>
<li>误码率：衡量磁表面存储器出错概率的参数，等于从辅存读出时，出错信息位数和读出信息的总位数之比。为了纠正出错率，通常采用循环冗余码发现并纠正错误</li>
</ul>
</li>
<li>辅助存储器-磁盘（硬盘）
<ul>
<li>表面是可磁化的硬磁性特性材料。- 移动磁头径向运动读取磁道信息</li>
<li>磁盘寻道算法：
<ul>
<li>先来先服务算法：按顺序访问进程的磁道读写需求</li>
<li>最短寻道时间优先：与磁头当前位置有关、优先访问离磁头最近的磁道</li>
<li>扫描算法（电梯算法）：每次只往一个方向移动、到达一个方向需要服务的尽头再反方向移动</li>
<li>循环扫描算法：只往一个方向移动，由内往外或由外往内读取<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/af1be3f8a5a19f9738e5b.png" alt="43.PNG"><br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/8fd497485ec44bca2765a.png" alt="42.PNG"></li>
</ul>
</li>
</ul>
</li>
</ul>
<h1>5. 输入输出系统</h1>
<h2>5.1. 输入输出系统发展概况</h2>
<ul>
<li>早期阶段：I/O设备与主存交换信息都必须通过CPU</li>
<li>接口模块和DMA阶段：
<ul>
<li>I/O设备通过接口模块与主机连接，计算机系统采用了总线结构，接口中通常设有数据通路和控制通路，数据经过接口既起到缓冲作用，又可完成串-并变换</li>
<li>控制通路用以传送CPU向I/O设备发出的各种控制命令，或使CPU接受来自I/O设备的反馈信号</li>
<li>为了进一步提高CPU工作效率，出现了直接存储器存取（Direct Memory Access,DMA）技术，I/O设备与主存之间有一条直接数据通路，I/O设备可以与主存直接交换信息，使CPU在I/O设备与主存交换信息时能继续完成自身的工作，资源利用率得到了进一步提高</li>
</ul>
</li>
<li>通道结构的阶段
<ul>
<li>对于大型计算机，DMA方式随着I/O设备增加而增加了硬件成本，还导致访问主存的冲突问题</li>
<li>CPU还需要对众多DMA接口管理，占用CPU时间，频繁进入周期挪用周期，影响CPU工作效率</li>
<li>在大中型计算机系统中，采用I/O通道的方式进行数据交换</li>
<li>通道是用来负责管理I/O设备以及实现主存与I/O设备之间交换信息的部件，可以视为一种具有特殊功能的处理器，具有专用的通道指令，能独立执行通道指令所编写的输入输出程序，但不是一个完全独立的处理器</li>
</ul>
</li>
<li>I/O处理机阶段
<ul>
<li>I/O处理机独立于主机工作，可完成I/O控制、码制转换、格式处理、数据块检错、纠错等操作，并行性更高</li>
</ul>
</li>
</ul>
<h2>5.2. 输入输出系统的组成</h2>
<ul>
<li>I/O软件
<ul>
<li>将用户编制的程序（或数据）输入主机内</li>
<li>将运算结果输送给用户</li>
<li>实现输入输出系统与主机工作的协调等</li>
</ul>
</li>
<li>I/O指令
<ul>
<li>操作码：与其他指令的判别代码</li>
<li>命令码：体现I/O设备的具体操作
<ul>
<li>将数据从I/O设备输入主机</li>
<li>将数据从主机输出到I/O设备</li>
<li>状态测试</li>
<li>形成某些操作指令，与不同I/O设备交换信息要完成不同的操作</li>
<li>设备码：多台I/O设备的选择码</li>
</ul>
</li>
</ul>
</li>
<li>通道指令：对具有I/O通道的系统专门设置的指令
<ul>
<li>指明参与传送（写入或读取）的数据组在主存中的首地址</li>
<li>指明需要传送的字节数或所传送数据组的末地址</li>
<li>指明所选设备的设备码及完成某种操作的命令码</li>
</ul>
</li>
<li>I/O硬件</li>
</ul>
<h2>5.3. I/O设备与主机的联系方式</h2>
<ul>
<li>I/O设备编址方式(I/O设备码看作地址码)
<ul>
<li>统一编址：将I/O地址看作存储器地址的一部分。占用主存容量，但无需专用的I/O指令</li>
<li>不统一编址：将I/O地址和存储器地址分开，对I/O设备的访问必须有专用的I/O指令。不占用主存容量，但需设I/O专用指令</li>
<li>当设备通过接口和主机相连时，CPU可以通过接口地址来访问I/O设备</li>
</ul>
</li>
<li>设备编址：每台设备赋予一个设备号，当需要启动设备时，可由I/O指令的设备码字段直接指出该设备的设备号。通过接口电路中的设备选择电路，便可选中要交换信息的设备</li>
<li>传送方式（需配置不同的接口电路）
<ul>
<li>并行传送：在同一瞬间，n位信息同时从CPU输出值I/O设备，或由I/O设备输入到CPU，传送速度较快，要求数据线多</li>
<li>串行传送（远距离通信）：在同一瞬间只传送一位信息，在不同时刻连续逐为传送一串信息。传送速度慢，只需一根数据线和一根地线</li>
</ul>
</li>
<li>联络方式：I/O设备与主机之间相互了解彼此所处的状态
<ul>
<li>立即响应方式：工作速度十分缓慢的I/O设备</li>
<li>异步工作采用应答信号联络：当I/O设备与主机工作速度不匹配，一方数据准备好了才通知另外一方取数据</li>
<li>同步工作采用同步时标联络：需要配置专用电路，用以产生同步时标来控制同步工作</li>
</ul>
</li>
<li>连接方式
<ul>
<li>辐射式：每台I/O设备都有一套控制线路和一组信号线，所用器件和连线较多，对I/O设备的增删都比较困难</li>
<li>总线式（现代计算机）：通过一组总线（地址先、数据线、控制线等），将所有的I/O设备和主机连接</li>
</ul>
</li>
</ul>
<h2>5.4. I/O设备与主机信息传送的控制方式</h2>
<ul>
<li>程序查询方式(轮询)
<ul>
<li>由CPU不断查询I/O设备是否已做好准备，从而控制I/O设备与主机交换信息</li>
<li>要求I/O接口内设置一个能反映I/O设备是否准备就绪的状态标记，CPU通过对此标记的检测，可得知I/O设备的准备情况</li>
<li>使CPU和I/O设备处于串行工作状态，CPU工作效率不高</li>
</ul>
</li>
<li>程序中断方式
<ul>
<li>当I/O设备准备就绪并向CPU发出中断请求后才予以响应，大大提高CPU的工作效率</li>
<li>CPU和I/O接口不仅在硬件方面需增加相应的电路，而在软件方面还必须编制中断服务程序</li>
<li>CPU有专门的电路响应中断信号，将当前工作暂停， 做IO设备的工作，做完再继续做当前工作</li>
<li>提供低速设备通知CPU的一种异步的方式，CPU可以高速运转的同时兼顾低速设备的响应</li>
</ul>
</li>
<li>DMA方式（I/O设备直接与主存交换信息）（硬盘和外置显卡）
<ul>
<li>DMA方式中，主存与I/O设备之间有一条数据通路，主存与I/O设备交换信息时，无须调用中断服务程序，可以提高CPU效率。若出现DMA和CPU同时访问主存，CPU总线总是将占有权让给DMA，通常把DMA这种占有称为窃取或挪用。窃取的时间一般为一个存取周期，故又把DMA占用存取周期称为窃取周期/挪用周期。而且在DMA窃取存取周期时，CPU能继续作内部操作（如乘法运算）</li>
<li>需要增加必要的接口电路</li>
<li>程序中断和DMA都是计算机IO和低速设备的交互方式，程序中断方式实现简单，DMA方式效率更高</li>
</ul>
</li>
<li>I/O通道方式</li>
<li>I/O处理机方式</li>
</ul>
<h2>5.5. I/O接口</h2>
<ul>
<li>I/O接口：主机与I/O设备之间设置的一个硬件电路机器相应的软件控制</li>
<li>设置原因
<ul>
<li>一台机器通常配有多台I/O设备，各自有设备号，通过接口可实现I/O设备的选择</li>
<li>I/O设备种类繁多，速度不一，与CPU速度相差可能很大，通过接口可实现数据缓冲，达到速度匹配</li>
<li>有些设备可能串行、可能并行传送，通过接口可实现</li>
<li>可实现电平转换</li>
<li>可传送控制命令</li>
<li>可通过接口监视设备的工作状态，供CPU查询</li>
</ul>
</li>
<li>端口：指接口电路中的一些寄存器，分别用来存放数据信息，控制信息和状态信息，相应的端口分别称为数据端口、控制端口、和状态端口。若干个端口加上相应的控制逻辑才能组成接口。</li>
</ul>
<h2>5.6. 接口的功能和组成</h2>
<ul>
<li>总线连接方式的I/O接口电路：其中I/O总线包括
<ul>
<li>数据线：I/O设备与主机之间数据代码的传送线，其根数一般等于存储字长的位数或字符的位数</li>
<li>设备选择线：主机选择IO设备进行操作的信号线，对连在总线上的设备进行选择。传送设备码，根数取决于I/O指令中设备码的位数</li>
<li>命令线：传输CPU向I/O设备发出的各种命令信号，如启动、清除、屏蔽、读、写等，一组单向总线，根数与命令信号多少有关</li>
<li>状态线：将I/O设备的状态向主机报告的信号线，一组单向总线。查询设备是否已经正常连接并就绪，查询设备是否已经被占用</li>
</ul>
</li>
<li>接口的功能和组成
<ul>
<li>选址功能</li>
<li>传送命令的功能：设有命令寄存器（存放I/O指令中的命令码。受设选中信号控制）和命令译码器</li>
<li>传送数据的功能（缓冲能力）设有数据缓冲寄存器，暂存I/O设备与主机准备交换的信息</li>
<li>反映I/O设备工作状态的功能（中断请求触发器，屏蔽触发器MASK）</li>
</ul>
</li>
<li>接口类型
<ul>
<li>按数据传送方式：并行接口。串行接口</li>
<li>按功能选择的灵活性分类：可编程接口，不可编程接口</li>
<li>按通用性分类：通用接口，专用接口</li>
<li>按数据传送的控制方式：程序型接口(连接速度较慢的设备)，DMA型接口</li>
</ul>
</li>
</ul>
<h2>5.7. 程序中断方式</h2>
<ul>
<li>中断：计算机在执行程序的过程中，当出现异常情况或特殊请求时，计算机停止现行程序的运行、转向对这些异常情况或特殊请求的处理，处理结束后在返回到现行程序的间断处，继续执行原程序</li>
<li>中断技术引入原因：适应I/O设备工作速度低的问题，提高计算机整机效率。实时控制的需要</li>
</ul>
<h2>5.8. 中断服务程序的流程</h2>
<ul>
<li>中断服务程序的流程
<ul>
<li>保护现场
<ul>
<li>保存程序断点，由中断隐指令完成</li>
<li>保存状态寄存器的内容，由中断服务程序完成</li>
</ul>
</li>
<li>中断服务（设备服务）</li>
<li>恢复现场：要求在退出中断服务程序之前，将程序中断时的“现场”恢复到原来的寄存器中</li>
<li>中断返回：中断服务程序的最后一条指令，使其返回到原程序的断点处，以便继续执行原程序</li>
</ul>
</li>
<li>多重中断：计算机在处理中断的过程中，有可能出现新的中断请求，如果CPU暂停现行的中断服务程序，转去处理新的中断请求，这种现象称为中断嵌套</li>
<li>单重中断：CPU在执行中断服务程序时，对新的中断请求不予理睬</li>
<li>两者区别：开中断在保护现场后面<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/c2fcdb7566ae66cd532a2.png" alt="37.PNG"></li>
</ul>
<h2>5.9. DMA方式</h2>
<ul>
<li>DMA与主存交换数据使采用的方法
<ul>
<li>停止CPU访问主存
<ul>
<li>当外设要传送一批数据时，由DMA接口向CPU发一个停止信号，要求CPU放弃地址线、数据线和有关控制线的使用权</li>
<li>控制简单，适用于数据传输率很高的I/O设备实现成组数据的传送</li>
<li>缺点是DMA接口在访问主存时，CPU基本上处于不工作状态或保持原状态</li>
<li>而且即使I/O设备高速运行，两个数据之间的准备间隔时间也总大于一个存取周期</li>
<li>因此，CPU对主存的利用率并没得到充分的发挥</li>
</ul>
</li>
<li>周期挪用（广泛使用）
<ul>
<li>每当I/O设备发出DMA请求时，I/O设备便挪用或窃取总线占用全一个或几个主存周期</li>
<li>I/O设备每挪用一个主存周期都要申请总线控制权，建立总线控制权和归还总线控制权</li>
<li>尽管传输一个字对主存而言只占用一个主存周期，但对DMA接口而言，实质上要占2-5个主存周期（由逻辑线路的延迟特性而定），适用于I/O设备读写周期大于主存周期的情况</li>
</ul>
</li>
<li>DMA与CPU交替访问
<ul>
<li>适合CPU工作周期比主存存取周期长的情况</li>
<li>不需要总线使用权的申请、建立和归还过程</li>
<li>CPU不停止主程序运行，不等待，也完成了DMA数据传送</li>
<li>硬件逻辑复杂</li>
</ul>
</li>
</ul>
</li>
<li>DMA接口的功能和组成
<ul>
<li>向CPU申请DMA传送</li>
<li>在CPU允许DMA工作时，处理总线控制权的转交</li>
<li>在DMA期间管理系统总线，控制数据传送</li>
<li>确定和修成数据传送的起始地址和数据长度，修正数据传送过程中的数据地址和数据长度</li>
<li>在数据块传送结束时，给出DMA操作完成的信号</li>
</ul>
</li>
<li>DMA特点
<ul>
<li>从数据传送看，程序中断方式靠程序传送，DMA方式靠硬件传送</li>
<li>从CPU响应时间看，程序中断在一条指令执行结束时响应，而DMA方式可在指令周期内任意存取周期结束时响应</li>
<li>程序中断方式有处理异常时间能力，DMA没有，主要用于大批数据的传送</li>
<li>程序中断方式需要中断现行程序，故需保护现场，DMA不需要</li>
<li>DMA优先级比程序中断高</li>
</ul>
</li>
</ul>
<h1>6. 计算机的运算方法</h1>
<h2>6.1. 进制的概述</h2>
<ul>
<li>常见进制：二进制、十进制、八进制、十六进制（网卡mac地址）、六十进制（时钟）</li>
<li>二进制运算基础
<ul>
<li>任何进制表示 N = dn * r^n-1 +...+ d1 * r^1 + d0</li>
<li>二进制整数转十进制（按权展开法）N = (01100101) = 1 * 2^6 + 1 * 2^5 + 1*2^2 + 1 = 101</li>
<li>十进制整数转二进制（重复相除法）N = (01100101) = 1 * 2^6 + 1 * 2^5 + 1*2^2 + 1 = 101<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/90a2e411c0c74485b9e47.png" alt="38.PNG"></li>
<li>二进制小数转十进制（按权展开法）N = （0.11001） = 1 * 2^-1 + 1 *2 ^-2 + 1 * 2^-5 - 0.78125 = 25/32</li>
<li>十进制小数转二进制（重复相乘法）N = （0.11001） = 1 * 2^-1 + 1 *2 ^-2 + 1 * 2^-5 - 0.78125 = 25/32<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/33fabec9c0a874b4f5b92.png" alt="39.PNG"></li>
</ul>
</li>
</ul>
<h2>6.2. 计算机中的数</h2>
<ul>
<li>计算机中的数均放在寄存器中，通常寄存器的位数为机器字长。</li>
<li>参与运算的数
<ul>
<li>无符号数：没有符号的数，在寄存器中的每一位都可用来存放数值</li>
<li>有符号数：需流出位置存放符号</li>
</ul>
</li>
<li>原码表示法
<ul>
<li>最左边符号位使用0表示正数、1表示负数,用逗号将符号位和数值隔开，用小数点将小数的符号位和数值隔开</li>
<li>0有两种表示方法：00、10</li>
</ul>
</li>
<li>补码表示法
<ul>
<li>原码进行运算非常复杂，特别是两个操作数符号不同的时候，需要判断两个操作数绝对值大小，使用绝对值大的数减去绝对值小的数，对于符号值、以绝对值大的为准；希望找到不同符号操作数更加简单的运算方法；希望找到使用正数代替负数的方法；使用加法操作代替减法操作，从而消除减法</li>
<li>正数的补码是本身，负数的补码是原码基础上符号位不变，其余各位取反后加1（反码+1）</li>
</ul>
</li>
<li>反码表示法
<ul>
<li>反码的目的是找出源码和补码之间的规律、消除转换过程中的减法</li>
<li>反码中的0也有2种表达方式</li>
<li>正数的反码是本身，负数的反码是原码基础上符号位不变，其余各位取反</li>
</ul>
</li>
</ul>
<h2>6.3. 数的定点表示和浮点表示</h2>
<ul>
<li>小数点的表示方法
<ul>
<li>定点表示（纯小数、纯整数）：定点表示数称为定点数。小数点固定在某个位置的数称为定点数</li>
<li>浮点表示，浮点表示的数称为浮点数：计算机处理的很大程度上不是纯小数或纯整数。数据范围很大，定点数难以表达。</li>
</ul>
</li>
<li>浮点数的表示形式（科学计数法）
<ul>
<li>123450000000 = 1.2345x10^11（尾数：1.2345、基数：10、阶码：11）</li>
<li>N = S * r^j （尾数：s（规定使用纯小数） 基数：r （2,4,8,16）阶码：j）</li>
<li>阶码符号位、阶码数值位、尾数符号位、尾数数值位</li>
<li>尾数位数n反应浮点数精度，阶符和阶码位数m合起来反应浮点数的表示范围和实际位置</li>
<li>尾数规定使用纯小数，将尾数最高位为1的浮点数称为规格化数 ，其精度最高，为了提高精度必须规格化</li>
<li>基数r越大，可表示的浮点数范围越大，表示的数的个数越多，但精度反而下降</li>
</ul>
</li>
<li>浮点数的表示范围
<ul>
<li>假设阶码数值取m位，尾数数值取n位</li>
<li>阶码范围：[-(2^m - 1),2^m - 1]</li>
<li>尾数范围：[-(1-2^-n),-(2^-n)] [2^-n,1-2^-n]</li>
<li>当浮点数阶码大于最大阶码称为上溢，小于最小阶码是称为下溢<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/c3af2d2b57a8f8b280ff6.png" alt="40.PNG"><br>
单精度浮点数：使用4字节、32位来表达浮点数<br>
双精度浮点数：使用8字节、64位来表达浮点数</li>
</ul>
</li>
<li>定点数和浮点数的对比
<ul>
<li>当定点数与浮点数位数相同时，浮点数表示的范围更大</li>
<li>当浮点数位数为规格化数时，浮点数的相对精度更高</li>
<li>浮点数运算包含阶码和尾数，运算结果要求规格化，故浮点数运算步骤多，浮点数的运算更为复杂</li>
<li>在溢出的判断方法上，浮点数是对规格化数的阶码进行判断，定点数是对数值本身进行判断</li>
<li>浮点数在数的表示范围、精度、溢出处理、编程等当面均优于定点数</li>
<li>浮点数在数的运算规则、运算速度、硬件成本方面不如定点数</li>
</ul>
</li>
</ul>
<h2>6.4. 定点数的加减法</h2>
<ul>
<li>整数加法：[A]补 + [B]补 = [A+B]补（mod2^n+1）</li>
<li>小数加法：[A]补 + [B]补 = [A+B]补（mod2）</li>
<li>整数减法：[A-B]补 = [A]补 + [-B]补（mod2^n+1）-&gt;[-B]补 = [B]补 连同符号位按位取反,末位+1</li>
<li>小数减法：[A-B]补 = [A]补 + [-B]补（mod2）-&gt;[-B]补 = [B]补 连同符号位按位取反,末位+1</li>
<li>数值位与符号位一同运算，并将符号位产生的进位自然丢掉</li>
<li>判断溢出：
<ul>
<li>一位符号判断溢出：无论加法还是减法，只要实际参加操作的两个数符号相同，结果又与原操作数不同，即为溢出，为了节省时间，通常用符号位产生的进位与最高有效位产生的进位亦或操作后，结果为1表示溢出，否则无溢出</li>
<li>双符号位判断法：单符号为表示变成双符号位：0=&gt;00,i=&gt;11，双符号位产生的进位丢弃，结果的双符号为不同则表示溢出。01正溢出，10负溢出</li>
</ul>
</li>
</ul>
<h2>6.5. 定点数乘法运算</h2>
<ul>
<li>乘法运算可用移位和加法实现</li>
<li>由乘数的末位值确定被乘数是否与原部分积相加，然后右移一位，形成新的部分积；同时，乘数也右移一位，由次低位作新的末位，空出最高位放部分积的最低位。</li>
<li>每次做加法时，被乘数仅仅与原部分积的高位相加，其低位被移至乘数所空出的高位位置。<br>
例2.X=0.0010，Y=-0.1101，XY=？<br>
被乘数A=|X|=00.0010,乘数B=|Y|=0.1101<br>
1.B的末位是1,A需要加B,得到00.0000+00.0010=00.0010,右移一位得到00.0001(部分积),B右移一位得到10.110<br>
2.B的末位是0,A需要加B,得到00.0001+00.0000=00.0001,右移一位得到00.0000(部分积),B右移一位得到110.11<br>
3.B的末位是1,A需要加B,得到00.0000+00.0010=00.0010,右移一位得到00.0001(部分积),B右移一位得到1110.1<br>
4.B的末位是1,A需要加B,得到00.0001+00.0010=00.0011,右移一位得到00.0001(部分积),B右移一位得到11110<br>
5.最后结果1.00011010。（对于结果正负，只需将X,Y两个数符号位做异或。同号为正，异号为负）</li>
</ul>
<h2>6.6. 定点数除法运算</h2>
<h2>6.7. 浮点数的加减法</h2>
<pre><code>    对阶-&gt;尾数求和-&gt;尾数规格化-&gt;舍入-&gt;溢出判断
        x = 0.1101 x 2^01 ,y = -0.1010 x 2^11 计算x+y
    对阶：
        阶码按小阶对齐大阶的原则
        对阶的目的是使得两个浮点数阶码一致，使得尾数可以进行运算
        对阶后 0.1101 x 2^01 -&gt; 0.001101 x 2^11
    尾数求和
        使用补码进行小数的加减法，使用双符号位
        [x]原 = 00.0011 [x]补 = 00.0011
        [y]原 = 11.1010 [y]补 = 11,0110
        S = [x+y]补 = 11.1001（进位mod2消掉）
    尾数规格化
        [S]补 = 00.1xxxxxx（S&gt;0）
        [S]补 = 11.0xxxxxx（S&lt;0）
        左规：00.0xxxxx 或11.1xxx尾数左移，阶码加 即:若符号位与最高位不一致,需要进行左规，
        右规：01.0xxxxx 或10.xxx尾数右移，阶码减 即:符号位不一致则右规
        11.1001不满足-&gt;(1)11.001(0)左移-&gt;11.0010
    舍入
        当右规时，才需要舍入，因为右规尾数低位丢失，引起误差，丢失精度，使用舍入提高精度
        0舍1入：被移去的最高位为1则末位+1，否则不变
</code></pre>
<p><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/c1bdf6abd172a57c4efc4.png" alt="40.PNG"><br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/323d182b0822f749168e4.png" alt="41.PNG"><br>
溢出：<br>
定点运算符号位不一致为溢出<br>
浮点运算尾数双符号位不一致不算溢出，因为尾数双符号可以进行右规<br>
浮点运算主要通过阶码的双符号位判断是否溢出<br>
如果规格化后，阶码双符号位不一致，则认为是溢出<br>
[x]补 = 01,xxxx上溢<br>
[x]补 = 10,xxxx下溢,按机器零处理</p>
<p><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/5bdcb2ff68d462511f3f0.png" alt="42.PNG"><br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/568bc0addc5c68dec5d3d.png" alt="43.PNG"><br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/ad871a13df917034af41e.png" alt="44.PNG"><br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/dfc2d9cbbb8d81d234162.png" alt="45.PNG"><br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/d3ed7d3f2499664d185bc.png" alt="46.PNG"><br>
浮点数的乘除法运算<br>
乘法：阶码相加，尾数求积<br>
除法：阶码相减，尾数求商<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/c23719ed84b26b05301b9.png" alt="49.PNG"><br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/99223cfe689840a5b62dc.png" alt="50.PNG"></p>
<h1>7. 指令系统</h1>
<h2>7.1. 机器指令</h2>
<ul>
<li>机器指令:每一条机器语言称为机器指令</li>
<li>指令系统:全部机器指令的集合、机器的指令系统集中反映了机器的功能</li>
<li>指令是由操作码和地址码组成
<ul>
<li>操作码：指明指令要完成的操作，位数反映了机器的操作种类（机器允许的指令条数）。如操作码占7位，则该机器最多包含2^7=128条指令</li>
<li>地址码：指出该指令的源操作数的地址（一个或两个）、结果的地址以及下一条指令的地址、地址包括主存、寄存器、I/O设备的地址</li>
</ul>
</li>
<li>四地址指令：包括OP操作码，A1第一操作数地址、A2第二操作数地址、A3结果地址、A4下一条指令地址。完成(A1)OP(A2)-&gt;A3操作</li>
<li>三地址指令：包括OP操作码，A1第一操作数地址、A2第二操作数地址、A3结果地址，完成(A1)OP(A2)-&gt;A3操作，后续指令的地址隐含在程序计数器PC中</li>
<li>二地址指令：包括OP操作码，完成(A1)OP(A2)-&gt;A1操作，此时A1字段既代表操作数的地址，又代表存放本次结果的地址.或者完成(A1)OP(A2)-&gt;A1操作，此时A2除了代表源操作数的地址外，还代表中间结果的存放地址</li>
<li>一地址指令：包括OP操作码，ACC既存放参与运算的操作数，又存放运算的中间结果。完成(ACC)OP(A1)-&gt;ACC操作、完成一条一地址指令只需两次访存</li>
<li>零地址指令：包括无地址码，如空操作（NOP）、停机（HLT）这类指令只有操作码。子程序返回（RET）、中断返回（IRET）这类指令没有地址码</li>
<li>指令字长：指令字长取决于操作码的长度、操作数地址的长度和操作数地址的个数</li>
</ul>
<h2>7.2. 操作数类型</h2>
<ul>
<li>地址：地址可被认为是一个无符号的整数</li>
<li>数字：计算机常见的数字有定点数、浮点数和十进制数</li>
<li>字符：ASCII码，重要的字符编码</li>
<li>逻辑数据：逻辑运算时，n个0和1的组合不是被看做算术数字而是被看做逻辑数</li>
</ul>
<h2>7.3. 操作类型</h2>
<ul>
<li>数据传送：包括寄存器与寄存器、寄存器与算术单元、存储单元与存储单元之间的传送。数据对接、交换地址数据、清零置一等操作</li>
<li>算术逻辑操作：算术运算（操作数之间的加减乘除运算）和逻辑运算（与，非，或，异或）</li>
<li>移位：算术移位、逻辑移位和循环移位。移位操作时间比乘除操作执行时间短，移位操作经常被用来代替简单的乘法和除法运算。数据左移（乘2）、数据右移（除2）</li>
<li>转移：改变计算机程序执行指令顺序
<ul>
<li>无条件转移</li>
<li>条件转移：根据当前指令的执行结果决定是否需要转移</li>
<li>调用与返回
<ul>
<li>调用指令包括过程调用、系统调用和子程序调用。实现一个程序转移到另一个程序的操作</li>
<li>调用指令（CALL）一般与返回（RETURN）指令配合使用.call 用于当前的程序位置转至子程序的入口，return用于子程序执行完后重新回到原程序的断点</li>
</ul>
</li>
</ul>
</li>
<li>陷阱与陷阱指令：陷阱其实是一种意外事故的中断，一旦出现意外故障，计算机发出陷阱信号，暂停当前程序的执行，转入故障处理程序进行相应故障处理</li>
<li>输入输出：对于I/O单独编址的计算机，设有输入输出指令</li>
<li>其他：等待指令、停机指令、空操作指令、开中断指令、关中断指令、置条件码指令等</li>
<li>数据在存储器中的存放方式：计算机中的数据存放在存储器或寄存器中，而寄存器的位数便可反应机器字长</li>
</ul>
<h2>7.4. 寻址方式</h2>
<ul>
<li>寻址方式是指定本指令的数据地址以及下一条将要执行的指令地址的方法</li>
<li>指令寻址
<ul>
<li>顺序寻址（通过程序计数器PC加1自动形成下一条指令的地址实现）</li>
<li>跳跃寻址（通过转移类指令实现）</li>
</ul>
</li>
<li>数据寻址：地址指令包括操作码、寻址特征、形式地址A。操作数的真实地址称为有效地址记为EA
<ul>
<li>立即寻址：操作数本身在指令字内，数据采用补码形式存放。形式地址A是操作数本身。执行阶段无需访存（速度快，地址码位数限制操作数表示范围）</li>
<li>直接寻址：指令字中的形式地址A就是操作数的真实地址EA。执行阶段访存一次（寻找操作数简单，地址码位数限制操作数表示范围）</li>
<li>隐含寻址：指令中操作数的地址，隐含在操作码或某个寄存器中</li>
<li>间接寻址：形式地址指出操作数有效地址所在的存储单元地址。便于编址程序，扩大了操作数的寻址范围，需要访存多次，使指令执行时间延长（操作数寻址范围大，速度慢）</li>
<li>寄存器寻址：地址码字段直接指出寄存器的编号，无需访存，减少执行寻址</li>
<li>寄存器间接寻址：地址码字段直接指出操作数所在主存的地址号，指令执行阶段需要访问主存</li>
<li>基址寻址：设有基址寄存器BR，操作数的有效地址EA等于指令字中的形式地址和基址寄存器中的内容相加。扩大操作数的寻址范围</li>
<li>变址寻址：设有变址寄存器IX，操作数的有效地址EA等于指令字中的形式地址和变址寄存器中的内容相加</li>
<li>相对寻址：有效地址将程序计数器PC与指令字中的形式地址A相加而成，常用于转移类指令</li>
<li>堆栈寻址：用寄存器组实现或主存一部分空间作堆栈</li>
</ul>
</li>
</ul>
<h1>8. CPU的结构和功能</h1>
<h2>8.1. 控制器的基本功能</h2>
<ul>
<li>取指令:控制器能自动形成指令的地址，并能发出取指令的命令，将对应的指令取到控制器中</li>
<li>分析指令:分析指令要完成什么操作，分析参与这次操作的操作数地址</li>
<li>执行指令:根据分析指令产生的操作命令和操作地址的要求，形成操作控制信号序列，通过对运算器、存储器以及I/O设备的操作，执行每条指令</li>
<li>控制程序的输入和运算结果的输出以及对总线的管理</li>
<li>中断处理：处理机器运行过程中出现的异常情况和特殊请求</li>
</ul>
<h2>8.2. CPU结构框图</h2>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/aa2e9cd7508dd7187ca80.png" alt="41.PNG" tabindex="0"><figcaption>41.PNG</figcaption></figure>
<h1>9. 计算机的控制器</h1>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/955a2f2ec34e75b115ff2.png" alt="44.PNG" tabindex="0"><figcaption>44.PNG</figcaption></figure>
<ul>
<li>程序计数器：
<ul>
<li>用来存储下一条指令的地址</li>
<li>循环从程序计数器中拿出指令</li>
<li>当指令被拿出时，指向下一条指令</li>
</ul>
</li>
<li>时序发生器
<ul>
<li>电气工程领域，用于发送时序脉冲</li>
<li>CPU根据不同的时序脉冲有节奏的进行工作（节拍器）</li>
</ul>
</li>
<li>指令译码器
<ul>
<li>指令译码器是控制器的主要部件之一</li>
<li>计算机指令由操作码和地址码组成</li>
<li>翻译操作码对应的操作以及控制传输地址码对应的数据</li>
</ul>
</li>
<li>指令寄存器
<ul>
<li>指令寄存器也是控制器的主要部件之一</li>
<li>从主存或高速缓存取计算机指令</li>
</ul>
</li>
<li>主存地址寄存器
<ul>
<li>保存当前CPU正要访问的内存单元的地址</li>
</ul>
</li>
<li>主存数据寄存器
<ul>
<li>保存当前CPU正要读或写的主存数据</li>
</ul>
</li>
<li>通用寄存器
<ul>
<li>用于暂时存放或传送数据或指令</li>
<li>可保存ALU的运算中间结果</li>
<li>容量比一般专用寄存器大</li>
</ul>
</li>
</ul>
<h1>10. 计算机的运算器</h1>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/c4f2c2c4bf4893ccfc6e9.png" alt="45.PNG" tabindex="0"><figcaption>45.PNG</figcaption></figure>
<ul>
<li>数据缓存器
<ul>
<li>分为输入缓冲和输出缓冲</li>
<li>输入缓冲暂时存放外设送过来的数据</li>
<li>输出缓存暂时存放送往外设的数据</li>
</ul>
</li>
<li>ALU
<ul>
<li>ALU 算术逻辑单元、运算器的主要组成</li>
<li>常见的位运算（左右移、与或非等）</li>
<li>算术运算（加减乘除）</li>
</ul>
</li>
<li>状态字寄存器
<ul>
<li>存放运算状态（条件码、进位、溢出、结果正负等）</li>
<li>存放运算控制信息（调试跟踪标记位、允许中断位等）</li>
</ul>
</li>
<li>通用寄存器
<ul>
<li>用于暂时存放或传送数据或指令</li>
<li>可保存ALU的运算中间结果</li>
<li>容量比一般专用寄存器大</li>
</ul>
</li>
</ul>
<h2>10.1. CPU的寄存器</h2>
<ul>
<li>用户可见寄存器：CPU执行机器语言访问的寄存器
<ul>
<li>通用寄存器：可由程序设计者指定许多功能，可用于存放操作数，也可用为满足某种寻址方式所需的寄存器</li>
<li>数据寄存器：存放操作数</li>
<li>地址寄存器：存放地址，可用于特殊的寻址方式</li>
<li>条件码寄存器：存放条件码，对用户部分透明，条件码是CPU根据运算结果由硬件设置的位</li>
<li>控制和状态寄存器
<ul>
<li>MAR：存储器地址寄存器、存放将被访问的存储单元的地址</li>
<li>MDR：存储器数据寄存器、存放欲存入存储器中的数据或最近从存储器中读出的数据</li>
<li>PC：程序计数器：存放现行指令的地址，可计数</li>
<li>IR：指令寄存器：存放当前欲执行的指令</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2>10.2. 控制单元和中断系统</h2>
<ul>
<li>控制单元CU是提供完成计算机全部指令操作的微操作命令序列部件</li>
<li>微操作序列形成方法
<ul>
<li>组合逻辑设计方法，为硬连线逻辑</li>
<li>微程序设计方法，为存储逻辑</li>
</ul>
</li>
<li>中断系统
<ul>
<li>处理计算机的各种中断</li>
</ul>
</li>
</ul>
<h2>10.3. 指令周期</h2>
<ul>
<li>指令周期:CPU每取出并执行一条指令所需的全部时间，也是CPU完成一条指令的时间
<ul>
<li>取指周期:完成取指令和分析指令的操作</li>
<li>执行周期:完成执行指令的操作</li>
<li>间址周期:间接寻址指令取操作数有效地址</li>
<li>中断周期:保存程序断点</li>
</ul>
</li>
</ul>
<h1>11. 中断系统</h1>
<h2>11.1. 概述</h2>
<ul>
<li>中断产生原因：为了提高计算机效率。为了处理一些异常情况以及实时控制、多道程序和多处理机的需要</li>
<li>引起中断的各种因素
<ul>
<li>人为设置的中断</li>
<li>程序性事故：如定点溢出</li>
<li>硬件故障：如插件接触不良</li>
<li>I/O设备：I/O设备被启动后，一旦准备就绪，便向CPU发出中断请求</li>
<li>外部事件：用户通过键盘来中断现行程序</li>
</ul>
</li>
<li>中断系统需解决的问题
<ul>
<li>各中断源如何向CPU提出中断请求</li>
<li>当多个中断源同时提出中断请求时，中断系统如何确定优先响应那个中断源的请求</li>
<li>CPU在什么条件、什么时候、以什么方式来响应中断</li>
<li>CPU响应中断后如何保护现场</li>
<li>CPU响应中断后，如何停止原程序的执行而转入中断服务程序的入口地址</li>
<li>中断处理结束后，CPU如何恢复现场，如何回到原程序的间断处</li>
<li>在中断处理过程中又出现了新的中断请求，CPU该如何处理</li>
</ul>
</li>
<li>中断请求标记：为了判断是哪个中断源提出请求，在中断系统中必须设置中断请求标记触发器INTR，当状态为1，表示中断源有请求，这种触发器可集中设在CPU内，组成一个中断请求标记寄存器</li>
</ul>
<h2>11.2. 中断判优逻辑</h2>
<ul>
<li>任何一个中断系统，在任意一个时刻，只能响应一个中断源的请求、各中断源的优先顺序是根据该中断源若得不到及时响应，致使机器工作出错的严重程度而定的。实现方法如下
<ul>
<li>硬件排队：1.链式排队器，对应中断请求触发器分散在各个接口电路中的情况。2.CPU内的排队器</li>
<li>软件排队：通过编写查询程序实现，程序按中断源的优先等级，从高至低逐级查询各中断源是否有中断请求</li>
</ul>
</li>
</ul>
<h2>11.3. 中断服务程序入口地址的寻找</h2>
<ul>
<li>硬件向量法:利用硬件产生向量地址，再由向量地址找到中断服务程序的入口地址.向量地址由中断向量地址部件产生，这个电路课分散设置在各个接口电路中，也可设置在CPU内</li>
<li>软件查询法:用软件寻找中断服务程序入口地址的方法</li>
</ul>
<h2>11.4. 中断响应</h2>
<ul>
<li>响应中断的条件:CPU响应I/O中断的条件时允许中断触发器必须为“1”</li>
<li>响应中断的时间:在指令执行周期结束后，响应任何中断源的请求，因为在执行周期结束时刻统一向所有中断源发中断查询信号，只有此时，CPU才能获知哪个中断源有请求</li>
<li>中断指令操作
<ul>
<li>保护程序断点：将当前程序计数器PC的内容保存到存储器中。它可以存在存储器的特定单元内，也可以存入堆栈</li>
<li>寻找中断服务程序的入口地址
<ul>
<li>第一种，在中断周期内，将向量地址送至PC，使CPU执行下一条无条件转移指令，转至中断服务程序的入口地址</li>
<li>第二种，在中断周期内，将软件查询入口地址的程序首地址送至PC，使CPU执行中断识别程序，找到入口地址</li>
</ul>
</li>
<li>关中断：中断周期内必须自动关中断，以禁止CPU再次响应新的中断请求</li>
</ul>
</li>
<li>保护现场
<ul>
<li>保存程序断点：由中断隐指令完成</li>
<li>CPU内部各寄存器内容的现场：在中断服务程序中由客户或系统用机器指令编程实现</li>
</ul>
</li>
<li>恢复现场<br>
在中断返回前，必须将寄存器的内容恢复到中断处理前的状态，由中断服务程序完成</li>
</ul>
<h2>11.5. 中断屏蔽技术(用于多重中断)</h2>
<ul>
<li>多重中断:当CPU正在执行某个中断服务程序是，另一个中断源又提出了新的中断请求，而CPU又响应了这个新的请求，暂时停止正在运行的服务程序，转去执行新的中断服务程序<br>
实现多重中断条件
<ul>
<li>提前设置“开中断”指令：多重中断的开中断指令的位置前于单重中断，从而保证多重中断允许出现中断嵌套</li>
<li>优先级别高的中断源有权中断优先级别低的中断源：在满足上面的条件才行</li>
</ul>
</li>
</ul>
<h1>12. 控制单元的功能</h1>
<h2>12.1. 微操作命令的分析</h2>
<ul>
<li>控制单元具有发出各种微操作命令（控制信号）序列的功能</li>
<li>取指周期
<ul>
<li>现行指令地址送至存储器地址寄存器 PC-&gt;MAR</li>
<li>向主存发送读命令，启动主存读操作 1-&gt;R</li>
<li>将MAR通过地址总线所指的主存单元中的指令经数据线读至MDR内M(MAR)-&gt;MDR</li>
<li>将MDR的内容送至IR MDR-&gt;IR</li>
<li>指令的操作码送至CU译码 OP(PC)-&gt;CU</li>
<li>形成下一条指令的地址 (PC)+1-&gt;PC</li>
</ul>
</li>
<li>间址周期
<ul>
<li>将指令的地址码部分送至存储器地址寄存器 Ad(IR)-&gt;MAR</li>
<li>向主存发送读命令，启动主存作读操作 1-&gt;R</li>
<li>将MAR通过地址总线所指的主存单元的有效地址经数据总线读至MDR内 M(MAR)-MDR</li>
<li>将有效地址送至指令寄存器的地址字段MDR-&gt;Ad(IR)</li>
</ul>
</li>
<li>执行周期
<ul>
<li>非访存指令
<ul>
<li>清除累加器指令CLA</li>
<li>累加器取反指令COM</li>
<li>算术右移一位指令SHR</li>
<li>循环左移一位指令CSL</li>
<li>停机指令STP</li>
</ul>
</li>
<li>访存指令
<ul>
<li>加法指令ADD X</li>
<li>存数指令STA X</li>
<li>取数指令LDA X</li>
</ul>
</li>
<li>转移类指令
<ul>
<li>无条件转移指令 JMP X</li>
<li>条件转移（负则转）指令BAN</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2>12.2. 中断周期</h2>
<ul>
<li>将特定地址0送至存储器地址寄存器</li>
<li>向主存发写命令，启动存储器写操作</li>
<li>将PC的程序断点送至MDR</li>
<li>将MDR的程序断点通过数据总线写入到MAR通过地址总线所指示的主存单元0地址单元中</li>
<li>将向量地址形成部件的输出送至PC，为下一条指令的取指周期做准备</li>
<li>关中断，将允许中断触发指令清0</li>
</ul>
<h1>13. 计算机指令的执行过程</h1>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/087360e79d3aefd3cb4b5.png" alt="47.PNG" tabindex="0"><figcaption>47.PNG</figcaption></figure>
<ul>
<li>CPU的流水线设计</li>
<li>类似工厂的装配线</li>
<li>工厂的装配线使得多个产品可以同时被加工</li>
<li>在同一个时刻，不同产品位于不同的加工阶段</li>
<li>串行执行m条指令：T1 = 3t x m</li>
<li>流水线执行m条指令：T2 = t x （m+2）</li>
<li>H = T2/T1 = t x (m+2) / 3t x m = 1/3 + 1/3m提高了3倍</li>
</ul>
<h1>CPU实现原子性</h1>
<ul>
<li>
<p>1.总线锁：指将CPU跟内存之间的通信锁住，其他CPU不能操作共享内存中的数据。即当一个CPU访问数据进行操作时，会先向总线发送一个LOCK#信号，如果成功，该CPU会独享这个共享内存直至操作完成或者超时，而此时其他CPU对内存的操作请求会被阻塞。使用LOCK#信号会把CPU与内存之间的通信锁住，使得锁定期间其他CPU无法操作其他内存地址的数据，因此总线锁开销比较大。</p>
</li>
<li>
<p>2.缓存锁: 指将原子操作放在CPU缓存中进行（L1、L2、L3高速缓存）。“缓存锁定”指当发生共享内存的锁定，CPU不会在总线上声明LOCK#信号，而是对CPU的缓存中的缓存行进行锁定，在锁定期间其他CPU不能同时缓存该数据，在修改后，通过缓存一致性保证原子性。</p>
</li>
<li>
<p>3.只能使用总线锁的情况</p>
<ul>
<li>操作的数据不能被缓存在CPU上或操作的数据跨多个缓存行时</li>
<li>处理器不支持</li>
</ul>
</li>
<li>
<p>4.MESI</p>
<ul>
<li>1.MESI协议是实现缓存一致性的在Intel上使用比较广泛的一种协议，缓存行的状态有四种.该协议要求在每个缓存行中维护两个状态位，使得每个数据单元可能处在这四种状态中的一种。
<ul>
<li>Modified(修改)表示缓存行的数据被修改了，但是还没有更新到主内存。处于这一状态的数据，只在本CPU中有缓存数据，其他CPU没有。</li>
<li>Exclusive(独享)表示缓存行中的数据是独有的。处于这一状态的数据，只在本CPU中有缓存，其他CPU没有，且数据与主内存中保持一致。</li>
<li>Share(共享)表示缓存行中的数据是共享的。处于这一状态的数据在多个CPU中都有缓存，且与主内存保持一致。</li>
<li>Invalid(无效)表示缓存行中的数据是无效的。</li>
</ul>
</li>
<li>MESI协议通过对不同的状态增添不同的监听任务保证缓存一致性
<ul>
<li>Modified:处于M状态的缓存行，必须时刻监听所有试图读取该缓存行对应的主内存地址的动作，如果监听到，则必须在此操作将其缓存行中的数据写回主内存，其缓存行状态设置为S。|</li>
<li>Exclusive:处于E状态的缓存行，必须时刻监听所有试图读取该缓存行对应的主内存地址的动作，如果监听到，则必须将其缓存行状态设置为S|</li>
<li>Share:处于S状态的缓存行，必须时刻监听所有试图使该缓存行无效或者独享动作，如果监听到，则必须将其缓存行状态设置为I|</li>
</ul>
</li>
</ul>
</li>
<li>
<p>2.MESI消息<br>
|消息名|消息类型|描述|<br>
|:-😐:-😐:-😐<br>
|Read|请求|通知其他处理器，当前处理器准备主内存某个数据。该消息包含待读取数据的内存地址<br>
|Read|Respond|响应|该消息包含被请求的读取消息的数据，可能是主内存提供的，也可能是嗅探到Read消息的其他处Cache提供，主要看嗅探到Read消息的Cache中缓存行的状态<br>
|Invalidate|请求|通知其他处理器将其高速缓存中指定内存地址对应的缓存行状态置为I<br>
|Invalidate|Acknowledge响应	接收到Invalidate消息的处理器必须回复此响应，以表示删除了其高速缓存上的响应副本（置为I）<br>
|Read|Invalidate|请求|由Read消息和Invalidate消息组合形成。它的作用是通知其它处理，发送该消息的处理器准备更新一个数据，请求其它处理器删除其高速缓存中相应的副本数据。接收到该消息的处理器必须回复Invalidate Acknowledge消息，主内存回复Read Response消息，发送该消息的处理器期望收到一个Read Response以及多个Invalidate Acknowledge|<br>
|Writeback|请求|该消息包含需要写入主内存的数据及其对应的内存地址|</p>
</li>
<li>
<p>3.MESI处理流程</p>
</li>
<li>
<p>MESI协议在数据的读写时，是通过往总线中发送消息请求以及接收响应来保证数据的一致性，以下以两个CPU为例子（CPUA、CPUB）</p>
</li>
<li>
<p>1.数据读流程</p>
<ul>
<li>CPUA需要读取数据X,CPUA首先根据数据的地址在自己的缓存中查找</li>
<li>1.1 如果能找到，并且缓存行状态时M、E、S，说明缓存行的数据对于当前读请求是可用的，直接从缓存行获取地址A对应的数据</li>
<li>1.2 如果找不到或者缓存行的状态是I，CPUA会先总线发送Read消息，其他处理器（CPUB）会监听总线上的消息，收到消息后，从消息中解析出需要读取的地址，然后在自己的缓存中查找缓存行，根据缓存行的状态会出现不同情况
<ul>
<li>1.2.1 状态为S/E , CPUB会构造Read Response消息，将缓存行中的数据放到消息中，发送到总线同时更新自己缓存行的状态为S，CPUA收到响应消息后，会将消息中的数据存入相应的缓存行中，同时更新缓存行的状态为S</li>
<li>1.2.2 状态为M，会先将自己缓存行中的数据写入主内存，并响应Read Response消息同时将缓存行状态更新为S</li>
<li>1.2.3 状态为I或者在自己的缓存中不存在地址A的数据，那么主内存会构造Read Response消息，从主内存读取包含指定地址的块号数据放入消息（缓存行大小和内存块大小一致所以可以存放的下），并将消息发送到总线（⭐怎么判断消息由CPUB发送还是主内存发送）</li>
</ul>
</li>
<li>CPUA获接收到总线消息之后，解析出数据保存在自己的缓存中。</li>
</ul>
</li>
<li>
<p>2.数据写流程(一个处理器的缓存回写到内存会导致其他处理器的缓存无效)</p>
<ul>
<li>CPUA需要对地址A的X数据进行写操作（⭐任何一个处理器执行内存操作时，必须拥有相应数据的所有权）</li>
<li>2.1CPUA首先根据内存地址在自己缓存中查找，根据不同的状态有不同处理
<ul>
<li>2.1.1为E/M时，说明当前CPUA已经拥有了相应数据的所有权，此时CPUA会直接将数据写入缓存行中，并更新缓存行状态为M，此时不需要向总线发送任何消息</li>
<li>2.1.2为S时，说明数据被共享，其它CPU中有可能存有该数据的副本，则CPUA向总线发送Invalidate 消息以获取数据的所有权，其它处理器（CPUB)收到Invalidate消息后,会将其高速缓存中相应的缓存行状态更新为I，表示已经逻辑删除相应的副本数据，并回复Invalidate Acknowledge消息，CPUA收到所有处理器的响应消息后，会将数据更新到相应的缓存行之中，同时修改缓存行状态为E，此时拥有数据的所有权，会对缓存行数据进行更新，最终该缓存行状态为M</li>
<li>2.1.3为I时或者找不到时，则CPUA向总线发送Read Invalidate消息
<ul>
<li>2.1.3.1其它处理器（CPUB）收到Invalidate 消息后，如果缓存行不为I的话，会将其高速缓存中相应的缓存行状态更新为I，表示已经逻辑删除相应的副本数据，并回复``Invalidate Acknowledge`消息</li>
<li>2.1.3.2主内存收到Read消息后，会响应Read Response消息将需要读取的数据告诉CPUA</li>
<li>2.1.3.3CPUA收到所有处理器的Invalidate Acknowledge消息和主内存的Read Response消息后，会将数据更新到相应的缓存行之中，同时修改缓存行状态为E，此时拥有数据的所有权，会对缓存行数据进行更新，最终该缓存行状态为M</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>MESI 协议更复杂，但我们没必要记得这么细。我们只需要记住最关键的 2 点：</p>
<ul>
<li>关键 1 - 阻止同时有多个核心修改的共享数据： 当一个 CPU 核心要求修改数据时，会先广播 RFO 请求获得 Cache 块的所有权，并将其它 CPU 核心中对应的 Cache 块置为已失效状态；</li>
<li>关键 2 - 延迟回写： 只有在需要的时候才将数据写回内存，当一个 CPU 核心要求访问已失效状态的 Cache 块时，会先要求其它核心先将数据写回内存，再从内存读取。</li>
</ul>
</li>
</ul>
]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/2b1b1bc7cd4defb97dd4a.png" type="image/png"/>
    </item>
    <item>
      <title>计算机网络</title>
      <link>https://javaguide.cn/backend/cs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C.html</link>
      <guid>https://javaguide.cn/backend/cs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C.html</guid>
      <source url="https://javaguide.cn/rss.xml">计算机网络</source>
      <description>操作系统 1. 计算机网络概述 1.1. 计算机网络概念 1.2. 计算机网络组成 1.3. 计算机网络功能：数据通信、资源共享、分布式处理、信息综合处理、负载均衡、提高可靠性 1.4. 计算机网络分类 1.5. 计算机网络的体系结构 1.6. 计算机网络性能指标 2. 物理层 2.1. 物理层的基本概念 2.2. 数据通信的基础知识（了解） 2.3....</description>
      <category>理论</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>操作系统</p>
<!--more-->
<!-- TOC -->
<ul>
<li><a href="#1-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%A6%82%E8%BF%B0">1. 计算机网络概述</a>
<ul>
<li><a href="#11-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%A6%82%E5%BF%B5">1.1. 计算机网络概念</a></li>
<li><a href="#12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%BB%84%E6%88%90">1.2. 计算机网络组成</a></li>
<li><a href="#13-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8A%9F%E8%83%BD%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1%E8%B5%84%E6%BA%90%E5%85%B1%E4%BA%AB%E5%88%86%E5%B8%83%E5%BC%8F%E5%A4%84%E7%90%86%E4%BF%A1%E6%81%AF%E7%BB%BC%E5%90%88%E5%A4%84%E7%90%86%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E6%8F%90%E9%AB%98%E5%8F%AF%E9%9D%A0%E6%80%A7">1.3. 计算机网络功能：数据通信、资源共享、分布式处理、信息综合处理、负载均衡、提高可靠性</a></li>
<li><a href="#14-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%88%86%E7%B1%BB">1.4. 计算机网络分类</a></li>
<li><a href="#15-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%9A%84%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84">1.5. <strong>计算机网络的体系结构</strong></a></li>
<li><a href="#16-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%80%A7%E8%83%BD%E6%8C%87%E6%A0%87">1.6. <strong>计算机网络性能指标</strong></a></li>
</ul>
</li>
<li><a href="#2-%E7%89%A9%E7%90%86%E5%B1%82">2. 物理层</a>
<ul>
<li><a href="#21-%E7%89%A9%E7%90%86%E5%B1%82%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5">2.1. 物理层的基本概念</a></li>
<li><a href="#22-%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1%E7%9A%84%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E4%BA%86%E8%A7%A3">2.2. 数据通信的基础知识（了解）</a></li>
<li><a href="#23-%E4%BC%A0%E8%BE%93%E5%AA%92%E4%BD%93">2.3. 传输媒体</a></li>
<li><a href="#24-%E4%BF%A1%E9%81%93%E5%A4%8D%E7%94%A8%E6%8A%80%E6%9C%AF">2.4. 信道复用技术</a></li>
<li><a href="#25-%E7%89%A9%E7%90%86%E5%B1%82%E8%AE%BE%E5%A4%87">2.5. 物理层设备</a></li>
<li><a href="#26-%E8%BF%9E%E6%8E%A5%E7%94%A8%E6%88%B7%E4%B8%8E%E4%BA%92%E8%81%94%E7%BD%91%E7%9A%84%E6%8E%A5%E5%85%A5%E7%BD%91">2.6. 连接用户与互联网的接入网</a></li>
</ul>
</li>
<li><a href="#3-%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82">3. 数据链路层</a>
<ul>
<li><a href="#31-%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82%E6%A6%82%E5%BF%B5">3.1. 数据链路层概念</a></li>
<li><a href="#32-%E5%B9%BF%E5%9F%9F%E7%BD%91%E4%BD%BF%E7%94%A8%E7%82%B9%E5%AF%B9%E7%82%B9%E4%BF%A1%E9%81%93%E7%9A%84%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82">3.2. 广域网使用点对点信道的数据链路层</a></li>
<li><a href="#33-%E5%B1%80%E5%9F%9F%E7%BD%91">3.3. 局域网</a></li>
<li><a href="#34-%E5%B1%80%E5%9F%9F%E7%BD%91%E4%BD%BF%E7%94%A8%E5%B9%BF%E6%92%AD%E4%BF%A1%E9%81%93%E7%9A%84%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82">3.4. 局域网使用广播信道的数据链路层</a></li>
<li><a href="#35-%E4%BB%A5%E5%A4%AA%E7%BD%91%E7%9A%84mac%E5%B1%82%E5%AA%92%E4%BD%93%E6%8E%A5%E5%85%A5%E6%8E%A7%E5%88%B6mac%E5%B1%82">3.5. 以太网的MAC层（媒体接入控制MAC层）</a></li>
<li><a href="#36-%E4%BB%A5%E5%A4%AA%E7%BD%91%E7%9A%84%E6%89%A9%E5%B1%95%E4%BB%8E%E7%BD%91%E7%BB%9C%E5%B1%82%E7%9C%8B%E6%9D%A5%E8%BF%98%E6%98%AF%E4%B8%80%E4%B8%AA%E7%BD%91%E7%BB%9C">3.6. 以太网的扩展(从网络层看来还是一个网络)</a></li>
</ul>
</li>
<li><a href="#4-%E7%BD%91%E7%BB%9C%E5%B1%82">4. 网络层</a>
<ul>
<li><a href="#41-ip%E4%BD%93%E7%B3%BB%E7%9A%84%E7%BD%91%E7%BB%9C%E5%B1%82%E6%8F%90%E4%BE%9B%E7%9A%84%E6%9C%8D%E5%8A%A1%E5%92%8C%E8%99%9A%E6%8B%9F%E4%BA%92%E8%BF%9E%E7%BD%91%E7%BB%9C">4.1. IP体系的网络层提供的服务和虚拟互连网络</a></li>
<li><a href="#42-ip%E5%9C%B0%E5%9D%80%E5%8F%8A%E5%85%B6%E7%BC%96%E5%9D%80%E6%96%B9%E6%B3%95%E4%B8%89%E4%B8%AA%E9%98%B6%E6%AE%B5">4.2. IP地址及其编址方法三个阶段</a></li>
<li><a href="#43-ip%E6%95%B0%E6%8D%AE%E6%8A%A5%E7%BD%91%E7%BB%9C%E5%B1%82%E5%8D%8F%E8%AE%AE%E6%95%B0%E6%8D%AE%E5%8D%95%E5%85%83">4.3. ip数据报(网络层协议数据单元)</a></li>
<li><a href="#44-%E5%9C%B0%E5%9D%80%E8%A7%A3%E6%9E%90%E5%8D%8F%E8%AE%AEarpaddress-resolution-protocol-%E5%90%8C%E4%B8%80%E4%B8%AA%E5%B1%80%E5%9F%9F%E7%BD%91%E8%B7%A8%E7%BD%91%E7%BB%9C%E7%94%B1%E8%B7%AF%E7%94%B1%E5%99%A8%E5%AE%8C%E6%88%90%E8%BD%AC%E5%8F%91">4.4. 地址解析协议ARP（Address Resolution Protocol 同一个局域网，跨网络由路由器完成转发）</a></li>
<li><a href="#45-%E7%BD%91%E7%BB%9C%E6%8E%A7%E5%88%B6%E6%8A%A5%E6%96%87%E5%8D%8F%E8%AE%AE-icmpinternet-control-message-protocol%E4%B8%BA%E4%BA%86%E6%9B%B4%E6%9C%89%E6%95%88%E5%9C%B0%E8%BD%AC%E5%8F%91ip%E6%95%B0%E6%8D%AE%E6%8A%A5%E5%92%8C%E6%8F%90%E4%BA%A4%E4%BA%A4%E4%BB%98%E6%88%90%E5%8A%9F%E7%9A%84%E6%9C%BA%E4%BC%9A">4.5. 网络控制报文协议 ICMP(Internet Control Message Protocol)（为了更有效地转发ip数据报和提交交付成功的机会）</a></li>
<li><a href="#46-%E5%86%85%E9%83%A8%E7%BD%91%E5%85%B3%E5%8D%8F%E8%AE%AE-%E8%B7%AF%E7%94%B1%E4%BF%A1%E6%81%AF%E5%8D%8F%E8%AE%AEriprouting-information-protocol">4.6. 内部网关协议-路由信息协议RIP(Routing Information Protocol)</a></li>
<li><a href="#47-%E5%86%85%E9%83%A8%E7%BD%91%E5%85%B3%E5%8D%8F%E8%AE%AEospfopenshortest-path-first">4.7. 内部网关协议OSPF(OpenShortest Path First)</a></li>
<li><a href="#48-%E5%A4%96%E9%83%A8%E7%BD%91%E5%85%B3%E5%8D%8F%E8%AE%AEbgp">4.8. 外部网关协议BGP</a></li>
<li><a href="#49-%E8%B7%AF%E7%94%B1%E5%99%A8%E7%9A%84%E6%9E%84%E6%88%90">4.9. 路由器的构成</a></li>
<li><a href="#410-%E8%99%9A%E6%8B%9F%E4%B8%93%E7%94%A8%E7%BD%91vpn">4.10. 虚拟专用网VPN</a></li>
<li><a href="#411-%E7%BD%91%E7%BB%9C%E5%9C%B0%E5%9D%80%E8%BD%AC%E6%8D%A2nat-network-address-translation">4.11. 网络地址转换NAT (Network Address Translation)</a></li>
</ul>
</li>
<li><a href="#5-%E8%BF%90%E8%BE%93%E5%B1%82">5. 运输层</a>
<ul>
<li><a href="#51-%E8%BF%90%E8%BE%93%E5%B1%82%E6%A6%82%E8%BF%B0">5.1. 运输层概述</a></li>
<li><a href="#52-%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E6%8A%A5%E5%8D%8F%E8%AE%AEudpuser-datagram-protocol">5.2. 用户数据报协议UDP(User Datagram Protocol)</a></li>
<li><a href="#53-%E4%BC%A0%E8%BE%93%E6%8E%A7%E5%88%B6%E5%8D%8F%E8%AE%AEtcptransmission-control-protocol">5.3. 传输控制协议TCP(Transmission Control Protocol)</a></li>
</ul>
</li>
<li><a href="#6-%E5%BA%94%E7%94%A8%E5%B1%82">6. 应用层</a>
<ul>
<li><a href="#61-%E6%A6%82%E8%BF%B0">6.1. 概述</a></li>
<li><a href="#62-%E5%9F%9F%E5%90%8D%E7%B3%BB%E7%BB%9Fdns">6.2. 域名系统DNS</a></li>
<li><a href="#63-ftpfile-transfer-protocol%E6%96%87%E4%BB%B6%E4%BC%A0%E9%80%81%E5%8D%8F%E8%AE%AE">6.3. FTP(File Transfer Protocol文件传送协议)</a></li>
<li><a href="#64-%E8%BF%9C%E7%A8%8B%E7%BB%88%E7%AB%AF%E5%8D%8F%E8%AE%AEtelnet">6.4. 远程终端协议TELNET</a></li>
<li><a href="#65-%E4%B8%87%E7%BB%B4%E7%BD%91">6.5. 万维网</a></li>
<li><a href="#66-%E8%B6%85%E6%96%87%E6%9C%AC%E4%BC%A0%E9%80%81%E5%8D%8F%E8%AE%AEhttphypertext-transfer-protocol">6.6. 超文本传送协议http(HyperText Transfer Protocol)</a></li>
<li><a href="#67-%E5%8A%A8%E6%80%81%E4%B8%BB%E6%9C%BA%E9%85%8D%E7%BD%AE%E5%8D%8F%E8%AE%AEdhcpdynamic-host-configuration-protocol">6.7. 动态主机配置协议DHCP(Dynamic Host Configuration Protocol)</a></li>
<li><a href="#68-https%E5%8D%8F%E8%AE%AE%E8%AF%A6%E8%A7%A3">6.8. HTTPS协议详解</a></li>
</ul>
</li>
</ul>
<!-- /TOC -->
<h1>1. 计算机网络概述</h1>
<h2>1.1. 计算机网络概念</h2>
<ul>
<li>ISP(Internet Service Provider)：因特网服务提供者（如中国电信等），可以从因特网管理结构申请到很多IP地址。任何机构和个人只要向某个ISP交纳规定费用就能获取IP地址使用权，并可通过该ISP接入互联网.中国通过海底电缆连接外国网络</li>
<li>IXP(Internet eXchagne Point)：因特网交换点，将两个ISP直接连接，不需要通过第三个ISP转发分组，更加有效利用网络资源。一般由一个或多个数据链路层的网络交换机构成的局域网组成，许多ISP再连接到这些网络交换机的相关端口</li>
<li>RFC(Request For Comments)所有的因特网标准都是以RFC的形式在因特网上发表的</li>
<li>计算机网络标准化工作步骤：因特网草案、建议标准、草案标准、因特网标准</li>
<li>计算机网络相关组织：国际标准化组织（ISO）、国际电信联盟（ITU）、美国电气和电子工程师协会（IEEE）等</li>
<li>计算机网络：互连的、自治的计算机系统的集合</li>
<li>AN(Access Network)接入网/本地接入网或居民接入网。接入网是从某个端系统到另一个端系统的路径中，由这个端系统到第一个边缘路由器之间的一些物理链路组成。用户可以使用多种接入网技术连接到因特网ISP</li>
<li>网络协议(network protocol)：为进行网络中数据交换而建立的规则、标准或约定，规定了所交换的数据的格式以及有关的同步问题。由以下三要素组成
<ul>
<li>语法：定义数据和控制信息的结构或格式</li>
<li>语义：定义要发出何种控制信息，完成何种动作以及做出何种响应</li>
<li>同步：即事件实现顺序的详细说明</li>
</ul>
</li>
<li>实体(entity)：任何可以发送和接收信息的硬件或软件进程</li>
<li>对等层：不同机器上的同一层</li>
<li>对等实体：同一层上的实体</li>
<li>协议：控制两个对等实体（或多个实体）进行通信的规则的集合，协议在语法方面的规则定义了所交换的信息的格式；而协议在语义方面的规则就定义了发送者或者接受者所要完成的操作；协议在同步方面规定了收发双方的时序关系，即在一定条件下应当发生什么事件。在协议的控制下，两个对等实体之间的通信使得本层能够向上一层提供服务。要实现本层协议，还需要使用下面一层提供的服务，下面的协议对上面的实体是透明的</li>
<li>服务访问点SAP(Service Access Point)/接口：在同一系统中相邻两层实体进行交互（即交换信息）的地方
<ul>
<li>服务数据单元SDU(Service Data Unit)：第n层的服务数据单元，记作n-SDU 层与层之间交换的数据的单位（层与层之间交换的数据单位）</li>
<li>协议控制信息PCI：第n层的协议控制信息，记作n-PCI</li>
<li>接口控制信息ICI：第n层的接口控制信息，记作n-ICI</li>
<li>协议数据单元PDU(Protocol Date Unit)：n-SDU + n-PCI = n-PDU （对等层次之间传送的数据单位）</li>
<li>接口数据单元IDU：n-SDU + n-ICI = n-IDU</li>
</ul>
</li>
</ul>
<h2>1.2. 计算机网络组成</h2>
<ul>
<li>工作方式组成
<ul>
<li>边缘部分：由所有连接在因特网上的主机/端系统组成，用来进行通信和资源共享；端系统之间的通信(实际是计算机进程间通信)方式分为：
<ul>
<li>终端机器-&gt;路由器-&gt;网关-&gt;地区ISP</li>
<li>终端机器-&gt;路由器-&gt;内部网关-&gt;统一网关-&gt;地区ISP</li>
<li>客户-服务器（C/S）方式：客户是服务的请求方，服务器是服务的提供方。服务的请求方和服务提供方都要使用网络核心部分所提供的服务</li>
<li>对等连接方式（P2P）方式：运行了对等连接软件的两个主机可以平等的、对等连接通信（每个主机既是客户端也是服务端）</li>
</ul>
</li>
<li>核心部分：由大量的网络和连接这些网络的路由器组成，为边缘部分提供连通性和交换服务
<ul>
<li>主干ISP-&gt;国际路由器-&gt;主干ISP</li>
<li>报文(message)：要发送的整块数据</li>
<li>分组/包(packet)：发送报文前把较长的报文划分为一个更小的等长数据段，在每个数据段前面加上必要的控制信息组成的首部/包头(header)后，就构成分组。分组是因特网中传送的数据单元。由于分组中的首部包含了诸如目的地址和源地址等重要控制信息，每个分组才能在因特网中独立地选择路径，并被正确交付到分组传输的终点</li>
<li>路由器是实现分组交换（packet switching）的关键构件，任务是转发收到的分组(网络层的IP数据报)。分组交换采用存储转发技术。路由器收到一个分组，先暂时在存储器(内存)中存储一下，检查其首部，查找转发表，按照首部中的目的地址，找到合适的接口转发出去，把分组交给下一个路由器。这样一步一步地（有时候会经过几十个不同的路由器）以存储转发的方式，把分组交付最终的目的主机。各路由器之间必须经常交换彼此掌握的路由信息，以便创建和维持路由器中的转发表，使得转发表在整个网络拓补发生变化时及时更新。</li>
<li>分组交换在传送数据之前不必占用一条端到端的通信资源，分组在哪段链路上传送时，才占用这段链路的通信资源;分组交换不需要建立连接和释放连接;采用在数据通信过程中断续（或动态）分配传输带宽的策略</li>
<li>分组在各路由器存储转发需要排队，造成一定时延;分组交换无法保证通信时端到端所需的带宽;各分组携带的控制信息造成一定开销。整个分组交换网还需要专门的管理和控制机制</li>
</ul>
</li>
</ul>
</li>
<li>物理组成
<ul>
<li>硬件：由主机、通信处理机（前端处理器）、通信线路（有线线路和无线线路）和交换设备（交换机等连接设备）组成</li>
<li>软件：实现资源共享的软件和方便用户使用的各种工具软件</li>
<li>协议：数据在线路上传输遵循的规则</li>
</ul>
</li>
<li>功能组成
<ul>
<li>通信子网：由各种传输介质、通信设备和相应的网络协议组成，为网络提供数据传输、交换和控制能力，实现联网计算机之间的通信</li>
<li>资源子网：由主机、终端以及各种软件资源、信息资源组成，负责全网的数据处理业务，向网络用户提供各种网络资源与服务</li>
</ul>
</li>
</ul>
<h2>1.3. 计算机网络功能：数据通信、资源共享、分布式处理、信息综合处理、负载均衡、提高可靠性</h2>
<h2>1.4. 计算机网络分类</h2>
<ul>
<li>按网络作用范围分类：广域网WAN(Wide Area Network)、城域网MAN(Metropolitan Area Network)、局域网LAN(Local Area Network)、个人区域网PAN(Personal Area Network)</li>
<li>按使用者分类：公用网(public network)、专用网(private network)</li>
<li>按拓补结构分类：星型网络、总线型网络、环形网络、网状形网络</li>
<li>按传输技术分类：广播式网络、点对点网络</li>
<li>按数据交换技术分类：电路交换网络、报文交换网络、分组交换网络</li>
<li>服务：下层为相邻上层提供的功能调用
<ul>
<li>面向连接的服务TCP：双方通信需要建立通信线路，包括建立连接、使用连接和释放连接3个过程</li>
<li>面向无连接的服务UDP/IP：通信时只需把每个带有目的地址的包（报文分组）传送到线路上，由系统选定路线进行传输</li>
<li>可靠服务：网络具有检错、纠错、应答机制，能保证数据正确、可靠地传送到目的地</li>
<li>不可靠服务：网络不能保证数据正确、可靠地传送到目的地，尽力而为的服务</li>
</ul>
</li>
</ul>
<h2>1.5. <strong>计算机网络的体系结构</strong></h2>
<ul>
<li><strong>计算机网络的体系结构</strong>:计算机网络的各层及其协议的集合/这个计算机网络及其构件所完成的功能的精确定义</li>
<li>计算机网络体系结构分层好处：各层之间是独立的、灵活性好、结构上可以分割开、易于实现和维护、能促进标准化工作<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/006edd2a16af2f7f2b12b.png" alt="24.PNG"></li>
<li>国际标准化组织ISO提出的开放系统互连基本参考模型OSI/RM(Open Systems Interconnection Reference Model)模型：法律上的国际标准（7层协议的体系结构）(了解)</li>
<li><strong>TCP/IP的体系结构</strong>：事实上的国际标准(5层协议的体系结构)
<ul>
<li><strong>应用层(用户对用户)</strong>：应用进程间的通信和交互规则（http、SMTP、FTP协议）使用报文作为数据单元</li>
<li><strong>传输层(应用对应用、进程对进程)</strong>：负责向两个主机进程之间的通信提供通用的数据传输服务（TCP/UDP协议）</li>
<li><strong>网络层(主机对主机)</strong>：负责为分组交换网上的不同主机提供通信服务，把运输层的报文封装成分组或包（IP数据报）</li>
<li><strong>数据链路层</strong>：负责将网络层交下来的IP数据报组成帧</li>
<li><strong>物理层</strong>：确定如何识别发送方的比特流和连接电缆的插头应该有多少引脚以及各条引脚应该如何连接。数据单位比特</li>
</ul>
</li>
</ul>
<h2>1.6. <strong>计算机网络性能指标</strong></h2>
<ul>
<li><strong>比特(bit)</strong>:二进制数字中一个的1或0</li>
<li><strong>速率/比特率</strong>:单位时间内传送的比特数，单位b/s、bit/s、kb/s。网络的<strong>额定速率</strong>.常用单位为Mbps</li>
<li><strong>带宽(bandwidth)</strong>：单位时间内从网络的某一点到另一点所能通过的<strong>最高数据率</strong>。单位b/s、kb/s。表示网络的通信线路传送数据的能力</li>
<li><strong>吞吐量(throughput)</strong>：单位时间内通过某个网络（或信道、接口）的<strong>实际数据量</strong>，有时吞吐量还可以用每秒传送的字节数或帧数表示。受网络的带宽或者网络的额定速率的限制</li>
<li><strong>时延(delay/latency)</strong>：数据（一个报文\分组\比特）从网络（或链路）的一端传送到另一端所需的时间，单位s，包括发送时延、传播时延、处理时延、排队时延
<ul>
<li>发送时延：发送时延 = 数据长度（bit）/发送速率（bit/s）(受限于网卡)</li>
<li>传播时延：传播时延 = 传输路径距离/传播速率(bit/s)（受限于传输介质）</li>
<li>排队时延：排队时延 = 数据包在网络设备中等待被处理的时间</li>
<li>处理时延：数据包到达设备或者目的机器被处理需要的时间</li>
</ul>
</li>
<li><strong>时延带宽积</strong>：传播时延乘以带宽（以比特为单位的链路长度）单位bit</li>
<li><strong>往返时间RTT(Round-Trip Time)</strong>：从发送方发送数据开始，到发送方收到来自接受方的立即发送的确认所需的时间。与发送的分组长度有关.ping命令查看RTT</li>
<li><strong>信道利用率</strong>：某信道有百分之几的时间是被利用的（有数据通过）。完全空闲的信道利用率为0</li>
<li><strong>网络利用率</strong>：全网路的信道利用率的加权平均值，信道或网络利用率太高会产生很大时延</li>
</ul>
<h1>2. 物理层</h1>
<h2>2.1. 物理层的基本概念</h2>
<ul>
<li>物理层的主要任务：确定与传输媒体的接口有关的一些特性
<ul>
<li>机械特性：指明接口所用接线器的形状和尺寸、引脚数目和排列、固定和锁定装置等</li>
<li>电气特性：指明接口电缆的各条线上出现的电压的范围</li>
<li>功能特性：指明某条线上出现的某一电平的电压的意义</li>
<li>过程特性：指明不同功能的各种可能时间的出现顺序</li>
</ul>
</li>
<li>物理层作用：考虑怎样才能在连接各种计算机的传输媒体上传输数据比特流，而不是指具体媒体。屏蔽传输媒体和通信手段的差异，使数据链路层感觉不到.连接不同的物理设备,传输比特流（高低电平、数字信号）</li>
<li>比特流：物理层的传输的单位(数字信号（高低电平）)</li>
</ul>
<h2>2.2. 数据通信的基础知识（了解）</h2>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/1b2277e0e71f845df91ca.png" alt="42.PNG" tabindex="0"><figcaption>42.PNG</figcaption></figure>
<ul>
<li>数据通信系统模型
<ul>
<li>源系统/发送端/发送方
<ul>
<li>源点(source)/源站/信源：源点设备产生要输出的数字比特流</li>
<li>发送器/调制解调器：源点生成的数字比特流要通过发送器编码成模拟信号</li>
</ul>
</li>
<li>传输系统/传输网络/信道：信号的传输媒质</li>
<li>目的系统/接收端/接收方
<ul>
<li>接收器/调制解调器：接收模拟信号进行解调还原成源点产生的数字比特流</li>
<li>终点(destination)/目的站/信宿：终点设备从接收器获取传送过来的数字比特流，然后输出信息</li>
</ul>
</li>
</ul>
</li>
<li>数据(data)：传送消息的实体，通常是有意义的符号序列</li>
<li>码元：在使用时间域的波形表示数字信号时，则代表不同离散数值的基本波形就称为码元</li>
<li>信号(signal)：数据的电气或电磁的表现。根据信号中代表消息的参数取值方式不同分为：
<ul>
<li>模拟/连续/宽带信号：代表消息的参数的取值是连续变化的；将基带信号调制后形成(用户的调制调节器到电话端局之间的用户线上传输的就是模拟信号)</li>
<li>数字/离散/基带信号：代表消息的参数的取值是有限离散的；将数据信号的0和1用不同的电压表示(PC到调制解调器之间，或在电话网中继线上传输的就是数字信号)</li>
</ul>
</li>
<li>信道(channel):用来表示向某一个方向传送信息的媒体，一条通信电路通常包含一条发送信道和一条接收信道</li>
<li>基带信号：来自信源的信号（计算机输出的代表各种文字或图像文件的数据信号都属于基带信号</li>
<li>调制(modulation): 解决基带信号往往包含较多的低频成分，甚至有直流成分，而很多信道并不能传输这种低频分量或直流分量的问题
<ul>
<li>基带调制/编码(coding)：仅对基带信号的波形进行变换，使它能够与信道特性相适应。变换后的信号依然是基带信号;常用曼彻斯特(Manchester)编码方式：产生信号频率高，还具有同步能力，即能从波形本身提取信号时钟频率</li>
<li>带通调制：使用载波进行调制，把基带信号的频率范围搬移到较高的频段，并转换为模拟/带通信号（仅在一段频率范围内能够通过信道）基本的带通调制方法如下
<ul>
<li>调幅(AM) 载波的振幅随基带数字信号而变化</li>
<li>调频(FM) 载波的频率随基带数字信号而变化</li>
<li>调相(PM) 载波的初始相位随基带数字信号而变化</li>
<li>为了达到更高的信息传输速率，必须采用多元制的振幅相位混合调制方法-&gt;正交振幅调制QAM(Quadrature Amplitude Modulation)</li>
</ul>
</li>
</ul>
</li>
<li>数据传输方式
<ul>
<li>串行传输：一个一个比特按照顺序传输（远距离传输）</li>
<li>并行传输：多个比特通过多条通信信道传输（近距离传输）</li>
</ul>
</li>
<li>通信方式
<ul>
<li>同步通信：要求接收端的时钟频率和发送端的时钟频率相等，以便接收端对收到的比特流的采用判决时间是准确的</li>
<li>异步通信：发送数据以字节为单位，发送完一个字节后可以经过任意长的时间间隔再发送下一个字节</li>
</ul>
</li>
<li><strong>信息交互方式</strong>
<ul>
<li><strong>单向通信/单工通信</strong>：只能有一个方向的通信而没有反方向的交互（无线电广播或有线电广播），1个信道</li>
<li><strong>双向交替通信/半双工通信</strong>：双方都可以发送消息，但不能双方同时发送和同时接收，2个信道</li>
<li><strong>双方同时通信/全双工通信</strong>：通信的双方都可以同时发送和接收消息，2个信道</li>
</ul>
</li>
<li>数字通信的优点：在接收端只要能从失真的波形识别出原来的信号，那么这种失真对通信质量就没有影响。码元的传输速率越高，或者信号传输的距离越远，或噪声干扰越大，或传输媒体质量越差，在接收端的波形失真就越严重。</li>
<li><strong>限制码元在信道上传输速率的因素</strong>：
<ul>
<li><strong>信道能通过的频率范围</strong>：<strong>奈奎斯特(Nyquist奈氏)准则</strong>：在任何信道中，码元传输速率是有上限的，传输速率超过此上限，就会出现严重的码间串扰的问题，使接收端对码元的判别成为不可能。如果信道的频带越宽，也就是能够通过的信号高频分量越多，那么就可以用更高的速率传送码元而不出现码间串扰</li>
<li><strong>信噪比</strong>：信号的平均功率和噪声的平均功率之比（S/N），单位分贝(dB)：<strong>香农(Shannon)公式</strong>：信道的带宽或信道中的信噪比越大，信息的极限传输速率越高，只要信息传输速率低于信道的极限信息传输速率，就可以找到某种办法来实现无差错的传输。当码元传输速率达到上限时，可以通过编码的方式让每个码元携带更多比特的信息量来提高信息的传输速率</li>
</ul>
</li>
</ul>
<h2>2.3. 传输媒体</h2>
<ul>
<li><strong>传输媒体/传输介质/传输媒介</strong>，就是数据传输系统中在发送器和接收器中的物理通路
<ul>
<li><strong>引导型传输媒体</strong>：电磁波沿着固体媒体传播：双绞线（网线，双绞为了抑制相邻导线噪声干扰）、同轴电缆（有线电视网）和光纤</li>
<li><strong>非引导型传输媒体</strong>：电磁波在自由空间中传输（无线）：无线电微波通信和红外通信、激光通信</li>
</ul>
</li>
</ul>
<h2>2.4. 信道复用技术</h2>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/4917849a166e641a1cb00.png" alt="43.PNG" tabindex="0"><figcaption>43.PNG</figcaption></figure>
<ul>
<li>提高信道利用率</li>
<li>频分复用FDM(Frequency Division Multiplexing)：按频率划分的不同信道，用户分到一定的频带后，在通信过程中自始至终都占用这个频带，所有用户在同样的时间占用不同的频率带宽</li>
<li>时分复用TDM(Time Division Multiplexing)/同步时分复用：按时间划分为一段段等长的时分复用帧(TMD帧)，每一个时分复用的用户在每一个TDM帧中占用固定序列号的间隙，所有用户是在不同时间占用同样的频带宽度，每个用户占用的频带宽度固定</li>
<li>统计/异步时分复用STDM(Statistic TDM)：所有用户是在不同时间占用同样的频带宽度，每个用户占用的频带宽度根据需要变化</li>
<li>波分复用WDM(Wavelength Division Multiplexing)/光的频分复用：光纤技术中由于光载波的频率很高，因此习惯上用波长而不用频率来表示所用的光载波，故称为波分复用</li>
<li>码分复用CDM(Code Division Multiplexing)：所有用户可以在同样的时间使用同样的频带。各用户使用经过特殊处理的不同码型，因此各个用户之间不会造成干扰</li>
</ul>
<h2>2.5. 物理层设备</h2>
<ul>
<li>中继器：将已经衰减得不完整的信号经过整理，重新产生完整的信号在继续传送，放大的是数字信号</li>
<li>集线器：多个端口的中继器，收到消息后广播到其他计算机，其他计算机判断是否是发给自己的，是自己的就处理</li>
</ul>
<h2>2.6. 连接用户与互联网的接入网</h2>
<ul>
<li>所谓接入网，就是指连接互联网与家庭、公司网络的通信线路 。一般家用的接入网方式包括 ADSL 、FTTH 、CATV、电话线、ISDN 等，公司则还可能使用专线
<ul>
<li>ADSL：Asymmetric Digital Subscriber Line，不对称数字用户线。它是一种利用架设在电线杆上的金属电话线来进行高速通信的技术，它的上行方向（用户到互联网）和下行方向（互联网到用户）的通信速率是不对称的</li>
<li>FTTH：Fiber To The Home，光纤到户。指的是将光纤接入家庭的意思</li>
<li>用户端路由器 发出的网络包通过 ADSL Modem 和电话线到达电话局，然后到达 ADSL 的网络运营商（即 ISP，互联<br>
网服务提供商）。在网络包从用户传输到运营商的过程中，会变换几种不同的形态，</li>
<li>BAS：Broadband Access Server，宽带接入服务器。它也是一种路由器。</li>
<li>PPP：Point-to-Point Protocol，点到点协议。它是电话线、ISDN 等通信线路所使用的一种协议，集成了用户认证、配置下发、数据压缩、加密等各种功能。</li>
<li>ADSL Modem 会把包拆分成很多小格子（图 4.3 ⑦），每一个小格子称为一个信元。信元是一个非常小的数据块，开头是有 5个字节的头部，后面是 48 个字节的数据，用于一种叫作 ATM 的通信技术。ADSL Modem 将包拆分成信元，并转换成电信号发送给分离器。</li>
<li>ATM：Asynchronous Transfer Mode，异步传输。它是在以电话线为载体的传统电话技术基础上扩展出来的一种通信方式。它的数据传输是以“信元”为单位来进行的，这和以包为单位传输数据的 TCP/IP 很像，但这种方式并不适用于计算机通信</li>
<li>将数字信息转换成模拟信号，ADSL 采用的方法要复杂一些。其中有两个原因，一个原因是方波信号的波形容易失真，随着距离的延长错误率也会提高；另一个原因是方波信号覆盖了从低频到高频的宽广频段，信号频率越高，辐射出来的电<br>
磁噪声就越强，因此信号频谱太宽就难以控制噪声。ADSL Modem 采用了一种用圆滑波形（正弦波）对信号进行合成来表示 0 和 1 的技术，这种技术称为调制。调制有很多方式，ADSL 采用的调制方式是振幅调制（ASK）和相位调制（PSK）相结合的正交振幅调制（QAM） 方式（振幅调制是用信号的强弱，也就是信号振幅的大小来对应 0 和 1 的方式。如图 4.4（b），振幅小的信号为0，振幅大的信号为 1，如果将振幅增加到 4 个级别，则振幅从小到大可分别对应<br>
00、01、10 和 11，这样就可以表示两个比特了。不过，信号会在传输过程中发生衰减，也会受到噪声影响而失真，如果振幅级别太多，接收方对信号的识别就容易出错，因此振幅级别也不能太多。另一个组成要素是相位调制，这是一种根据信号的相位来对应 0 和 1 的方式。Modem 产生的信号是以一定周期振动的波，如图 4.5 所示，振动的起始位置不同，波的形状也就不同。如果将波的一个振动周期理解为一个圆，则起始位置就可以用 0 度到 360 度的角度来表示，这个角度就是相位，用角度来对应 0 和 1 的方式就叫作相位调制。例如，从 0 度开始的波为 0，从 180 度开始的波为 1，这是一种最简单的对应关系，ADSL 使用的正交振幅调制就是将前面这两种方式组合起来实现的。正交振幅调制就可以用一个波表示更多的比特，从而提高传输速率。正交振幅调制中，通过增加振幅和相位的级别，就可以增加能表示的比特数。例如，如果振幅和相位各自都有 4 个级别，那么组合起来就有 16 个级别，也就可以表示 4 个比特的值。当然，和单独使用振幅调制或相位调制的情况一样，级别过多就容易发生误判，因此这种方法提升的速率是有限度的。）</li>
<li>信号是一个频率的波，不同频率的波可以合成，也可以用滤波器从合成的波中分离出某个特定频率的波。因此，我们可以使用多个频率合成的波来传输信号，这样一来，能够表示的比特数就可以成倍提高了。ADSL 使用间隔为 4.3125 kHz 的上百个不同频率的波进行合成，每个波都采用正交振幅调制，而且，根据噪声等条件的不同，每个波表示的比特数是可变的。也就是说，噪声小的频段可以给波分配更多的比特，噪声大的频段则给波分配较少的比特 ，每个频段表示的比特数加起来，就决定了整体的传输速率。ADSL 技术中，上行方向（用户到互联网）和下行方向（互联网到用户）的传输速率是不同的，原因也在这里。如果上行使用 26 个频段，下行则可以使用 95 个或者 223 个频段，波的数量不同，导致了上下行速率不同。当然，下行使用的频段较高，这些信号容易衰减而且更容易受到噪声的影响，因此这些频段可能只能表示较少的比特数，或者干脆无法传输信号。距离越远，频率越高，这种情况也就越显著，因此如果你家距离电话<br>
局太远，速率就会下降。噪声和衰减等影响线路质量的因素在每条线路上都不同，而且会随着时间发生变化。因此，ADSL 会持续检查线路质量，动态判断使用的频段数量，以及每个频段分配到的比特数。具体来说，当 Modem 通电后，会发送测试信号，并根据信号的接收情况判断使用的频段数量和每个频段的比特数，这个过程称为训练（握<br>
手），需要几秒到几十秒的时间。</li>
<li>要通过分离器将传入的信号分离，以确保 ADSL 信号不会传入电话机。具体来说，分离器的功能是将一定频率以上的信号过滤掉，也就是过滤掉了 ADSL 使用的高频信号，这样一来，只有电话信号才会传入电话机，但对于另一头的 ADSL Modem，则是传输原本的混合信号给它。ADSL Modem 内部已经具备将 ADSL 频率外的信号过滤掉的功能，因此不需要在分离器进行过滤，如果ADSL 通信过程中拿起话筒导致线路状态改变，就需要重新训练（握手），这就会导致几十秒的通信中断，分离器可以防止发生这样的问题。</li>
<li>信号通过电话线到达电话局之后，会经过配线盘、分离器到达 DSLAM （图 4.3 ⑨）。在这里，电信号会被还原成数字信息——信元（图 4.3 ⑩）。 DSLAM 通过读取信号波形，根据振幅和相位判断对应的比特值，将信号还原成数字信息，这一过程和用户端的 ADSL Modem 在接收数据时的过程是一样的。因此，如果在电话局里安装一大堆和用户端一样的 ADSL Modem，也可以完成这些工作，只不过安装这么多 Modem需要占用大量的空间，而且监控起来也非常困难。因此，电话局使用了 DSLAM 设备，它是一种将相当于很多个 ADSL Modem 的功能集中在一个外壳里的设备。</li>
<li>DSLAM：DSL Access Multiplexer，数字用户线接入复用设备。它是一种电话局用的多路 ADSL Modem，可以理解为将多个 ADSL Modem 整合在一个外壳里的设备。DSLAM 具有 ATM 接口，和后方路由器收发数据时使用的是原始网络包拆分后的 ATM 信元形式</li>
<li>BAS 负责将 ATM 信元还原成网络包并转发到互联网内部。</li>
</ul>
</li>
<li>光纤接入网（FTTH）
<ul>
<li>光信号亮表示 1，暗表示 0.先将数字信息转换成电信号，然后再将电信号转换成光信号。这里的电信号非常简单，1 用高电压表示，0 用低电压表示。将这样的电信号输入 LED、激光二极管等光源后，这些光源就会根据信号电压的变化发光，高电压发光亮，低电压发光暗。这样的光信号在光纤中传导之后，就可以通过光纤到达接收端。接收端有可以感应光线的光敏元件，光敏元件可以根据光的亮度产生不同的电压。当光信号照射到上面时，光亮的时候就产生高电压，光暗的时候就产生低电压，这样就将光信号转换成了电信号。最后再将电信号转换成数字信息，我们就接收到数据了。</li>
<li>光源在所有方向上都会发光，因此会有各种角度的光线进入纤芯，但入射角度太大的光线会在纤芯和包层（纤芯外沿部分）的边界上折射出去，只有入射角较小的光线会被包层全反射，从而在纤芯中前进.光也是一种波，因此光也有如图 4.5 中那样的相位，当光线在纤芯和包层的边界上反射时，会由于反射角产生相位变化。当朝反射面前进的光线和被反射回来的光线交会时，如果两条光线的相位不一致，就会彼此发生干涉抵消，只有那些相位一致的光线才会继续在光纤中传导。光在被纤芯和包层的边界反射时，相位会发生变化。这个变化的量随光在反射面的反射角度不同而不同，大多数角度下，都会因为相位不同而被干涉抵消。不过，有几个特定的角度下，向反射面前进的光和反射回来的光的相位是一致的，只有以这些角度反射的光才能继续向前传导（图 4.13）。进入光纤的光线有各种角度，但其中，只有少数按照特定角度入射以保持相位一致的光线才会继续传导。</li>
<li>光纤可以划分成几种类型，大体上包括较细的单模光纤（8～10 μm）和较粗的多模光纤（50 μm 或 62.5 μm）。单模光纤的纤芯很细，只有入射角很小的光线才能进入，因此在能够保持相位一致的角度中，只有角度最小的光线能进入光纤。反过来可以说，单模光纤的纤芯直径就是按照只允许相位一致的最小角度的光进入而设计的。多模光纤的纤芯比较粗，入射角比较大的光也可以进入，这样一来，在相位一致的角度中，不仅角度最小的可以在光纤中传导，其他角度更大一些的也可以，也就是说，可以有多条光线在纤芯中同时传导。换句话说，单模和多模实际上表示相位一致的角度有一个还是多个</li>
<li>多模光纤中可以传导多条光线，这意味着能通过的光线较多，对光源和光敏元件的性能要求也就较低，从而可以降低光源和光敏元件的价格。相对地，单模光纤的纤芯中只能传导一条光线，能通过的光线较少，相应地对于光源和光敏元件的性能要求就较高，但信号的失真会比较小。</li>
<li>信号失真与光在纤芯传导时反射的次数相关。多模光纤中，多条反射角不同的光线同时传导，其中反射角越大的光线反射次数越多，走过的距离也就越长；相对地，反射角越小的光线走过的距离越短。光通过的距离会影响其到达接收端的时间，也就是说，通过的距离越长，到达接收端的时间越长。结果，多条光线到达的时间不同，信号的宽度就会被拉伸，这就造成了失真。因此，光纤越长，失真越大，当超过允许范围时，通信就会出错（图 4.15）。相对地，单模光纤则不会出现这样的问题。因为在纤芯传导的光线只有一条，不会因为行进距离的差异产生.时间差，所以即便光纤很长，也不会产生严重的失真。光纤的最大长度也是由上述性质决定的。单模光纤的失真小，可以比多模光纤更长，因此多模光纤主要用于一座建筑物里面的连接，单模光纤则用于距离较远的建筑物之间的连接。FTTH 属于后者，因此主要使用单模光纤。</li>
<li>FTTH ，从形态上可大致分为两种.一种是用一根光纤直接从用户端连接到最近的电话局（图 4.16（a））。这种类型的 FTTH 中，用户和电话局之间通过光纤直接连接，网络包的传输方式如下。首先，用户端的光纤收发器(将以太网的电信号转换成光信号的设备，也叫“终端盒”) 将以太网的电信号转换成光信号。这一步只进行电信号到光信号的转换，而不会像 ADSL 一样还需要将包拆分成信元，大家可以认为是将以太网包原原本本地转换成了光信号。接下来，光信号通过连接到光纤收发器的光纤直接到达BAS 前面的多路光纤收发器。FTTH 一般使用单模光纤，因此其纤芯中只有特定角度的光信号能够反射并前进。然后，多路光纤收发器将光信号转换成电信号，BAS 的端口接收之后，将包转发到互联网内部。把网络包发送到互联网之后，服务器会收到响应，响应包的光信号也是沿着同一条光纤传输到用户端的。这里，前往互联网的上行光信号和前往用户的下行光信号在光纤中混合在一起，信号会变得无法识别，因此我们需要对它们进行区分，办法是上行和下行信号采用不同波长的光。波长不同的光混合后可通过棱镜原理进行分离，因此光纤中的上行和下行信号即便混合起来也可以识别。像这样在一条光纤中使用不同的波长传输多个光信号的方式叫作波分复用.另一种光纤的接入方式是在用户附近的电线杆上安装一个名为分光器的设备，通过这个设备让光纤分路，同时连接多个用户 （图 4.16（b））。在这种方式下，用户端不使用光纤收发器，而是使用一个叫作ONU 的设备，它将以太网的电信号转换成光信号之后，会到达 BAS 前面的一个叫作 OLT 的设备。光信号的传导方式和刚才介绍的直连方式是一样的，但有一点不同，因为多个用户同时收发网络包时信号会在分光器产生碰撞。因此， OLT 和 ONU 中具备通过调整信号收发时机来避免碰撞的功能。具体来说， OLT 会调整信号发送时机并向 ONU 下发指令，ONU 则根据 OLT 的指令来发送数据。反过来，当 BAS 端向用户发送数据时，分光器只需要将信号发给所有用户就可以了，这里并不会发生碰撞，但这样做会导致一个用户收到其他所有用户的信号，造成信息泄露的问题，因此需要在每个包前面加上用于识别 ONU 的信息，当ONU 收到信号后，会接收发给自己的信号并将其转换成以太网信号(通过光纤分路连接多个用户的光纤接入模式统称为 PON（Passive Optical Network，无源光网络），可分为 GE-PON、WDM-PON、B-PON、G-PON 等多种方式，现在大多使用最高速率为 1 Gbit/s 的 GE-PON 方式。ONU：Optical Network Unit，光网络单元。它和光纤收发器一样，可以将电信号转换成光信号，除此之外还具有和电话局的 OLT 相互配合避免信号碰撞的功能。这个设备有时也被叫作终端盒，因此终端盒这个词本身是对光纤收发器和 ONU 等光纤终端设备的统称。)</li>
</ul>
</li>
</ul>
<p><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/4b09022d9497be0d42775.png" alt="48.PNG"><br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/b67214c5ba95462379b7a.png" alt="49.PNG"></p>
<h1>3. 数据链路层</h1>
<h2>3.1. 数据链路层概念</h2>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/c97b0b9b567e71323152a.png" alt="44.PNG" tabindex="0"><figcaption>44.PNG</figcaption></figure>
<ul>
<li>研究在同一个局域网中，分组怎样从一个主机传送到另一个主机（不经过路由器）</li>
<li><strong>链路(link)</strong>：从一个站点到相邻节点的一段物理线路（有线或者无线），而中间没有任何其他的交换结点。</li>
<li><strong>数据链路(data link)</strong>：物理线路和实现通信协议的硬件或者软件构成了数据链路</li>
<li><strong>网络适配器</strong>：既有硬件，也有软件实现了数据链路协议，包括了数据链路层和物理层两个功能</li>
<li><strong>帧</strong>：数据链路层的协议数据单元，数据链路层的数据的基本单位,物理层只传输比特流、不管"帧"</li>
<li><strong>数据链路层使用的信道类型</strong>：
<ul>
<li>点对点信道:使用一对一的点对点通信方式</li>
<li>广播信道：使用一对多的广播通信方式</li>
</ul>
</li>
<li>数据链路层把网络层交下来的IP数据报构成帧发送到链路上，以及把接收到的帧中的数据取出并上交给网络层</li>
<li>数据链路层协议的三个问题
<ul>
<li><strong>封装成帧(framing)</strong>：在网络层的IP数据报的前后分别添加首部和尾部，这样就构成了帧，接收端在收到物理层上交比特流后，就能根据首部和尾部的标记，从收到的比特流中识别帧的开始和结束。一个帧的长度等于数据部分加上帧首部和帧尾部的长度。然后交给物理层传输
<ul>
<li>最大传送单元（MTU Maximum Transfer Unit）：帧的数据部分长度上限；为了提高帧的传输效率，应当使帧的数据部分长度尽可能地大于首部和尾部的长度。过小:次数太多，会影响传输的效率，数据帧过大:时延太大。MTU一般为1500字节</li>
<li>帧定界：帧首部控制字符SOH(Start Of Header)放在帧的最前面表示帧开始，帧尾部控制字符EOT(End Of Transmission)表示帧的结束，接收方收到帧不完整时（只有开始无结束）必须丢弃</li>
<li>注意:当数据是由可打印的ASCII码组成的文本文件时，SOH二进制编码为00000001。EOT二进制编码为00000100</li>
</ul>
</li>
<li><strong>透明传输</strong>:无论什么样的比特组合的数据都能够通过这个数据链路层
<ul>
<li>本质：使数据中出现的控制字符"SOH"和"EOT"在接收端不被解释为控制字符</li>
<li>当传送的帧是文本文件（键盘上输入）组成的帧时不可能出现帧定界控制符，而二进制的计算机程序或图像可能</li>
<li>字节填充(byte stuffing)/字符填充(character stuffing):发送端的数据链路层在数据中出现控制字符“EOT”或”SOH“时没在其前面插入一个转义字符”ESC“(00011011)，而在接收端的数据链路层再把数据送往网络层之前删除这个转义字符，如果转义字符也出现在数据中那么在转义字符前面再插入一个转义字符，当接收到两个转义字符的时候把前面的那个删除掉就行</li>
</ul>
</li>
<li><strong>差错检测</strong>：比特在传输过程中产生的错误(收到干扰产生)
<ul>
<li>传输差错：比特差错、帧丢失、帧重复、帧失序</li>
<li>比特差错：1可能变成0,0可能变成1</li>
<li>误码率BER(Bit Error Rate)：在一段时间内，传输错误的比特所占的比特总数，信噪比越高，误码率越小</li>
<li>比特差错检测办法：循环冗余检验CRC，为进行检错添加冗余码称为帧检验序列FCS</li>
<li>在数据链路层使用CRC循环冗余检验(Cyclic Redundancy Check)，能够实现的是无比特差错传输，而不是可靠传输（没有重传）</li>
<li>数据链路层只进行数据的检测，不进行纠正（错误直接丢弃）</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2>3.2. 广域网使用点对点信道的数据链路层</h2>
<ul>
<li>通信的主要步骤
<ul>
<li>结点A的数据链路层把网络层交下来的ip数据报添加首部和尾部封装成帧</li>
<li>结点A把封装好的帧发送给结点B的数据链路层</li>
<li>若结点B的数据链路层收到的帧无差错，则从收到的帧中提取出ip数据报上交给上面的网络层；否则丢弃这个帧</li>
</ul>
</li>
<li>点对点协议PPP(Point-to-Point Protocol)
<ul>
<li>PPP协议组成
<ul>
<li>用户计算机和ISP进行通信时的数据链路层协议</li>
<li>一个将ip协议封装到串行链路的方法：PPP既支持异步链路（无奇偶校验的8比特数据），也支持面向比特的同步链路，ip数据报在PPP帧中就是信息部分，其的长度受最大传送单元的MTU限制</li>
<li>一个用来建立、配置和测试的数据链路连接的链路控制协议LCP(Link Control Protocol)，通信的双方可以协商一些选项</li>
<li>一套网络控制协议NCP(Network Control Protocol)，其中的每一个协议支持不同的网络层协议</li>
</ul>
</li>
<li>PPP协议的帧格式<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/6a68bf17cb131382f3cb1.png" alt="1.png">
<ul>
<li>ppp帧首部
<ul>
<li>标志字段F(Flag)：规定为0x7E（01111110），表示一个帧的开始，帧定界符</li>
<li>地址字段A：规定为0xFF（11111111）</li>
<li>控制字段C：规定为0x03（00000011）</li>
<li>协议字段：2字节，为0x0021时，PPP帧的信息字段就是IP数据报。0xC021时，PPP链路控制协议LCP；0x8021时，网络层的控制数据。</li>
</ul>
</li>
<li>信息字段的长度是可变的，不超过1500字节</li>
<li>PPP帧尾部
<ul>
<li>尾部中的第一字段（2字节）是使用CRC的帧检验序列FCS</li>
<li>标志字段F，规定为0x7E(01111110)，表示一个帧的结束。</li>
</ul>
</li>
</ul>
</li>
<li>PPP协议透明传输实现方式
<ul>
<li>当PPP使用异步传输（逐个字符地传送）时，把转义符定义为0x7D（01111101），此时使用字节填充实现透明传输，转义算法为当 0x7d 出现在数据中时，紧接着的字符的第 6 个比特要取其补码，即与 0x20 做异或运算。RFC1662规定：
<ul>
<li>0x7E字节转成2字节序列（0x7D，0x5E）</li>
<li>0x7D字节（出现了和转义字符一样的比特组合）转变成2字节序列（0x7D，0x5D）</li>
<li>ASCII码的控制字符（即数值小于0x20的字符），则在该字符前面需要加入0x7D字节，同时将该字符的编码加以改变。例如出现0x03(在控制字符中是“传输结束”EXT）就要把它转变为2字节序列（0x7D，0x23）</li>
</ul>
</li>
<li>当PPP协议在SONET/SDH链路使用同步传输（一连串的比特连续传送），采用零比特传输实现透明传输
<ul>
<li>在发送端，扫描整个信息字段，只要发现有5个连续的1，则立即填入一个0（硬件实现），接收端收到5个连续1时，把后面的0删除还原成原来的信息比特流</li>
</ul>
</li>
</ul>
</li>
<li>PPP协议工作过程
<ul>
<li>当用户拨号接入ISP后，就建立了一条从用户PC到ISP的物理连接。用户PC向ISP发送一系列的链路控制协议LCP分组，以便建立LCP连接。这些分组及其响应选择了将要使用的一些PPP参数，然后进行网络层配置，网络控制协议NCP给新接入的用户PC分配一个临时的IP地址,DNS服务器地址以及默认网关的IP地址。这样PC用户就称为因特网上的一个有IP地址的主机了.当用户通信完毕时，NCP释放网络层连接，收回原来分配出去的IP地址。LCP释放数据链路层连接。最后释放的是物理层的连接。</li>
<li>PPP链路的起始和终止状态永远是链路静止(Link Dead)状态，这时在用户PC和ISP的路由器之间并不存在物理层的连接</li>
<li>当用户PC通过调制调节器呼叫路由器（点击拨号）时，<strong>用户名和密码通过 RADIUS（远程用户拨号认证系统，包括pap和chap） 协议从 RAS 发送到认证服务器</strong>,路由器就能够检测到调制调解器发出的载波信号。在双方建立物理层连接后，PPP进入"链路建立"状态(Link Establish)。</li>
<li>LCP开始协商一些配置选项，即发送LCP的配置请求帧(Configure-Request)（PPP帧，协议字段为LCP对应代码），包括链路上的最大帧长，所使用的的鉴别协议(authentication protocol)的规约（如果有的话），以及不适使用PPP帧中的地址和控制字段（因为这两个字段的值是固定的，没有任何信息量，可以忽略）</li>
<li>链路的另一端可以发送一下几种响应中的一种
<ul>
<li>配置确认帧(Configure-Ack)：所有选项都接受</li>
<li>配置否认帧(Configure-Nak)：所有选项都理解但不接受</li>
<li>配置拒绝帧(Configure-Reject)：选项里面有的无法识别或不能接受，需要协商</li>
</ul>
</li>
<li>协商结束后双方建立了LCP链路，接着进入"鉴别"(Authenticate)状态，只允许传送LCP协议的分组，鉴别协议的分组以及监测链路质量的分组。
<ul>
<li>若使用口令兼备协议PAP，则需要发起通信的一方发送身份标识符和口令，系统可允许用户重试若干次</li>
<li>如果需要有更好的安全性。则可使用握手鉴别协议CHAP。</li>
</ul>
</li>
<li>若身份鉴别失败。则转到链路终止状态。若鉴别成功，则进入网络层协议状态(Network layer)（PPP链路的两端的网络控制协议NCP根据网络层的不同协议互相交换网络层特定的网络控制分组）PPP协议两端的网络层可以运行不同的网络层协议，但仍然可使用同一个PPP协议进行通信
<ul>
<li>（了解）如果在PPP链路上运行的是IP协议，则对PPP链路的每一段配置IP协议模块（如分配IP地址）时就要使用NCP中支持IP的协议-IP控制协议IPCP。IPCP分组也封装成PPP帧（协议字段为0x8021）在PPP链路上传送。在低速链路上运行时，双方还可以协商使用压缩的TCP和IP首部，以减少在链路上发送的比特数</li>
</ul>
</li>
<li>网络层配置完毕后，链路进入可进行数据通信的"链路打开"状态。链路的两个PPP断点可以彼此向对方发送分组。两个PPP端点还可发送会送请求LCP分组和回送回答LCP分组，以检查链路的状态</li>
<li>数据传输结束后可以有链路的一段发出终止请求LCP分组）(Terminate-Request)请求终止链路连接，在收到对方发来的终止确认LCP分组(Terminate-Ack)后，转到LCP链路终止状态，如果链路出现故障，也会从链路打开状态转到链路终止状态，当调制调解器的载波停止后，回到链路静止状态</li>
<li>PPPoE 是将 PPP 消息装入以太网包进行传输的方式</li>
<li>通过隧道将网络包发送给运营商.隧道有几种实现方式.TCP 连接就是其中一种实现方式（图 4.19（a））。这种方式中，首先需要在网络上的两台隧道路由器 之间建立 TCP 连接，然后将连接两端的套接字当作是路由器的端口，并从这个端口来收发数据。换句话说，在路由器收发包时，是基于隧道的规则向隧道中放入或取出网络包，这时，TCP 连接就好像变成了一根网线，包从这里穿过到达另一端.基于封装（encapsulation）的隧道实现方式，这种方式是将包含头部在内的整个包装入另一个包中传输到隧道的另一端。在这种方式中，包本身可以原封不动地到达另一端的出口</li>
<li>互联网接入路由器在转发包时需要进行地址转换<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/b59468b6af5bf95567787.png" alt="3.png">	<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/ecca2b702dfa139bc55bb.png" alt="50.PNG"></li>
</ul>
</li>
</ul>
</li>
</ul>
<h2>3.3. 局域网</h2>
<ul>
<li>局域网最主要的特点：就是网络为一个单位所拥有，且地理范围和站点数目均有限。</li>
<li>局域网的主要优点
<ul>
<li>具有广播功能，从一个站点可方便地访问全网。局域网上的主机可共享连接在局域网上的各种硬件和软件资源</li>
<li>便于系统的扩展和逐渐地演变，各设备的位置可灵活地调整和改变</li>
<li>提高系统的可靠性(reliability)、可用性(availibility)、生存性(survivability)</li>
</ul>
</li>
<li>局域网可按网络拓扑进行分类<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/be0dea012e5a83f9b0661.png" alt="30.png">
<ul>
<li>星形网：由于集线器(hub)的出现和双绞线大量用于局域网中，星形以太网和多级星形结构的以太网获得了非常广泛的应用</li>
<li>环形网： 最典型的就是令牌环形网(token ring)，简称为令牌环。</li>
<li>总线网：各站直接连在总线上。总线两端的匹配电阻吸收在总线上传播的电磁波信号的能量，避免在总线上产生有害的电磁波反射</li>
</ul>
</li>
<li>共享信道的方法
<ul>
<li>静态划分信道(代价高，不适合于局域网使用)用户只要分配到了信道就不会和其他用户发送冲突。如频分复用</li>
<li>动态媒体接入控制/多点接入(multiple access) （信道并非在用户通信时固定分配给用户）
<ul>
<li><strong>随机接入</strong>：所有用户可随机地发送信息。但如果恰巧有两个或更多的用户在同一时刻发送信息，那么在共享媒体上就要发生碰撞(发生了冲突)，使得这些用户的发送都失败。因此必须有解决碰撞的网络协议</li>
<li>受控接入：用户不能随机地发送信息而必须服从一定的控制。分为分散控制的令牌环局域网和集中控制的多点线路探询(polling)/轮询。</li>
</ul>
</li>
</ul>
</li>
<li>通信适配器的作用（网络接口卡NIC(Network Interface Card)或网卡，装有处理器和存储器RAM和ROM，)
<ul>
<li>插入主板时，需要把管理该适配的器的设备驱动程序安装在计算机操作系统中。这个驱动程序以后就会告诉适配器，应当从存储器什么位置上把多长的数据块发送到局域网，或者应当在存储器的什么位置上把局域网传送过来的数据块存储下来</li>
<li>进行数据串行传输和并行传输的转换：适配器和局域网之间的通信是通过电缆或双绞线以串行传输方式进行的，和计算机之间的通信则是通过计算机主板上的I/O总线以并行传输方式进行的。</li>
<li>由于网络上的数据率和计算机总线上的数据率并不相同，所以在适配器中必须装有对数据进行缓存的存储芯片</li>
<li>实现以太网协议。适配器包含了数据链路层和物理层两层次的功能</li>
<li>适配器接收和发送各种帧时不使用计算机的CPU。这时CPU可以处理其他任务。当适配器收到有差错的帧时，就把这个帧丢弃而不必通知计算机。当适配器收到正确的帧时，它就使用中断来通知该计算机并交付给协议栈中的网络层。当计算机要发送IP数据报时，就由协议栈把IP数据报向下交给适配器，组装成帧后发送到局域网。</li>
<li>计算机的硬件地址——MAC地址，就在适配器的ROM中，生产时已经写入。计算机的软件地址——IP地址，就在计算机的存储器中</li>
<li><strong>网卡并不是通上电之后就可以马上开始工作的，而是和其他硬件一样，都需要进行初始化。也就是说，打开计算机启动操作系统的时候，网卡驱动程序会对硬件进行初始化操作，然后硬件才进入可以使用的状态。这些操作包括硬件错误检查、初始设置等步骤，这些步骤对于很多其他硬件也是共通的，但也有一些操作是以太网特有的，那就是在控制以太网收发操作的 MAC 模块中设置 MAC 地址。读取 MAC 地址的操作是由网卡驱动程序来完成的，因此网卡驱动程序也可以不从网卡 ROM 中读取地址，而是将配置文件中设定的 MAC 地址拿出来放到内存中并用于设定 MAC 头部，或者也可以通过命令输入 MAC 地址。网卡中保存的 MAC 地址会由网卡驱动程序读取并分配给MAC模块。</strong></li>
</ul>
</li>
</ul>
<h2>3.4. 局域网使用广播信道的数据链路层</h2>
<ul>
<li>使用原因：同一时间只允许一台计算机发送数据，否则各计算机会相互干扰，发送数据被破坏。随着交换式集线器（交换机）普及，信号已经不会发生碰撞了）</li>
<li>为了通信方便，以太网采取了以下两种措施
<ul>
<li>采用较为灵活的无连接的工作方式，即不必先建立连接就可以直接发送数据，适配器对发送的数据帧不进行编号，也不要求对方发回确认。以太网提供的服务是尽最大努力的交付，即不可靠的交付；当目的站收到由差错的数据帧时就丢弃。对有差错帧是否需要重传则由高层来决定，以太网并不知道重传帧，而是当做新的数据帧来发送；总线上只要有一台计算机在发送数据，总线的传输资源就会被占用，在同一时间只能允许一台计算机发送数据；否则各计算机之间就会互相干扰，使得所发送数据被破坏，以太网使用最简单的随机接入，解决冲突的协议是：CSMA/CD，载波监听多点接入/碰撞检测(Carrier Sense Multiple Access with Conllsion Detection)</li>
<li>以太网发送的数据都是使用曼彻斯特编码的信号。二进制基带数字信号通常就是高，低电压交替出现的信号；这种信号最大的问题就是当出现一长串连1或0时，接收端无法从接收到的比特流中提取位同步（比特同步）信号；而曼彻斯特编码方法是把每一个码元分成两个相等的间隔，码元1是在前一个间隔为低电压，而后一个间隔为高电压，码元0刚好相反（1是“前高后低”，而0是“前第后高”），曼彻斯特编码的缺点是，它所占的频带宽度比原始的基带信号增加了一倍（因为每秒传送的码元加倍了）<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/b4888f40d9536a83c09e5.png" alt="45.PNG"></li>
</ul>
</li>
<li>CSMA/CD协议的要点：
<ul>
<li>“多点接入”：总线型网络，许多计算机以多点接入的方式连接在一根总线上。</li>
<li>“载波监听”：每个站必须不停地用电子技术检测信道。发送前检测为了获得发送权，发送中检测为了发现有没有其他站的发送和本站发送的碰撞</li>
<li>“碰撞检测”：边发送边监听；当几个站同时在总线上发送数据时，总线上的信号电压变化幅度将会增大（相互叠加），当适配器检测到的信号电压变化幅度超过一定的门限值时，就认为总线上至少有两个站同时在发送数据，表明产生了碰撞；这时，总线上传输的信号产生严重的失真，无法从中恢复出有用的信息，此时其适配器就要立即停止发送，经过一段随机时间再发</li>
<li>虽然每一个站在发送数据之前已经监听到信道为"空闲"，但电磁波在总线上总是以有限的速率传播，导致数据还会在总线上碰撞</li>
<li>总线上的单程端到端传播时延记为τ，发送数据后最迟要经过2τ（两倍的总线端到端的往返传播时延）才能知道自己发送的数据和其他站发送的数据有碰撞，因此，以太网端到端往返时间2r称为争用期contention period（碰撞窗口collision window）；经过争用期还没有检测到碰撞，才能肯定这次发送不会发送碰撞；</li>
<li>在使用CSMA/CD协议时，一个站不可能同时进行发送和接收（但必须边发送边监听）。只能进行半双工通信</li>
<li>以太网采用截断二进制指数退避算法(truncated binary exponential backoff)来确定碰撞后重传的时机，避免空闲后各站重传时发生冲突的概率减小；基本退避时间为争用期2τ，具体的争用期时间51.2μs,也称为512比特时间，1比特时间为发送1比特所需时间。从离散的整数集合[0,1..（2^k-1）]中随机取出一个数，记为r。重传应推后的时间就是r倍的争用期，即r*2τ；K为碰撞次数时。K=Min[重传次数，10]，当重传达16次仍不能成功时，则丢弃该帧，并向高层报告</li>
<li>适配器每发送一个新的帧，就要执行一次CSMA/CD算法，适配器对过去发送过的碰撞没有记忆功能；</li>
<li>为了避免在发送完毕之前没有检测出碰撞：以太网规定一个最短帧长64字节，即512bit，通过填充使帧长不小于64字节；凡是长度小于64字节的帧都是由于冲突而异常中止的无效帧，只要收到了这种无效帧，就应当立即将其丢弃；</li>
<li>强化碰撞：当发送数据的站发现碰撞时，除了立即停止发送数据外，还要再发送32或48比特的人为干扰信号(jamming signal)，以便让所有用户都知道发生碰撞</li>
<li>以太网规定帧间最小间隔为9.6μs，相当于96比特时间，为了使刚刚接收到数据帧的站的接收缓存来得及清理</li>
</ul>
</li>
<li>CSMA/CD协议的要点归纳：
<ul>
<li>1.准备发送：适配器从网络层获得一个分组，加上以太网的首部和尾部，组成以太网帧，放入适配器的缓存中，但在发送之前，必须先检测信道；</li>
<li>2.检测信道：若检测到信道忙，则应不停地检测，一直等待信道转为空闲。若检测到信道空闲，并在96比特时间内信道保持空闲，就发送这个帧；</li>
<li>3.在发送过程中仍不停地检测信道，即网络适配器要边发送边监听，这里只有两种可能性：
<ul>
<li>一是发送成功：在争用期内一直没有检测到碰撞，这个帧肯定能够发送成功；回到1</li>
<li>二是发送失败：在争用期内检测到碰撞，这是立即停止发送数据，并按照规定发送人为干扰信号；适配器接着就执行指数退避算法，等待r倍512比特时间后，返回步骤2，继续检测信道；但若重传16次还不能成功，则停止重传而向上报错；</li>
</ul>
</li>
<li>以太网每发送完一帧同时已发送的帧暂时保留一下。如果在争用期内检测发生了碰撞，那么还要推迟一段时间后再把这个暂时保留的帧重传1次</li>
</ul>
</li>
<li>集线器/中继式集线器:星型拓补的中心可靠性很高的设备（半双工，交换机全双工）
<ul>
<li>使用集线器的以太网在逻辑上仍然是一个总线网，各站共享逻辑上的总线，使用的依然是CSMA/CD协议</li>
<li>一个集线器上有许多接口。每个接口通过RJ-45插头与主机相连。很像多接口的转发器</li>
<li>集线器工作在物理层，接口的作用就是简单的转发比特，不进行碰撞检测，碰撞检测是主机的网卡进行的。</li>
<li>集线器采用专门的芯片进行自适应串音回波抵消</li>
<li></li>
<li>集线器连接的多个主机构成子网，多个集线器再与路由器连接构成大的网络</li>
<li>家用路由器可以包含集线器功能</li>
<li>集线器会将信号发往所有线路，如果同时输入多个信号就会发生碰撞，无法同时传输多路信号</li>
</ul>
</li>
</ul>
<h2>3.5. 以太网的MAC层（媒体接入控制MAC层）</h2>
<ul>
<li>在局域网中，硬件地址又称为物理地址或者MAC地址，实际上是适配器地址或适配器标识符或接口标识符。
<ul>
<li>IEEE 802标准规定了一种48位的全球地址，固化在网卡（适配器）的ROM中的地址。更换适配器就更换了mac地址，6字节，与地理位置无关。一个网卡一个MAC地址。使用十六进制表示 ipconfig /all</li>
<li>网卡具有过滤功能，当它收到一个MAC帧就开始用硬件检查MAC帧中的目的地址，如果是发往本站的就收下，不是就丢弃，不做其他处理。包括
<ul>
<li>单播(unicast)帧（一对一）。即收到的帧的MAC地址与本站的硬件地址相同</li>
<li>广播(broadcast)帧（一对全体）。即发送给本局域网上所有站点的帧（全1地址）</li>
<li>多播(multicast)帧（一对多）。即发送给本局域网上一部分站点的帧</li>
</ul>
</li>
<li>网卡至少能识别单播和广播帧，网卡还有一个混杂方式工作模式，只要发现有帧在以太网上传播就会接收下来。可作为窃听方式和网络维护和管理人员改善网络的一种工具</li>
<li>只有在操作系统启动过程中对网卡进行初始化的时候才会读取 MAC 地址，读取出来之后会存放在内存中，每次执行收发操作时实际上使用的是内存中的值。此外，读取 MAC 地址的操作是由网卡驱动程序来完成的，因此网卡驱动程序也可以不从网卡 ROM 中读取地址，而是将配置文件中设定的 MAC 地址拿出来放到内存中并用于设定 MAC 头部，或者也可以通过命令输入 MAC 地址</li>
</ul>
</li>
<li>MAC帧的格式<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/6e6f75f5ff77fd87d1f5b.png" alt="7.png"><br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/73e559b40b3f2144d0cdb.png" alt="46.PNG">
<ul>
<li>前同步码：7个字节（1和0交替）用来使接收端的适配器在接收MAC帧时能够迅速调整时钟频率，使它和发送端的频率相同。在使用SONET/SDH进行同步传输时则不需要前同步码，因为同步传输时收发双方的位同步总是一直保持着</li>
<li>帧开始定界符：1个字节(10101011)</li>
<li>MAC目的地址：6个字节，网卡只处理与当前适配器的物理地址相同的数据帧，不同则直接丢弃。</li>
<li>源MAC地址：6个字节</li>
<li>类型：用来标志上一层使用的是什么协议，决定把数据交付给上层的协议，该字段为0x0800时交付给IP协议，为0x0806交付给ARP，0X8035交付给RARP。0x86DD交付给IPv6</li>
<li>数据/有效载荷:46(最小长度64字节减去18字节首部,不够则在数据后面加入整数字节填充字段)-1500字节(MTU)</li>
<li>帧检验序列FCS（使用CRC循环冗余校验法）：4个字节，检测该帧是否出现差错。不包括前同步码和帧开始定界符</li>
</ul>
</li>
<li>MAC帧中没有帧长度字段：因为曼彻斯特编码的每一个码元（不管码元是1或0）的正中间一定有一次电压的转换（从高到低或从低到高）。当发送方吧一个以太网帧发送完毕后，就不再发送其他码元了（1,0都不发送）。因此，发送方网络适配器的接口上的电压就不再变化了，这样接收方就可以很容易地找到以太网帧的结束位置。在这个位置往前数4个字节（FCS字段长度4字节）就能确定数据字段结束的位置了</li>
<li>当帧长度小于46字节时，mac就会在数据字段的后面加入一个整数字节的填充字段，保证不小于46字节，上层协议必须定义了数据长度保证知道数据长度，用以去掉填充字段</li>
<li>以太网上传送数据以帧为单位传送，各帧直接必须有间隙，因此接收端只要找到帧开始界定符，其后面到达的比特流就都属于同一个MAC帧，可见以太网不需要使用帧结束界定符，也不需要使用字节插入保证透明传输</li>
<li>无效的MAC帧
<ul>
<li>帧的长度不是整数个字节</li>
<li>用收到的帧检验序列FCS查出有差错。</li>
<li>帧长度数据字段不在46-1500之间。有效的MAC帧长度为64-1518字节之间（首部占18字节）</li>
</ul>
</li>
<li>MAC帧在不同网络上传送时，其mac帧首部中的源地址和目的地址要发生变化</li>
</ul>
<h2>3.6. 以太网的扩展(从网络层看来还是一个网络)</h2>
<ul>
<li>在物理层扩展以太网：扩展主机和集线器之间距离要使用一对光纤和一对光纤调制调解器（作用是进行电信号和光信号的转换）</li>
<li>在数据链路层扩展以太网（使用网桥）
<ul>
<li>网桥工作在数据链路层，它根据MAC帧的目的地址对收到的帧进行转发或过滤。网桥在转发帧时，不改变帧的源地址</li>
<li>当网桥收到一个帧时，先检查此帧的目的MAC地址，然后再确定将该帧转发到哪一个接口，或者是把它丢弃</li>
<li>网桥的内部结构
<ul>
<li>网桥有多个接口。以太网通过网桥连接起来后，就成为一个覆盖范围更大的以太网，而原来的每个以太网就可以称为一个网段(segment)</li>
<li>网桥通过转发表来转发帧。转发表也称为转发数据库或路由目录。每一项包括地址和接口</li>
</ul>
</li>
<li>网桥的优点
<ul>
<li>过滤通信量，增大吞吐量，网桥工作在数据链路层的MAC子层，可以使以太网各网段成为隔离区的碰撞域。</li>
<li>扩大了物理范围，因而也增加了整个以太网上工作站的最大数目。</li>
<li>提高了可靠性，当网络出现了故障时，一般只影响个别网段。</li>
<li>可互连不同物理层、不同MAC子层和不同速率(如10Mb/s或100Mb/s)的以太网</li>
</ul>
</li>
<li>网桥的缺点
<ul>
<li>增加了时延；由于网桥对接收的帧要先存储和查找转发表，然后才转发，而转发之前，还必须执行CSMA/CD算法(发生碰撞时要退避)</li>
<li>在MAC子层并没有流量控制功能。当网络上的负荷很重时，网桥中的缓存的存储空间可能不够而发生溢出，以致产生帧丢失的现象。</li>
<li>只适用于用户数不太多(不超过几百个)和通信量不太大的以太网，否则有时还会因传播过多的广播信息而产生网络拥塞(广播风暴)</li>
</ul>
</li>
<li>透明网桥的工作原理
<ul>
<li>先按照自学习算法处理收到的帧，并且按照转发表转发出去，</li>
<li>记录所有接收到接口的帧的源地址记录为接口对应的地址的key、value格式，同时记录进入网桥的时间，过期就删除该地址记录</li>
</ul>
</li>
<li>源路由网桥：由发送帧的源站负责路由选择的网桥，在发送帧时，把详细的路由信息放在帧的首部中
<ul>
<li>为了发现合适的路由，源站以广播的方式向欲通信的目的站发送一个发现帧为探测之用，发现帧将在整个以太网沿着所有可能的路由传送。在传送过程中，每个发现帧都记录所经过的路由。当这些发现帧到达目的站时，就沿着各自的路由返回源站。源站得知这些路由后，从所有可能的路由中选择出一个最佳路由。以后，凡从这个源站向该目的地发送的帧的首部，都必须携带源站所确定的这一路由信息。</li>
<li>发现帧还能帮助源站确定整个网络可以通过的帧的最大长度。</li>
<li>源路由网桥对主机不透明，主机必须知道网桥的表示以及连接到哪一个网段上，使用源路由网桥可以利用最佳路由，若在两个以太网之间使用并联的源路由网桥，则可使通信量较平均地分配给每个网桥，用透明网桥则只能使用生成树，而生成树一般并不能保证所使用的的路由是最佳的，也不能在不同的链路中负载均衡。</li>
</ul>
</li>
<li>多接口网桥：以太网交换机（实质上就是有一个多接口的网桥）工作在数据链路层，每个接口都直接与一个单个主机或另一个集线器相连(普通网桥的接口往往连接到以太网的一个网段)，并且一般都工作在全双工方式。当主机需要通信时，交换机能同时连通许多对的接口，使每一对互相通信的主机都能像独占传输媒体那个样，无碰撞地传输数据。也是一种即插即用设备，内部转发表也是通过自学习算法逐渐建立起来。不存在碰撞问题，因为交换机端口和网卡的PHY（MAU）模块以及MAC模块，其内部发送的和接收的电路是各自独立的，信号不会发生碰撞，只要不使用集线器，就可以避免信号碰撞了，根据MAC地址判断转发目标
<ul>
<li>交换机内部有一张MAC地址与网线端口的对应表。当收到包时，会将相应的端口号和发送方的MAC地址写入表中，这样就可以根据地址判断出该设备连接在哪个端口上了。交换机就是根据这些信息判断应该把包转发到哪里的</li>
<li>交换机端口的 MAC 模块不具有 MAC 地址。交换机根据 MAC 地址表查找 MAC 地址，然后将信号发送到相应的端口。</li>
<li>MAC 地址表的维护:第一种是收到包时，将发送方 MAC 地址以及其输入端口的号码写入 MAC 地址表中。由于收到包的那个端口就连接着发送这个包的设备，所以只要将这个包的发送方 MAC 地址写入地址表，以后当收到发往这个地址的包时，交换机就可以将它转发到正确的端口了。交换机每次收到包时都会执行这个操作，另一种是删除地址表中某条记录的操作，这是为了防止设备移动时产生问题。地址表中的记录不能永久有效，而是要在一段时间不使用后就自动删除。</li>
<li>当交换机发现一个包要发回到原端口时，就会直接丢弃这个包。</li>
<li>是地址表中找不到指定的 MAC 地址。这可能是因为具有该地址的设备还没有向交换机发送过包，或者这个设备一段时间没有工作导致地址被从地址表中删除了。这种情况下，交换机无法判断应该把包转发到哪个端口，只能将包转发到除了源端口之外的所有端口上，无论该设备连接在哪个端口上都能收到这个包。这样做不会产生什么问题，因为以太网的设计本来就是将包发送到整个网络的，然后只有相应的接收者才接收包，而其他设备则会忽略这个包。</li>
<li>如果接收方 MAC 地址是一个广播地址 ，那么交换机会将包发送到除源端口之外的所有端口</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1>4. 网络层</h1>
<h2>4.1. IP体系的网络层提供的服务和虚拟互连网络</h2>
<ul>
<li>研究分组怎么从一个网络通过路由器转发到另外一个网络</li>
<li>TCP/IP体系的网络层向上只提供简单灵活的、无连接的，尽量大努力交付的数据报服务。网络发送分组时不需要先建立连接。每一个分组（IP数据报）独立发送，与其前后的分组无关（不进行编号）。网络层不提供服务质量的承诺。所发送的分组可能出错，丢失，重复和失序，也不保证分组交付的时限。</li>
<li>互联网是可以由多种异构网络互连组成。参加互连的计算机网络都使用相同的网际协议IP，因此可以把互连以后的计算机网络看成一个虚拟互联网络，物理设备通过使用IP协议,屏蔽了物理网络之间的差异，将网络互相连接起来要使用一些中间设备
<ul>
<li>物理层使用的中间设备叫做转发器（同一个网络）</li>
<li>数据链路层使用的中间设备叫做网桥或桥接器（同一个网络）</li>
<li>网络层使用的中间设备叫做路由器（连接不同网络）</li>
<li>网络层以上使用的中间设备叫做网关。用网关连接两个不兼容的系统需要在高层进行协议的转换（连接不同网络）</li>
</ul>
</li>
<li>路由器根据目标地址判断下一个路由器的位置（IP协议根据目标地址判断下一个IP转发设备的位置）</li>
<li>集线器再子网中将网络包传输到下一个路由（子网中的以太网协议将包传输到下一个转发设备）<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/89ee1e096d0ac2a37d859.png" alt="21.PNG"></li>
</ul>
<h2>4.2. IP地址及其编址方法三个阶段</h2>
<ul>
<li>ip地址：因特网上的每个主机（或路由器）的每一个接口分配一个在全球唯一的32位标识符。由因特网名字和数字分配机构ICANN进行分配；ip地址不仅仅指明了主机，而且指明了主机所连接的网络（在整个因特网内唯一）</li>
<li>ip地址的特点：
<ul>
<li>每一个IP地址都由网络号(因特网范围内唯一)和主机号(网络号所指明的网络范围内唯一)两部分组成。是一种分等级的地址结构，IP地址管理机构在分配IP地址时只分配网络号，而剩下的主机号则由得到该网络号的单位自行分配。这样就方便了IP地址的管理。路由器仅根据目的主机所连接的网络号来转发分组，使路由表中的项目数大幅度减少，从而减少了路由表所占的存储空间及查找的时间</li>
<li>IP地址是标志主机（或路由器）和一条链路的接口。当一个主机同时连接到两个网络上时，就必须同时具有两个相应的IP地址，其网络号必须是不同的。这种主机称为多归属主机。由于一个路由器至少应当连接到两个网络，因此一个路由器至少应当有两个不同的IP地址</li>
<li>一个网络是指具有相同网络号的主机的集合。用转发器或网桥连接起来的若干个局域网具有同样的网络号.具有不同网络号的局域网必须使用路由器进行互连</li>
<li>物理地址是数据链路层和物理层使用的地址，而IP地址是网络层和以上各层使用的逻辑地址（ip地址由软件实现）</li>
<li>ip地址放在ip数据报的首部，而硬件地址则放在mac帧的首部。在网络层以上使用的是ip地址，而数据链路层及以下使用的是硬件地址</li>
</ul>
</li>
<li>ip地址的编址方法共经历三个历史阶段：
<ul>
<li>分类的ip地址：由网络号和主机号组成，A、B、C类地址都是单播地址（一对一通信），一种分等级的地址结构<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/49b9deb5b0584458f6ed5.png" alt="9.png">
<ul>
<li>A类地址:单播地址（2^31个地址）
<ul>
<li>网络号1个字节，（类别位）第一位为0，网络号数2^7-2。127作为本地软件环回测试(loopback test)本主机的进程之间的通信之用。全0保留地址，表示本网络</li>
<li>主机号3个字节，主机数2^24-2。全0表示“本主机”所连接到的单个网络地址，而全1表示该网络上的所有主机（广播地址）</li>
</ul>
</li>
<li>B类地址:单播地址（2^30个地址）
<ul>
<li>网络号2个字节，前两位为10，网络号数2^14-1。128.0.0.0不指派</li>
<li>主机号2个字节，最大主机数是2^16-2（减去全0和全1的主机号）。</li>
</ul>
</li>
<li>C类地址:单播地址（2^29个地址）
<ul>
<li>网络号3个字节，前三位为110，网络号数（2^21-1）。192.0.0.0不指派</li>
<li>主机号1个字节，最大主机数是2^8-2。（减去全0和全1的主机号）。</li>
</ul>
</li>
<li>D类地址:多播地址：网络号栈4个字节，前四位为1110</li>
<li>E类地址：前4位1111，保留以后用<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/3c75de06024e9ff9efed9.png" alt="22.PNG"></li>
</ul>
</li>
<li>划分子网
<ul>
<li>两级IP地址弊端：IP地址空间的利用率有时很低、不灵活，不能随时灵活增加某单位网络，给每一个物理网络分配一个网络号会使路由表变得太大因而使网络性能变坏。</li>
<li>划分子网：IP地址中增加了一个“子网号字段”。使两级IP地址变成三级IP地址。
<ul>
<li>物理网络划分为若干个子网后对外仍然表现为一个没有划分子网的网络。</li>
<li>网络的主机号减少了若干位作为子网号。 IP地址={&lt;网络号&gt;,&lt;子网号&gt;,&lt;主机号&gt;}</li>
<li>凡是从其他网络发送给本单位某个主机的IP数据报，仍然是根据IP数据报的目的网络号找到连接在本单位网络上的路由器。本单位网络上的路由器接收了数据报之后，按照目的网络号和子网号找到目的网络的子网，将IP数据报交付给目的主机。</li>
</ul>
</li>
<li>子网掩码
<ul>
<li>子网掩码，32位，一般是由全1和全0组成，全1部分包括了网络号和子网号，全0部分包括了主机号。子网掩码和IP地址的二进制数字逐位相“与”（全1得1，其他为0）。就可以得到子网网络地址。A类地址255.0.0.0、B类地址255.255.0.0、c类地址255.255.255.0，子网掩码为了更便于查找路由表，区分ip地址种类</li>
<li>主机号部分全为0代表整个子网，全1代表向子网上所有设备发送包（广播）</li>
<li>若一个路由器连接在两个子网上就拥有两个网络地址和两个子网掩码</li>
</ul>
</li>
<li>使用子网分组的转发
<ul>
<li>使用子网划分后，路由表必须包含目的网络地址，子网掩码和下一跳地址。路由器转发分组的算法（流程）如下：
<ul>
<li>1）从收到的数据报首部提取目的IP地址D</li>
<li>2）先判断是否为直接交付。对路由器直接相连的网络进行逐个检查：用各网络的子网掩码和D逐位相与,看结果是否和相对应的目的网络地址匹配。若匹配，则把分组进行直接交付，转发任务结束。否则就是间接交付，执行（3）。</li>
<li>3）若路由表中有目的地址为D的特定主机路由，则把数据报传送给路由表中所指明的下一跳路由：否则执行（4）。</li>
<li>4）对路由表的每一行，用其中的子网掩码和D逐位相与，其结果为N与该行的目的网络地址匹配，则把数据报传送给下一跳路由器；否则执行（5）。</li>
<li>5）若路由表中有一个默认路由，则把数据报传送给路由表中所指明的默认路由器；否则执行（6）。</li>
<li>6）报告转发分组出错。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>无分类域间路由选择CIDR(Classless Inter-Domain Routing)构成超网（IPV4地址耗尽）
<ul>
<li>32位的IP地址分为网络前缀和主机好两部分:CIDR使用CIDR计法, 在ip地址后面加上/ 写上网络前缀的位数</li>
<li>CIDR把网络前缀相同的连续ip地址组成一个CIDR地址块/超网.只要知道CIDR地址块中的任何一个地址，就可以知道这个地址块的起始地址（主机全0）和最大地址（主机全1），以及地址块中的地址数。由于一个CIDR地址中有很多地址，所有在路由表中就利用CIDR地址来查找目的网络。这种地址的聚合常称为路由聚合，使得路由表中的一个项目可以表示原来传统分类地址的多个，路由聚合也称为构成超网</li>
<li>32位子网掩码：斜线计法中，斜线后面的数字就是地址掩码中1的个数，后面全部是0，</li>
<li>前缀最长匹配：在CIDR中路由表中每一个项目包括了网络前缀和下一条的地址.路由选择网络前缀最长的路由.</li>
<li>二叉线索查找路由表：在前缀最长匹配算法中,用二叉树的数据结构进行组织提高查找速度，先从IP地址中找出各个IP地址中唯一的前缀, 然后通过唯一的前缀构成二叉树, 其中二叉树的左孩子是对应的值为0, 右孩子值为1</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2>4.3. ip数据报(网络层协议数据单元)</h2>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/7db126fcc82bce692b2e6.png" alt="13.png" tabindex="0"><figcaption>13.png</figcaption></figure>
<ul>
<li>IP数据报：32位（4字节）。一个IP数据报由固定长度20字节的首部和长度可变数据两部分组成。
<ul>
<li>版本：占4位，IP协议版本。通信双方使用的IP协议的版本必须一致。目前广泛使用的IP协议版本号为IPv4。</li>
<li>首部长度：占4位，表示5-15，单位32位字(4字节)，20-60字节。如果IP数据报的数据部分不是4字节的整数倍时，必须利用最后的填充字段加以填充</li>
<li>区分服务。占8位，用来获得更好的服务。这个字段原来叫做服务类型，但实际一直没人用。</li>
<li>总长度。首部和数据之和的长度，16位，单位字节。最大总长度2^16-1。IP数据报的总长度如果大于数据链路层的MTU（最大传送单元1500字节） 需要进行分片处理。IP协议规定，因特网中所有主机和路由器，必须能够接受长度不超过576字节的数据报。在分片时，数据报首部中的总长度字段是指分片后的每一个分片的首部长度与该分片的数据长度总和</li>
<li>标识(identification)：占16位。IP软件在存储器中维持一个计数器，每产生一个数据报，标识的计数器就会加1，相同的标识字段值使分片后的各数据报片最后能正确得重装成原来的数据报</li>
<li>标志(flag)：占3位，但目前只有两位有意义。最低位记为MF(More Fragment)MF=1表示后面“还有分片”的数据报。MF=0表示为最后一位。中间一位记为DF(Don't Flagment)记为不能分片。只有当DF=0时才允许分片。</li>
<li>片偏移：占13位。片偏移指出：较长的分组在分片后，某片在原分组中的相对位置。以8字节为单位，也就是每个分片的长度一定是8字节的整数倍。标识=字节序号除以8。</li>
<li>生存时间TTL：占8位，单位跳数，0-255，数据报在因特网中至多可以经过多少个路由器，由发出数据报源点设置这个字段。防止无法交付的数据在网络中兜圈子。每经过一个路由器就减1。当TTL为0时就丢掉这个数据报。</li>
<li>协议 占8位。指出此数据报携带的数据是使用哪种协议，以便目的主机IP层知道将数据上交给那个处理过程,TCP<br>
06,UDP17,ICMP01</li>
<li>首部检验和 占16位。只检验数据报的首部。数据报每经过一个路由，路由器都要从新计算一下首部检验和（一些字段，如生存时间、标志、片偏移等都可能发生变化）。在发送方，先把IP数据报首部划分为许多16位字的序列，并把校验和字段设置零。用反码算术运算把所有16位字相加后，将得到的和的反码写入检验和字段。接收方收到数据报后，将首部的所有16位字再用反码算术运算相加一次。将得到的和取反码，即得出接收方校验和的计算结果，若首部未发生任何变化，结果必为0，否则丢弃数据报</li>
<li>源地址 占32位</li>
<li>目的地址 占32位</li>
<li>IP数据报首部的可变部分（很少使用）：一个选项字段，用来支持排错、测量以及安全等措施，内容丰富，此字段的长度可变，从1-40字节不等，取决于所选择的项目</li>
</ul>
</li>
<li>ip层分组转发的流程
<ul>
<li>路由表按主机的网络地址来制作，在路由表中每一条路由最主要的是一下两个信息：目的网络地址，下一跳地址。（可以用route print查看路由表。Interface 列，表示网卡等网络接口，这些网络接口可以将包发送给通信对象，Gateway 列表示下一个路由器的 IP 地址，将包发给这个 IP 地址，该地址对应的路由器 就会将包转发到目标地址。如果 Gateway 和 Interface 列的 IP 地址相同，就表示不需要路由器进行转发，可以直接将包发给接收方的 IP 地址。Metric表示通过这条路由传输包的成本，越小说明距离越近。路由表的第 1 行中，目标地址和子网掩码 都是 0.0.0.0，这表示默认网关，如果其他所有条目都无法匹配，就会自动匹配这一行）。路由表的子网掩码列值表示在匹配网络目标地址时需要对比的比特数量（路由聚合）<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/7513ea41a9cf0dde6f01c.png" alt="47.PNG"></li>
<li>因特网所有的分组转发都是基于目的主机所在的网络。IP数据报最终可以找到目的主机所在的网络上的路由器（可能要通过多次间接交付）。只有到达最后一个路由器时，才试图向目的主机对数据报的直接交付</li>
<li>特定主机路由：对特定的目的主机指明一个路由。有利于对网络的连接或路由表进行排错</li>
<li>默认路由（0.0.0.0）：减少路由表所占用的空间和搜索路由表所用的时间。找不到匹配路由时选择默认路由。只要将子网掩码设置为 0.0.0.0，那么无论任何地址都能匹配到这一条记录，这样就不会发生不知道要转发到哪里的问题了</li>
<li>待转发的数据报怎么找到下一跳的路由器？
<ul>
<li>当路由器收到一个待转发的数据报，在从路由表得出下一跳路由器的IP地址后交送数据链路层的网络接口软件。把下一跳的路由器的IP地址转换成硬件地址（ARP），并放在链路层的MAC帧的首部并根据这个硬件地址找到下一跳路由器。当发送一连串数据报时，上述的这种查找路由表、计算硬件地址、写入MAC帧的首部等过程，将不断重复进行，造成一定开销</li>
</ul>
</li>
<li>分组转发算法
<ul>
<li>1）从数据报的首部提取目的主机的IP地址D，得出目的网络地址为N。</li>
<li>2）若N就是于此路由直接相连的某个网络地址，则进行直接交付，不需要在经过其他的路由器，直接把数据报交付目的主机。</li>
<li>3）若路由表中有目的地址为D的特定主机路由，则把数据报传送给路由表中所指明的下一跳路由器；否则执行（4）</li>
<li>4）若路由表中有到达网络N的路由，则把数据报传送给路由表中所指明的下一跳路由；否则，执行5）</li>
<li>5）若路由表中有一个默认路由，则把数据报传送给路由表中所指明的默认路由；否则，执行6）</li>
<li>6）报告转发分组出错。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2>4.4. 地址解析协议ARP（Address Resolution Protocol 同一个局域网，跨网络由路由器完成转发）</h2>
<ul>
<li>ARP协议就是为了从网络层使用的ip解析出在数据链路层使用的硬件地址。cmd查看命令 arp -a</li>
<li>ARP协议是在ARP高速缓存中存放从ip地址到硬件地址的映射表，并且这个映射表经常动态更新（新增或者超时删除）<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/43213b677e352d96ea3ac.png" alt="11.png"><br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/55bc0e6f1c478415b2fa6.png" alt="12.png"></li>
<li>ARP协议工作原理
<ul>
<li>每个主机都设有一个ARP缓存表，里面有本局域网上各主机和路由器的IP地址到硬件地址的映射表</li>
<li>当主机A要向本局域网上的某个主机B发送IP数据报时，就先在其ARP高速缓存中查找有无主机B的IP地址。如果有，就在ARP高速缓存中查出其对应的硬件地址，再把其硬件地址写入到MAC帧，然后通过局域网把该MAC帧发往此硬件地址</li>
<li>如果主机高速缓存中没有则运行ARP，按照以下步骤查找出主机B的硬件地址。
<ul>
<li>ARP进程在本局域网广播发送一个ARP请求分组。同时把自己的ip地址到硬件地址的映射写入ARP请求分组。本局域网上所有的主机上运行的ARP进程都收到此ARP请求分组</li>
<li>主机B在ARP请求分组中见到自己的IP地址，记录A的地址映射并向A发送ARP响应分组(单播)，同时写入自己的硬件地址。</li>
<li>主机A收到主机B的ARP响应分组后，就在其ARP高速缓存中写入主机B的IP地址到硬件地址的映射。</li>
<li>由于其余的所有主机的IP地址都与ARP请求分组中要查询的IP地址不一致，因此都不理睬这个ARP请求分组</li>
</ul>
</li>
<li>委托ARP或ARP代理（ARP Proxy）:当发送主机和目的主机不在同一个局域网中时，发送主机通过ARP协议获得的是一台可以通往局域网外的路由器的MAC地址。于是此后发送主机发往目的主机的所有帧，都将发往该路由器，通过它向外发送。</li>
<li>ARP缓存表每一项都设置生存时间，凡超过生存时间的项目就从高速缓存中删除掉</li>
</ul>
</li>
<li>arp -a命令查看ARP缓存内容，arp -d [ip] 删除ARP缓存条目</li>
</ul>
<h2>4.5. 网络控制报文协议 ICMP(Internet Control Message Protocol)（为了更有效地转发ip数据报和提交交付成功的机会）</h2>
<p><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/82332515ce8c9937d8eb1.png" alt="31.PNG"><br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/d6eb753a0094cd33c27d8.png" alt="23.PNG"></p>
<ul>
<li>ICMP网络控制报文协议：允许主机或路由器报告差错情况和提供有关异常情况的报告，ICMP报文作为IP数据报的数据部分。所有的ICMP差错报文中的数据字段都有同样的格式，把收到的需要进行差错报告的IP数据报的首部和数据字段的前8个字节（运输层端口号TCP和UDP，发送序号TCP）提取出来，作为ICMP报文的数据字段，再加上相应的ICMP差错报文的前8个字节构成ICMP的差错报告报文。</li>
<li>ICMP报文种类-&gt;检验和字段用来检验整个ICMP报文
<ul>
<li>差错报告报文
<ul>
<li>类型值3：终点不可达，当路由器或主机不能交付数据报时就向源点发送终点不可达报文</li>
<li>类型值4：源点抑制，当路由器或主机由于阻塞而丢弃数据报时，就向源点发送源点抑制报文，使源点把数据报的发送速率减慢</li>
<li>类型值5：改变路由(Redirect），路由器把改变路由报文发给主机，让主机知道下次应将数据报发送给另外的路由器</li>
<li>类型值11：超时，当路由器收到生存时间为零的数据报时，除丢弃该数据报外，还要向源点发送时间超过报文。当终点在预先规定的时间内不能收到一个数据报的全部数据碎片时，就把数据报片都丢弃，并向源点发送超时报文</li>
<li>类型值12：参数问题，当路由器或目的主机收到的数据报首部中有的字段的值不正确时，就丢弃该数据报，并向源点发送参数问题报文</li>
<li>以下几种情况都不会导致产生ICMP差错报文（防止过去允许ICMP差错报文对广播分组响应所带来的广播风暴）
<ul>
<li>ICMP差错报文</li>
<li>第一个分片的数据报片的所有后续数据报片</li>
<li>具有多播地址的数据报</li>
<li>具有特殊地址（127.0.0.0或0.0.0.0）的数据报<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/c5e11a83c00b6f5eed2e4.png" alt="35.PNG"></li>
</ul>
</li>
</ul>
</li>
<li>询问报告报文
<ul>
<li>类型值8或者0：回送(Echo)请求或应答，主机或路由器向特定的目的主机发出的询问。用来测试目的站是否可达以及了解有关状态，收到此报文的主机必须给源主机或路由器发送ICMP回送回答报文</li>
<li>类型值13或14：时间戳(Timestamp)请求或应答。请某个主机或路由器回答当前的日期和时间。在ICMP时间戳回答报文中有一个32位的字段，写入从1900年1月1日到当前时刻共多少秒，用来进行时钟同步和测量时间</li>
</ul>
</li>
<li>ICMP的应用举例
<ul>
<li>PING（Packet InterNet Groper）分组网间探测，用于测试两个主机之间的连通性。ping使用了ICMP回送请求与回送回答报文。 应用层直接使用网络层ICMP的一个例子</li>
<li>TraceRoute/tracert用来跟踪一个分组从源点到终点的路径。使用了ICMP时间超过差错报告报文
<ul>
<li>TraceRoute从源主机向目的主机发送一连串的IP数据包，数据报中封装的是无法交付的UDP用户数据报。第一个P1的生存时间TTL设置为1。当P1达到路径上的第一个路由器R1时，R1先收下它，接着把TTL的值减1。由于TTL的值等于零了，R1就把P1丢弃了，并向源主机发送一个<strong>ICMP时间超过差错报告报文</strong>。接着发送第二个数据报P2，并把TTL设置为2。P2先到达路由器R1，R1收下，把TTL减1再转发给路由器R2。R2收到P2时TTL为1，但减1后TTL变为零了。R2就丢弃P2，并向源主机发送一个ICMP时间超过差错报告报文......TraceRoute每次将送出的报文的TTL加1来发现另一个路由器，这样一直继续下去，当最后一个数据报刚刚到达目的主机的时候，数据报的TTL是1。主机不转发数据包也不把TTL值减1。目的主机要向主机发送<strong>ICMP终点不可达差错报告报文</strong>。这样，源主机达到了自己的目的，因为这些路由器和最后目的主机发来的ICMP报文正好给出了源主机想知道的路由信息——到达目的主机所经过的路由器的IP地址，以及到达其中的每一个路由器的往返时间。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>因特网的路由选择协议
<ul>
<li>根据算法是否随网络的通信量或拓补自适应地调整变化划分：
<ul>
<li>静态路由选择策略——非自适应路由选择，简单和开销较小，不能及时适应网络状态的变化。小网络</li>
<li>动态路由选择策略——自适应路由选择，能较好地适应网络状态的变化，实现起来复杂，开销也比较大。大网络</li>
</ul>
</li>
<li>因特网采用的路由选择协议主要是自适应的、分布式路由选择协议
<ul>
<li>因特网的规模非常大。如果让所有的路由器知道所有的网络怎样到达。则这种路由表将非常大，处理起来也太花时间，而所有这些路由器之间交换路由信息所需的带宽会使因特网的通信链路饱和</li>
<li>许多单位不愿意外界了解自己单位网络的布局细节和本部门采用的路由选择协议，但同时还希望连接到因特网上，为此，因特网将整个互联网划分为许多较小的自治系统</li>
</ul>
</li>
<li>自治系统AS(AutonomousSystem)：一个管理机构下的网络设备群。尽管AS使用了多种内部路由选择协议，但AS对其他AS表现出的是一个单一的和一致的路由选择策略。一个大的ISP就是一个自治系统，自治系统之间的路由选择称为域间路由选择，自治系统内部的路由选择叫做域内路由选择</li>
<li>因特网有两大类路由选择协议
<ul>
<li>内部网关协议IGP(Interior Gateway Protocol)&nbsp;即在一个自治系统内部使用的路由选择协议。与互联网中其他自治系统选用什么路由选择协议无关。如RIP和OSPF协议</li>
<li>外部网关协议EGP(External Gateway Protocol)&nbsp;源站和目的站处在不同的自治系统使用的路由选择协议。如BGP协议</li>
</ul>
</li>
</ul>
</li>
<li>互联网的实体并不是由一个组织运营管理的单一网络，而是由多个运营商网络相互连接组成的（图 4.23）。<br>
ADSL、FTTH 等接入网是与用户签约的运营商设备相连的，这些设备称为 POP</li>
<li>NOC：Network Operation Center，网络运行中心。NOC 是运营商的核心设备，从 POP 传来的网络包都会集中到这里，并从这里被转发到离目的地更近的POP，或者是转发到其他的运营商。这里也需要配备高性能的路由器</li>
<li>IX：互联网交换中心。设置一个中心设备，将所有的运营商都用通信线路连接起来。通过连接到中心设备的方式来减少线路数量，这个中心设备就称为IX，IX 的核心是具有大量高速以太网 端口的二层交换机。二层交换机的基本原理和一般交换机相同，大家可以认为 IX 的核心就是大型的、高速的交换机。</li>
</ul>
<h2>4.6. 内部网关协议-路由信息协议RIP(Routing Information Protocol)</h2>
<ul>
<li>RIP是一种分布式的基于距离向量的路由选择协议。要求网络中的每一个路由器都要维护从它自己到其他每一个目的网络的距离记录。</li>
<li>距离/跳数：从一路由器到直接连接的网络的距离定义为1。从一个路由器到非直接连接的网络的距离定义为所经过的路由器数加1。加“1”是因为到达目的网络后就进行直接交付，而到直接的网络的距离已经定义为1。RIP允许一条路径最多只能包含15个路由器。“距离”为16时即相当于不可达。可见RIP只适用于小型互联网。RIP不能在两个网络之间同时使用多条路由。RIP选择一个具有最少路由器的路由（即最短路由），哪怕还存在另一条高速(低时延)但路由器较多的路由。</li>
<li>按固定的时间间隔（30s）仅和相邻路由器交换本路由器的路由表(到某个网络N、到N的距离，下一跳地址，更新原则是到每个网络的最短距离)。当网络拓补发生变化时，路由器也及时向相邻路由器通告拓补变化后的路由信息。使得每一个路由器到每一个目的网络的路由是最短的</li>
<li>RIP协议和OSPF协议都是分布式路由选择协议，每个路由器都要不断地和其他一些路由器交换路由信息</li>
<li>路由表的建立：路由器在刚刚开始工作时，只知道到直接连接的网络的距离（此距离定义为1）。以后，每一个路由器也只和数目非常有限的相邻路由器交换并更新路由信息。经过若干次更新后，所有的路由器最终都会知道到达本自治系统中任何一个网络的最短距离和下一跳路由器的地址。RIP协议的收敛(convergence)过程较快，即在自治系统中所有的结点都得到正确的路由选择信息的过程。</li>
<li>距离向量算法(Bellman-Ford算法)
<ul>
<li>收到相邻路由器（其地址为X）的一个RIP报文：</li>
<li>先修改此RIP报文中的所有项目：下一跳地址都改为X，距离+1。对修改后的RIP报文中的每一个项目(到目的网络N。距离d，下一跳地址X)
<ul>
<li>若项目中的目的网络不在路由表中，则把该项目加到路由表中；</li>
<li>若项目中的目的网络在路由表中且下一跳字段给出的路由器地址是同样的，则把收到的项目替换原路由表中的项目；</li>
<li>若项目中的目的网络在路由表中且下一跳字段给出的路由器地址是不同的，收到项目中的距离小于路由表中的距离，则进行更新；</li>
</ul>
</li>
<li>若3分钟还没有收到相邻路由器的更新路由表，则把此相邻路由器记为不可达路由器，即将距离置为16（表示不可达）</li>
</ul>
</li>
<li>RIP2协议的报文格式（使用运输层的用户数据报UDP进行传送，端口520）<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/9cdf8ba4e441e5c894475.png" alt="15.png">
<ul>
<li>首部：4个字节，命令字段指出报文的意义。1表示请求路由信息，2表示对请求路由信息的响应或未被请求而发出的路由更新报文。“必须为0”是为了4字节的对齐</li>
<li>路由部分：20个字节 地址族标识符（地址类别）字段用来标志所使用的地址协议(IP地址时为2)。路由标记填入自治系统号ASN，考虑使RIP有可能收到本自治系统以外的路由选择信息</li>
<li>RIP2还具有简单的鉴别功能，若使用鉴别功能，则将原来写入第一个路由信息（20字节）的位置用作鉴别。并将地址族标识符置为全1(0xFFFF)，路由标记吸入鉴别类型，剩下16字节为鉴别数据。在鉴别数据之后才写入路由信息，此时最多能放入24个路由信息</li>
<li>最多可以包括25个路由，最大长度是4+20X25=504字节</li>
</ul>
</li>
<li>RIP协议的优缺点：
<ul>
<li>当网络出现故障时，原因只能相信相邻路由器。要经过比较长的时间才能将此信息传送到所有的路由器。“坏消息传的慢”，更新收敛时间过长。（可以通过让路由器记录收到某特定路由信息的接口，而不让同一路由信息再通过此接口向反方向传送）</li>
<li>实现简单，开销较小。</li>
<li>限制了网络的规模，使用的最大距离为15（16表示不可达）。路由器之间交换的路由信息是路由器中的完整路由表，因而随着网络规模的扩大，开销也就增加。对于较大的网络应该使用OSPF协议</li>
</ul>
</li>
</ul>
<h2>4.7. 内部网关协议OSPF(OpenShortest Path First)</h2>
<ul>
<li>OSPF “开放最短路径优先” 使用了Dijkstra提出的最短路径算法SPF 分布式的链路状态协议</li>
<li>OSPF只有当链路状态发生变化时，使用洪泛法，本自治系统中所有路由器通过所有输出端口发送与本路由器相邻的所有路由器的链路状态信息。“链路状态”就是说明本路由器都和哪些路由器相邻，以及该链路的“度量”(metric)（费用、距离、时延、带宽等）</li>
<li>链路状态数据库/全网的拓扑结构图(link-statedatabase)：由于各路由器之间频繁地交换链路状态信息，因此所有的路由器最终都能建立一个链路状态数据库。它在全网范围内是一致的（这称为链路状态数据库的同步）。因此，每一个路由器都知道全网一共有多少路由器，以及哪些路由器时相连的，代价是多少。每个路由器使用链路状态数据库中的数据，构造出自己的路由表。OSPF的链路状态数据库能较快地进行更新，使各个路由器能及时更新其路由表。OSPF的更新过程收敛得快是其重要优点。</li>
<li>为了使OSPF能够用于规模很大的网络，OSPF将一个自治系统再划分为若干个更小的范围，叫作区域。每一个区域都有一个32位的区域标识符（用点分十进制表示）。在一个区域内的路由器最好不超过200个。将利用洪泛法交换链路状态信息的范围局限于每一个区域而不是整个的自治系统，这就减少了整个网络上的通信量。在一个区域内部的路由器只知道本区域的完整网络拓扑，而不知道其他区域的网络拓扑的情况。为了使每一个区域能够和本区域以外的区域进行通信。OSPF使用层次结构的区域划分。在上层的区域叫作主干区域(backbonearea)。主干区域的标识符规定为0.0.0.0。主干区域的作用是用来连通其他在下层的区域。从其他区域来的信息都由区域边界路由器进行概括，每个区域至少一个区域边界路由器，在主干区域内的路由器叫做主干路由器，一个路由器既可以是区域边界路由器也可以是主干路由器，在主干区域内还要有一个路由器专门和自治系统外的其他自治系统交换路由信息，这样的路由叫做自治系统边界路由器</li>
<li>OSPF分组：使用IP数据报传送，IP数据报首部的协议字段为89，使用24字节的固定首部长度<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/2267913f15f5a39da05b8.png" alt="32.PNG">
<ul>
<li>版本号--当前版本号2。</li>
<li>类型--OSPF分组5种类型中的哪一种。</li>
<li>分组长度--包括OSPF头在内的分组的长度。以字节为单位</li>
<li>路由器标识符--标志发送该分组的路由器的接口的IP地址</li>
<li>区域标识符--分组所属的区域标识符</li>
<li>校验和--包含有除了对数据损坏的认证部分之外的整个OSPF分组的校验。检验分组中的差错</li>
<li>鉴别类型--包含有认证的类型码：0没有认证（null authentication）。1为普通文本（口令）。2为MD5</li>
<li>鉴别：鉴别类型为0就填入0，鉴别类型为1则填入8个字符的口令</li>
</ul>
</li>
<li>OSPF共有以下五种分组类型：
<ul>
<li>类型1，问候(Hello)分组，用来发现和维持邻站的可达性。</li>
<li>类型2，数据库描述(Database Description)分组，向邻站给出自己的链路状态数据库中的所有链路状态项目的摘要信息。</li>
<li>类型3，链路状态请求(Link State Request)分组，向对方请求发送某些链路状态项曰的详细信息。</li>
<li>类型4，链路状态更新(Link State Update)分组，用洪泛法对全网更新链路状态。路由器使用这种分组将其链路状态通知给邻站</li>
<li>类型5，链路状态确认(Link State Acknowledgment)分组，对链路更新分组的确认。</li>
</ul>
</li>
<li>OSPF的其他特点
<ul>
<li>OSPF允许管理员给每条路由指派不同的代价。对于不同类型的业务可计算出不同的路由。</li>
<li>如果到同一个目的网络有多条相同代价的路径，那么可以将通信量分配给这几条路径。这叫作多路径间的负载平衡(load balancing)。</li>
<li>所有在OSPF路由器之间交换的分组（例如，链路状态更新分组）都具有鉴别的功能，因而保证了仅在可信赖的路由器之间交换链路状态信息。</li>
<li>OSPF支持可变长度的子网划分和无分类的编址CIDR。</li>
<li>由于网络中的链路状态可能经常发生变化，OSPF让每一个链路状态都带上一个32位的序号，序号越大状态就越新。</li>
</ul>
</li>
<li>OSPF的基本操作
<ul>
<li>OSPF规定，每两个相邻路由器每隔10秒钟要交换一次问候分组确知邻站是可达的。因为只有可达邻站的链路状态信息才存入链路状态数据库（路由表就是根据链路状态数据库计算出来的）。若有40秒钟没有收到某个相邻路由器发来的问候分组，则可认为该相邻路由器是不可达的，应立即修改链路状态数据库，并重新计算路由表。</li>
<li>其他的四种分组都是用来进行链路状态数据库的同步。同步就是指不同路由器的链路状态数据库的内容是一样的。两个同步的路由器叫做“完全邻接的”(fully adjacent)路由器。</li>
<li>当一个路由器刚开始工作时，为了减少开销，OSPF让每一个路由器用数据库描述分组和相邻路由器交换本数据库中已有的链路状态摘要信息（主要就是指出有哪些路由器的链路状态信息（以及其序号）已经写入了数据库）。经过与相邻路由器交换数据库描述分组后，路由器就使用链路状态请求分组，向对方请求发送自己所缺少的某些链路状态项目的详细信息。通过一系列的这种分组交换，全网同步的链路数据库就建立了</li>
<li>在网络运行的过程中，只要一个路由器的链路状态发生变化，该路由器就要使用链路状态更新分组，用可靠的洪泛法向全网更新链路状态。</li>
<li>为了确保链路状态数据库与全网保持一致，OSPF还规定每隔一段时间（如30分钟）就要刷新一次数据库中的链路状态</li>
<li>OSPF协议对多点接入的局域网采用了指定的路由器的方法，使广播的信息量大大减少。指定的路由器代表该局域网上所有的链路向连接到该网络的各路由器发送的状态信息<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/e7e37152fa4c50bf2cb28.png" alt="51.PNG"></li>
</ul>
</li>
</ul>
<h2>4.8. 外部网关协议BGP</h2>
<ul>
<li>BGP使用原因：因特网规模太大，使得AS之间路由选择非常困难，AS之间的路由选择必须考虑有关策略</li>
<li>BGP是不同自治系统的路由器之间交换路由信息的协议。采用路径向量路由选择协议</li>
<li>BGP发言人(BGPspeaker)
<ul>
<li>每一个自治系统的管理员要选择至少一个路由器作为该自治系统的“BGP发言人”。两个BGP发言人都是通过一个共享网络连接在一起的，而BGP发言人往往就是BGP边界路由器，一个BGP发言人与其他自治系统中的BGP发言人要交换路由信息，就要先建立TCP连接，然后在此连接上交换BGP报文以建立BGP会话(session)，利用BGP会话交换路由信息。当BGP发言人互相交换了网络可达性的信息（到达某个网络（使用网络前缀表示）所要经过的一系列自治系统）后，各BGP发言人就根据所采用的策略从收到的路由信息中找出到达各AS的较好路由。</li>
</ul>
</li>
<li>BGP报文(端口号179)<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/f4447060bd5a6795d4412.png" alt="33.PNG">
<ul>
<li>四种类型的BGP报文具有同样的通用首部，其长度为19字节。通用首部分为三个字段。
<ul>
<li>标记(marker)字段为16字节长，用来鉴别收到的BGP报文。当不使用鉴别时，标记字段要置为全1。</li>
<li>长度字段指出包括通用首部在内的整个BGP报文以字节为单位的长度，最小值是19，最大值是4096。</li>
<li>类型字段的值为l到4，分别对应于上述四种BGP撮文中的一种。</li>
</ul>
</li>
<li>OPEN报文：共有6个字段，即版本（1字节，值是4）、本自治系统号（2字节，使用全球唯一的16位自治系统号，由ICANN地区登记机构分配）、保持时间（2字节，以秒计算的保持为邻站关系的时间）、BGP标识符（4字节，该路由器的IP地址）、可选参数长度（1字节）和可选参数。用来与相邻的另一个BGP发言人建立关系。使通信初始化</li>
<li>UPDATE报文共有5个字段，即不可行路由长度（2字节，指明下一个字段的长度）、撤消的路由（列出所有要撤消的路由）、路径属性总长度（2字节，指明F一个字段的长度）、路径属性（定义在这个报文中增加的路径的属性）和网络层可达性信息NLRI(Network Layer Reachability Information)。最后这个字段定义发出此报文的网络，包括网络前缀的位数、IP地址前缀。用来发送某一路由的信息，以及列出要撤消的多条路由。</li>
<li>KEEPALIVE报文只有BGP的19字节长的通用首部。用来确认打开报文和周期性地证实邻站关系。</li>
<li>NOTIFICATION报文有3个字段，即差错代码（1字节）、差错子代码（1字节）和差错数据（给出有关差错的诊断信息），用来发送检测到的差错</li>
<li>ROUTE-REFRESH报文，只有4字节长，不采用BGP报文格式，请求对等端重新通告</li>
</ul>
</li>
<li>BGP协议的特点
<ul>
<li>BGP协议交换路由信息的结点数量级是自治系统个数的量级，这要比这些自治系统中的网络数少很多。	每一个自治系统中BGP发言人（或边界路由器）的数目是很少的。这样就使得自治系统之间的路由选择不致过分复杂。</li>
<li>BGP支持CIDR，因此BGP的路由表也就应当包括目的网络前缀、下一跳路由器，以及到达该目的网络所要经过的各个自治系统序列。由于使用了路径向量信息。就可以很容易地避免产生兜圈子的路由。如果一个BGP发言人收到了其他BGP发言人发来的路径通知，它要检查一下本自治系统是否在此通知的路径中，如果在这条路径中，就不能采用这条路径</li>
<li>在BGP刚刚运行时，BGP的邻站是交换整个的BGP路由表。但以后只需要在发生变化时更新有变化的部分。节省网络带宽和路由器的处理开销。</li>
<li>两个不同AS定期地交换路由信息，有一个商谈的过程（因为很可能对方路由器的负荷已很重，因而不愿意再加重负担）。因此，一开始向邻站进行商谈时就必须发送OPEN报文。如果邻站接受这种邻站关系，就用KEEPALIVE撮文响应。这样,两个BGP发言人的邻站关系就建立,一旦邻站关系建立了，就要继续维持这种关系。双方中的每一方都需要确信对方是存在的，且一直在保持这种邻站关系。为此，这两个BGP发言人彼此要周期性地交换KEEPALIVE报文（一般每隔30秒）。KEEPALIVE报文只有19字节长（只用BGP报文的通用首部）因此不会造成网络上太大的开销。</li>
<li>BGP发言人可以用UPDATE报文撤消它以前曾经通知过的路由，也可以宣布增加新的路由。撤消路由可以一次撤消许多条，但增加新路由时，每个更新报文只能增加一条</li>
<li>BGP可以很容易地解决距离向量路由选择算法中"坏消息传播得慢"的问题。当某个路由器或链路出现故障时，由于BGP发言人可以从不止一个邻站获得路由信息，因此很容易选择出新的路由。距离向量算法往往不能给出正确选择，因为这些算法不能支持哪些邻站到目的站的路由是独立的</li>
</ul>
</li>
</ul>
<h2>4.9. 路由器的构成</h2>
<ul>
<li>路由只有网络层和网络接口层</li>
<li>mac地址表：mac地址映射到硬件接口</li>
<li>路由器是一种具有多个输入端口和多个输出端口的专用计算机，其任务是转发分组。从路由器某个输入端口收到的分组，按照分组要去的目的地（即目的网络），把该分组从路由器的某个合适的输出端口转发给下一跳路由器。下一跳路由器也按照这种方法处理分组，直到该分组到达终点为止。路由器的转发分组正是网络层的主要工作</li>
<li>路由器结构可以分为路由选择(控制)部分和分组转发部分
<ul>
<li>分组转发部分可以支持多种通信技术，ADSL、FTTH，以及各种宽带专线等，只要端口模块安装了支持这些技术的硬件即可。</li>
</ul>
</li>
<li>路由器在转发包时，首先会通过端口将发过来的包接收进来，这一步的工作过程取决于端口对应的通信技术。对于以太网端口来说，就是按照以太网规范进行工作，而无线局域网端口则按照无线局域网的规范工作，总之就是委托端口的硬件将包接收进来。接下来，分组转发部分会根据接收到的包的 IP 头部中记录的接收方 IP 地址，在路由表中进行查询，以此判断转发目标。然后，分组转发部分将包转移到转发目标对应的端口，端口再按照硬件的规则将包发送出去，也就<br>
是分组转发部分委托端口模块将包发送出去的意思</li>
<li>路由器的端口有IP地址和MAC地址，能够成为以太网的发送方或者接收方，而交换机只负责转发，不能成为发送方或者接收方。只接收与自身地址匹配的包，遇到不匹配的包则直接丢弃。</li>
<li>路由器根据IP地址转发。路由器会忽略主机号，只匹配网络号。</li>
<li>对路由表进行维护。根据路由协议机制，通过路由器之间的信息交换由路由器自行维护路由表的记录</li>
<li>通过路由器转发的网络包，其接收方 MAC 地址为路由器端口的 MAC 地址。</li>
<li>如果在路由表中无法找到匹配的记录，路由器会丢弃这个包，并通过 ICMP 消息告知发送方 。</li>
<li>我们需要知道输出端口的 MTU ，看看这个包能不能不分片直接发送。最大包长度是由端口类型决定的，用这个最大长度减掉头部的长度就是 MTU，将 MTU 与要转发的包长度进行比较。如果输出端口的 MTU 足够大，那么就可以不分片直接发送；如果输出端口的 MTU 太小，那么就需要将包按照这个 MTU 进行分片，但在此之前还需要看一下 IP 头部中的标志字段，确认是否可以分片。一般来说都是可以分片的，但下面两种情况不能分片：1）发送方应用程序等设置了不允许分片；2）这个包已经是经过分片后的包。如果查询标志字段发现不能分片，那么就只能丢弃这个包，并通过 ICMP 消息通知发送方。否则，就可以按照输出端口 MTU 对数据进行依次拆分了。在分片中，TCP 头部及其后面的部分都是可分片的数据，尽管TCP 头部不属于用户数据，但从 IP 来看也是 TCP 请求传输的数据的一部分。数据被拆分后，每一份数据前面会加上 IP 头部，其大部分内容都和原本的 IP 头部一模一样，但其中有部分字段需要更新，这些字段用于<br>
记录分片相关的信息。</li>
<li>IP（路由器）负责将包送达通信对象这一整体过程，而其中将包传输到下一个路由器的过程则是由以<br>
太网（交换机）来负责的。</li>
<li>包过滤就是在对包进行转发时，根据 MAC 头部、IP 头部、TCP 头部的内容，按照事先设置好的规则决定是转发这个包，还是丢弃这个包。我们通常说的防火墙设备或软件，大多数都是利用这一机制来防止非法入侵的 。</li>
</ul>
<h2>4.10. 虚拟专用网VPN</h2>
<ul>
<li>因特网中的所有路由器，对目的地址是专用地址（可重用地址）的数据报一律不进行转发，采用专用IP地址的互联网络称为专用互联网或者本地互联网/专用网，仅机构内部使用。内网地址：
<ul>
<li>10.0.0.0到10.255.255.255(或记为10.0.0.0/8 称为24位块)</li>
<li>172.16.0.0到172.31.255.255(或记为172.16.0.0/12 称为20位块)</li>
<li>192.168.0.0到192.168.255.255(或记为192.168.0.0/16 称为16位块)</li>
</ul>
</li>
<li>VPN属于远程访问技术，简单地说就是利用公用网络架设专用网络。例如某公司员工出差到外地，他想访问企业内网的服务器资源，这种访问就属于远程访问。</li>
<li>让外地员工访问到内网资源，利用VPN的解决方法就是在内网中架设一台VPN服务器。外地员工在当地连上互联网后，通过互联网连接VPN服务器，然后通过VPN服务器进入企业内网。为了保证数据安全，VPN服务器和客户机之间的通讯数据都进行了加密处理。有了数据加密，就可以认为数据是在一条专用的数据链路上进行安全传输，就如同专门架设了一个专用网络一样，但实际上VPN使用的是互联网上的公用链路，因此VPN称为虚拟专用网络，其实质上就是利用加密技术在公网上封装出一个数据通讯隧道。</li>
</ul>
<h2>4.11. 网络地址转换NAT (Network Address Translation)</h2>
<ul>
<li>需要在专用网连接到因特网的路由器上安装NAT软件。装有NAT软件的路由器叫做NAT路由器，它至少有一个有效的外部全球IP地址。这样，所有使用本地地址的主机在和外界通信时，都要在NAT路由器上将其本地地址转换成全球IP地址，才能和因特网连接(其实相当于交给NAT代理访问网络上的其他主机)</li>
<li>为了更加有效利用NAT路由器上的全球IP地址，常用的NAT把运输层的端口号拥塞，称为网络地址与端口号转换NAPT</li>
<li>通过NAT路由器的通信必须由专用网内的主机发起，因为NAT路由器不知道应当把目的IP地址转换成专用网内的哪个本地IP地址</li>
<li>包收发过程中，地址转换设备需要根据对应表查找私有地址和公有地址的对应关系，再改写地址和端口号之后进行转发。当数据收发结束，进入断开阶段，访问互联网的操作全部完成后，对应表中的记录就会被删除。</li>
</ul>
<h1>5. 运输层</h1>
<h2>5.1. 运输层概述</h2>
<ul>
<li>运输层有两个很重要的功能
<ul>
<li>复用：发送方不同的应用进程都可以使用同一个运输层协议传送数据</li>
<li>分用：接收方的运输层在剥去报文的首部后能够把这些数据正确交付目的应用进程</li>
</ul>
</li>
<li>运输层属于面向通信部分的最高层，同时也是用户功能中的最底层。网络的边缘部分的两个主机使用网络的核心部分的功能进行端到端的通信时，只有主机的协议栈才有运输层，而路由器在转发分组时都只用到下三层的功能</li>
<li>协议端口号(protocol port number)/端口(port)。16位、标识TCP/IP体系中不同操作系统的应用进程。分为两种：服务端使用的端口号：系统端口号[0～1023]、登记端口号[1024～49151]；客户端使用的短暂端口号：[49152～65535]<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/6d619df80480ebf17163c.jpg" alt="18.png"></li>
</ul>
<h2>5.2. 用户数据报协议UDP(User Datagram Protocol)</h2>
<ul>
<li>
<p>UDP特点</p>
<ul>
<li><strong>UDP支持一对一、一对多、多对一和多对多的交互通信</strong></li>
<li><strong>UDP使用尽最大努力交付，即不保证可靠交付</strong>。因此主机不需要维持复杂的连接状态表</li>
<li><strong>UDP是面向报文的。发送方的UDP对应用程序交下来的报文，在添加首部后就直接交付IP层</strong>；若报文太长，IP层在传送时可能要进行分片，若报文太短，会使IP数据报的首部的相对长度太大，都会降低了IP层的效率。</li>
<li><strong>UDP的首部开销小，只有8个字节，比TCP的20个字节的首部要短</strong></li>
<li>UDP是无连接的，发送数据之前不需要建立连接（发送数据结束时也没有连接可释放），减少了开销和发送数据之前的时延</li>
<li>UDP没有拥塞控制，因此网络出现的拥塞不会使源主机的发送速率降低。</li>
<li>UDP用于视频音频等</li>
</ul>
</li>
<li>
<p>UDP报文格式</p>
<ul>
<li>首部字段：8个字节，由四个字段组成，每个字段的长度都是两个字节
<ul>
<li>源端口: 2字节 源端口号，在需要对方回信时选用，不需要时可全0</li>
<li>目的端口:2字节 目的端口号。这在终点交付报文时必须要使用到</li>
<li>长度:2字节 UDP用户数据报的长度，其最小值是8（仅有首部）</li>
<li>检验和:2字节 检测UDP用户数据报在传输中是否有错。有错就丢弃</li>
</ul>
</li>
<li>数据字段<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/f02170314a64b67683f88.png" alt="34.PNG"></li>
</ul>
</li>
<li>
<p>UDP计算检验和——把首部和数据部分一起都检验</p>
<ul>
<li>在发送方的UDP用户数据报之前临时增加12个字节的伪首部(不参与传输)，并把全零放入检验和字段。然后把伪首部以及UDP用户数据报看成是由许多16位的字串接起来。若UDP用户数据报的数据部分不是偶数个字节，则要填入一个全零字节（但此字节不发送）。最后按二进制反码计算出这些16位字的和。将此和的二进制反码作为检验和字段，就发送这样的UDP用户数据报</li>
<li>在接收方，把收到的UDP用户数据报连同伪首部（以及可能的填充全零字节）一起，按二进制反码求这些16位字的和。当无差错时其结果应为全1。否则就表明有差错出现，接收方就应丢弃这个UDP用户数据报（也可以上交给应用层，但附上出现了差错的警告）<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/349726b142d5dc53670b7.png" alt="26.PNG"><br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/9beb33fa6584bca0b141c.png" alt="35.PNG"></li>
</ul>
</li>
</ul>
<h2>5.3. 传输控制协议TCP(Transmission Control Protocol)</h2>
<ul>
<li>
<p>TCP特点</p>
<ul>
<li>TCP是面向连接的。发送数据之前，必须先建立TCP连接。在发送数据结束时，必须释放已经建立的TCP连接</li>
<li>每一条TCP连接只能有一对一的两个端点(endpoint)。TCP连接的端点叫做套接字(socket)。套接字Socket = IP地址：端口号，同一个IP地址或者端口号都有多个TCP连接，套接字本质是通信操作的各种控制信息，可用netstat -and查看，a显示所有套接字，n IP地址和端口号，o显示使用该套接字的程序PID。0.0.0.0表示无通信，不绑定IP地址。*:*表示UDP</li>
<li>TCP提供可靠交付的服务。通过TCP连接传送的数据，无差错、不丢失、不重复、并且按序到达</li>
<li>TCP提供全双工通信。TCP允许通信双方的应用进程在任何时候都能发送数据。两端都设有发送缓存和接收缓存用来临时存放双向通信的数据。在发送或接收时，应用程序在把数据传送或放入给TCP的缓存后，在合适的时候把数据发送出去或者读取出来</li>
<li>TCP是面向字节流的。TCP把应用程序交下来的数据看成仅仅是一连串的无结构无意义的字节流。TCP保证接收方应用程序所收到的字节流和发送方应用程序所发出的字节流完全一样。接收方应用程序必须有能力识别收到的字节流，把他还原成有意义的应用层数据</li>
</ul>
</li>
<li>
<p>TCP报文段的首部格式（首部长度[20-60]字节-&gt;固定20字节+【0-40】字节的选项）<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/b527fa063670a3fe0e678.png" alt="20.png"></p>
<ul>
<li>源端口和目的端口:各占2个字节，源端口号和目的端口号。</li>
<li>序号/报文段序号seq：4字节。本报文段数据的第一个字节的序号，[0, 2^32-1]，使用mod2^32运算。TCP连接中传送的字节流中的每一个字节都按顺序编号。一个字节一个序号，字节流的起始序号必须在连接建立时设置。（为了安全，初始值是随机的）</li>
<li>确认号ack:4字节，期望收到对方下一个报文段的第一个数据字节的序号。若确认号为N，则表明到序号N-1为止的所有数据都已正确收到</li>
<li>数据偏移:4位，TCP报文段的首部长度。0-15 单位是32位字/4字节</li>
<li>保留:占6位，保留为今后使用，但目前置为0</li>
<li>控制位-&gt;紧急URG(URGent):当URG=1时，发送方TCP就把紧急数据插入到本报文段数据的最前面，表示有紧急数据要传输，而在紧急数据后面的数据仍是普通数据。这时要与首部中紧急指针(Urgent Pointer)字段配合使用。（Control + C）</li>
<li>控制位-&gt;确认ACK(ACKnowlegment)ACK=1确认号有效。ACK=0确认号无效。TCP规定，在连接建立后所有传送的报文段都必须把ACK置1</li>
<li>控制位-&gt;推送PSH(PuSH)当PSH=l时，就尽快交付接收应用进程，而不再等到整个缓存都填满了后再向上交付</li>
<li>控制位-&gt;复位RST(ReSeT)RST=1表明TCP连接中出现严重差错，必须释放连接然后再重新建立连接。还用来拒绝非法报文段或拒绝打开连接</li>
<li>控制位-&gt;同步SYN (SYNchronization)  在连接建立时用来同步序号。</li>
<li>控制位-&gt;终止FIN (FINis) 当FIN=l时，表明此报文段的发送方的数据已发送完毕，并要求释放运输连接</li>
<li>窗口rwnd:2字节。[0, 2^16-1] 从本报文段首部中的确认号算起，接收方目前允许对方发送的数据量（因为接收方的数据缓存空间有限）窗口字段明确指出了现在允许对方发送的数据量</li>
<li>检验和：2字节。检验的范围包括首部和教据这两部分。和UDP一样计算检验和，但应把伪首部第4个字段中的17改为6（TCP的协议号是6），把第5字段中的UDP长度改为TCP长度</li>
<li>紧急指针:2字节。URG=1时才有意义，指出了紧急数据的末尾在报文段中的位置（紧急数据结束后就是普通数据）。当所有紧急数据都处理完时，TCP就告诉应用程序恢复到正常操作。即使窗口为零时也可发送紧急数据。</li>
<li>选项:长度可变，最长40字节
<ul>
<li>最大报文段长度MSS (Maximum Segment Size):每一个TCP报文段中的数据字段的最大长度。若选择较小的MSS长度，网络的利用率就降低。若TCP报文段非常长，lP层传输时要分解成多个短数据报片。在终点要把收到的各个短数据报片装配成原来的TCP报文段。当传输出错时还要进行重传。也会使开销增大。因此，MSS应尽可能大些，只要在IP层传输时不需要分片就行。在连接建立的过程中，双方能把自己能够支持的MSS写入这一字段，以后就按照这个数值传输数据，两个传送方向可以有不同的MSS值。MSS的默认值是536字节长。故所有在互联网上的主机都应该接受的报文段长度是536+20（固定首部长度）=556字节。（？由MAC帧最大传输单元MTU决定，减去TCP和IP头部得到）</li>
<li>窗口扩大选项:为了扩大窗口。占3字节，其中有一个字节表示移位值S(最大值是14)。新的窗口值等于TCP首部中的窗口位数从16增大到(16+S),相当于窗口最大值增大到 2^(16+14)-1=2^30-1)。窗口扩大选项可以在双方初始建立TCP连接时进行协商。</li>
<li>时间戳选项：10字节，其中最主要的字段时间戳值字段（4字节）和时间戳回送回答字段（4字节）。
<ul>
<li>计算往返时间RTT。发送方在发送报文段时把当前时钟的时间值放入时间戳字段，接收方在确认该报文段时把时间戳字段值复制到时间戳回送回答字段。发送方在收到确认报文后，可以准确地计算出RTT</li>
<li>处理TCP序号超过2^32/防止序号绕回PAWS (ProtectAgainst Wrapped Sequence numbers)。高速网络在一次TCP连接的数据传送中序号很可能会被重复使用。为了使接收方能够把新的报文段和其他的报文段区分开，可以加上这种时间戳</li>
</ul>
</li>
<li>选择确认SACK：只传送缺少的数据而不重传已经正确到达接收方的数据。接收方告诉发送方没收到的连续的字节块边界，字节块左边界是第一个字节的序号，而右边减1才是字节块中的最后一个序号。选项中最多能指明4个字节块的占4个字节的边界信息(即最多32字节)。另外还包括一个字节指明是SACK选项，另一个字节指明这个选项要占用多少字节</li>
</ul>
</li>
</ul>
</li>
<li>
<p>TCP的运输连接管理<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/41e6eb528927d80eac755.png" alt="27.png"><br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/b03555c0c8b95dd455de1.png" alt="29.png"></p>
<ul>
<li>TCP连接建立（三次握手）需要客户端再发送确认的目的是防止已失效的连接请求报文（滞留）突然又传到服务端，产生错误，同时确认两边的发送和接收功能正常
<ul>
<li>TCP服务器进程先创建传输控制块TCB，然后服务器进程就处于LISTEN（收听）状态，等待客户的连接请求。如有，即作出响应</li>
<li>TCP客户进程也是先创建传输控制模块TCB，然后向TCP服务端发出连接请求报文段，这时首部中的同步位SYN=1，同时选择一个初始序号seq=x。TCP客户进程进入SYN-SENT（同步已发送）状态（TCP规定，SYN=1的报文段不能携带数据，但要消耗掉一个序号）</li>
<li>TCP服务器收到连接请求报文段后，如同意建立连接，则向A发送确认。在确认报文段中应把SYN位和ACK位都置1，确认号是ack=x+l，同时也为自己选择一个初始序号seq=y。这个报文段也不能携带数据，但同样要消耗掉一个序号。TCP服务器进程进入SYN-RCVD（同步收到）状态。</li>
<li>TCP客户进程收到服务器的确认后，还要向服务器给出确认，确认报文ACK=1，确认号ack=y+1，序号seq=x+1，客户端进入连接状态(TCP的标准规定，ACK报文段可以携带数据，但如果不携带数据则不消耗序号)</li>
<li>TCP服务端收到客户端的确认后，也进入ESTABLISHED状态</li>
</ul>
</li>
<li>TCP连接释放（四次挥手）
<ul>
<li>TCP客户端先向其TCP服务端发出连接释放报文段，并停止再发送数据，主动关闭TCP连接。把连接释放报文段首部的终止控制位FIN置1，其序号seq=u，它等于前面已传送过的数据的最后一个字节的序号加l。进入FIN-WAIT-1（终止等待1）状态，等待服务器的确认。TCP规定，FIN报文段即使不携带数据，它也消耗掉一个序号。</li>
<li>TCP服务端收到连接释放报文段后即发出确认，确认号是ack=u+l，而这个报文段自己的序号是v，等于前面已传送过的数据的最后一个字节的序号加1。然后就进入CLOSE-WAIT（关闭等待）状态。TCP服务器进程这时应通知高层应用进程，因而从客户端到服务端这个方向的连接就释放了，这时的TCP连接处于半关闭(half-close)状态，即客户端已经没有数据要发送了，但服务端若发送数据，客户端仍要接收。从服务端到客户端这个方向的连接并未关闭，这个状态可能会持续一些时间。</li>
<li>TCP客户端收到服务段的确认后，进入FIN-WAIT-2（终止等待2）状态，等待服务端发出的连接释放报文段，若服务端已经没有要想要发送的数据，则通知TCP释放连接，服务端发出释放报文FIN=1，假定服务端的序号为w（在半关闭状态下服务端又可能发送了一些数据），服务端必须重复上次已发送过的确认号ack=u+1，此时服务端进入LAST-ACK（最后确认）状态，等待客户端的确认</li>
<li>TCP客户端收到服务端的连接释放报文后，必须发出确认，把ACK=1，确认号为ack=w+1，序号seq=u+1（前面发送过的FIN报文段也要消耗一个序号），进入TIME-WAIT（时间等待）状态。经过时间等待计时器（TIME-WAIT timer）设置的时间2MSL后，客户端进入CLOSED状态；时间MSL叫做最长报文段寿命（建议设置为2分钟）</li>
</ul>
</li>
<li>等待计时器：为什么客户端段在TIME-WAIT状态必须等待2MSL时间？
<ul>
<li>为了保证客户端发送的最后一个ACK报文能到达服务端。这个ACK报文有可能丢失，因而处在LAST-ACK状态的服务端收不到对已发送的FIN+ACK报文段的确认。服务端就会超时重传FIN+ACK报文段，而客户端就能在2MSL时间内收到这个重传的FIN+ACK报文段，接着客户端重传一次确认，重新启动2MSL计时器，最后客户端和服务端都正常进入CLOSED状态</li>
<li>为了防止已失效的连接请求报文段出现在本连接中，客户端在发送完最后一个ACK报文段后，再经过时间2MSL，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失，这样就可以使下一个新的连接中不会出现这种旧的连接请求报文段。服务端只要收到了客户端发出的确认，就进入CLOSED状态。同样，服务端在撤销相应的传输控制块之后，就结束了这次的TCP连接，服务端结束TCP连接的时间要比客户端早</li>
</ul>
</li>
<li>保活计时器(Keepalive timer)
<ul>
<li>服务器每收到一次客户端的数据，就重新设置保活计时器，通常是2小时，若2小时候没有收到客户的数据，服务器就发送一个探测报文段，以后每隔75分钟就发送一次，若一连发送10个探测报文段后仍无客户的响应，服务器就认为客户端出现故障，接着关闭连接</li>
</ul>
</li>
</ul>
</li>
<li>
<p>TCP的有限状态机<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/2ab4d20951e951319e040.png" alt="27.png"></p>
</li>
<li>
<p>传输控制协议TCP可靠传输</p>
<ul>
<li>可靠传输：当出现差错时让发送方重传出现差错的数据，同时在接收方来不及处理收到的数据时，及时告诉发送方适当降低发送数据的速度。这样一来，本来是不可靠的传输信道就能够实现可靠传输了。</li>
<li>可靠传输协议：自动重传请求（Automatic Repeat reQuest，ARQ）协议包括停止等待ARQ协议、连续ARQ协议</li>
<li>自动重传请求（Automatic Repeat reQuest，ARQ）协议，停止等待协议（简单但是信道利用率低）
<ul>
<li>停止等待：每发送完一个分组就停止发送，等待对方的确认，在收到确认后再发下一个分组</li>
<li>超时重传：发送方只要超过了一段时间没有收到确认，就认为刚才发送的分组丢失，重传前面发送过的分组。要实现超时重传，就要在每发送完一个分组设置一个超时计时器。如果在超时计时器到期之前收到了对方的确认，就撤销已设置的超时计时器。超时计时器设置的重传时间应当比数据在分组传输的平均往返时间更长一些。（如果重传时间设定太长，通信效率低，太短，产生不必要的重传，浪费网络资源）TCP 会在发送数据的过程中持续测量 ACK 号的返回时间，如果ACK号返回变慢，则相应延长等待时间；相对地，如果ACK号马上就能返回，则相应缩短等待时间</li>
<li>发送方在发送完一个分组后，必须暂时保留已发送的分组的副本（为发生超时重传时使用）。只有在收到相应的确认后才能清除暂时保留的分组副本</li>
<li>分组和确认分组都必须进行编号。这样才能明确是哪一个发送出去的分组收到了确认，而哪一个分组还没有收到确认。</li>
<li>确认丢失（接收方发送的确认丢失了）：接收方又收到了重传的分组。丢弃这个重复的分组。并向发送方发送确认。</li>
<li>确认迟到（接收方发送的确认迟到了）发送方收到接收方重复的确认时，收下就丢弃，接收方收到重复的分组时，同样丢弃重复的分组，并重传确认分组</li>
</ul>
</li>
<li>连续ARQ协议（以字节为单位的滑动窗口协议）
<ul>
<li>发送方维持的发送窗口，位于发送窗口内的分组都可按照分组序号从小到大连续发送出去，而不需要等待对方的确认。信道利用率提高了</li>
<li>连续ARQ协议规定，发送方每收到一个确认，就把发送窗口向前滑动一个分组的位置。接收方一般采用累积确认的方式。接收方不必对收到的分组逐个发送确认，而是在收到几个分组后，<strong>对按序到达的最后一个分组发送确认</strong>，表示到这个分组为止的所有分组都己正确收到。接收方可以在合适的时候发送确认，也可以在自己有数据要发送时把确认信息顺便捎带上（接收方不应过分推迟发送确认，否则会导致发送方不必要的冲转，反而浪费网络资源，TCP规定，确认推迟的时间不应该超过0.5秒。若收到一连串具有最大长度的报文段，则必须每个一段报文段就要发送一个确认，捎带确认不经常发生，因为大多数应用程序不同时在两个方向上发送数据），</li>
<li>累积确认容易实现，即使确认丢失也不必重传。但不能向发送方反映出接收方已经正确收到的所有分组的信息。当通信线路质量不好时，会发生回退N问题，如果发送方发送前5个分组，而中间的第三个分组丢失了，这时接收方只能对前两个分组发出确认。发送方无法知道后面三个分组的下落，而只好把后面的三个分组都再重传一次，叫做回退N，表示需要再退回来重传已发送过的N个分组。</li>
<li>对不按序到达的数据先临时存放在接收窗口中，等到字节流中所缺少的字节收到后，再按序交付上层应用</li>
</ul>
</li>
</ul>
</li>
<li>
<p>传输控制协议TCP流量控制(flow control)</p>
<ul>
<li>流量控制：让发送方的速率不要太快，要让接收方来得及接收</li>
<li>滑动窗口机制：连接建立后，发送方的发送窗口rwnd不能超过接收方给出的接收窗口数值（单位字节）通过窗口大小控制对方发送速率</li>
<li>发送方收到零窗口通知后不久，接收方的接收缓存又有一些存储空间，但接收方的发送窗口信息丢失，发送方一直等待非零窗口导致死锁：只要TCP连接的一方收到对方的零窗口通知，启动持续计时器，若时间到期，则发送一个零窗口探测报文段，对方就在确认这个字段时给出现在的窗口值。如果窗口仍然是零，重新设置持续计时器。如果窗口不是零，那么死锁局面打破</li>
</ul>
</li>
<li>
<p>TCP的拥塞(congestion)控制</p>
<ul>
<li>拥塞:某段时间，若对网络中某一资源的需求超过了该资源所能提供的可用部分，网络的性能就要变坏的情况。</li>
<li>拥塞控制就是防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不致过载。</li>
<li>拥塞控制所要做的都有一个前提，就是网络能够承受现有的网络负荷。拥塞控制是一个全局性的过程，涉及到所有的主机、所有的路由器，以及与降低网络传输性能有关所有因素。但TCP连接的端点只要迟迟不能收到对方的确认信息，就猜想在当前网络中的某处很可能发生了拥塞，但这时却无法知道拥塞到底发生在网络的何处，也无法知道发生拥塞的具体原因。</li>
<li>相反，流量控制往往指点对点通信量的控制，是个端到端的问题（接收端控制发送端）。流量控制所要做的就是抑制发送端发送数据的速率，以便使接收端来得及接收。</li>
<li>发送方维持一个叫做拥塞窗口CWND的状态变量，拥塞窗口的大小取决于网络的拥塞程度，并且动态地变化，发送方让自己的发送窗口等于拥塞窗口，如果再考虑到接收方的接收能力，那么发送窗口还可能小于拥塞窗口</li>
<li>只要发送方没有按时收到应当到达的确认报文，就猜想网络可能出现拥塞。</li>
<li>TCP拥塞控制方法
<ul>
<li>慢开始和拥塞避免算法
<ul>
<li>慢开始：先把拥塞窗口cwnd设置为一个最大报文段MSS的数值。每收到一个对新的报文段确认就把发送方的拥塞窗口增加至多一个MSS的数值，每经过一个传输轮次，拥塞窗口cwnd就加倍</li>
<li>拥塞避免算法：每经过一个往返时间就把发送方的拥塞窗口cwnd加1</li>
<li>慢开始门限ssthresh：防止拥塞窗口增长过大引起网络拥塞，拥塞窗口cwnd小于慢开始门限使用慢开始算法，否则使用拥塞避免算法</li>
<li>无论在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞（其根据就是没有按时收到确认），就要把慢开始门ssthresh设置为出现拥塞时的发送方窗口值的一半（但不能小于2）。然后把拥塞窗口cwnd重新设置为l，执行慢开始算法</li>
</ul>
</li>
<li>快重传和快恢复
<ul>
<li>快重传：接收方每收到一个失序的报文段后就立即发出重复确认（为的是使发送方及早知道有报文段没有到达对方），而不用等待自己发送数据时才进行捎带确认，发送方一连收到三个重复确认就立即重传对方尚未收到的下一个报文段。而不必继续等待为收到报文段设置的重传计时器到期</li>
<li>快恢复：当发送方连续收到三个重复确认时，慢开始门限减半，把cwnd值设置为慢开始门限的数值，执行拥塞避免算法</li>
</ul>
</li>
</ul>
</li>
<li>发送窗口的上限值 = Min[rwnd,cwnd]，当rwnd&lt;cwnd时，是接收方的接收能力限制发送方窗口的最大值，当rwnd&gt;cwnd时，是网络拥塞限制发送方窗口的最大值</li>
</ul>
</li>
<li>
<p>4个定时器: 超时定时器，持续计时器，等待计时器，保活计时器</p>
</li>
</ul>
<h1>6. 应用层</h1>
<h2>6.1. 概述</h2>
<ul>
<li>运输层为应用进程提供了端到端的通信服务，但不同的网络应用进程之间，还需要有不同的通信规则，因此需要有应用层协议<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/64d1c2fd5d2936cc62893.jpg" alt="18.png"></li>
</ul>
<h2>6.2. 域名系统DNS</h2>
<ul>
<li>
<p>域名系统DNS（Domain Name System）是因特网使用的命名系统，完成域名（主机名字）到IP地址的解析，也可以将邮件地址与邮件服务器进行关联，域名到IP地址的解析由分布在互联网上的许多域名服务器程序共同完成的，因特网的域名系统DNS被设计成为一个联机分布式数据库系统。</p>
</li>
<li>
<p>域名与IP并用原因：1.域名比IP方便记忆理解，2.IP长度固定运行效率高</p>
</li>
<li>
<p>域名到IP地址的解析过程</p>
<ul>
<li>当某一个应用进程需要把主机名解析为IP地址时，该应用进程就调用解析程序（包含在操作系统的Socket库中，用于调用网络功能的程序组件集合），并成为DNS的一个客户，把待解析的域名放在DNS请求报文中，以UDP用户数据报的方式发送给本地域名服务器（减少开支）。本地域名服务器再查找域名后，把对应的IP地址放在回答报文中返回，应用进程获得目的主机的IP地址后即可进行通信。</li>
<li>若本地域名服务器不能回答该请求，则此时域名服务器就暂时成为DNS中的另一个客户，然后再向根域名服务器发送信息，得到顶级域名服务器IP地址，然后继续向顶级域名服务器发出查询请求。这种过程直到找到该请求的域名服务器为止</li>
<li>来自客户端查询消息包括：域名（服务器，邮件服务器（@后面的部分）的名称），Class（IN标识互联网，识别除互联网外的应用），记录类型（表示域名对应何种类型的记录。A：域名对应的是IP地址，MX：域名对应邮件服务器和优先级（数值小的优先），PTR：根据IP地址查域名，CNAME：查询域名相关别名，NS：查询DNS服务器IP地址，SOA：查询域名属性信息）</li>
</ul>
</li>
<li>
<p>域名的层次结构</p>
<ul>
<li>互联网采用层次树状结构的命名方法，任何一个连接在互联网上的主机或路由器，都有一个唯一的域名，</li>
<li>域是名字空间中一个可被管理的划分，域还可以划分子域，子域还可以划分为子域的子域，形成了顶级域、二级域、三级域等。</li>
<li>每个域名由标号序列组成，各标号用点“.”隔开，域名中的标号都由英文字母和数字组成，每一个标号都不超过63个字符，不区分大小写字母，除了-不能使用其他标点服务号，级别最低的域名写左边，级别最高的域名写最右边，完整域名不能超过255个字符；<a href="http://mail.cctv.com" target="_blank" rel="noopener noreferrer">mail.cctv.com</a> mail三级域名，cctv二级域名，com一级域名，各级域名由其上一级的域名管理机构管理，而最高的顶级域名则由ICANN进行管理，mail.cctv.com域的DNS服务器注册到cctv.com域的DNS服务器中，cctv.com域的DNS服务器注册到com域DNS服务器中</li>
</ul>
</li>
<li>
<p>域名服务器</p>
<ul>
<li>DNS服务器管辖范围以区为单位，区小于等于域。域名服务器所负责管辖的范围叫区，一个区中的所有节点必须是能够连通的，每一个区设置相应的权限域名服务器，用来保存该区中的所有主机的域名到IP地址的映射，</li>
<li>根域名服务器：最高层次的域名服务器，所有的根域名服务器都知道所有的顶级域名服务器的域名和IP地址，因特网共有13个不同IP地址的域名服务器，根域名服务器采用任播技术，当DNS客户向某个根域名服务器的IP地址发出查询报文时，互联网上的路由器就能找到离这个DNS客户最近的一个根域名服务器，根域名服务器不把待查询的域名直接转换成IP地址，而是告诉本地域名服务器下一步应该找哪个顶级域名服务器</li>
<li>顶级域名服务器：负责管理在该顶级域名服务器注册的所有二级域名，当收到DNS查询请求时，就给出最后的结果或者下一步域名服务器地址</li>
<li>权限域名服务器：负责一个区的域名服务器，当不能给出查询答案时，会给出下一步权限服务器地址</li>
<li>本地域名服务器：当一台主机发出DNS查询请求时，请求报文发给本地域名服务器，每一个ISP都有本地域名服务器</li>
<li>所有DNS服务器都保存了根域的DNS服务器信息<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/f0da2fd8d1f899f57658a.png" alt="37.PNG"></li>
</ul>
</li>
<li>
<p>域名解析过程</p>
<ul>
<li>本机向本地域名服务器查询一般都是采用递归查询：如果本机所询问的本地域名服务器不知道被查询域名的IP地址，那么本地域名服务器以DNS客户的身份，向其他根域名服务器继续发出查询请求报文（替该主机继续查询），而不是让该主机自己进行下一步查询。因此，递归查询的返回结果是所要查询的IP地址，或者是报错，表示无法查询到所需的IP地址</li>
<li>本地域名服务器向根域名服务器查询通常采用迭代查询：当本地域名服务器收到本地域名服务器发出的迭代查询请求报文时，要么给出IP地址，要么给出下一步要查询的域名服务器地址，让本地域名服务器进行后续的查询，本地域名服务器也可以采用递归查询，取决于最初查询的请求报文设置要求使用哪一种查询方式</li>
<li>为了提高域名服务的可靠性，DNS域名服务器把数据复制到几个域名服务器来保存，其中一个是主域名服务器，其他的是辅助域名服务器，主域名服务器定期把数据复制到辅助域名服务器中，而更改数据只能在主域名服务器中进行，保证数据的一致性</li>
<li>为了提高DNS查询效率，减轻根域名服务器的负荷和减少互联网上的DNS查询报文数量，在域名服务器中广泛使用高速缓存，用来存放最近查询过的域名以及从何处获得域名映射信息的记录（不存在也会缓存）</li>
<li>为了保证高速缓存中的内容正确，域名服务器应为每项内容设计计时器并处理超过合理时间的项。当域名服务器已从缓存中删去某项信息后又被请求查询该项信息，就必须重新到授权管理该项的域名服务器获取绑定信息，当权限域名回答一个查询请求时，在响应中都指明绑定有效存在的时间值，增加此时间值可减少网络开销，而减少此时间值可提高域名转换的准确性</li>
</ul>
</li>
</ul>
<h2>6.3. FTP(File Transfer Protocol文件传送协议)</h2>
<ul>
<li>FTP概述：FTP提供交互式访问，允许客户指明文件的类型和格式，并允许文件具有存取权限；FTP屏蔽了各计算机系统的细节，因而适合于在异构网络中任一计算机之间传送文件</li>
<li>文件共享协议
<ul>
<li>复制整个文件：若要存取一个文件必须先获得一个本地的文件副本。要修改文件，只能对文件副本修改，然后将修改后的文件副本传回到原节点
<ul>
<li>基于TCP的FTP：减少或消除在不同操作系统下处理文件的不兼容性
<ul>
<li>使用客户服务器方式：一个FTP服务器进程可同时为多个客户进程提供服务。FTP的服务器进程由主进程（接收新请求）和若干和从属进程（负责处理单个请求）（控制进程和数据传送进程）组成</li>
<li>主进程工作步骤
<ul>
<li>打开端口21，使客户进程能够连上</li>
<li>等待客户进程发出连接请求</li>
<li>启动从属进程处理客户进程发来的请求。从属进程对客户进程的请求处理完毕后即终止，但从属进程在运行期间根据需要还可能创建其他一些子进程。</li>
<li>回到等待状态，继续接受其他客户进程发来的请求。主进程与从属进程的处理是并发地进行</li>
</ul>
</li>
<li>在进行文件传输时，FTP的客户机和服务器之间要建立两个TCP连接，一个用于传输控制命令和响应，称为控制连接，一个用于实际的文件内容传输，称为数据连接。控制连接在整个会话期间一直打开，FTP客户端发出请求，通过控制连接发送给服务端的控制进程。服务端的控制进程在收到FTP客户端发来的文件传输请求后就创建数据传送进程，用来连接客户端和服务器短的数据传送进程。完成实际文件的传送，传送完毕后关闭数据传送连接并结束运行</li>
</ul>
</li>
<li>基于UDP的TFTP（简单文件传送协议）
<ul>
<li>采用客户服务器方式，TFTP只支持文件传输而不支持交互，而且需要有自己的差错修改措施</li>
<li>TFTP优点
<ul>
<li>TFTP可用于UDP环境，当需要将程序或文件同时向许多机器下载时就往往需要使用TFTP</li>
<li>TFTP代码所占内存较小。这对较小的计算机或者某些特殊用途的设备很重要，这些设备不需要硬盘，只需要固化了TFTP和UDP以及IP的小容量只读存储器即可，当接通电源后，设备执行只读存储器中的代码，在网络上广播一个TFTP请求，网络上的TFTP服务器发送响应，其中包括可执行二进制程序。设备收到此文件后将其放入内存，然后开始运行程序。这种方式增加了灵活性，较少开销</li>
</ul>
</li>
<li>TFTP的主要特点
<ul>
<li>每次传送的数据报文中有512字节的数据，但最后一次可不足512字节</li>
<li>数据报文按序编号，从1开始</li>
<li>支持ASCII码或者二进制传送</li>
<li>可对文件进行读写</li>
<li>使用简单的首部</li>
</ul>
</li>
<li>发送完一个文件块后就等待对方的确认， 确认应指明所确认的块编号，发送数据后的规定时间内收不到确认就要重发数据PDU。发送确认PDU的一方，若在规定时间内收不到下一个文件块，也要重发确认PDU，可保证文件的传送不至因某一个数据报的丢失而告失败</li>
<li>TFTP客户进程发送一个读请求报文或者写请求报文给TFTP服务进程，端口号69，TFTP服务器进程选择一个新的端口和TFTP进程进行通信。若文件的长度恰好为512字节整数倍，则在文件传送完毕后，还必须在最后发送一个含首部而无数据的数据报文，若文件长度不是512字节的整数倍，则最后传送报文中的数据字段一定不满512字节，正好作为文件结束的标志</li>
</ul>
</li>
</ul>
</li>
<li>联机访问：允许多个程序同时对一个文件进行存取。由操作系统提供对远地共享文件进行访问的服务，用户可以用远地文件作为输入和输出来运行任何应用程序，操作系统中的文件系统则提供对共享文件的透明存取（将原来用于处理本地文件的应用程序用来处理远地文件时，不需要对应用程序作明显的改动，属于文件共享协议的网络文件系统NFS）
<ul>
<li>NFS允许应用进程打开一个远地文件，并能在该文件的某一个特定的位置上开始读写数据。这样NFS可使用户只复制一个大文件中的很小的片段，把要添加的数据和在文件后面写数据的请求一起发送到远地NFS服务器，NFS服务器更新文件后返回应答信息。在网络上传送的只是少量的修改数据</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2>6.4. 远程终端协议TELNET</h2>
<ul>
<li>TELNET通过TCP连接注册到远地的另一台主机上，将用户的击键传到远地主机，同时也能将远地主机的输出通过TCP连接返回到用户屏幕。这种服务是透明的，因为用户感觉到好像键盘和显示器是直接连接到远地主机上</li>
<li>TELNET也使用客户-服务器方式，服务器中的主进程等待新请求，并产生从属进程处理每一个连接</li>
<li>TELNET能适应许多计算机和操作系统差异，它定义了数据和命令怎么通过因特网。就是所谓的网络虚拟终端NVT。客户软件和服务器软件完成了NVT格式转换为远地和本地系统格式的转换</li>
<li>TELNET格式定义简单。所有通信使用8位一个字节。在运转时，NVT使用7位ASCII码传送数据，高位置为1用作控制命令。ASCII码，共有95个可打印字符（如字母、数字、标点符号）和33个控制字符 。所有可打印字符在NVT中的意义和在ASCII码中一样。但NVT只使用了ASCII码的控制字符中的几个。NVT还定义了两字符的CR-LF为标准的行结束控制符。当用户键入回车按键时，TELNET客户端把它转换为CR-LF再进行传输，而TELNET要把CR-LF转换为远地机器的行结束符</li>
<li>TELNET的选项协商使TELNET客户和TELNET服务器可商定使用更多终端功能，协商双方是平等的</li>
</ul>
<h2>6.5. 万维网</h2>
<ul>
<li>万维网是一个分布式的超媒体系统，是超文本（包含指向其他文档的链接的文本）系统的扩充。万维网以客户端服务器方式工作，用户主机上运行客户端程序，万维网文档所驻留的主机则运行服务器程序。客户程序向服务器程序发请求，服务器程序向客户程序送回客户所要的万维网文档。在客户端程序主窗口上显示的万维网文档称为页面</li>
<li>万维网使用在整个互联网中唯一的统一资源定位符url标志万维网上的各种文档，使用超文本传送协议http。http使用tcp进行可靠传送，使用超文本标记语言html，使得万维网文档在各种主机上显示和查找信息</li>
<li>URL(Uniform Resource Locator)（统一资源定位符，不区分大小写）：&lt;协议&gt;://&lt;主机&gt;:&lt;端口&gt;/&lt;路径&gt; .表示互联网上得到的资源位置和访问这些资源的方法，是与互联网相连的机器上的任何可访问对象的一个指针，互联网上的所有资源都有一个唯一确定的url，资源指在互联网上可以被访问的任何对象，包括文件目录、文件、文档、图像、声音以及与互联网相连的任何形式的数据。资源还包括电子邮件地址和USENET新闻组及其报文。</li>
<li>http的url默认端口号80：可忽略</li>
</ul>
<h2>6.6. 超文本传送协议http(HyperText Transfer Protocol)</h2>
<ul>
<li>http的操作过程
<ul>
<li>http规定客户端与服务端每次交互，都由一个ASCII码串构成的请求和一个类似通用因特网邮件的扩充，即类MIME的相应组成，HTTP报文通常都用TCP连接传送</li>
<li>http是面向事务的应用层协议，传送完成超文本跳转所必须的信息，而且传送任何可从互联网上得到的信息</li>
<li>http是无连接的，虽然使用了TCP连接，但通信双方在交换HTTP报文之前不需要先建立http连接</li>
<li>http是无状态的，服务器不记得曾经访问过的用户，也不记得为该用户曾经服务过多少次</li>
<li>请求一个万维网文档所需的时间是该文档的传输时间加上两倍往返时间RTT（一个RTT用于建立TCP，另一个RTT用于请求和接收万维网文档）。TCP建立连接的三报文握手的第三个报文段中的数据，就是客户对万维网的请求报文</li>
<li>http1.1使用持续连接：万维网服务器器再发送响应后仍然在一段时间内保持这条连接，使同一个客户（浏览器）和该服务器可以继续在这条连接上传送后续的http请求报文和响应报文，不局限于传送同一个页面链接的文档，只要是同一个服务器就可以</li>
<li>http1.1协议的持续连接工作方式
<ul>
<li>非流水线方式：客户端收到前一个响应后才能发出下一个请求。在TCP连接建立后，客户每访问一次对象都要用去一个往返时间RTT、服务器发送完一个对象后，其TCP连接处于空闲状态，浪费了服务器资源</li>
<li>流水线方式：客户端收到响应报文前能够接着发送新的请求报文。服务器可以连续发回响应报文，客户访问的所有对象只需花费一个RTT时间。流水线工作方式使TCP连接中的空闲时间减少，提高了效率</li>
</ul>
</li>
</ul>
</li>
<li>代理服务器/万维网高速缓存
<ul>
<li>代理服务器把最近的一些请求和响应暂存在本地磁盘中。当新请求到达时，若代理服务器发现这个请求和暂存的请求相同，就返回暂存的响应，而不需要按URL的地址再去互联网访问该资源，代理服务器既是服务器也是客户端</li>
</ul>
</li>
<li>http的报文结构：http是面向文本的，报文中的每一个字段都是ASCII码串，各字段的长度都是不固定的
<ul>
<li>开始行：用于区分是请求报文还是响应报文，在请求报文中的开始行叫做请求行，响应报文中叫状态行，在开始行的三个字段间都以空格分隔开，CR和LF分别代表回车和换行</li>
<li>首部行：说明浏览器、服务器或报文主体的一些信息，在每一个首部行中都有首部字段名和它的值，每一行在结束的地方都要有回车和换行，首部行结束时，还有一空行将首部行和后面的实体主题分开
<ul>
<li>Authorization 身份认证数据</li>
<li>Connection 设置发送响应之后 TCP 连接是否继续保持的通信选项</li>
<li>Referer 当通过点击超级链接进入下一个页面时，在这里会记录下上一个页面的 URI</li>
<li>User-Agent 客户端软件的名称和版本号等相关信息</li>
<li>Accept 客户端可支持的数据类型（Content-Type），以 MIME 类型来表示</li>
<li>Accept-Charset 客户端可支持的字符集</li>
<li>Accept-Encoding 客户端可支持的编码格式（Content-Encoding），一般来说表示数据的压缩格式</li>
<li>Accept-Language 客户端可支持的语言，汉语为 zh，英语为 en</li>
<li>Accept-Language 客户端可支持的语言，汉语为 zh，英语为 en</li>
<li>AcceptLanguage 客户端可支持的语言，汉语为 zh，英语为 en</li>
<li>If-ModifiedSince 如果希望仅当数据在某个日期之后有更新时才执行请求，可以在这个字段指定希望的日期。用于判断客户端缓存的数据是否已经过期，如果已经过期则获取新的数据</li>
<li>Allow 表示指定的 URI 支持的方法</li>
<li>Content-Encoding 当消息体经过压缩等编码处理时，表示其编码格式</li>
<li>Content-Length 表示消息体的长度</li>
<li>Content-Type 表示消息体的数据类型，以 MIME 规格定义的数据类型来表示</li>
<li>Content-Language 表示消息体的语言。汉语为 zh，英语为 en</li>
</ul>
</li>
<li>实体主体：请求报文中一般不要，响应报文中也可能没有这个字段。格式由content-type定义</li>
<li>http请求报文特点
<ul>
<li>请求行：方法、请求资源URL，以及HTTP版本
<ul>
<li>OPTION：请求一些选项信息</li>
<li>GET：请求读出URL所标志的信息（只能发送几百字节的数据，超过用POST提交）</li>
<li>HEAD 请求读出由URL所标志的信息的首部</li>
<li>POST：给服务器添加信息</li>
<li>PUT：指明URL下存储一个文档，不存在则创建</li>
<li>DELETE 删除指明的URL所标志的资源</li>
<li>TRACE：将服务器收到的请求行和头部返回给客户端。用于使用代理的环境中检查改写请求的情况。进行环回测试的请求报文</li>
<li>CONNET：用于代理服务器传输加密消息</li>
</ul>
</li>
</ul>
</li>
<li>http响应报文特点
<ul>
<li>状态行：HTTP版本，状态码，以及解释状态码的简单短语
<ul>
<li>1xx表示通知信息（请求的处理进度和情况）的，如请求收到了正在进行处理</li>
<li>2xx表示成功了，如接受或知道了</li>
<li>3xx表示重定向，如要完成请求还必须采取进一步行动</li>
<li>4xx表示客户的差错，如请求中有错误的语法或不能完成</li>
<li>5xx表示服务器差错，如服务器失效无法完成请求</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Cookie：http服务器和客户直接传递的状态信息
<ul>
<li>当用户浏览某个使用Cookie的网站时，服务器就为用户产生一个唯一的识别码，并以此作为索引在服务器的后端数据库产生一个项目，接着在给用户的响应报文中添加字段名为"Set-Cookie：xxx"的首部行，值就是赋予用户的"识别码"，用户收到响应时，浏览器会在它管理的特定Cookie文件中添加一行，包括这个服务器的主机名和"Set-Cookie"后面给出的识别码。当用户继续访问该网站时，没发出一个http请求，浏览器就从Cookie文件中取出这个网站的识别码，并放到http请求报文的Cookie首部行中"Cookie":xxx</li>
</ul>
</li>
</ul>
<h2>6.7. 动态主机配置协议DHCP(Dynamic Host Configuration Protocol)</h2>
<ul>
<li>为了把协议软件做成通用的和便于移植，需要把软件参数化，在协议中给这些参数赋值的动作称为协议配置</li>
<li>动态主机配置协议DHCP提供即插即用联网机制，允许一台计算机加入新的网络和获取IP地址而不用手工参与</li>
<li>每个网络至少有一个DHCP中继代理（路由器），配置了DHCP服务器的IP地址信息。当DHCP中继收到主机以广播形式发送的发现报文后，就以单播方式向DHCP服务器转发此报文，并等待其回答。收到DHCP服务器回答的提供报文后，DHCP中继代理再把此提供报文发回给主机</li>
<li>DHCP报文是局域网协议，使用UDP用户数据报数据，DHCP就是自动获得IP地址和自动获得DNS服务器地址的原理，表示自动使用DHCP协议</li>
<li>DHCP服务器分配给DHCP客户的IP地址是临时的，只能在一段有限时间(租用期)内使用这个分配到的IP地址</li>
<li>DHCP工作过程
<ul>
<li>DHCP服务器被动打开UDP端口67，等待客户端发来的报文</li>
<li>DHCP客户从UDP端口68发送DHCP发现报文</li>
<li>凡收到DHCP发现报文的DHCP服务器发出DHCP提供报文，DHCP客户可能收到多个DHCP提供报文</li>
<li>DHCP客户从几个DHCP服务器中选择其中一个，并向所选择的DHCP服务器发送DHCP请求报文</li>
<li>被选择的DHCP服务器发送确认报文DHCPACK并提供IP地址，从这时起，DHCP客户可以使用这个IP地址，这种状态称为已绑定状态，因为在DHCP的IP地址和硬件地址已经完成绑定，并且可以开始使用得到的临时IP地址。DHCP客户要根据服务器提供的租用期T设置两个计时器T1（0.5T）和T2（0.785T）</li>
<li>T1时间到， DHCP发送请求报文DHCPREQUEST要求更新租用期</li>
<li>DHCP服务器若同意，则发回确认报文DHCPACK，DHCP客户得到了新的租用期，重新设置计时器</li>
<li>DHCP服务器若不同意，则发回否认报文DHCPNACK。DHCP客户必须立即停止使用原来的IP地址，重新申请</li>
<li>若DHCP服务器不响应请求报文DHCPREQUEST，T2时间到，DHCP客户必须重新发送请求报文DHCPREUEST，继续后面步骤</li>
<li>DHCP客户端可以随时提前终止服务器所提供的租用期，这时只需向DHCP服务器发送释放报文DHCPREKEASE即可</li>
</ul>
</li>
</ul>
<h2>6.8. HTTPS协议详解</h2>
<ul>
<li>HTTP是明文传输的,HTTPS(Secure)是安全的HTTP协议,http(s)😕/&lt;主机&gt;:&lt;端口&gt;/&lt;路径&gt; 443</li>
<li>加密模型
<ul>
<li>A、B是拥有一定数学关系的一组秘钥</li>
<li>私钥 私钥自己使用，不对外公开</li>
<li>公钥 公钥给大家使用，对外公开</li>
<li>数字证书
<ul>
<li>数字证书是可信任组织颁发给特定对象的认证</li>
<li>证书格式、版本号 证书序列号 签名算法 有效期 对象名称 对象公开秘钥</li>
</ul>
</li>
<li>SSL(Secure Sockets Layer: 安全套接层)
<ul>
<li>数据安全和数据完整</li>
<li>对传输层数据进行加密后传输</li>
</ul>
</li>
<li>根据随机数1、2、3和相同的算法生成对称秘钥</li>
<li>双方使用对称秘钥进行加密通信</li>
<li>综合使用对称加密、非对称加密</li>
<li>双方分别生成秘钥，没有经过传输	<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/036c1b8c9273e6a20e47d.png" alt="38.PNG"><br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/6a77477bfda27fbc401c9.png" alt="39.PNG"><br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/47d5cb3100ce3dc3088bf.png" alt="40.PNG"><br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/782f3db11aa8a906653c6.png" alt="41.PNG"></li>
</ul>
</li>
</ul>
]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/006edd2a16af2f7f2b12b.png" type="image/png"/>
    </item>
    <item>
      <title>MongoDB</title>
      <link>https://javaguide.cn/backend/database/mongodb.html</link>
      <guid>https://javaguide.cn/backend/database/mongodb.html</guid>
      <source url="https://javaguide.cn/rss.xml">MongoDB</source>
      <description>MongoDB是nosql数据库的一种,对node.js有比较好的支持 是非关系型数据库 1. 关系型数据库与非关系型数据库 2. MongoDB是最接近关系型数据库的非关系型数据库 支持的数据类型√ 3. mongodb数据库的基本概念 MongoDB命令 5.4. node.js操作mongodb(所有对mongodb数据库操作都是异步的) 1. ...</description>
      <category>数据库</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>MongoDB是nosql数据库的一种,对node.js有比较好的支持<br>
是非关系型数据库</p>
<!--more-->
<!-- TOC -->
<ul>
<li><a href="#1-%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E9%9D%9E%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93">1. 关系型数据库与非关系型数据库</a></li>
<li><a href="#2-mongodb%E6%98%AF%E6%9C%80%E6%8E%A5%E8%BF%91%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E9%9D%9E%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93">2. MongoDB是最接近关系型数据库的非关系型数据库</a></li>
<li><a href="#%E6%94%AF%E6%8C%81%E7%9A%84%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B">支持的数据类型√</a></li>
<li><a href="#3-mongodb%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5">3. mongodb数据库的基本概念</a></li>
<li><a href="#mongodb%E5%91%BD%E4%BB%A4">MongoDB命令</a></li>
<li><a href="#54-nodejs%E6%93%8D%E4%BD%9Cmongodb%E6%89%80%E6%9C%89%E5%AF%B9mongodb%E6%95%B0%E6%8D%AE%E5%BA%93%E6%93%8D%E4%BD%9C%E9%83%BD%E6%98%AF%E5%BC%82%E6%AD%A5%E7%9A%84">5.4. node.js操作mongodb(所有对mongodb数据库操作都是异步的)</a></li>
</ul>
<!-- /TOC -->
<h1>1. 关系型数据库与非关系型数据库</h1>
<ul>
<li>关系型数据库是指表与表之间存在联系</li>
<li>所有关系型数据库在操作之前都要设计表结构</li>
<li>所有关系型数据库都要通过sql语音来操作</li>
<li>关系型数据库的表还支持约束</li>
<li>非关系型数据库非常灵活（键值对）</li>
</ul>
<h1>2. MongoDB是最接近关系型数据库的非关系型数据库</h1>
<ul>
<li>数据库→数据库；数据表→集合；表记录→文档对象</li>
</ul>
<h1>支持的数据类型√</h1>
<p>1、String<br>
2、Integer<br>
3、Double<br>
4、Boolean<br>
5、Object<br>
6、Object ID<br>
7、Arrays<br>
8、Min/Max Keys<br>
9、Datetime<br>
10、Code<br>
11、Regular Expression 等</p>
<h1>3. mongodb数据库的基本概念</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>数据库（大对象）→集合（数组）→文档（小对象）
{
	a(数据库):{
		aa(集合):[
			{"name":"junye1"},（文档1）
			{"name":"junye2"},（文档2）
		]
	}
	b(数据库):{
		bb(集合):[
			{"name":"junye3"},（文档3）
			{"name":"junye4"},（文档4）
		]
	}

}
</code></pre></div><h1>MongoDB命令</h1>
<ul>
<li>测试是否成功mongod --version测试是否成功</li>
<li>开启服务mongod [--dbpath=数据存储目录路径]默认使用执行mongod命令所处盘符根目录下的/data/db作为数据存储目录，所以在执行第一次命令的时候手动创建一个/data/db作为数据存储目录</li>
<li>关闭服务 ：ctrl+c</li>
<li>查看数据库列表show dbs</li>
<li>查看当前操作的数据库db</li>
<li>切换到指定数据库，如没有则（当有数据的时候）新建:use 数据库名称</li>
<li>插入数据 db.student.insertOne({"name":"jack"})</li>
<li>查询集合（“表==数组”）show conllections</li>
<li>查询集合下所有的数据db.student.find()</li>
</ul>
<h1>5.4. node.js操作mongodb(所有对mongodb数据库操作都是异步的)</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code># 使用第三方monggose操作（基于上面的包再次封装）（推荐）

//安装npm -i install monggose
const mongoose = require('mongoose');
mongoose.connect('mongodb://localhost/test');

const Cat = mongoose.model('Cat', { name: String });

const kitty = new Cat({ name: 'Zildjian' });
kitty.save().then(() =&gt; console.log('meow'));

# 6. node.js连接mongodb设计集合结构

var mongoose = require('mongoose');
var Schema = mongoose.Schema;
//设计集合结构(表结构)
//字段名称是表结构中的属性名称(约束)值
var blogSchema = new Schema({
	title:  String,
	author: String,
	body:   String,
	comments: [{ body: String, date: Date }],
	date: { type: Date, default: Date.now },
	hidden: Boolean,
	meta: {
	  votes: Number,
	  favs:  Number,
	  require：true
	}
});
//将文档结构发布为模型
//第一个参数表示数据库名称，mongoose会自动将大写名词的字符串生成小写复数的集合名称例如这里的Blog会变成blogs集合名称
//第二个参数表示架构Schema
var Blog = mongoose.model('Blog', blogSchema);

# 插入数据

var testsave = new Blog({
	title:  "haha",
	author: "junye",
	body:   "ceshi",
	comments: [{ body: "xh", date: "2018-08-06" }],
	date: { type: "2018-08-06", default: "2018-08-06" },
	hidden: false,
	meta: {
		1
	}

})
test.save((function)(err,ret//返回值){
	if(err){console.log('保存失败')}
	else{console.log('保存成功')}
})

# 查询数据

//查询所有
Blog.find(function(err,ret){
	if(err){
		console.log('查询失败')
	}else{console.log(ret)//返回所有数组}
})
//条件查询（可能多个）
Blog.find({title:'haha'},function(err,ret){
	if(err){
		console.log('查询失败')
	}else{console.log(ret)//返回所有数组}
})
//查询一个
Blog.findOne({title:'haha'},function(err,ret){
	if(err){
		console.log('查询失败')
	}else{console.log(ret)//返回所有数组}
})

# 删除数据

//根据条件删除所有
Blog.remove({title:'haha'},function(err,ret){
	if(err){
		console.log('删除失败')
	}else{console.log('删除成功')}
})
//根据条件删除一个
Blog.findOneAndRemove(conditions,[options],[callback])
//根据id删除一个
Model.findByIdAndRemove(conditions,[options],[callback])

# 更新数据

//根据条件更新所有
Blog.findByIdAndUpdate(conditions,[options],[callback])
//根据指定条件更新一个
Blog.findOneAndUpdate([conditions],[update][options],[callback])
//根据id更新一个
Blog.findByIdAndUpdate('xxxxxxxx',function(err,ret){
	if(err){
		console.log('更新失败')
	}else{console.log(ret)//更新成功}
})

# 异步promise操作数据库的方法
User.findOne({
	username:'456'
})
.then(function(user){
	if(user){
		console.log('用户已存在')
	}else{
		return new User({
			username:'aaa'
			password:'123'
			email:'dads'
		}).save()
	}
}).then(function(ret){

})
# 异步回调操作数据库的方法
User.findOne({username:'456'},function(user){}
	if(user){
	}else{
		new User({
			username:'aaa'
			password:'123'
			email:'dads'
		}),save(function(){
		
		})
	}
)
</code></pre></div>]]></content:encoded>
    </item>
    <item>
      <title>MySQL</title>
      <link>https://javaguide.cn/backend/database/mysql.html</link>
      <guid>https://javaguide.cn/backend/database/mysql.html</guid>
      <source url="https://javaguide.cn/rss.xml">MySQL</source>
      <description>1. 数据库概念 2. MySQL支持的数据类型 2.1. 数值类型 2.2. 日期时间类型 2.3. 字符串类型 2.4. 选择合适的数据类型 3. MySQL中的运算符 3.1. 算术运算符 3.2. 比较运算符 3.3. 逻辑运算符 3.4. 位运算符 4. MySQL常用函数 4.1. 聚合函数 4.2. 字符串函数 4.3. 数值函数 4.4...</description>
      <category>数据库</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<!-- TOC -->
<ul>
<li><a href="#1-%E6%95%B0%E6%8D%AE%E5%BA%93%E6%A6%82%E5%BF%B5">1. 数据库概念</a></li>
<li><a href="#2-mysql%E6%94%AF%E6%8C%81%E7%9A%84%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B">2. MySQL支持的数据类型</a>
<ul>
<li><a href="#21-%E6%95%B0%E5%80%BC%E7%B1%BB%E5%9E%8B">2.1. 数值类型</a></li>
<li><a href="#22-%E6%97%A5%E6%9C%9F%E6%97%B6%E9%97%B4%E7%B1%BB%E5%9E%8B">2.2. 日期时间类型</a></li>
<li><a href="#23-%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%B1%BB%E5%9E%8B">2.3. 字符串类型</a></li>
<li><a href="#24-%E9%80%89%E6%8B%A9%E5%90%88%E9%80%82%E7%9A%84%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B">2.4. 选择合适的数据类型</a></li>
</ul>
</li>
<li><a href="#3-mysql%E4%B8%AD%E7%9A%84%E8%BF%90%E7%AE%97%E7%AC%A6">3. MySQL中的运算符</a>
<ul>
<li><a href="#31-%E7%AE%97%E6%9C%AF%E8%BF%90%E7%AE%97%E7%AC%A6">3.1. 算术运算符</a></li>
<li><a href="#32-%E6%AF%94%E8%BE%83%E8%BF%90%E7%AE%97%E7%AC%A6">3.2. 比较运算符</a></li>
<li><a href="#33-%E9%80%BB%E8%BE%91%E8%BF%90%E7%AE%97%E7%AC%A6">3.3. 逻辑运算符</a></li>
<li><a href="#34-%E4%BD%8D%E8%BF%90%E7%AE%97%E7%AC%A6">3.4. 位运算符</a></li>
</ul>
</li>
<li><a href="#4-mysql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0">4. MySQL常用函数</a>
<ul>
<li><a href="#41-%E8%81%9A%E5%90%88%E5%87%BD%E6%95%B0">4.1. 聚合函数</a></li>
<li><a href="#42-%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%87%BD%E6%95%B0">4.2. 字符串函数</a></li>
<li><a href="#43-%E6%95%B0%E5%80%BC%E5%87%BD%E6%95%B0">4.3. 数值函数</a></li>
<li><a href="#44-%E6%97%A5%E6%9C%9F%E5%92%8C%E6%97%B6%E9%97%B4%E5%87%BD%E6%95%B0">4.4. 日期和时间函数</a></li>
<li><a href="#45-%E6%B5%81%E7%A8%8B%E5%87%BD%E6%95%B0">4.5. 流程函数</a></li>
<li><a href="#46-%E5%85%B6%E4%BB%96%E5%87%BD%E6%95%B0">4.6. 其他函数</a></li>
</ul>
</li>
<li><a href="#5-%E8%A7%86%E5%9B%BE">5. 视图</a></li>
<li><a href="#6-%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B%E5%92%8C%E5%87%BD%E6%95%B0">6. 存储过程和函数</a>
<ul>
<li><a href="#61-%E5%88%9B%E5%BB%BA%E4%BF%AE%E6%94%B9%E5%88%A0%E9%99%A4%E6%9F%A5%E7%9C%8B%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B%E6%88%96%E8%80%85%E5%87%BD%E6%95%B0">6.1. 创建、修改、删除、查看存储过程或者函数</a></li>
<li><a href="#62-%E5%8F%98%E9%87%8F%E7%9A%84%E4%BD%BF%E7%94%A8">6.2. 变量的使用</a></li>
<li><a href="#63-%E6%9D%A1%E4%BB%B6%E7%9A%84%E5%AE%9A%E4%B9%89%E5%92%8C%E5%A4%84%E7%90%86">6.3. 条件的定义和处理</a></li>
<li><a href="#64-%E5%85%89%E6%A0%87%E7%9A%84%E4%BD%BF%E7%94%A8">6.4. 光标的使用</a></li>
<li><a href="#65-%E6%B5%81%E7%A8%8B%E6%8E%A7%E5%88%B6">6.5. 流程控制</a></li>
</ul>
</li>
<li><a href="#7-%E8%A7%A6%E5%8F%91%E5%99%A8">7. 触发器</a></li>
<li><a href="#8-mysql%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E">8. MySQL存储引擎</a>
<ul>
<li><a href="#81-mysql%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E7%89%B9%E6%80%A7">8.1. MySQL存储引擎特性</a></li>
<li><a href="#82-myisam">8.2. MyISAM</a></li>
<li><a href="#83-innodb">8.3. InnoDB</a></li>
<li><a href="#84-memory">8.4. MEMORY</a></li>
<li><a href="#85-innodb%E4%B8%8Ememory%E5%8C%BA%E5%88%AB">8.5. InnoDB与MEMORY区别</a></li>
</ul>
</li>
<li><a href="#9-memory%E8%A1%A8">9. MEMORY表</a>
<ul>
<li><a href="#91-merge">9.1. MERGE</a></li>
</ul>
</li>
<li><a href="#10-mysql%E8%BF%9E%E6%8E%A5">10. MySQL连接</a>
<ul>
<li><a href="#101-%E9%95%BF%E8%BF%9E%E6%8E%A5%E4%B8%8E%E7%9F%AD%E8%BF%9E%E6%8E%A5">10.1. 长连接与短连接</a></li>
</ul>
</li>
<li><a href="#11-mysql%E7%B4%A2%E5%BC%95">11. MySQL索引</a>
<ul>
<li><a href="#111-%E7%B4%A2%E5%BC%95%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9">11.1. 索引的优缺点</a></li>
<li><a href="#112-%E7%B4%A2%E5%BC%95%E5%88%86%E7%B1%BB">11.2. 索引分类</a>
<ul>
<li><a href="#1121-%E6%8C%89%E7%89%A9%E7%90%86%E5%AD%98%E5%82%A8%E5%88%86%E7%B1%BB">11.2.1. 按物理存储分类</a>
<ul>
<li><a href="#11211-%E8%81%9A%E7%B0%87%E7%B4%A2%E5%BC%95">11.2.1.1. 聚簇索引</a></li>
<li><a href="#11212-%E9%9D%9E%E8%81%9A%E7%B0%87%E7%B4%A2%E5%BC%95">11.2.1.2. 非聚簇索引</a></li>
</ul>
</li>
<li><a href="#1122-%E6%8C%89%E5%AD%97%E6%AE%B5%E7%89%B9%E6%80%A7%E5%88%86%E7%B1%BB">11.2.2. 按字段特性分类</a>
<ul>
<li><a href="#11221-%E4%B8%BB%E9%94%AE%E7%B4%A2%E5%BC%95">11.2.2.1. 主键索引</a></li>
<li><a href="#11222-%E5%94%AF%E4%B8%80%E6%99%AE%E9%80%9A%E7%B4%A2%E5%BC%95%E5%92%8C%E5%94%AF%E4%B8%80%E7%B4%A2%E5%BC%95%E7%9A%84%E5%8C%BA%E5%88%AB">11.2.2.2. 唯一普通索引和唯一索引的区别</a></li>
</ul>
</li>
<li><a href="#1123-%E6%8C%89%E7%B4%A2%E5%BC%95%E5%AD%97%E6%AE%B5%E4%B8%AA%E6%95%B0%E5%88%86%E7%B1%BB">11.2.3. 按索引字段个数分类</a>
<ul>
<li><a href="#11231-%E5%8D%95%E5%88%97%E7%B4%A2%E5%BC%95">11.2.3.1. 单列索引</a></li>
<li><a href="#11232-%E7%BB%84%E5%90%88%E7%B4%A2%E5%BC%95">11.2.3.2. 组合索引</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#113-%E7%B4%A2%E5%BC%95%E4%BD%BF%E7%94%A8">11.3. 索引使用</a>
<ul>
<li><a href="#1131-%E5%89%8D%E7%BC%80%E7%B4%A2%E5%BC%95">11.3.1. 前缀索引</a></li>
</ul>
</li>
<li><a href="#114-%E9%87%8D%E5%BB%BA%E7%B4%A2%E5%BC%95">11.4. 重建索引</a></li>
<li><a href="#115-%E6%9F%A5%E7%9C%8B%E7%B4%A2%E5%BC%95%E4%BD%BF%E7%94%A8%E6%83%85%E5%86%B5">11.5. 查看索引使用情况</a></li>
<li><a href="#116-mysql%E7%B4%A2%E5%BC%95%E5%AE%9E%E7%8E%B0">11.6. MySQL索引实现</a></li>
<li><a href="#117-%E7%B4%A2%E5%BC%95%E7%BB%B4%E6%8A%A4">11.7. 索引维护</a></li>
<li><a href="#118-%E7%B4%A2%E5%BC%95%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99">11.8. 索引设计原则</a></li>
<li><a href="#119-%E7%B4%A2%E5%BC%95%E7%9A%84%E5%B8%B8%E8%A7%81%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B%E5%AE%9E%E7%8E%B0%E7%B4%A2%E5%BC%95%E7%9A%84%E6%96%B9%E5%BC%8F">11.9. 索引的常见数据模型实现索引的方式</a></li>
<li><a href="#1110-%E8%87%AA%E5%A2%9E%E4%B8%BB%E9%94%AE%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF">11.10. 自增主键使用场景</a></li>
</ul>
</li>
<li><a href="#12-mysql%E4%BA%8B%E5%8A%A1">12. MySQL事务</a>
<ul>
<li><a href="#121-%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB">12.1. 事务隔离级别</a></li>
<li><a href="#122-%E6%9F%A5%E7%9C%8B%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB">12.2. 查看事务隔离级别</a></li>
<li><a href="#123-%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB%E7%9A%84%E5%AE%9E%E7%8E%B0">12.3. 事务隔离级别的实现</a>
<ul>
<li><a href="#1231-%E9%94%81">12.3.1. 锁</a></li>
<li><a href="#1232-mvcc">12.3.2. MVCC</a>
<ul>
<li><a href="#12321-%E5%BF%AB%E7%85%A7%E8%AF%BB">12.3.2.1. 快照读</a></li>
<li><a href="#12322-%E5%BD%93%E5%89%8D%E8%AF%BBcurrent-read">12.3.2.2. 当前读（current read）</a></li>
<li><a href="#12323-mvcc%E7%9A%84%E5%AE%9E%E7%8E%B0">12.3.2.3. MVCC的实现</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#124-%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E5%B9%BB%E8%AF%BB">12.4. 如何解决幻读？</a></li>
<li><a href="#125-%E4%BA%8B%E5%8A%A1%E7%AE%A1%E7%90%86">12.5. 事务管理</a>
<ul>
<li><a href="#1251-myisam%E4%BA%8B%E5%8A%A1%E7%AE%A1%E7%90%86">12.5.1. MyISAM事务管理</a></li>
<li><a href="#1252-innodb%E4%BA%8B%E5%8A%A1%E7%AE%A1%E7%90%86">12.5.2. InnoDB事务管理</a></li>
</ul>
</li>
<li><a href="#126-%E6%80%8E%E4%B9%88%E8%AE%BE%E8%AE%A1%E4%BA%8B%E5%8A%A1%E8%BF%9E%E6%8E%A5%E6%B1%A0%E2%88%9A">12.6. 怎么设计事务连接池？√</a></li>
<li><a href="#127-%E4%B8%BA%E4%BB%80%E4%B9%88%E5%BB%BA%E8%AE%AE%E4%BD%A0%E5%B0%BD%E9%87%8F%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8%E9%95%BF%E4%BA%8B%E5%8A%A1%E5%A6%82%E4%BD%95%E9%81%BF%E5%85%8D%E9%95%BF%E4%BA%8B%E5%8A%A1%E5%AF%B9%E4%B8%9A%E5%8A%A1%E7%9A%84%E5%BD%B1%E5%93%8D">12.7. 为什么建议你尽量不要使用长事务?如何避免长事务对业务的影响？</a></li>
<li><a href="#128-%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E7%9A%84%E4%BD%BF%E7%94%A8">12.8. 分布式事务的使用</a>
<ul>
<li><a href="#1281-%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E7%9A%84%E5%8E%9F%E7%90%86">12.8.1. 分布式事务的原理</a></li>
<li><a href="#1282-%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E8%AF%AD%E6%B3%95">12.8.2. 分布式事务语法</a></li>
<li><a href="#1283-%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E5%AD%98%E5%9C%A8%E7%9A%84%E9%97%AE%E9%A2%98">12.8.3. 分布式事务存在的问题</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#13-mysql%E9%94%81">13. MYSQL锁</a>
<ul>
<li><a href="#131-%E6%8C%89%E9%94%81%E7%9A%84%E7%B2%92%E5%BA%A6%E5%88%86%E7%B1%BB">13.1. 按锁的粒度分类</a>
<ul>
<li><a href="#1311-%E5%85%A8%E5%B1%80%E9%94%81">13.1.1. 全局锁</a></li>
<li><a href="#1312-%E8%A1%A8%E7%BA%A7%E9%94%81">13.1.2. 表级锁</a>
<ul>
<li><a href="#13121-%E5%85%83%E6%95%B0%E6%8D%AE%E9%94%81mdlmeta-data-lock">13.1.2.1. 元数据锁MDLmeta data lock</a></li>
<li><a href="#13122-myisam%E8%A1%A8%E9%94%81">13.1.2.2. MyISAM表锁</a></li>
<li><a href="#13123-innodb%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E4%BD%BF%E7%94%A8%E8%A1%A8%E9%94%81">13.1.2.3. InnoDB什么时候使用表锁</a></li>
</ul>
</li>
<li><a href="#1313-innodb%E8%A1%8C%E9%94%81">13.1.3. InnoDB行锁</a>
<ul>
<li><a href="#13131-innodb-%E8%A1%8C%E9%94%81%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F">13.1.3.1. InnoDB 行锁实现方式</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#132-%E6%8C%89%E9%94%81%E7%9A%84%E7%B1%BB%E5%9E%8B%E5%88%86%E7%B1%BB">13.2. 按锁的类型分类</a>
<ul>
<li><a href="#1321-%E8%AF%BB%E5%86%99%E9%94%81%E8%A1%8C%E9%94%81%E6%A8%A1%E5%BC%8F">13.2.1. 读写锁行锁模式</a></li>
<li><a href="#1322-%E6%84%8F%E5%90%91%E9%94%81%E8%A1%A8%E9%94%81%E6%A8%A1%E5%BC%8F">13.2.2. 意向锁表锁模式</a></li>
<li><a href="#1323-%E8%AF%BB%E5%86%99%E9%94%81%E4%B8%8E%E6%84%8F%E5%90%91%E9%94%81%E5%85%BC%E5%AE%B9%E6%80%A7">13.2.3. 读写锁与意向锁兼容性</a></li>
</ul>
</li>
<li><a href="#133-innodb%E4%B8%AD%E8%A1%8C%E9%94%81%E5%AE%9A%E7%9A%84%E6%96%B9%E5%BC%8F">13.3. InnoDB中行锁定的方式</a>
<ul>
<li><a href="#1331-%E8%AE%B0%E5%BD%95%E9%94%81record-lock">13.3.1. 记录锁（Record Lock）</a></li>
<li><a href="#1332-%E9%97%B4%E9%9A%99%E9%94%81gap-lock">13.3.2. 间隙锁（Gap Lock）</a></li>
<li><a href="#1333-%E4%B8%B4%E9%94%AE%E9%94%81next-key-%E9%94%81">13.3.3. 临键锁（Next-Key 锁）</a></li>
<li><a href="#1334-%E5%8A%A0%E9%94%81%E8%A7%84%E5%88%99">13.3.4. 加锁规则</a></li>
</ul>
</li>
<li><a href="#134-%E6%81%A2%E5%A4%8D%E5%92%8C%E5%A4%8D%E5%88%B6%E7%9A%84%E9%9C%80%E8%A6%81%E5%AF%B9-innodb-%E9%94%81%E6%9C%BA%E5%88%B6%E7%9A%84%E5%BD%B1%E5%93%8D">13.4. 恢复和复制的需要，对 InnoDB 锁机制的影响</a></li>
<li><a href="#135-%E6%AD%BB%E9%94%81">13.5. 死锁</a>
<ul>
<li><a href="#1351-%E6%AD%BB%E9%94%81%E4%BE%8B%E5%AD%90">13.5.1. 死锁例子</a></li>
<li><a href="#1352-%E6%AD%BB%E9%94%81%E4%BA%A7%E7%94%9F%E5%8E%9F%E5%9B%A0">13.5.2. 死锁产生原因</a></li>
<li><a href="#1353-%E6%AD%BB%E9%94%81%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88">13.5.3. 死锁解决方案</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#14-mysql%E6%97%A5%E5%BF%97">14. MYSQL日志</a>
<ul>
<li><a href="#141-%E6%97%A5%E5%BF%97%E5%88%86%E7%B1%BB">14.1. 日志分类</a>
<ul>
<li><a href="#1411-mysql%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6">14.1.1. mysql配置文件</a></li>
<li><a href="#1412-%E9%94%99%E8%AF%AF%E6%97%A5%E5%BF%97">14.1.2. 错误日志</a></li>
<li><a href="#1413-%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%97%A5%E5%BF%97binlog">14.1.3. 二进制日志（BINLOG）</a>
<ul>
<li><a href="#14131-binlog%E6%97%A5%E5%BF%97%E6%A0%BC%E5%BC%8F">14.1.3.1. binlog日志格式</a></li>
</ul>
</li>
<li><a href="#1414-%E6%9F%A5%E8%AF%A2%E6%97%A5%E5%BF%97">14.1.4. 查询日志</a></li>
<li><a href="#1415-%E6%85%A2%E6%9F%A5%E8%AF%A2%E6%97%A5%E5%BF%97">14.1.5. 慢查询日志</a></li>
<li><a href="#1416-redo-log">14.1.6. redo log</a></li>
<li><a href="#1417-undo-log%E5%9B%9E%E6%BB%9A%E6%97%A5%E5%BF%97">14.1.7. undo log（回滚日志）</a></li>
</ul>
</li>
<li><a href="#142-%E4%BA%8B%E5%8A%A1%E6%98%AF%E5%A6%82%E4%BD%95%E9%80%9A%E8%BF%87%E6%97%A5%E5%BF%97%E6%9D%A5%E5%AE%9E%E7%8E%B0%E7%9A%84">14.2. 事务是如何通过日志来实现的?</a></li>
<li><a href="#143-%E4%B8%A4%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A4">14.3. 两阶段提交</a>
<ul>
<li><a href="#1431-%E4%B8%BA%E4%BB%80%E4%B9%88%E6%97%A5%E5%BF%97%E5%BF%85%E9%A1%BB%E6%9C%89%E4%B8%A4%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A4%E5%91%A2">14.3.1. 为什么日志必须有“两阶段提交”呢？</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#15-buffer-pool">15. buffer Pool</a>
<ul>
<li><a href="#151-%E6%95%B0%E6%8D%AE%E9%A1%B5">15.1. 数据页</a></li>
<li><a href="#152-%E7%BC%93%E5%AD%98%E9%A1%B5">15.2. 缓存页</a></li>
<li><a href="#153-sort_buffer">15.3. sort_buffer</a>
<ul>
<li><a href="#1531-%E5%85%A8%E5%AD%97%E6%AE%B5%E6%8E%92%E5%BA%8F">15.3.1. 全字段排序</a></li>
<li><a href="#1532-rowid%E6%8E%92%E5%BA%8F">15.3.2. rowid排序</a></li>
</ul>
</li>
<li><a href="#154-join-buffer">15.4. join buffer</a>
<ul>
<li><a href="#1541-nested-loop-join%E5%BE%AA%E7%8E%AF%E5%B5%8C%E5%A5%97%E7%AE%97%E6%B3%95">15.4.1. Nested-Loop join（循环嵌套）算法</a>
<ul>
<li><a href="#15411-index-nested-loop-joinnlj">15.4.1.1. Index Nested-Loop JoinNLJ</a></li>
<li><a href="#15412-batched-key-acessbka%E7%AE%97%E6%B3%95">15.4.1.2. Batched Key AcessBKA算法</a></li>
<li><a href="#15413-block-nested-loop-joinbnl">15.4.1.3. Block Nested-Loop JoinBNL</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#155-redo-log-buffer">15.5. redo log buffer</a></li>
</ul>
</li>
<li><a href="#16-sql%E4%BC%98%E5%8C%96">16. SQL优化</a>
<ul>
<li><a href="#161-sql%E4%BC%98%E5%8C%96%E6%AD%A5%E9%AA%A4">16.1. SQL优化步骤</a>
<ul>
<li><a href="#1611-%E6%85%A2%E6%9F%A5%E8%AF%A2%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90">16.1.1. 慢查询日志分析</a></li>
<li><a href="#1542-%E6%85%A2sql%E9%A2%84%E9%98%B2">15.4.2. 慢SQL预防</a></li>
</ul>
</li>
<li><a href="#162-%E5%B8%B8%E7%94%A8sql%E7%9A%84%E4%BC%98%E5%8C%96">16.2. 常用SQL的优化</a>
<ul>
<li><a href="#1621-%E5%AE%9A%E6%9C%9F%E5%88%86%E6%9E%90%E8%A1%A8%E6%A3%80%E6%9F%A5%E8%A1%A8%E4%BC%98%E5%8C%96%E8%A1%A8">16.2.1. 定期分析表、检查表、优化表</a></li>
<li><a href="#1622-%E5%A4%A7%E6%89%B9%E9%87%8F%E6%8F%92%E5%85%A5%E6%95%B0%E6%8D%AE">16.2.2. 大批量插入数据</a></li>
<li><a href="#1623-%E4%BC%98%E5%8C%96-insert-%E8%AF%AD%E5%8F%A5">16.2.3. 优化 INSERT 语句</a></li>
<li><a href="#1624-%E4%BC%98%E5%8C%96-group-by-%E8%AF%AD%E5%8F%A5">16.2.4. 优化 GROUP BY 语句</a></li>
<li><a href="#1625-%E4%BC%98%E5%8C%96-order-by-%E8%AF%AD%E5%8F%A5">16.2.5. 优化 ORDER BY 语句</a></li>
<li><a href="#1626-%E4%BC%98%E5%8C%96limit%E8%AF%AD%E5%8F%A5">16.2.6. 优化LIMIT语句</a></li>
<li><a href="#1627-%E4%BC%98%E5%8C%96%E5%B5%8C%E5%A5%97%E6%9F%A5%E8%AF%A2">16.2.7. 优化嵌套查询</a></li>
<li><a href="#1628-%E5%AF%B9%E4%BA%8E%E5%90%AB%E6%9C%89-or-%E7%9A%84%E6%9F%A5%E8%AF%A2%E5%AD%90%E5%8F%A5">16.2.8. 对于含有 OR 的查询子句</a></li>
<li><a href="#1629-%E4%BD%BF%E7%94%A8force-index%E6%8C%87%E5%AE%9A%E7%B4%A2%E5%BC%95">16.2.9. 使用FORCE INDEX指定索引</a></li>
<li><a href="#16210-%E5%88%A0%E9%99%A4%E5%A4%A7%E9%87%8F%E6%95%B0%E6%8D%AE">16.2.10. 删除大量数据</a></li>
<li><a href="#16211-%E4%BC%98%E5%8C%96count%E6%9F%A5%E8%AF%A2">16.2.11. 优化count查询</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#17-%E4%BC%98%E5%8C%96%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AF%B9%E8%B1%A1">17. 优化数据库对象</a>
<ul>
<li><a href="#171-%E4%BC%98%E5%8C%96%E8%A1%A8%E7%9A%84%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B">17.1. 优化表的数据类型</a></li>
<li><a href="#172-%E9%80%9A%E8%BF%87%E6%8B%86%E5%88%86%E6%8F%90%E9%AB%98%E8%A1%A8%E7%9A%84%E8%AE%BF%E9%97%AE%E6%95%88%E7%8E%87">17.2. 通过拆分提高表的访问效率</a>
<ul>
<li><a href="#1721-%E9%80%86%E8%A7%84%E8%8C%83%E5%8C%96">17.2.1. 逆规范化</a></li>
<li><a href="#1722-%E4%BD%BF%E7%94%A8%E4%B8%AD%E9%97%B4%E8%A1%A8%E6%8F%90%E9%AB%98%E5%A4%A7%E6%95%B0%E6%8D%AE%E8%A1%A8%E7%BB%9F%E8%AE%A1%E6%9F%A5%E8%AF%A2%E9%80%9F%E5%BA%A6">17.2.2. 使用中间表提高大数据表统计查询速度</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#18-%E4%BC%98%E5%8C%96-mysql-server">18. 优化 MySQL Server</a>
<ul>
<li><a href="#181-linux%E7%B3%BB%E7%BB%9F%E4%BC%98%E5%8C%96">18.1. Linux系统优化</a></li>
<li><a href="#182-%E6%9F%A5%E7%9C%8B-%E5%BD%B1%E5%93%8Dmysql-server-%E6%80%A7%E8%83%BD%E7%9A%84%E9%87%8D%E8%A6%81%E5%8F%82%E6%95%B0">18.2. 查看 影响MySQL Server 性能的重要参数</a>
<ul>
<li><a href="#1821-myisam-key_buffer_size">18.2.1. MyISAM-key_buffer_size</a></li>
<li><a href="#1822-myisam-table_cache">18.2.2. MYISAM-table_cache</a></li>
<li><a href="#1823-innodb_buffer_pool_size">18.2.3. innodb_buffer_pool_size</a></li>
<li><a href="#1824-innodb_flush_log_at_trx_commit%E8%AE%BE%E7%BD%AE">18.2.4. innodb_flush_log_at_trx_commit设置</a></li>
<li><a href="#1825-innodb_additional_mem_pool_size%E8%AE%BE%E7%BD%AE">18.2.5. innodb_additional_mem_pool_size设置</a></li>
<li><a href="#1826-innodb_lock_wait_timeout">18.2.6. innodb_lock_wait_timeout</a></li>
<li><a href="#1827-innodb_support_xa">18.2.7. innodb_support_xa</a></li>
<li><a href="#1828-innodb_log_buffer_size">18.2.8. innodb_log_buffer_size</a></li>
<li><a href="#1829-innodb_log_file_size">18.2.9. innodb_log_file_size</a></li>
<li><a href="#18210-%E5%85%B6%E4%BB%96%E5%8F%82%E6%95%B0">18.2.10. 其他参数</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#19-%E7%A3%81%E7%9B%98-io-%E4%BC%98%E5%8C%96">19. 磁盘 I/O 优化</a>
<ul>
<li><a href="#191-%E4%BD%BF%E7%94%A8%E7%A3%81%E7%9B%98%E9%98%B5%E5%88%97">19.1. 使用磁盘阵列</a>
<ul>
<li><a href="#1911-%E5%B8%B8%E8%A7%81-raid-%E7%BA%A7%E5%88%AB%E5%8F%8A%E5%85%B6%E7%89%B9%E6%80%A7">19.1.1. 常见 RAID 级别及其特性</a></li>
<li><a href="#1912-%E5%A6%82%E4%BD%95%E9%80%89%E6%8B%A9-raid-%E7%BA%A7%E5%88%AB">19.1.2. 如何选择 RAID 级别</a></li>
<li><a href="#1913-%E8%99%9A%E6%8B%9F%E6%96%87%E4%BB%B6%E5%8D%B7%E6%88%96%E8%BD%AFraid">19.1.3. 虚拟文件卷或软RAID</a></li>
</ul>
</li>
<li><a href="#192-%E4%BD%BF%E7%94%A8-symbolic-links-%E5%88%86%E5%B8%83-io">19.2. 使用 Symbolic Links 分布 I/O</a></li>
<li><a href="#193-%E7%A6%81%E6%AD%A2%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%9B%B4%E6%96%B0%E6%96%87%E4%BB%B6%E7%9A%84-atime-%E5%B1%9E%E6%80%A7">19.3. 禁止操作系统更新文件的 atime 属性</a></li>
<li><a href="#194-%E7%94%A8%E8%A3%B8%E8%AE%BE%E5%A4%87raw-device%E5%AD%98%E6%94%BE-innodb-%E7%9A%84%E5%85%B1%E4%BA%AB%E8%A1%A8%E7%A9%BA%E9%97%B4">19.4. 用裸设备（Raw Device）存放 InnoDB 的共享表空间</a></li>
</ul>
</li>
<li><a href="#20-%E5%BA%94%E7%94%A8%E4%BC%98%E5%8C%96">20. 应用优化</a>
<ul>
<li><a href="#201-%E4%BD%BF%E7%94%A8%E8%BF%9E%E6%8E%A5%E6%B1%A0">20.1. 使用连接池</a></li>
<li><a href="#202-%E5%87%8F%E5%B0%91%E5%AF%B9-mysql-%E7%9A%84%E8%AE%BF%E9%97%AE">20.2. 减少对 MySQL 的访问</a></li>
<li><a href="#203-%E4%BD%BF%E7%94%A8%E7%BC%93%E5%AD%98">20.3. 使用缓存</a></li>
<li><a href="#204-%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1">20.4. 负载均衡</a>
<ul>
<li><a href="#2041-%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6-%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB">20.4.1. 主从复制-读写分离</a></li>
<li><a href="#2042-%E9%87%87%E7%94%A8%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%9E%B6%E6%9E%84mysql-cluster">20.4.2. 采用分布式数据库架构MySQL CLUSTER</a></li>
</ul>
</li>
<li><a href="#205-%E5%85%B6%E4%BB%96%E4%BC%98%E5%8C%96%E6%8E%AA%E6%96%BD">20.5. 其他优化措施</a></li>
</ul>
</li>
<li><a href="#21-%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D">21. 备份与恢复</a>
<ul>
<li><a href="#211-%E5%A4%87%E4%BB%BD%E5%88%86%E7%B1%BB%E5%A4%87%E4%BB%BD%E6%95%B0%E6%8D%AE%E7%9A%84%E7%B1%BB%E5%9E%8B%E5%92%8C%E5%B7%A5%E5%85%B7">21.1. 备份分类，备份数据的类型和工具</a></li>
<li><a href="#212-%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%E7%AD%96%E7%95%A5">21.2. 备份/恢复策略</a></li>
<li><a href="#213-%E9%80%BB%E8%BE%91%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D">21.3. 逻辑备份与恢复</a></li>
<li><a href="#214-%E7%89%A9%E7%90%86%E5%A4%87%E4%BB%BD%E5%92%8C%E6%81%A2%E5%A4%8D">21.4. 物理备份和恢复</a>
<ul>
<li><a href="#2141-%E5%86%B7%E5%A4%87%E4%BB%BD">21.4.1. 冷备份</a></li>
<li><a href="#2142-%E7%83%AD%E5%A4%87%E4%BB%BD">21.4.2. 热备份</a></li>
</ul>
</li>
<li><a href="#215-%E5%8F%8C%E6%9C%BA%E7%83%AD%E5%A4%87%E4%BB%BD">21.5. 双机热备份</a></li>
<li><a href="#216-%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8D%E8%83%BD%E5%81%9C%E6%9C%BA%E8%AF%B7%E9%97%AE%E5%A6%82%E4%BD%95%E5%A4%87%E4%BB%BD-%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E5%85%A8%E5%A4%87%E4%BB%BD%E5%92%8C%E5%A2%9E%E9%87%8F%E5%A4%87%E4%BB%BD">21.6. 数据库不能停机，请问如何备份? 如何进行全备份和增量备份?</a></li>
<li><a href="#217-%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%E6%97%B6%E9%97%B4%E6%98%AF%E5%A4%9A%E9%95%BF">21.7. 备份恢复时间是多长？</a></li>
<li><a href="#218-%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%E5%A4%B1%E8%B4%A5%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86">21.8. 备份恢复失败如何处理？</a></li>
<li><a href="#219-mysqldump-%E5%92%8C-xtrabackup-%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86">21.9. mysqldump 和 xtrabackup 实现原理？</a></li>
<li><a href="#2110-%E8%A1%A8%E7%9A%84%E5%AF%BC%E5%85%A5%E5%AF%BC%E5%87%BA">21.10. 表的导入导出</a></li>
<li><a href="#2111-%E8%A1%A8%E7%9A%84%E5%A4%8D%E5%88%B6">21.11. 表的复制</a></li>
<li><a href="#2112-%E8%AF%AF%E5%88%A0%E6%95%B0%E6%8D%AE">21.12. 误删数据</a>
<ul>
<li><a href="#21121-delete%E8%AF%AF%E5%88%A0%E6%95%B0%E6%8D%AE%E8%A1%8C">21.12.1. delete误删数据行</a>
<ul>
<li><a href="#211211-%E6%81%A2%E5%A4%8D%E6%96%B9%E6%B3%95">21.12.1.1. 恢复方法</a></li>
<li><a href="#211212-%E9%A2%84%E9%98%B2%E5%88%A0%E8%AE%B0%E5%BD%95%E6%96%B9%E6%B3%95">21.12.1.2. 预防删记录方法</a></li>
<li><a href="#211213-%E5%88%A0%E9%99%A4%E8%A1%A8%E6%89%80%E6%9C%89%E6%95%B0%E6%8D%AE%E7%9A%84%E6%96%B9%E6%B3%95">21.12.1.3. 删除表所有数据的方法</a></li>
</ul>
</li>
<li><a href="#21122-drop-table%E6%88%96%E8%80%85truncate-table%E8%AF%AF%E5%88%A0%E6%95%B0%E6%8D%AE%E8%A1%A8drop-database%E8%AF%AF%E5%88%A0%E5%BA%93">21.12.2. drop table或者truncate table误删数据表/drop database误删库</a>
<ul>
<li><a href="#211221-%E6%81%A2%E5%A4%8D%E6%96%B9%E6%B3%95">21.12.2.1. 恢复方法</a></li>
<li><a href="#211222-%E9%A2%84%E9%98%B2%E8%AF%AF%E5%88%A0%E5%BA%93%E8%A1%A8%E7%9A%84%E6%96%B9%E6%B3%95">21.12.2.2. 预防误删库/表的方法</a></li>
</ul>
</li>
<li><a href="#21123-rm%E5%91%BD%E4%BB%A4%E8%AF%AF%E5%88%A0%E6%95%B4%E4%B8%AAmysql%E5%AE%9E%E4%BE%8B">21.12.3. rm命令误删整个MySQL实例</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#22-mysql%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86">22. MySQL权限管理</a>
<ul>
<li><a href="#221-%E6%9D%83%E9%99%90%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86">22.1. 权限系统的工作原理</a></li>
<li><a href="#222-%E8%B4%A6%E5%8F%B7%E7%AE%A1%E7%90%86">22.2. 账号管理</a></li>
</ul>
</li>
<li><a href="#23-mysql-%E5%AE%89%E5%85%A8">23. MySQL 安全</a></li>
<li><a href="#24-mysql%E5%A4%8D%E5%88%B6">24. MySQL复制</a>
<ul>
<li><a href="#241-%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E6%B5%81%E7%A8%8B">24.1. 主从复制流程</a></li>
<li><a href="#242-%E5%A4%8D%E5%88%B6%E9%85%8D%E7%BD%AE">24.2. 复制配置</a></li>
<li><a href="#243-%E5%A4%87%E5%BA%93%E5%B9%B6%E8%A1%8C%E5%A4%8D%E5%88%B6%E8%83%BD%E5%8A%9B">24.3. 备库并行复制能力</a></li>
<li><a href="#244-%E5%B9%B6%E8%A1%8C%E5%A4%8D%E5%88%B6%E7%AD%96%E7%95%A5">24.4. 并行复制策略</a>
<ul>
<li><a href="#2441-mysql-56%E6%8C%89%E5%BA%93%E5%B9%B6%E8%A1%8C%E5%A4%8D%E5%88%B6">24.4.1. MySQL 5.6按库并行复制</a></li>
<li><a href="#2442-mysql-57%E7%9A%84%E5%B9%B6%E8%A1%8C%E5%A4%8D%E5%88%B6%E7%AD%96%E7%95%A5">24.4.2. MySQL 5.7的并行复制策略</a></li>
<li><a href="#2443-mysql-5722%E7%9A%84%E5%B9%B6%E8%A1%8C%E5%A4%8D%E5%88%B6%E7%AD%96%E7%95%A5">24.4.3. MySQL 5.7.22的并行复制策略</a></li>
</ul>
</li>
<li><a href="#245-%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E9%97%AE%E9%A2%98">24.5. 主从复制问题</a>
<ul>
<li><a href="#2451-%E5%BE%AA%E7%8E%AF%E5%A4%8D%E5%88%B6%E9%97%AE%E9%A2%98">24.5.1. 循环复制问题</a></li>
<li><a href="#2452-%E4%B8%BB%E5%A4%87%E5%BB%B6%E8%BF%9F">24.5.2. 主备延迟</a></li>
<li><a href="#2453-%E4%B8%BB%E5%A4%87%E5%BB%B6%E8%BF%9F%E7%9A%84%E6%9D%A5%E6%BA%90">24.5.3. 主备延迟的来源</a></li>
<li><a href="#2454-%E4%B8%BB%E5%A4%87%E5%BB%B6%E8%BF%9F%E5%9C%BA%E6%99%AF">24.5.4. 主备延迟场景</a></li>
<li><a href="#2455-%E4%B8%BB%E4%BB%8E%E4%B8%8D%E4%B8%80%E8%87%B4">24.5.5. 主从不一致</a></li>
</ul>
</li>
<li><a href="#246-%E6%97%A5%E5%B8%B8%E7%AE%A1%E7%90%86%E7%BB%B4%E6%8A%A4">24.6. 日常管理维护</a>
<ul>
<li><a href="#2461-%E6%9F%A5%E7%9C%8B%E4%BB%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%8A%B6%E6%80%81">24.6.1. 查看从服务器状态</a></li>
<li><a href="#2462-%E4%B8%BB%E4%BB%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%90%8C%E6%AD%A5">24.6.2. 主从服务器同步</a></li>
<li><a href="#2463-%E4%BB%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%A4%8D%E5%88%B6%E5%87%BA%E9%94%99%E7%9A%84%E5%A4%84%E7%90%86">24.6.3. 从服务器复制出错的处理</a></li>
<li><a href="#2464-log-event-entry-exceeded-max_allowed_packet-%E7%9A%84%E5%A4%84%E7%90%86">24.6.4. log event entry exceeded max_allowed_packet 的处理</a></li>
<li><a href="#2465-%E5%A4%9A%E4%B8%BB%E5%A4%8D%E5%88%B6%E5%A4%9A%E5%8F%B0%E4%B8%BB%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AF%B9%E4%B8%80%E5%8F%B0%E4%BB%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%97%B6%E7%9A%84%E8%87%AA%E5%A2%9E%E9%95%BF%E5%8F%98%E9%87%8F%E5%86%B2%E7%AA%81%E9%97%AE%E9%A2%98">24.6.5. 多主复制多台主服务器对一台从服务器时的自增长变量冲突问题</a></li>
<li><a href="#2466-%E6%9F%A5%E7%9C%8B%E4%BB%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E5%A4%8D%E5%88%B6%E8%BF%9B%E5%BA%A6">24.6.6. 查看从服务器的复制进度</a></li>
<li><a href="#2467-%E5%88%87%E6%8D%A2%E4%B8%BB%E5%A4%87%E6%9C%8D%E5%8A%A1%E5%99%A8">24.6.7. 切换主备服务器</a>
<ul>
<li><a href="#24671-%E4%B8%BB%E5%A4%87%E5%88%87%E6%8D%A2%E7%AD%96%E7%95%A5">24.6.7.1. 主备切换策略</a></li>
<li><a href="#24672-%E5%9F%BA%E4%BA%8E%E4%BD%8D%E7%82%B9%E7%9A%84%E4%B8%BB%E5%A4%87%E5%88%87%E6%8D%A2">24.6.7.2. 基于位点的主备切换</a></li>
<li><a href="#24673-%E4%B8%BB%E5%A4%87%E5%88%87%E6%8D%A2%E6%96%B9%E6%A1%88gtidglobal-transaction-identifier">24.6.7.3. 主备切换方案GTIDGlobal Transaction Identifier</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#247-%E5%A6%82%E4%BD%95%E5%88%A4%E6%96%AD%E4%B8%80%E4%B8%AA%E4%B8%BB%E6%95%B0%E6%8D%AE%E5%BA%93%E6%98%AF%E4%B8%8D%E6%98%AF%E5%87%BA%E9%97%AE%E9%A2%98%E4%BA%86">24.7. 如何判断一个主数据库是不是出问题了？</a>
<ul>
<li><a href="#2471-%E5%A4%96%E9%83%A8%E5%88%A4%E6%96%AD">24.7.1. 外部判断</a></li>
<li><a href="#2472-%E5%86%85%E9%83%A8%E5%88%A4%E6%96%AD">24.7.2. 内部判断</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#25-mysql-cluster">25. MySQL Cluster</a>
<ul>
<li><a href="#251-mysql-cluster%E6%9E%B6%E6%9E%84">25.1. MySQL Cluster架构</a></li>
</ul>
</li>
<li><a href="#26-%E5%AD%97%E7%AC%A6%E9%9B%86">26. 字符集</a>
<ul>
<li><a href="#261-%E6%80%8E%E6%A0%B7%E9%80%89%E6%8B%A9%E5%90%88%E9%80%82%E7%9A%84%E5%AD%97%E7%AC%A6%E9%9B%86">26.1. 怎样选择合适的字符集</a></li>
<li><a href="#262-mysql-%E5%AD%97%E7%AC%A6%E9%9B%86">26.2. MySQL 字符集</a></li>
<li><a href="#263-mysql-%E5%AD%97%E7%AC%A6%E9%9B%86%E7%9A%84%E8%AE%BE%E7%BD%AE">26.3. MySQL 字符集的设置</a></li>
</ul>
</li>
<li><a href="#27-sql-mode">27. SQL Mode</a>
<ul>
<li><a href="#271-sql-mode%E7%AE%80%E4%BB%8B">27.1. SQL Mode简介</a></li>
<li><a href="#272-%E5%B8%B8%E7%94%A8%E7%9A%84-sql-mode">27.2. 常用的 SQL Mode</a></li>
<li><a href="#273-sql-mode-%E5%9C%A8%E8%BF%81%E7%A7%BB%E4%B8%AD%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8">27.3. SQL Mode 在迁移中如何使用</a></li>
</ul>
</li>
<li><a href="#28-%E5%85%A8%E8%A1%A8%E6%89%AB%E6%8F%8F">28. 全表扫描</a>
<ul>
<li><a href="#281-%E5%85%A8%E8%A1%A8%E6%89%AB%E6%8F%8F%E5%AF%B9server%E5%B1%82%E7%9A%84%E5%BD%B1%E5%93%8D">28.1. 全表扫描对server层的影响</a></li>
<li><a href="#282-%E5%85%A8%E8%A1%A8%E6%89%AB%E6%8F%8F%E5%AF%B9innodb%E7%9A%84%E5%BD%B1%E5%93%8D">28.2. 全表扫描对InnoDB的影响</a></li>
<li><a href="#283-%E6%89%AB%E6%8F%8F%E8%A1%8C%E6%95%B0">28.3. 扫描行数</a></li>
<li><a href="#284-%E5%A6%82%E4%BD%95%E6%AD%A3%E7%A1%AE%E5%9C%B0%E6%98%BE%E7%A4%BA%E9%9A%8F%E6%9C%BA%E6%B6%88%E6%81%AF">28.4. 如何正确地显示随机消息？</a></li>
<li><a href="#285-%E6%95%91%E7%81%AB%E6%96%B9%E6%B3%95">28.5. 救火方法</a>
<ul>
<li><a href="#2851-%E7%9F%AD%E8%BF%9E%E6%8E%A5%E9%A3%8E%E6%9A%B4">28.5.1. 短连接风暴</a></li>
<li><a href="#2852-qps%E7%AA%81%E5%A2%9E%E9%97%AE%E9%A2%98">28.5.2. QPS突增问题</a></li>
<li><a href="#2853-%E6%9F%A5%E8%AF%A2%E6%85%A2">28.5.3. 查询慢</a></li>
<li><a href="#2854-%E5%A6%82%E4%BD%95%E5%AE%89%E5%85%A8%E5%9C%B0%E7%BB%99%E5%B0%8F%E8%A1%A8%E5%8A%A0%E5%AD%97%E6%AE%B5">28.5.4. 如何安全地给小表加字段？</a></li>
<li><a href="#2855-%E5%9C%A8-mysql-%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%90%E8%A1%8C%E7%BC%93%E6%85%A2%E7%9A%84%E6%83%85%E5%86%B5%E4%B8%8B%E8%BE%93%E5%85%A5%E4%BB%80%E4%B9%88%E5%91%BD%E4%BB%A4%E8%83%BD%E7%BC%93%E8%A7%A3%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%8E%8B%E5%8A%9B">28.5.5. 在 MySQL 服务器运行缓慢的情况下输入什么命令能缓解服务器压力？</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#29-%E6%95%B0%E6%8D%AE%E5%BA%93flush">29. 数据库flush</a>
<ul>
<li><a href="#291-flush%E7%9A%84%E8%A7%A6%E5%8F%91%E6%9D%A1%E4%BB%B6">29.1. flush的触发条件</a></li>
<li><a href="#292-innodb%E5%88%B7%E8%84%8F%E9%A1%B5%E7%9A%84%E6%8E%A7%E5%88%B6%E7%AD%96%E7%95%A5">29.2. InnoDB刷脏页的控制策略</a></li>
</ul>
</li>
<li><a href="#30-%E6%95%B0%E6%8D%AE%E5%88%A0%E9%99%A4%E6%B5%81%E7%A8%8B">30. 数据删除流程</a>
<ul>
<li><a href="#301-%E9%87%8D%E5%BB%BA%E8%A1%A8-%E8%A7%A3%E5%86%B3%E7%A9%BA%E6%B4%9E%E9%97%AE%E9%A2%98">30.1. 重建表-解决空洞问题</a></li>
</ul>
</li>
<li><a href="#31-%E7%BB%84%E6%8F%90%E4%BA%A4group-commit%E6%9C%BA%E5%88%B6">31. 组提交（group commit）机制</a></li>
<li><a href="#32-%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%98%E6%9C%89kill%E4%B8%8D%E6%8E%89%E7%9A%84%E8%AF%AD%E5%8F%A5">32. 为什么还有kill不掉的语句？</a>
<ul>
<li><a href="#321-kill%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B">32.1. kill命令执行过程</a></li>
</ul>
</li>
<li><a href="#33-%E4%B8%B4%E6%97%B6%E8%A1%A8">33. 临时表</a>
<ul>
<li><a href="#331-%E5%86%85%E5%AD%98%E8%A1%A8%E4%B8%8E%E4%B8%B4%E6%97%B6%E8%A1%A8%E5%8C%BA%E5%88%AB">33.1. 内存表与临时表区别</a></li>
<li><a href="#332-%E4%B8%B4%E6%97%B6%E8%A1%A8%E7%89%B9%E6%80%A7">33.2. 临时表特性</a></li>
<li><a href="#333-%E4%B8%B4%E6%97%B6%E8%A1%A8%E7%9A%84%E5%BA%94%E7%94%A8">33.3. 临时表的应用</a></li>
<li><a href="#334-%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%B4%E6%97%B6%E8%A1%A8%E5%8F%AF%E4%BB%A5%E9%87%8D%E5%90%8D">33.4. 为什么临时表可以重名？</a></li>
<li><a href="#335-%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E4%BC%9A%E4%BD%BF%E7%94%A8%E5%86%85%E9%83%A8%E4%B8%B4%E6%97%B6%E8%A1%A8">33.5. 什么时候会使用内部临时表？</a></li>
</ul>
</li>
<li><a href="#34-%E8%87%AA%E5%A2%9E%E4%B8%BB%E9%94%AE%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E6%98%AF%E8%BF%9E%E7%BB%AD%E7%9A%84">34. 自增主键为什么不是连续的？</a>
<ul>
<li><a href="#341-%E8%87%AA%E5%A2%9E%E5%80%BC%E4%BF%9D%E5%AD%98%E4%BD%8D%E7%BD%AE">34.1. 自增值保存位置</a></li>
<li><a href="#342-%E8%87%AA%E5%A2%9E%E5%80%BC%E4%BF%AE%E6%94%B9%E6%9C%BA%E5%88%B6">34.2. 自增值修改机制</a></li>
</ul>
</li>
<li><a href="#35-%E8%A6%81%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8%E5%88%86%E5%8C%BA%E8%A1%A8">35. 要不要使用分区表？</a>
<ul>
<li><a href="#351-%E5%88%86%E5%8C%BA%E8%A1%A8%E7%89%B9%E6%80%A7">35.1. 分区表特性</a></li>
<li><a href="#352-%E4%BB%80%E4%B9%88%E5%9C%BA%E6%99%AF%E4%B8%8B%E9%80%82%E5%90%88%E4%BD%BF%E7%94%A8%E5%88%86%E5%8C%BA%E8%A1%A8%E5%91%A2">35.2. 什么场景下适合使用分区表呢？</a></li>
<li><a href="#353-%E5%88%86%E5%8C%BA%E8%A1%A8%E4%B8%BB%E9%94%AE%E6%80%8E%E4%B9%88%E8%AE%BE%E8%AE%A1">35.3. 分区表主键怎么设计？</a></li>
</ul>
</li>
<li><a href="#36-mysql%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AE%BE%E8%AE%A1%E8%A7%84%E8%8C%83">36. MYSQL数据库设计规范</a></li>
<li><a href="#37-%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB">37. 读写分离</a>
<ul>
<li><a href="#371-%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84">37.1. 读写分离基本架构</a></li>
<li><a href="#372-%E8%BF%87%E6%9C%9F%E8%AF%BB%E5%85%B6%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88">37.2. 过期读其解决方案</a>
<ul>
<li><a href="#3721-%E5%88%A4%E6%96%AD%E4%B8%BB%E5%A4%87%E6%97%A0%E5%BB%B6%E8%BF%9F%E6%96%B9%E6%A1%88">37.2.1. 判断主备无延迟方案</a></li>
<li><a href="#3722-%E9%85%8D%E5%90%88semi-sync%E6%96%B9%E6%A1%88">37.2.2. 配合semi-sync方案</a></li>
<li><a href="#3723-%E7%AD%89%E4%B8%BB%E5%BA%93%E4%BD%8D%E7%82%B9%E6%96%B9%E6%A1%88">37.2.3. 等主库位点方案；</a></li>
<li><a href="#3724-%E7%AD%89gtid%E6%96%B9%E6%A1%88">37.2.4. 等GTID方案</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#38-%E5%85%B6%E4%BB%96">38. 其他</a>
<ul>
<li><a href="#381-mysql%E8%87%AA%E5%A2%9Eid%E7%94%A8%E5%AE%8C%E6%80%8E%E4%B9%88%E5%8A%9E">38.1. mysql自增id用完怎么办?</a></li>
<li><a href="#382-jdbc%E4%B8%ADstatement%E5%92%8Cpreparestatement%E7%9A%84%E5%8C%BA%E5%88%AB">38.2. jdbc中statement和Preparestatement的区别？</a></li>
<li><a href="#383-mysql%E7%9B%91%E6%8E%A7">38.3. MySQL监控</a></li>
</ul>
</li>
</ul>
<!-- /TOC -->
<h1>1. 数据库概念</h1>
<ul>
<li>启动MySQL服务:net start mysql5;</li>
<li>停止MySQL服务:net stop mysql5</li>
<li>查看MySQL服务的状态：netstat -nlp</li>
<li>登录mysql:mysql [-host=ip地址] -u用户名 -p</li>
</ul>
<h1>2. MySQL支持的数据类型</h1>
<h2>2.1. 数值类型</h2>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/5eb3564ceca7b636f4065.png" alt="数据类型-数值类型.PNG" tabindex="0"><figcaption>数据类型-数值类型.PNG</figcaption></figure>
<ul>
<li>zerofill(填充0):在数字位数（类型名称后面的小括号内指定显示宽度,但存储字节数不变）不够的空间用字符“0”填满，如果插入大于宽度限制的值，还是按照类型的实际精度进行保存</li>
<li>UNSIGNED(无符号):整数类型里面保存非负数或者需要较大的上限值时适用，取值范围变为0到上限取原值的2倍，如果一个列指定为zerofill，则该列自动添加 UNSIGNED 属性</li>
<li>AUTO_INCREMENT。整数类型在需要产生唯一标识符或顺序值时适用。一般从1开始，每行增加 1。一个表中最多只能有一个。对于使用AUTO_INCREMENT的列，应该定义为PRIMARY KEY或UNIQUE键</li>
<li>小数包括浮点数和定点数。浮点数包括 float（单精度）和 double（双精度），定点数则只有decimal。以字符串形式存放，比浮点数更精确，适合用来表示货币等精度高的数据</li>
<li>浮点数和定点数都可以用类型名称后加“(M,D)”，表示显示M位数字（整数位+小数位），D位位于小数点后面，浮点数如果不写精度M和标度D，则会按照实际精度值显示，如果有精度和标度，则会自动将四舍五入后的结果插入，系统不会报错；定点数如果不写精度和标度，则按照默认值 decimal(10,0)来进行操作，并且如果数据超越了精度和标度值，系统则会报错。</li>
<li>BIT(M)用来存放多位二进制数，M范围1～64，默认1。必须用bin()（二进制）或者 hex()（六进制）函数读取。数据插入bit类型字段时，首先转换为二进制，如果位数允许，将成功插入；</li>
</ul>
<h2>2.2. 日期时间类型</h2>
<table>
<thead>
<tr>
<th style="text-align:center">数据类型</th>
<th style="text-align:center">字节</th>
<th style="text-align:center">最小值</th>
<th style="text-align:center">最大值</th>
<th style="text-align:center">零值</th>
<th style="text-align:center">场景</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">DATE</td>
<td style="text-align:center">4</td>
<td style="text-align:center">1000-01-01</td>
<td style="text-align:center">9999-12-31</td>
<td style="text-align:center">0000-00-00</td>
<td style="text-align:center">年月日</td>
</tr>
<tr>
<td style="text-align:center">TIME</td>
<td style="text-align:center">3</td>
<td style="text-align:center">-838:59:59</td>
<td style="text-align:center">838:5959</td>
<td style="text-align:center">00:00:00</td>
<td style="text-align:center">时分秒</td>
</tr>
<tr>
<td style="text-align:center">YEAR</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1901</td>
<td style="text-align:center">2155</td>
<td style="text-align:center">0000</td>
<td style="text-align:center">年份</td>
</tr>
</tbody>
</table>
<ul>
<li>如果超出有效值范围，在默认的SQLMode下，系统会进行错误提示，并将以零值来进行存储</li>
</ul>
<h2>2.3. 字符串类型</h2>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/296fd0f48ca82e9d987ac.png" alt="数据类型-字符串类型.PNG" tabindex="0"><figcaption>数据类型-字符串类型.PNG</figcaption></figure>
<ul>
<li>BINARY和VARBINARY包含二进制字符串而不包含非二进制字符串。保存BINARY值时通过填充“0x00”（零字节）以达到字段定义长度。BINARY(3)列，当插入时'a'变为'a\0\0'</li>
<li>ENUM枚举类型，需要在建表时通过枚举方式显式指定值范围（忽略大小写），1～255个成员需要1个字节；255～65535需要2个字节存储。最多65535个。create table t (gender enum('M','F'));插入不在ENUM指定范围内的值时，默认插入第一个值。一次只能选一个成员</li>
<li>SET也是一个字符串对象，最多64个。每8个成员占1个字节存储；Create table t (col set （'a','b','c','d'）;包含重复成员的集合将只取一次；对于超出允许值范围的值将报错，一次可选多个成员</li>
</ul>
<h2>2.4. 选择合适的数据类型</h2>
<ul>
<li>
<p>应该根据实际情况选择能够满足需求的最小存储类型</p>
</li>
<li>
<p>VARCHAR属于可变长度的字符类型。CHAR属于固定长度的字符类型。所以处理速度比VARCHAR快得多，但其缺点是浪费存储空间，程序需要对行尾空格进行处理，对于那些长度变化不大并且对查询速度有较高要求的数据可以考虑使用CHAR类型存储</p>
<ul>
<li>MyISAM：建议使用CHAR</li>
<li>MEMORY：CHAR或VARCHAR列都是作为CHAR类型处理</li>
<li>InnoDB：建议使用VARCHAR类型。所有数据行都使用指向数据列值的头指针，主要的性能因素是数据行使用的存储总量。由于CHAR平均占用的空间多于VARCHAR，因此使用VARCHAR来最小化需要处理的数据行的存储总量和磁盘I/O是比较好</li>
</ul>
</li>
<li>
<p>TEXT与BLOB</p>
<ul>
<li>BLOB和TEXT值在执行大量的删除操作，会在数据表中留下很大的“空洞”，以后填入这些“空洞”的记录在插入的性能上会有影响。为了提高性能，建议定期使用 OPTIMIZE TABLE 对表进行碎片整理避免</li>
<li>BLOB 或 TEXT可以使用合成的（Synthetic）索引来提高查询性能。就是根据大文本字段的内容并通过使用 MD5()SHA1()或 CRC32()函数或者使用自己的应用程序逻辑来计算一个散列值存储在单独的数据列中，接下来就可以通过检索散列值找到数据。只能用于精确匹配的查询（散列值对于类似&lt;或&gt;=等范围搜索操作符是没有用处的）。如果散列算法生成的字符串带有尾部空格，就不要把它们存储在CHAR或VARCHAR列中，它们会受到尾部空格去除的影响。如果需要对BLOB或者 CLOB 字段进行模糊查询，MySQL提供了前缀索引，在不必要的时候避免检索大型的BLOB或TEXT值</li>
<li>把BLOB或TEXT列分离到单独的表中。在某些环境中，如果把这些数据列移动到第二张数据表中，可以把原数据表中的数据列转换为固定长度的数据行格式，这会减少主表中的碎片，可以得到固定长度数据行的性能优势。它还可以使主数据表在运行 SELECT * 查询的时候不会通过网络传输大量的 BLOB 或 TEXT 值。</li>
</ul>
</li>
<li>
<p>浮点数与定点数。浮点数一般用于表示含有小数部分的数值。编程中注意浮点数存在误差，尽量避免比较；对货币等对精度敏感的数据应该用定点数</p>
</li>
<li>
<p>如果应用只需要记录“年份”，可用1个字节来存储的YEAR类型，能节约存储，提高表的操作效率；如果要记录年月日时分秒，并且记录的年份比较久远，那么最好使用DATETIME，而不要用TIMESTAMP。因为TIMESTAMP的日期范围比DATETIME要短得多；如果记录的日期需要让不同时区的用户使用，那么最好使用 TIMESTAMP，因为日期类型中只有它能够和实际时区相对应</p>
</li>
<li>
<p>尽可能的使用not null定义字段(innodb的特性所决定，非not null的值，需要额外的在字段存储，同时也会增加IO和存储的开销）</p>
</li>
<li>
<p>尽量少用text类型，非用不可时最好考虑分表。</p>
</li>
<li>
<p>表中有大字段 X(例如：text 类型)，且字段 X 不会经常更新，以读为为主，请问您是选择拆成子表，还是继续放一起?</p>
<ul>
<li>拆带来的问题：连接消耗+存储拆分空间。拆的话最好和经常要查询的表的主键在物理结构上放置在一起(分区) 顺序 IO ，减少连接消耗，最后这是一个文本列再加上一个全文索引来尽量抵消连接消耗。</li>
<li>不拆可能带来的问题：查询性能。实际场景下，例如说商品表数据量比较大的情况下使用拆的方案，会将商品描述单独存储到一个表中。</li>
</ul>
</li>
</ul>
<h1>3. MySQL中的运算符</h1>
<h2>3.1. 算术运算符</h2>
<ul>
<li>+、-、*、/或者DIV（除法，返回商）、%或者MOD(a,b)（除法，返回余数）</li>
<li>除法运算和模运算中，如果除数为0，将是非法除数，返回结果为NULL</li>
</ul>
<h2>3.2. 比较运算符</h2>
<ul>
<li>=(不能比较null)、&lt;&gt;或者!=(不能比较null)、&lt;=&gt;（能比较NULL等于）、&lt;、&gt;、&lt;=、&gt;=、[not] between(全包含)、[not] in、is [not] null、like [_'单个字符，'%'多个字符]、REGEXP或RLIKE(正则表达式匹配),select中的比较true则是1，false则是0,用于比较数字、字符串(不区分大小写)和表达式.数字作为浮点数比较，而字符串以不<br>
区分大小写的方式进行比较。</li>
</ul>
<h2>3.3. 逻辑运算符</h2>
<ul>
<li>NOT或者!</li>
<li>AND或者&amp;&amp; 逻辑与，操作数有0，结果0；有NULL且无0 结果NULL，其他1</li>
<li>OR或者|| 逻辑或，操作数有1，结果1；有NULL且无1，结果NULL，其他0</li>
<li>XOR 逻辑异或,操作数有NULL，结果null,无null真假值相异，结果 1；其他0。</li>
</ul>
<h2>3.4. 位运算符</h2>
<ul>
<li>&amp; 位与（位 AND）、| 位或 （位 OR ）、^ 位异或（位 XOR）、~ 位取反、&gt;&gt; 位右移、&lt;&lt; 位左移,位运算是将给定的操作数转化为二进制后，对各个操作数每一位都进行指定的逻辑运算，得到的二进制结果转换为十进制数后就是位运算的结果。</li>
</ul>
<h1>4. MySQL常用函数</h1>
<h2>4.6. 其他函数</h2>
<ul>
<li>DATABASE() 返回当前数据库名</li>
<li>VERSION() 返回当前数据库版本</li>
<li>USER() 返回当前登录用户名</li>
<li>PASSWORD(str) 返回字符串str的加密版本</li>
<li>MD5() 返回字符串str的MD5值</li>
</ul>
<h1>5. 视图</h1>
<ul>
<li>视图（View）是一种虚拟存在的表，并不在数据库中实际存在，行和列数据来自定义视图的查询中使用的表，并且是在使用视图时动态生成的。</li>
<li>视图相对于普通的表的优势
<ul>
<li>简单：用户完全不需要关心后面对应的表的结构、关联条件和筛选条件，对用户来说已经是过滤好的复合条件的结果集。</li>
<li>安全：用户只能访问他们被允许查询的结果集，对表的权限管理并不能限制到某个行某个列，但是通过视图就可以简单的实现</li>
<li>数据独立：一旦视图结构确定了，可以屏蔽表结构变化对用户的影响，源表增加列对视图没有影响；源表修改列名，则可以通过修改视图来解决，不会造成对访问者的影响</li>
</ul>
</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code># 创建或者修改视图要有 CREATE VIEW权限，并且对于查询涉及的列有SELECT权限。如果使用CREATE OR REPLACE 或者 ALTER 修改视图，还需要该视图的DROP权限。
# 创建视图
mysql&gt; CREATE [OR REPLACE] [ALGORITHM = {UNDEFINED | MERGE | TEMPTABLE}] VIEW view_name [(column_list)] AS select_statement [WITH [CASCADED | LOCAL] CHECK OPTION]
# 修改视图
mysql&gt; ALTER [ALGORITHM = {UNDEFINED | MERGE | TEMPTABLE}]VIEW view_name [(column_list)] AS select_statement [WITH [CASCADED | LOCAL] CHECK OPTION]

# 在 FROM 关键字后面不能包含子查询
# LOCAL 是只要满足本视图的条件就可以更新视图记录；
# CASCADED(默认) 则是必须满足所有针对该视图的所有视图的条件才可以更新视图记录
# 以下情况视图不更新
  # 包含聚合函数（SUM、MIN、MAX、COUNT 等）、DISTINCT、GROUP BY、HAVING、UNION 或者 UNION ALL
  # 常量视图。create or replace view pi as select 3.1415926 as pi;
  # SELECT 中包含子查询。create view city_view as select (select city from city where city_id = 1);
  # JION
  # FROM 一个不能更新的视图。
  # WHERE 字句的子查询引用了 FROM 字句中的表。

# 删除视图 
# 需要有该视图DROP权限。
mysql&gt; DROP VIEW [IF EXISTS] view_name [, view_name] ...[RESTRICT | CASCADE]

# 查看视图
# 显示表和视图的名字
mysql&gt; SHOW TABLES 
# 显示表和视图的信息（表行数）
mysql&gt; SHOW TABLE STATUS [FROM db_name] [LIKE 'pattern']
# 查询某个视图的定义
mysql&gt; SHOW CREATE VIEW view_name
# 查看视图的相关信息
mysql&gt; select * from information_schema.views where table_name = 'staff_list'
</code></pre></div><h1>6. 存储过程和函数</h1>
<ul>
<li>存储过程和函数是事先经过编译并存储在数据库中的一段SQL语句的集合，可以简化应用开发人员的很多工作，减少数据在数据库和应用服务器之间的传输，对于提高数据处理的效率是有好处的。</li>
<li>存储过程的好处在于处理逻辑都封装在数据库端，调用者不需要了解中间的处理逻辑，一旦处理逻辑发生变化，只需要修改存储过程即可，而对调用者的程序完全没有影响。</li>
<li>函数必须有返回值，而存储过程没有，存储过程的参数可以使用IN、OUT、INOUT类型，而函数的参数只能是IN类型。</li>
<li>创建存储过程或者函数需要 CREATE ROUTINE 权限，修改或者删除存储过程或者函数需要 ALTER ROUTINE 权限，执行存储过程或者函数需要 EXECUTE 权限</li>
<li>存储过程和函数的优势是可以将数据的处理放在数据库服务器上进行，避免将大量的结果集传输给客户端，减少数据的传输，但是在数据库服务器上进行大量的复杂运算也会占用服务器的CPU，造成数据库服务器的压力，所以不要在存储过程和函数中进行大量的复杂运算，应尽量将这些运算操作分摊到应用服务器上执行</li>
</ul>
<h2>6.1. 创建、修改、删除、查看存储过程或者函数</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>
# proc_parameter: [ IN | OUT | INOUT ] param_name type
# func_parameter: param_name type
# type: Any valid MySQL data type
# characteristic: 
  # COMMENT 'string'(存储过程或者函数的注释信息) 
  # SQL SECURITY { DEFINER(默认) | INVOKER }指定子程序该用创建子程序者还是使用调用者的许可来执行
# routine_body: Valid SQL routine statement
# 存储过程和函数允许包含DDL语句，Commit或者回滚，调用其他的过程或者函数，但是不允许执行LOAD DATA INFILE语句
# 执行创建过程和函数可以通过“DELIMITER $$”命令将语句的结束符从“;”修改成其他符号如“$$”，这样“;”就不会被解释成语句的结束而提示错误。创建完毕再通过“DELIMITER ;”命令再将结束符改回成“;”

mysql&gt; CREATE [DEFINER = { user | CURRENT_USER }] PROCEDURE 存储过程名 ([proc_parameter[,...]]) [characteristic ...] routine_body

mysql&gt; CREATE [DEFINER = { user | CURRENT_USER }] FUNCTION 函数名 ([func_parameter[,...]]) RETURNS type [characteristic ...] routine_body


# 修改函数/存储过程
mysql&gt; ALTER {PROCEDURE | FUNCTION} 存储过程名/函数名 [characteristic ...]

# 调用过程
mysql&gt; CALL 存储过程名/函数名([parameter[,...]])

# 创建大量数据的存储过程
mysql&gt; create table t(id int primary key, a int, b int,index(a))engine=innodb;
delimiter ;;
create procedure idata()
begin
declare i int;
set i=1;
while(i&lt;=1000)do
insert into t values(i,i,i);
set i=i+1;
end while;
end;;
delimiter ;
call idata();

# 一次只能删除一个存储过程或者函数，需要有该过程或者函数的ALTER ROUTINE 权限
mysql&gt; DROP {PROCEDURE | FUNCTION} [IF EXISTS] 存储过程名/函数名

# 查看存储过程或者函数
mysql&gt; SHOW {PROCEDURE | FUNCTION} STATUS [LIKE 'pattern']

# 查看存储过程或者函数的定义
mysql&gt; SHOW CREATE {PROCEDURE | FUNCTION} 存储过程名/函数名

# 查看存储过程和函数的信息
mysql&gt; select * from information_schema.routines where ROUTINE_NAME = 'film_in_stock'
</code></pre></div><h2>6.2. 变量的使用</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code># 局部变量的定义：作用范围在BEGIN…END块中，可以用在嵌套的块中。必须写在复合语句的开头，并且在任何其他语句前面
mysql&gt; DECLARE 变量名[,...] 数据类型 [DEFAULT value]

# 变量的直接赋值(常量或者赋表达式)
mysql&gt; SET 变量名 = expr [, var_name = expr] ...

# 变量的查询结果赋值
mysql&gt; SELECT col_name[,...] INTO 变量名[,...] table_expr
</code></pre></div><h2>6.3. 条件的定义和处理</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code># 条件的定义
# condition_value:{ SQLSTATE [VALUE] sqlstate_value| mysql_error_code }
mysql&gt; DECLARE 条件名 CONDITION FOR condition_value

# 条件的处理
# handler_type: { CONTINUE | EXIT } CONTINUE 表示继续执行下面的语句，EXIT 则表示执行终止
# condition_value:
  { SQLSTATE [VALUE] sqlstate_value
  | condition_name 条件名
  | SQLWARNING 以 01 开头的 SQLSTATE 代码的速记
  | NOT FOUND 以 02 开头的 SQLSTATE 代码的速记
  | SQLEXCEPTION 没有被 SQLWARNING 或 NOT FOUND 捕获的 SQLSTATE 代码的速记
  | mysql_error_code }
mysql&gt; DECLARE handler_type HANDLER FOR 条件名[,...] sp_statement

# 对于错误ERROR 1062 (23000): Duplicate entry '1' for key 'PRIMARY' 可以这么声明
# SQLSTATE
mysql&gt; DECLARE CONTINUE HANDLER FOR SQLSTATE '23000' SET @x2 = 1 

# mysql-error-code：
mysql&gt; DECLARE CONTINUE HANDLER FOR 1062 SET @x2 = 1;

# 事先定义 condition_name：
mysql&gt; DECLARE DuplicateKey CONDITION FOR SQLSTATE '23000';
mysql&gt; DECLARE CONTINUE HANDLER FOR DuplicateKey SET @x2 = 1;

# SQLEXCEPTION
mysql&gt; DECLARE CONTINUE HANDLER FOR SQLEXCEPTION SET @x2 = 1;
</code></pre></div><h2>6.4. 光标的使用</h2>
<ul>
<li>在存储过程和函数中可以使用光标对结果集进行循环的处理。</li>
<li>变量、条件、处理程序、光标都是通过DECLARE定义，变量和条件必须在最前面声明，然后才能是光标的声明，最后才可以是处理程序的声明</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code># 声明光标
mysql&gt; DECLARE 光标名 CURSOR FOR select_statement

# OPEN 光标
mysql&gt; OPEN 光标名

# FETCH 光标
mysql&gt; FETCH 光标名 INTO var_name [, var_name] ...

# CLOSE 光标
mysql&gt; CLOSE 光标名

# 光标使用例子
mysql&gt; CREATE PROCEDURE payment_stat ()
 -&gt; BEGIN
 -&gt; DECLARE i_staff_id int;
 -&gt; DECLARE d_amount decimal(5,2);
 -&gt; DECLARE cur_payment cursor for select staff_id,amount from payment;
 -&gt; DECLARE EXIT HANDLER FOR NOT FOUND CLOSE cur_payment;
 -&gt; 
 -&gt; set @x1 = 0;
 -&gt; set @x2 = 0;
 -&gt; 
 -&gt; OPEN cur_payment;
 -&gt; 
 -&gt; REPEAT
 -&gt; FETCH cur_payment INTO i_staff_id, d_amount;
 -&gt; if i_staff_id = 2 then
 -&gt; set @x1 = @x1 + d_amount;
 -&gt; else 
 -&gt; set @x2 = @x2 + d_amount;
 -&gt; end if;
 -&gt; UNTIL 0 END REPEAT;
 -&gt; 
 -&gt; CLOSE cur_payment;
 -&gt; 
 -&gt; END;
 -&gt; $$
</code></pre></div><h2>6.5. 流程控制</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code># IF 语句
IF search_condition THEN statement_list
[ELSEIF search_condition THEN statement_list] ...
[ELSE statement_list]
END IF

# CASE 语句
CASE case_value
WHEN when_value THEN statement_list
[WHEN when_value THEN statement_list] ...
[ELSE statement_list]
END CASE
Or: 
CASE
WHEN search_condition THEN statement_list
[WHEN search_condition THEN statement_list] ...
[ELSE statement_list]
END CASE

# LOOP语句，简单的循环，退出循环的条件需要使用其他的语句定义.通常可以使用 LEAVE 语句实现
[begin_label:] LOOP
statement_list
END LOOP [end_label]

# LEAVE语句，用来从标注的流程构造中退出，通常和 BEGIN ... END 或者循环一起使用。
LEAVE [end_label]

# ITERATE语句，必须用在循环中，作用是跳过当前循环的剩下的语句，直接进入下一轮循环。
ITERATE [end_label]

# REPEAT 语句，有条件的循环控制语句，当满足条件的时候退出循环，
[begin_label:] REPEAT
statement_list
UNTIL search_condition
END REPEAT [end_label]

# WHILE 语句，有条件的循环控制语句，即当满足条件时执行循环的内容，
[begin_label:] WHILE search_condition DO
statement_list
END WHILE [end_label]

# WHILE是满足条件才执行循环，REPEAT是满足条件退出循环；WHILE在首次循环执行之前就判断条件，最少执行0次，REPEAT是在首次执行循环之后才判断条件，最少执行1次
</code></pre></div><h1>7. 触发器</h1>
<ul>
<li>触发器是与表有关的数据库对象，在满足定义条件时触发，并执行触发器中定义的语句集合。可以协助应用在数据库端确保数据的完整性</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code># 创建触发器
# trigger_time触发时间，BEFORE在检查约束前触发，AFTER在检查约束后触发
# trigger_event触发事件INSERT、UPDATE 或者 DELETE
# 对同一个表相同触发时间的相同触发事件，只能定义一个触发器
# 别名OLD.和NEW.来引用触发器中发生变化的记录内容，触发器只支持行级触发的，不支持语句级触发
# 对于有重复记录，需要进行UPDATE操作的INSERT，触发顺序是BEFORE INSERT、BEFORE UPDATE、AFTER UPDATE
# 对于没有重复记录的INSERT，触发顺序是 BEFORE INSERT、AFTER INSERT
# 对于那些实际执行 UPDATE 操作的记录，仍然会执行 BEFORE INSERT 触发器的内容
mysql&gt; CREATE TRIGGER trigger_name trigger_time trigger_event ON tbl_name FOR EACH ROW trigger_stmt
  
# 删除触发器
mysql&gt; DROP TRIGGER [数据库.]trigger_name

# 查询指定触发器的指定信息
mysql&gt; select * from information_schema.triggers where trigger_name = 'ins_film_bef'

# 触发器的使用
# 触发程序不能调用将数据返回客户端的存储程序，不能使用采用CALL语句的动态SQL，但是允许存储程序通过参数将数据返回触发程序。也就是存储过程或者函数通过OUT或者INOUT类型的参数将数据返回触发器是可以的，但是不能调用直接返回数据的过程
# 不能在触发器中使用以显式或隐式方式开始或结束事务的语句，如 START TRANSACTION、COMMIT 或 ROLLBACK。
# 触发器是按照 BEFORE触发器、行操作、AFTER触发器的顺序执行的，其中任何一步操作发生错误都不会继续执行剩下的操作。如果是对事务表进行的操作，那么会整个作为一个事务被回滚（Rollback），但是如果是对非事务表进行的操作，那么已经更新的记录将无法回滚
</code></pre></div><h1>8. MySQL存储引擎</h1>
<h2>8.1. MySQL存储引擎特性</h2>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/ab7895c0171c95bd93cf1.png" alt="各种存储引擎.PNG" tabindex="0"><figcaption>各种存储引擎.PNG</figcaption></figure>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code># 查看mysql默认存储引擎
mysql&gt; show variables like 'table_type';
# 查看当前数据库支持的存储引擎
mysql&gt; SHOW ENGINES或者SHOW VARIABLES LIKE 'have%'
</code></pre></div><h2>8.2. MyISAM</h2>
<ul>
<li>数据文件和索引文件可以放置在不同的目录，平均分布IO，获得更快的速度。需要在建表时通过 DATA DIRECTORY 和 INDEX DIRECTORY 语句指定指定索引文件和数据文件的绝对路径</li>
<li>MyISAM类型的表可能会损坏，可以用CHECK TABLE检查MyISAM表，并用REPAIR TABLE修复一个损坏的MyISAM表。表损坏可能导致数据库异常重新启动，需要尽快修复并尽可能地确认损坏的原因</li>
<li>MyISAM表支持3种不同的存储格式，
<ul>
<li>静态表（默认）:每个记录长度固定。优点是存储速度快，容易缓存，故障恢复容易；缺点是占用的空间通常比动态表多。数据在存储的时候会按照列的宽度定义补足空格，但是在应用访问的时候并不会得到这些空格，这些空格在返回给应用之前已经去掉。如果需要保存的内容后面本来就带有空格，那么在返回结果的时候也会被去掉</li>
<li>动态表:包含变长字段，优点是占用的空间相对少，但是频繁地更新删除记录会产生碎片，需要定期执行OPTIMIZE TABLE或myisamchk -r改善性能，故障恢复困难</li>
<li>压缩表。由myisampack工具创建，占据非常小的磁盘空间。因为每个记录是被单独压缩的，所以只有非常小的访问开支</li>
</ul>
</li>
<li>Myisam 用 B+Tree 来存储数据的。</li>
</ul>
<h2>8.3. InnoDB</h2>
<ul>
<li>
<p>自动增长列</p>
<ul>
<li>插入值如果是空或者0，则实际插入的将是自动增长后的值。如果指定了具体值，且小于自增值，则自增值不变；大于等于自增值，则自增值修改为具体值</li>
<li>自增值生成算法：从auto_increment_offset初始值开始，以auto_increment_increment为步长，持续叠加</li>
<li>ALTER TABLE *** AUTO_INCREMENT = n;在内存中设置自动增长列的初始值，默认从1开始，如果数据库重启，那么这个值就会丢失，需要重新设置。可使用LAST_INSERT_ID()查询当前线程最后插入记录使用的值。如果一次插入了多条记录，那么返回的是第一条记录使用的自动增长值。对于InnoDB，自动增长列必须是索引。如果是组合索引，也必须是组合索引的第一列，对于MyISAM，自动增长列可以是组合索引的其他列，这样插入记录后，自动增长列是按照组合索引的前面几列进行排序后递增的</li>
</ul>
</li>
<li>
<p>外键约束:在创建外键的时候，要求父表必须有对应的索引，子表在创建外键的时候也会自动创建对应的索引。仅InnoDB 存储引擎支持对外部关键字约束条件的检查。其他不支持，仅起备忘作用</p>
</li>
<li>
<p>存储方式:InnoDB 存储表和索引有以下两种方式。</p>
<ul>
<li>共享表空间存储（innodb_file_per_table=OFF），表结构保存在.frm 文件中，数据和索引保存在 innodb_data_home_dir和 innodb_data_file_path定义的表空间中，可以是多个文件。表删掉空间不回收</li>
<li>多表空间存储（innodb_file_per_table=ON），表结构保存在.frm文件中，数据和索引单独保存在.ibd中。如果是个分区表，每个分区保存在表名+分区名.ibd文件，可以在创建分区的时候指定每个分区的数据文件的位置，将表IO均匀分布在多个磁盘上。修改多表空间的参数innodb_file_per_table并重启后，只对新建的表生效。即便在多表空间的存储方式下，共享表空间仍然是必须的，InnoDB把内部数据词典和未作日志放在这个文件中。表删掉空间回收</li>
</ul>
</li>
<li>
<p>InnoDB 通过 B+Tree 结构对 ID 建索引，然后在叶子节点中存储记录。</p>
</li>
<li>
<p>若建索引的字段不是主键 ID，则对该字段建索引，然后在叶子节点中存储的是该记录的主键，然后通过主键索引找到对应的记录。</p>
</li>
</ul>
<h2>8.4. MEMORY</h2>
<ul>
<li>MEMORY使用存在内存中的内容来创建表。存储为一个磁盘文件.frm。访问速度快</li>
<li>MySQL启动时使用--init-file选项，把INSERT INTO ... SELECT 或 LOAD DATA INFILE放入这个文件中，就可以在服务启动时从持久稳固的数据源装载表</li>
<li>释放被MEMORY表使用的内存，执行DELETE FROM或TRUNCATE TABLE，或者整个地删除表（使用 DROP TABLE 操作）。</li>
<li>max_heap_table_size表示每个MEMORY表中可以放置的数据量的大小</li>
</ul>
<h2>8.5. InnoDB与MEMORY区别</h2>
<ul>
<li>InnoDB引擎把数据放在主键索引上，其他索引上保存的是主键id。称之为索引组织表（IndexOrganizied Table）。Memory引擎采用的是把数据单独存放，索引上保存数据位置的数据组织形式，我们称之为堆组织表（HeapOrganizied Table）。</li>
<li>当数据文件有空洞的时候，InnoDB表在插入新数据的时候，为了保证数据有序性，只能在固定的位置写入新值，内存表找到空位就可以插入新值；内存表每个数据行被删除以后，空出的这个位置都可以被接下来要插入的数据复用。</li>
<li>数据位置发生变化的时候，InnoDB表只需要修改主键索引，内存表需要修改所有索引；</li>
<li>InnoDB表用主键索引查询时需要走一次索引查找，用普通索引查询的时候，需要走两次索引查找。而内存表没有这个区别，所有索引的“地位”都是相同的。</li>
</ul>
<h1>9. MEMORY表</h1>
<ul>
<li>内存临时表排序的时候使用了rowid排序方法</li>
<li>如果内存临时表大小超过了tmp_table_size，那么内存临时表就会转成磁盘临时表。磁盘临时表使用的引擎默认是InnoDB，是由参数internal_tmp_disk_storage_engine控制的。当使用磁盘临时表的时候，对应的就是一个没有显式索引的InnoDB表的排序过程。</li>
<li>不建议你在生产环境上使用内存表。
<ul>
<li>内存表的锁是表锁</li>
<li>数据没有持久化</li>
</ul>
</li>
<li>内存临时表刚好可以无视内存表的两个不足
<ul>
<li>临时表不会被其他线程访问，没有并发性的问题；</li>
<li>临时表重启后也是需要删除的，清空数据这个问题不存在；</li>
<li>备库的临时表也不会影响主库的用户线程。</li>
<li>内存表支持hash索引，对复杂查询的加速效果还是很不错的。</li>
</ul>
</li>
<li>怎么避免内存表突然丢数据，然后导致主备同步停止的情况。假设主库暂时不能修改引擎，
<ul>
<li>先把备库的内存表引擎先都改成InnoDB。对于每个内存表，执行set sql_log_bin=off;alter table tbl_name engine=innodb;避免备库重启的时候，数据丢失的问题。由于主库重启后，会往binlog里面写“delete from tbl_name”，这个命令传到备库，备库的同名的表数据也会被清空。因此，就不会出现主备同步停止的问题。</li>
<li>如果由于主库异常重启，触发了HA，这时候我们之前修改过引擎的备库变成了主库。而原来的主库变成了新备库，在新备库上把所有的内存表（这时候表里没数据）都改成InnoDB表。所以，如果我们不能直接修改主库上的表引擎，可以配置一个自动巡检的工具，在备库上发现内存表就把引擎改了。</li>
<li>同时避免创建新的内存表。</li>
</ul>
</li>
</ul>
<h2>9.1. MERGE</h2>
<ul>
<li>MERGE 存储引擎是一组 MyISAM 表的组合，这些 MyISAM 表必须结构完全相同，MERGE表本身并没有数据</li>
<li>对MERGE表的插入操作，是通过INSERT_METHOD子句定义插入的表，使用FIRST或LAST值使得插入操作被相应地作用在第一或最后一个表上，不定义这个子句或者定义为NO，表示不能对这个MERGE表执行插入操作，对MERGE表的删除操作，只是删除定义，对内部的表没有任何的影响</li>
<li>MERGE表在磁盘上保留两个文件，文件存储表定义.frm 和文件包含组合表的信息.MRG(由哪些表组成、插入新的数据时的依据)</li>
<li>MERGE表并不能智能地将记录写到对应的表中，而分区表是可以的。通常使用MERGE表来对多个表进行查询和更新操作，而对这种按照时间记录的操作日志表则可以透明地进行插入操作。</li>
</ul>
<h1>10. MySQL连接</h1>
<h2>10.1. 长连接与短连接</h2>
<ul>
<li>
<p>长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。短连接则是指每次执行完很少的几次查询就断开连接，下次查询再重新建立一个。</p>
</li>
<li>
<p>有时候Mysql占用内存涨的很快的原因和解决方案？ 建立连接的过程通常是比较复杂的，在使用中要尽量使用长连接。但太多长连接可能导致内存占用太大，被系统强行杀掉（OOM），从现象看就是MySQL异常重启了。解决方案1.使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开长连接。2.执行mysql_reset_connection来重新初始化连接资源，无需重连和重新做权限验证(MySQL5.7以上)</p>
</li>
<li>
<p>MySQL建立连接的过程成本是很高的。除了正常的网络连接三次握手外，还需要做登录权限判断和获得这个连接的数据读写权限。</p>
</li>
<li>
<p>如果客户端由于压力过大，迟迟不能接收数据，会对服务端造成什么严重的影响？核心是造成了“长事务”。如果前面的语句有更新，意味着它们在占用着行锁，会导致别的语句更新被锁住；当然读的事务也有问题，就是会导致undo log不能被回收，导致回滚段空间膨胀</p>
</li>
</ul>
<h1>11. MySQL索引</h1>
<ul>
<li>索引是一种用于快速查询数据的数据结构，由存储引擎实现</li>
</ul>
<h2>11.2. 索引分类</h2>
<h3>11.2.1. 按物理存储分类</h3>
<h4>11.2.1.1. 聚簇索引</h4>
<ul>
<li>聚簇索引：
<ul>
<li>查询速度快，因为整个B+树本身就是一颗多叉平衡树，叶子节点也都是有序的，定位到索引的节点，就相当于定位到了数据</li>
<li>依赖于有序的数据 ：因为B+树是多路平衡树，如果索引的数据不是有序的，那么就需要在插入时排序，如果数据是整型还好，否则类似于字符串或 UUID 这种又长又难比较的数据，插入或查找的速度肯定比较慢。</li>
<li>更新代价大：如果对索引列的数据被修改时，那么对应的索引也将会被修改，而且聚集索引的叶子节点还存放着数据，修改代价肯定是较大的，所以对于主键索引来说，主键一般都是不可被修改的。</li>
</ul>
</li>
</ul>
<h4>11.2.1.2. 非聚簇索引</h4>
<ul>
<li>非聚集索引：
<ul>
<li>更新代价比聚集索引要小。非聚集索引的叶子节点是不存放数据的</li>
<li>非聚集索引也依赖于有序的数据</li>
<li>可能会二次查询（回表）当查到索引对应的指针或主键后，可能还需要根据指针或主键再到数据文件或表中查询</li>
</ul>
</li>
</ul>
<h3>11.2.2. 按字段特性分类</h3>
<h4>11.2.2.1. 主键索引</h4>
<ul>
<li>在InnoDB表中，当没有显示的指定表的主键时，会使用唯一索引且不允许存在null值的字段为默认的主键，否则InnoDB将会自动创建一个6Byte的rowid作为主键</li>
<li>辅助索引（二级索引）：叶子节点存储的数据是主键</li>
</ul>
<h4>11.2.2.2. 唯一普通索引和唯一索引的区别</h4>
<ul>
<li>查询过程：查询时都是通过B+树从树根开始，按层搜索到叶子节点(数据页)，然后在数据页内部通过二分法来定位记录。对于普通索引来说，查找到满足条件的第一个记录后，一直查找直到找到第一个不满足条件的记录，对于唯一索引来说，查找到第一个满足条件的记录后，就会停止继续检索。由于InnoDB的数据是按数据页为单位(默认是16KB)来读写的。当找到满足条件的记录的时候，它所在的数据页就都在内存里了。对于普通索引来说，多一次查找和判断下一条记录的操作，就只需要一次指针寻找和一次计算，当如果满足条件的记录刚好是这个数据页的最后一个记录，那么要取下一个记录，必须读取下一个数据页，但是，对于整型字段，一个数据页可以放近千个key，因此出现概率低。计算平均性能差异时，对于CPU来说可忽略不计</li>
<li>更新过程：当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InooDB会将这些更新操作缓存在change buffer中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行change buffer中与这个页有关的操作。保证这个数据逻辑的正确性</li>
<li>change buffer在内存中有拷贝，也会被写入到磁盘上。将change buffer中的操作应用到原数据页，得到最新结果的过程称为merge。数据页被访问、系统后台线程定时任务、在数据库正常关闭都会merge。如果能够将更新操作先记录在change buffer，减少读磁盘，语句的执行速度会得到明显的提升。而且，数据读入内存是需要占用buffer pool的，所以这种方式还能够避免占用内存，提高内存利用率</li>
<li>对于唯一索引来说，所有的更新操作都要先判断是否违反唯一性约束。必须要将数据页读入内存才能判断。因此，唯一索引的更新就不能使用change buffer，只有普通索引能使用</li>
<li>change buffer用的是buffer pool里的内存，innodb_change_buffer_max_size表示change buffer最大占用buffer pool的百分比</li>
<li>如果要在表中插入一个新记录的话，InnoDB的处理流程
<ul>
<li>1.这个记录要更新的目标页在内存中。对于唯一索引来说，找到3和5之间的位置，判断到没有冲突，插入这个值，语句执行结束；对于普通索引来说，找到3和5之间的位置，插入这个值，语句执行结束。普通索引和唯一索引对更新语句性能影响的差别，只是一个判断，只会耗费微小的CPU时间。</li>
<li>2.这个记录要更新的目标页不在内存中。对于唯一索引来说，需要将数据页读入内存，判断到没有冲突，插入这个值，语句执行结束；对于普通索引来说，则是将更新记录在change buffer，语句执行就结束了。将数据从磁盘读入内存涉及随机IO的访问。change buffer因为减少了随机磁盘访问，所以对更新性能的提升明显</li>
</ul>
</li>
<li>change buffer的使用场景
<ul>
<li>对普通索引写多读少的更新过程有加速作用(账单类，日志类系统)，而不适用于唯一索引。反过来，假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在change buffer，但之后由于马上要访问这个数据页，会立即触发merge过程。这样随机访问IO的次数不会减少，反而增加了change buffer的维护代价。</li>
</ul>
</li>
<li>change buffer的操作会在事务提交时记录到redo log，所以崩溃恢复的时候，change buffer不会丢失数据</li>
<li>merge的执行流程
<ul>
<li>从磁盘读入数据页到内存（老版本的数据页）</li>
<li>从change buffer里找出这个数据页的change buffer 记录(可能有多个），依次应用，得到新版数据页</li>
<li>写redo log。这个redo log包含了数据的变更和change buffer的变更</li>
<li>数据页和内存中change buffer对应的磁盘位置都还没有修改，属于脏页，之后各自刷回自己的物理数据</li>
</ul>
</li>
</ul>
<h3>11.2.3. 按索引字段个数分类</h3>
<h4>11.2.3.1. 单列索引</h4>
<h4>11.2.3.2. 组合索引</h4>
<ul>
<li>组合索引 是指对表上的多个列进行索引。联合索引也是一棵B+树，不同的是联合索引的键值数量不是1，而是大于等于2</li>
<li>where查询存在多个条件查询的时候，我们需要对查询的列创建组合索引。这样减少索引存储空间的开销</li>
<li>如何安排索引内的字段顺序？
<ul>
<li>索引的复用能力。如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的</li>
<li>空间。如果既有联合查询，又有基于a、b各自的查询呢？这时候你不得不需要同时维护(a,b)、(b) 这两个索引。最好在长度较小的字段上建立索引</li>
</ul>
</li>
</ul>
<h2>11.3. 索引使用</h2>
<h2>11.4. 重建索引</h2>
<ul>
<li>索引可能因为删除，或者页分裂等原因，导致数据页有空洞，重建索引的过程会创建一个新的索引，把数据按顺序插入，这样页面的利用率最高，也就是索引更紧凑、更省空间</li>
<li>重建普通索引k alter table T drop index k; alter table T add index(k);</li>
<li>重建主键索引id alter table T engine=InnoDB;</li>
</ul>
<h2>11.5. 查看索引使用情况</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code># Handler_read_key代表了一个行被索引值读的次数，值越高表示索引经常使用
# Handler_read_rnd_next在数据文件中读下一行的请求数。值越高表示索引不经常使用
mysql&gt; show status like 'Handler_read%' 
</code></pre></div><h2>11.6. MySQL索引实现</h2>
<ul>
<li>在MySQL中，索引是在存储引擎层实现的</li>
<li>在InnoDB中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表。InnoDB使用了B+树索引模型，所以数据都是存储在B+树中的。每一个索引在InnoDB里面对应一棵B+树。</li>
<li>根据叶子节点的内容分为主键索引和非主键索引。主键索引的叶子节点存的是整行数据。称为聚簇索引（clustered index）。非主键索引的叶子节点内容是主键的值。称为二级索引（secondary index）</li>
<li>如果是主键查询，则只需要搜索主键所在的B+树</li>
<li>如果普通索引查询方式，则需要先搜索索引树，得到主键的值，再到主键所在的索引树搜索一次。这个过程称为回表。基于非主键索引的查询需要多扫描一棵索引树。因此，应该尽量使用主键查询。</li>
</ul>
<h2>11.7. 索引维护</h2>
<ul>
<li>B+树为了维护索引有序性，在插入新值的时候需要做必要的维护。可能在现有记录后面插入一个新记录。可能需要逻辑上挪动后面的数据，空出位置。如果最后所在的记录所在的数据页已经满了，这时候需要申请一个新的数据页，然后挪动部分数据过去。这个过程称为页分裂。在这种情况下性能下降。页分裂操作降低了数据页的利用率。当相邻两个页由于删除了数据，利用率很低之后，会将数据页做合并。合并的过程，可以认为是分裂过程的逆过程</li>
</ul>
<h2>11.8. 索引设计原则</h2>
<ul>
<li>考虑建立联合索引而不是单列索引。因为索引是需要占用磁盘空间的。离散度大的或者长度小的列放到联合索引的前面select count(distince xxx) from t;尽量不要包含多个列的排序，如果需要最好给这些列创建复合索引。复合索引中只要有一列含有NULL值，那么这一列对于此复合索引就是无效的。所以我们在数据库设计时不要让字段的默认值为NULL</li>
<li>索引字段越小越好，节省存储空间（因为数据库数据存储单位是以“页”为单位的，数据存储的越多，IO也会越大）</li>
<li>取消外键，可交由程序来约束，性能更好</li>
<li>尽量使用数字型字段，若只含数值信息的字段尽量不要设计为字符型，会降低查询和连接的性能并增加存储开销。这是因为引擎在处理查询和连接时会逐个比较字符串中每一个字符，而对于数字型而言只需要比较一次</li>
<li>字符串创建索引的方式
<ul>
<li>直接创建完整索引，可能比较占用空间；</li>
<li>前缀索引，节省空间，磁盘IO减少，索引高速缓存中的块能容纳更多的键值，查询速度加快，但会增加查询扫描次数，并且不能使用覆盖索引，不支持范围查询； 可通过查询count(distinct left(field,n))/count(1) 大于0.95的n，确定使用多长的前缀</li>
<li>倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题；查询select * from t where x = reverse('x'); 记得使用count(distinct)方法去做个验证。</li>
<li>hash字段/crc32字段索引，查询性能稳定，有额外的存储和计算消耗，不支持范围扫描。添加一个整数字段保存校验码，同时在这个字段上创建索引。这样索引就变小了，记得查询要判断filed和校验码是否相同。select * from t where x=crc32/hash('x') and x='x'</li>
</ul>
</li>
<li>普通索引(业务唯一)和唯一索引：
<ul>
<li>写多读少的场景普通索引能用上change buffer优化，推荐使用普通索引而唯一只需业务保证即可</li>
<li>使用唯一索引。考虑某列中值的分布。索引的列的基数越大，索引的效果越好。区分度大的</li>
<li>在一些“归档库”的场景，可以考虑使用唯一索引的。比如，线上数据只需要保留半年，然后历史数据保存在归档库。这时候，归档数据已经是确保没有唯一键冲突了。要提高归档效率，可以考虑把表里面的唯一索引改成普通索引</li>
</ul>
</li>
<li>索引列的基数越大，索引效果越好。组合索引基数更大，推荐使用</li>
<li>应尽可能的避免更新 clustered 索引数据列，因为 clustered 索引数据列的顺序就是表记录的物理存储 顺序，一旦该列值改变将导致整个表记录的顺序的调整，会耗费相当大的资源。若应用系统需要频繁更新 clustered 索引数据列，那么需要考虑是否应将该索引建为 clustered 索引。</li>
<li>尽可能的使用 varchar/nvarchar 代替 char/nchar ，因为首先变长字段存储空间小，可以节省存储空间，其次对于查询来说，在一个相对较小的字段内搜索效率显然要高些</li>
<li>避免频繁创建和删除临时表，以减少系统表资源的消耗。在新建临时表时，如果一次性插入数据量很大，那么可以使用 select into 代替 create table，避免造成大量 log ，以提高速度；如果数据量不大，为了缓和系统表的资源，应先create table，然后insert。</li>
<li>如果使用到了临时表，在存储过程的最后务必将所有的临时表显式删除，先 truncate table ，然后 drop table ，这样可以避免系统表的较长时间锁定。</li>
</ul>
<h2>11.9. 索引的常见数据模型(实现索引的方式)</h2>
<ul>
<li>哈希表
<ul>
<li>以键-值（key-value）存储数据的结构，只要输入查找值key，就可以找到其对应值Value。把值放在数组里，用一个哈希函数把key换算成一个确定的位置，然后把value放在数组的这个位置。多个key值经过哈希函数的换算，会出现同一个值的情况。哈希冲突，处理方法是拉出一个链表。查找时先用哈希函数把key换算，找到在哈希表的位置，然后顺序遍历链表，找到value。在哈希表中的key不是递增的，好处是增加新value时很快，只需往后追加，因为不是有序的，所以区间查询速度慢，每次要全部扫描。适用于只有等值查询的场景，比如Memcached及其他一些NoSQL引擎。</li>
</ul>
</li>
<li>有序数组
<ul>
<li>在等值查询时，key值按顺序保存，使用二分法就能快速找到key和对应值，时间复杂度是O(log(N)),范围查询时，先用二分查找找到第一个大于最小值的key，然后向右遍历到第一个大于最大值的key，退出循环即可。但是在更新数据的时候，往中间插入一个记录就必须得挪动后面所有的记录，成本太高。只适用于静态存储引擎，比如你要保存的是2017年某个城市的所有人口信息，这类不会再修改的数据。</li>
</ul>
</li>
<li>B树&amp;B+树：
<ul>
<li>B树/B-树/多路平衡查找树 ，B+树是B树的一种变体。B是Balanced(平衡)的意思。</li>
<li>B树的所有节点既存放键(key) 也存放 数据(data)； B+树只有叶子节点存放 key 和 data，其他内节点只存放 key。</li>
<li>B树的叶子节点都是独立的；B+树的叶子节点有一条引用链指向与它相邻的叶子节点。</li>
<li>B树的检索的过程相当于对范围内的每个节点的关键字做二分查找，可能还没有到达叶子节点，检索就结束了；B+树的检索效率就很稳定了，任何查找都是从根节点到叶子节点的过程，叶子节点的顺序检索很明显。</li>
</ul>
</li>
</ul>
<h2>11.10. 自增主键使用场景</h2>
<ul>
<li>从性能看，自增主键每次插入一条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂。而有业务逻辑的字段做主键，则往往不容易保证有序插入，这样写数据成本相对较高</li>
<li>从存储空间的角度来看。主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小，自增主键往往占用的空间比较小</li>
<li>什么场景适合用业务字段直接做主键？KV场景，当只有一个唯一索引，此时业务字段直接做主键，由于没有其他索引，所以也就不用考虑其他索引的叶子节点大小。考虑到“尽量使用主键查询”原则，直接将这个索引设置为主键，可以避免每次查询需要搜索两棵树</li>
</ul>
<h1>12. MySQL事务</h1>
<ul>
<li>事务：一个事务中多次操作要么全部成功，要么全部失败</li>
<li>在MySQL中，事务支持是在引擎层实现的。</li>
<li>MySQL 支持对 MyISAM 和 MEMORY 存储引擎的表进行表级锁定，对 BDB 存储引擎的表进行页级锁定，对 InnoDB 存储引擎的表进行行级锁定。默认情况下，表锁和行锁都是自动获得的，不需要额外的命令。但是有时用户需要明确地进行锁表或者进行事务的控制，以便确保整个事务的完整性，这样就需要使用事务控制和锁定语句来完成。</li>
</ul>
<h2>12.1. 事务隔离级别</h2>
<ul>
<li>
<p>V1、V2、V3的返回值分别是什么?</p>
<ul>
<li>读未提交，V1=V2=V3=2</li>
<li>读提交，V1=1,V2=2。事务B的更新在提交后才能被A看到。所以，V3=2。</li>
<li>可重复读，V1=V2=1，V3=2。V2=1是因为事务在执行期间看到的数据前后必须一致</li>
<li>串行化，在事务B执行“将1改成2”的时候，会被锁住。直到事务A提交后，事务B才可以继续执行。从A的角度看，V1=V2=1，V3=2<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/26a9f40cfc3a646324c43.png" alt="事务隔离级别.png"></li>
</ul>
</li>
<li>
<p>什么时候需要“可重复读”的场景呢？</p>
</li>
<li>
<p>数据校对逻辑的案例。假设你在管理一个个人银行账户表。一个表存了每个月月底的余额，一个表存了账单明细。这时候你要做数据校对，也就是判断上个月的余额和当前余额的差额，是否与本月的账单明细一致。你一定希望在校对过程中，即使有用户发生了一笔新的交易，也不影响你的校对结果。这时候使用“可重复读”隔离级别就很方便。事务启动时的视图可以认为是静态的，不受其他事务更新的影响</p>
</li>
<li>
<p>为什么表结构不支持“可重复读”？这是因为表结构没有对应的行数据，也没有rowtrx_id，因此只能遵循当前读的逻辑</p>
</li>
<li>
<p>可重复读也可避免幻读，使用行X锁（SELECT ... FOR UPDATE，约等于SERIALIZABLE），即便当前记录id不存在，当前事务也会获得一把记录锁（因为InnoDB的行锁锁定的是索引，存在就加行X锁，否则加 next-key lock间隙X锁），其他事务则无法插入此索引的记录，故杜绝了幻读。</p>
</li>
</ul>
<h2>12.2. 查看事务隔离级别</h2>
<ul>
<li>Oracle数据库的默认隔离级别其实就是“读提交”，因此对于从Oracle迁移到MySQL的应用，一定要将MySQL的隔离级别设置为“读提交”。即启动参数transaction-isolation的值设置成READ-COMMITTED。</li>
<li>show variables like 'transaction_isolation'</li>
</ul>
<h2>12.3. 事务隔离级别的实现</h2>
<h3>12.3.1. 锁</h3>
<ul>
<li>在读取数据前，对其加锁，阻止其他事务对数据进行修改。</li>
</ul>
<h3>12.3.2. MVCC</h3>
<ul>
<li>不用加任何锁，非阻塞并发读，通过一定机制生成一个数据请求时间点的一致性数据快照（Snapshot)，并用这个快照来提供一定级别（语句级或事务级）的一致性读取。从用户的角度来看，好象是数据库可以提供同一数据的多个版本，因此，这种技术叫做数据多版本并发控制/多版本数据库（MultiVersion Concurrency Control，简称 MVCC 或MCC）</li>
<li>是一种用来解决读-写冲突的无锁并发控制，也就是为事务分配单向增长的时间戳，为每个修改保存一个版本，版本与事务时间戳关联，读操作只读该事务开始前的数据库的快照。 这样在读操作不用阻塞写操作，写操作不用阻塞读操作的同时，避免了脏读和不可重复读。</li>
</ul>
<h4>12.3.2.1. 快照读</h4>
<ul>
<li>在可重复读级别下，不加锁的select操作就是快照读，即不加锁的非阻塞读；基于提高并发性能的考虑，快照读的实现是基于多版本并发控制MVCC,在很多情况下，避免了加锁操作，降低了开销；既然是基于多版本，即快照读可能读到的并不一定是数据的最新版本，而有可能是之前的历史版本</li>
<li>串行化隔离级别下，快照读会退化为当前读。</li>
</ul>
<h4>12.3.2.2. 当前读（current read）</h4>
<ul>
<li>当前读（current read）读已经提交完成的最新版本,包括update，insert，delete语句、select * from t where id = 1 [lock in share mode/for update]</li>
</ul>
<h4>12.3.2.3. MVCC的实现</h4>
<ul>
<li>InnoDB使用一致性读视图consistent read view，undo log，隐藏字段，实现MVCC（多版本并发控制）/事务隔离。在内部实现中，InnoDB 通过数据行的 DB_TRX_ID 和 Read View 来判断数据的可见性。如不可见，则通过数据行的 DB_ROLL_PTR 找到 undo log 中的历史版本。每个事务读到的数据版本可能是不一样的，在同一个事务中，用户只能看到该事务创建 Read View 之前已经提交的修改和该事务本身做的修改。</li>
<li>InnoDB每个事务都有自增的唯一的事务ID即transaction id。每次事务更新数据的时候，都会生成一个新的数据版本，并且把transaction id赋值给这个数据版本，记为rowtrx_id。数据表中的一行记录，其实可能有多个版本，每个版本有自己的rowtrx_id。其中，多个版本的数据记录在undolog 。事务读取数据时需要根据当前版本和undo log计算出来值。</li>
<li>undo log
<ul>
<li>当读取记录时，若该记录被其他事务占用或当前版本对该事务不可见，则可以通过 undo log 读取之前的版本数据，以此实现快照读</li>
<li>insert undo log在insert 操作中产生。只对事务本身可见【只在事务回滚时需要】故该可以在事务提交后直接删除。不需要进行 purge 操作</li>
<li>update undo log update 或 delete 操作中产生。需要提供MVCC机制，因此不能在事务提交时就进行删除。提交时放入undo log链表，等待purge线程进行最后的删除。</li>
<li>当系统里没有比这个回滚日志更早的read-view的时候。回滚日志会被删除</li>
</ul>
</li>
<li>版本链：类似一个链表，通过回滚指针DB_ROLL_PTR，串联起来。链表头部是最新的数据，尾部是最旧的记录</li>
</ul>
<h2>12.4. 如何解决幻读？</h2>
<ul>
<li>产生幻读的原因是行锁只能锁住行，不能锁住插入新纪录行。只好引入间隙锁(Gap Lock)。锁的就是两个值之间的空隙</li>
<li>执行 select * from t where d=5 for update的时候，不仅将给行加上了行锁，还给行两边的空隙加上了间隙锁。跟间隙锁存在冲突关系的，是“往这个间隙中插入一个记录”这个操作。间隙锁之间都不存在冲突关系。</li>
<li>间隙锁和行锁合称next-key lock，间隙锁记为开区间，把next-key lock记为前开后闭区间。 InnoDB给每个索引加了一个不存在的最大值supremum，这样才符合“都是前开后闭区间”。</li>
<li>间隙锁的引入，可能会导致同样的语句锁住更大的范围，这其实是影响了并发度的</li>
<li>间隙锁是在可重复读隔离级别下才会生效的。也可以使用读提交隔离级别加binlog_format=row的组合</li>
</ul>
<h2>12.5. 事务管理</h2>
<h3>12.5.1. MyISAM事务管理</h3>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code># LOCK TABLES可以锁定用于当前线程的表。如果表被其他线程锁定，则当前线程会等待，直到可以获取所有锁定为止。
# UNLOCK TABLES可以释放当前线程获得的任何锁定。当前线程执行另一个LOCK TABLES时，或当与服务器的连接被关闭时，所有由当前线程锁定的表被隐含地解锁
mysql&gt; LOCK TABLES tbl_name [AS alias] {READ [LOCAL] | [LOW_PRIORITY] WRITE} [, tbl_name [AS alias] {READ [LOCAL] | [LOW_PRIORITY] WRITE}] ...
mysql&gt; UNLOCK TABLES
</code></pre></div><h3>12.5.2. InnoDB事务管理</h3>
<ul>
<li>在同一个事务中，最好不使用不同存储引擎的表，否则 ROLLBACK 时需要对非事务类型的表进行特别的处理，因为 COMMIT、ROLLBACK 只能对事务类型的表进行提交和回滚。</li>
<li>所有的 DDL 语句是不能回滚的，并且部分的 DDL 语句会造成隐式的提交。</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code># MySQL是默认自动提交（Autocommit）的,一条sql语句就是一个事务，如果需要通过明确的Commit和Rollback来提交和回滚事务，那么需要通过明确的事务控制命令来开始事务
# 在第一个操作表的语句时启动事务
# 如果在锁表期间，start transaction会造成一个隐含unlock tables被执行
mysql&gt; START TRANSACTION | BEGIN [WORK] 
# 立即开启事务
mysql&gt; start transaction with consistent snapshot

# 修改当前连接的提交方式，如果设置了0，则事务持续到提交或者回滚或者连接断开
# 如果只是对某些语句需要进行事务控制，则使用 START TRANSACTION 语句开始一个事务比较方便，这样事务结束之后可以自动回到自动提交的方式，如果希望所有的事务都不是自动提交的，那么通过修改 AUTOCOMMIT 来控制事务比较方便，这样不用在每个事务开始的时候再执行 START TRANSACTION 语句。
mysql&gt; SET AUTOCOMMIT = {0 | 1}

# 提交/回滚事务
# CHAIN 和 RELEASE子句分别用来定义在事务提交或者回滚之后的操作，CHAIN会立即启动一个新事物，并且和刚才的事务具有相同的隔离级别，RELEASE则会断开和客户端的连接
mysql&gt; COMMIT/ROLLBACK [WORK] [AND [NO] CHAIN] [[NO] RELEASE] 

# 在事务中可以通过定义SAVEPOINT，指定回滚事务的一个部分，但是不能指定提交事务的一个部分。对于复杂的应用，可以定义多个不同的 SAVEPOINT，满足不同的条件时，回滚不同的SAVEPOINT。如果定义了相同名字的 SAVEPOINT，则后面定义的SAVEPOINT 会覆盖之前的定义。删除后的SAVEPOINT，不能再执行ROLLBACK TO SAVEPOINT命令
mysql&gt; savepoint test;
mysql&gt; rollback to savepoint test;
mysql&gt; RELEASE SAVEPOINT test;
</code></pre></div><h2>12.6. 怎么设计事务连接池？√</h2>
<ul>
<li>事务连接池可以保证同一个事务中多个操作共用一个数据库连接，从而保证了事务的一致性和隔离性。</li>
<li>事务连接池会在第一个操作开始时获取数据库连接，并将该连接与当前线程绑定，之后的所有操作都会使用该连接，直到事务结束时才将连接释放。这样就可以保证同一个事务中的所有操作都使用同一个连接</li>
<li>事务连接池在实现上需要考虑线程安全、事务嵌套等问题，因此比传统连接池更加复杂和高级。一些流行的Java框架和中间件，如Spring和Hibernate，都提供了事务连接池的实现。</li>
</ul>
<h2>12.7. 为什么建议你尽量不要使用长事务?如何避免长事务对业务的影响？</h2>
<ul>
<li>查找持续时间超过60s的事务。select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))&gt;60</li>
<li>长事务意味着系统里面会存在很老的事务视图。这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。在MySQL 5.5及以前的版本，回滚日志是跟数据字典一起放在ibdata文件里的，即使长事务最终提交，回滚段被清理，文件也不会变小；</li>
<li>长事务还占用锁资源，也可能拖垮整个库</li>
<li>应用开发端：
<ul>
<li>
<ol>
<li>确认是否使用了set autocommit=0。可通过general_log的日志来确认。把它改成1</li>
</ol>
</li>
<li>
<ol start="2">
<li>确认是否有不必要的只读事务。有些框架会习惯不管什么语句先用begin/commit框起来。</li>
</ol>
</li>
<li>
<ol start="3">
<li>业务连接数据库的时候，根据业务本身的预估，通过SETMAX_EXECUTION_TIME来控制每个语句执行的最长时间，避免单个语句执行太长时间</li>
</ol>
</li>
</ul>
</li>
<li>数据库端：
<ul>
<li>
<ol>
<li>监控 information_schema.Innodb_trx表，设置长事务阈值，超过就报警/或者kill；</li>
</ol>
</li>
<li>
<ol start="2">
<li>Percona的pt-kill这个工具不错，推荐使用；</li>
</ol>
</li>
<li>
<ol start="3">
<li>在业务功能测试阶段要求输出所有的general_log，分析日志行为提前发现问题；</li>
</ol>
</li>
<li>
<ol start="4">
<li>MySQL 5.6或者更新版本，把innodb_undo_tablespaces设置成2（或更大值）如果出现大事务导致回滚段过大，这样设置后清理起来更方便</li>
</ol>
</li>
</ul>
</li>
</ul>
<h2>12.8. 分布式事务的使用</h2>
<h3>12.8.1. 分布式事务的原理</h3>
<ul>
<li>MySQL中使用分布式事务的应用程序涉及一个或多个资源管理器和一个事务管理器
<ul>
<li>资源管理器（RM）用于提供通向事务资源的途径。数据库服务器是一种资源管理器。该管理器必须可以提交或回滚由RM 管理的事务</li>
<li>事务管理器（TM）用于协调作为一个分布式事务一部分的事务。TM与管理每个事务的RMS进行通讯。一个分布式事务中各个单个事务均是分布式事务的“分支事务”。分布式事务和各分支通过一种命名方法进行标识</li>
</ul>
</li>
<li>MySQL相当于一个用于管理分布式事务中的 XA 事务的资源管理器。与 MySQL 服务器连接的客户端相当于事务管理器</li>
<li>要执行一个分布式事务，必须知道这个分布式事务涉及到了哪些资源管理器，并且把每个资源管理器的事务执行到事务可以被提交或回滚时。根据每个资源管理器报告的有关执行情况的内容，这些分支事务必须作为一个原子性操作全部提交或回滚。要管理一个分布式事务，必须要考虑任何组件或连接网络可能会故障。</li>
<li>用于执行分布式事务的过程使用两阶段提交，发生时间在由分布式事务的各个分支需要进行的行动已经被执行之后。
<ul>
<li>在第一阶段，所有的分支被预备好。它们被TM告知要准备提交。这意味着用于管理分支的每个RM会记录对于被稳定保存的分支的行动。分支指示是否它们可以这么做。这些结果被用于第二阶段。</li>
<li>在第二阶段，TM告知RMS是否要提交或回滚。如果在预备分支时，所有的分支指示它们将能够提交，则所有的分支被告知要提交。如果在预备时，有任何分支指示它将不能提交，则所有分支被告知回滚。在有些情况下，一个分布式事务可能会使用一阶段提交。例如，当一个事务管理器发现，一个分布式事务只由一个事务资源组成（即单一分支），则该资源可以被告知同时进行预备和提交。</li>
</ul>
</li>
</ul>
<h3>12.8.2. 分布式事务语法</h3>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code># 启动XA事务。xid是一个XA事务标识符，用来唯一标识一个分布式事务。xid值由客户端提供，或由MySQL服务器生成
# xid 值包含 1～3 个部分：gtrid [, bqual [, formatID ]]
# gtrid分布式事务标识符，相同的分布式事务应该使用相同的gtrid，表示xa事务属于哪个分布式事务
# bqual分支限定符，默认值是空串。对于一个分布式事务中的每个分支事务，bqual值必须唯一
# formatID 是一个数字，用于标识由 gtrid 和 bqual 值使用的格式，默认值是1
mysql&gt; XA {START|BEGIN} xid [JOIN|RESUME] 

# 标识XA事务，然后使事务进入 PREPARE 状态，两阶段提交的第一个提交阶段。
mysql&gt; XA END xid [SUSPEND [FOR MIGRATE]]
mysql&gt; XA PREPARE xid

# 提交或者回滚具体的分支事务。两阶段提交的第二个提交阶段，分支事务被实际的提交或者回滚
mysql&gt; XA COMMIT xid [ONE PHASE]
mysql&gt; XA ROLLBACK xid

# 返回当前数据库中处于PREPARE状态的分支事务的详细信息
mysql&gt; XA RECOVER 
</code></pre></div><h3>12.8.3. 分布式事务存在的问题</h3>
<ul>
<li>分布式的关键在于如何确保分布式事务的完整性，以及在某个分支出现问题时的故障解决。</li>
<li>如果分支事务在达到 prepare 状态时，数据库异常重新启动，服务器重新启动以后，可以继续对分支事务进行提交或者回滚得操作，但是提交的事务没有写 binlog，存在一定的隐患，可能导致使用 binlog 恢复丢失部分数据。如果存在复制的数据库，则有可能导致主从数据库的数据不一致</li>
<li>如果分支事务的客户端连接异常中止，那么数据库会自动回滚未完成的分支事务，如果此时分支事务已经执行到 prepare 状态，那么这个分布式事务的其他分支可能已经成功提交，如果这个分支回滚，可能导致分布式事务的不完整，丢失部分分支事务的内容。</li>
<li>如果分支事务在执行到 prepare 状态时，数据库异常，且不能再正常启动，需要使用备份和 binlog 来恢复数据，那么那些在 prepare 状态的分支事务因为并没有记录到 binlog，所以不能通过 binlog 进行恢复，在数据库恢复后，将丢失这部分的数据。</li>
</ul>
<h1>13. MYSQL锁</h1>
<ul>
<li>MyISAM和MEMORY存储引擎采用的是表级锁（table-level locking），同一张表上任何时刻只能有一个更新在执行，影响业务并发度</li>
<li>BDB存储引擎采用的是页面锁（page-level locking）</li>
<li>InnoDB存储引擎默认行级锁（row-level locking），也支持表级锁，但默认采用行级锁</li>
<li>表级锁更适合于以查询为主，只有少量按索引条件更新数据的应用；行级锁则适合于有大量按索引条件并发更新少量不同数据，同时又有并发查询的应用</li>
</ul>
<h2>13.1. 按锁的粒度分类</h2>
<h3>13.1.1. 全局锁</h3>
<ul>
<li>全局锁(FTWRL)是对整个数据库实例加锁。让整个库处于只读状态，使用场景是不支持事务的引擎逻辑备份</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code># 全局锁
mysql&gt; flush tables with read lock 
# 主动释放锁。也可以在客户端断开的时候自动释放
mysql&gt; unlock tables
</code></pre></div><h3>13.1.2. 表级锁</h3>
<h4>13.1.2.1. 元数据锁MDL(meta data lock)</h4>
<ul>
<li>在访问一个表的时候会被自动加上。为了保证读写的正确性。当对一个表做增删改查操作的时候，加MDL读锁；当要对表做结构变更操作的时候，加MDL写锁。读锁之间不互斥，读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行</li>
<li>事务中的MDL锁在语句执行是申请，事务提交时才释放</li>
</ul>
<h4>13.1.2.2. MyISAM表锁</h4>
<ul>
<li>MyISAM 存储引擎只支持表锁</li>
<li>查询表级锁争用情况show status like 'table%'，如果Table_locks_waited值比较高，则存在着较严重的表级锁争用情况</li>
<li>表级锁的锁模式包括：表共享读锁（Table Read Lock）和表独占写锁（Table Write Lock）。读操作与写操作之间，以及写操作之间是串行的！读读操作是并行的</li>
<li>lock table 表名 write/read [local];使用unlock tables或者客户端断开的时候释放。别的线程的会被阻塞，local表示在满足 MyISAM 表并发插入条件的情况下，允许其他用户在表尾并发插入记录</li>
<li>MyISAM 在执行查询语句（SELECT）前，会自动给涉及的所有表加读锁，在执行更新操作（UPDATE、DELETE、INSERT 等）前，会自动给涉及的表加写锁，用户一般不需要直接用 LOCK TABLE 命令给 MyISAM 表显式加锁。显示加锁一般是为了事务，实现对某一时间点多个表的一致性读取</li>
<li>在用 LOCK TABLES 给表显式加表锁时，必须同时取得所有涉及到表的锁，在执行 LOCK TABLES 后，只能访问显式加锁的这些表，不能访问未加锁的表；同时，如果加的是读锁，那么只能执行查询操作，而不能执行更新操作。其实，在自动加锁的情况下也基本如此，MyISAM 总是一次获得 SQL 语句所需要的全部锁。因此不会出现死锁（Deadlock Free）。当使用 LOCK TABLES 时，不仅需要一次锁定用到的所有表，且同一个表在SQL语句中出现多少次，就要通过与SQL语句中相同的别名锁定多少次，否则也会出错！</li>
<li>并发插入（Concurrent Inserts）
<ul>
<li>系统变量concurrent_insert控制MyISAM存储引擎并发插入,
<ul>
<li>0/NEVER则不允许并发插入。</li>
<li>1/AUTO 如果MyISAM表中没有空洞（即表的中间没有被删除的行），MyISAM允许在一个进程读表的同时，另一个进程从表尾插入记录。默认</li>
<li>2/ALWAYS ，无论MyISAM表中有没有空洞，都允许在表尾并发插入记录</li>
</ul>
</li>
<li>可以利用MyISAM存储引擎的并发插入特性，来解决应用中对同一表查询和插入的锁争用。例如设为2，总是允许并发插入；同时，通过定期在系统空闲时段执行OPTIMIZE TABLE语句来整理空间碎片，收回因删除记录而产生的中间空洞</li>
</ul>
</li>
<li>MyISAM锁调度
<ul>
<li>写优先调度机制：进程同时请求读锁和写锁，写进程先获得锁；即使读请求先到锁等待队列，写请求后到，写锁也会插到读锁请求之前！MySQL认为写请求一般比读请求要重要。因此MyISAM 表不太适合于有大量更新操作和查询操作应用，因为，大量的更新操作会造成查询操作很难获得读锁，从而可能永远阻塞。</li>
<li>通过指定启动参数low-priority-updates，使MyISAM引擎默认给予读请求以优先的权利。</li>
<li>通过执行命令SET LOW_PRIORITY_UPDATES=1，使该连接发出的更新请求优先级降低。</li>
<li>通过指定INSERT、UPDATE、DELETE语句的LOW_PRIORITY属性，降低该语句的优先级。</li>
<li>系统参数max_write_lock_count设置一个合适的值，当一个表的读锁达到这个值后，MySQL就暂时将写请求的优先级降低，给读进程一定获得锁的机会。</li>
</ul>
</li>
<li>一些需要长时间运行的查询操作，也会使写进程“饿死”！因此，应用中应尽量避免出现长时间运行的查询操作，不要总想用一条SELECT语句来解决问题，因为这种看似巧妙的SQL语句，往往比较复杂，执行时间较长，在可能的情况下可以通过使用中间表等措施对SQL语句做一定的“分解”，使每一步查询都能在较短时间完成，从而减少锁冲突。如果复杂查询不可避免，应尽量安排在数据库空闲时段执行，比如一些定期统计可以安排在夜间执行。</li>
</ul>
<h4>13.1.2.3. InnoDB什么时候使用表锁</h4>
<ul>
<li>情况1：事务需要更新大表大量数据，如果使用默认的行锁，事务执行效率低，可能造成其他事务长时间锁等待和锁冲突</li>
<li>情况2：事务涉及多个表，可能引起死锁，造成大量事务回滚。可以考虑一次性锁定事务涉及的表</li>
<li>InnoDB使用表锁注意点
<ul>
<li>LOCK TABLES给InnoDB加表级锁，由Server层负责，仅当autocommit=0、innodb_table_locks=1（默认）时，InnoDB才会给MySQL加的表锁，Server层也才能感知InnoDB加的行锁，InnoDB才能自动识别涉及表级锁的死锁；否则，InnoDB将无法自动检测并处理这种死锁</li>
<li>事务结束前，不要用UNLOCK TABLES释放表锁，因为会隐含地提交事务；COMMIT或ROLLBACK并不能释放用LOCK TABLES 加的表级锁，必须用UNLOCK TABLES释放</li>
</ul>
</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code># 写表 t1 并从表 t 读
SET AUTOCOMMIT=0;
LOCK TABLES t1 WRITE, t2 READ, ...;
[do something with tables t1 and t2 here];
COMMIT;
UNLOCK TABLES;
</code></pre></div><h3>13.1.3. InnoDB行锁</h3>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code># 查看InnoDB行锁争用情况（如 InnoDB_row_lock_waits 和 InnoDB_row_lock_time_avg）
mysql&gt; show status like 'innodb_row_lock%';
# 如果发现锁争用比较严重，可通过设置InnoDB Monitors来进一步观察发生锁冲突的表、数据行等，并分析锁争用的原因
# 设置监视器
CREATE TABLE innodb_monitor(a INT) ENGINE=INNODB;
# 查看监视器
show engine innodb status;
# 关闭监视器
DROP TABLE innodb_monitor;
# 设置监视器后，在 SHOW INNODB STATUS 的显示内容中，会有详细的当前锁等待的信息，包括表名、锁类型、锁定记录的情况等，便于进行进一步的分析和问题的确定。打开监视器以后，默认情况下每 15 秒会向日志中记录监控的内容，如果长时间打开会导致.err 文件变得非常的巨大，所以用户在确认问题原因之后，要记得删除监控表以关闭监视器
</code></pre></div><ul>
<li>两阶段锁协议：在InnoDB事务中，行锁是在需要的时候才加上的，等到事务结束时才释放。</li>
<li>如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放</li>
<li>服务器CPU消耗接近100%，但整个数据库每秒就执行不到100个事务。这是什么原因呢？可能是死锁了</li>
</ul>
<h4>13.1.3.1. InnoDB 行锁实现方式</h4>
<ul>
<li>InnoDB行锁是通过给索引对应的记录所要索引值加锁来实现的，Oracle是通过在数据块中对相应数据行加锁来实现的</li>
<li>InnoDB行锁在不通过索引条件查询的时候，使用的是表锁</li>
<li>是否使用索引来检索数据是由 MySQL 通过判断不同执行计划的代价来决定的。如果 MySQL 认为全表扫描效率更高，比如对一些很小的表，它就不会使用索引，InnoDB将使用表锁</li>
</ul>
<h2>13.2. 按锁的类型分类</h2>
<h3>13.2.1. 读写锁(行锁模式)</h3>
<ul>
<li>共享锁(S)/读锁：事务在读取记录的时候获取共享锁，允许多个事务同时获取。SELECT * FROM 表名 WHERE条件 LOCK IN SHARE MODE</li>
<li>排他锁(X)/写锁：事务在修改记录的时候获取排他锁，不允许多个事务同时获取。SELECT * FROM 表名 WHERE条件 FOR UPDATE</li>
<li>共享锁主要用在需要数据依存关系时来确认某行记录是否存在，并确保没有其他事务对这个记录进行UPDATE或者DELETE操作。但是如果当前事务也需要对该记录进行更新操作，则很有可能造成死锁，对于锁定行记录后需要进行更新操作的应用，应该使用 SELECT... FOR UPDATE 方式获得排他锁</li>
</ul>
<h3>13.2.2. 意向锁(表锁模式)</h3>
<ul>
<li>根据表中的记录没有行锁并快速判断是否可以对某个表使用表锁。</li>
<li>意向共享锁(Intention Shared Lock,IS)事务打算给数据行加行共享锁(S锁)，加共享锁前必须先取得该表的IS锁</li>
<li>意向排他锁(Intention Exclusive Lock，IX)事务打算给数据行加行排他锁(x锁)，加排他锁前必须先取得该表的IX锁</li>
<li>意向锁是InnoDB自动加的，无法手动操作，在为数据行加共享/排他锁之前，InooDB会先获取该数据行所在在数据表的对应意向锁</li>
</ul>
<h3>13.2.3. 读写锁与意向锁兼容性</h3>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/68a4a42572c418a19750a.png" alt="MYSQL行锁兼容性.PNG" tabindex="0"><figcaption>MYSQL行锁兼容性.PNG</figcaption></figure>
<ul>
<li>X与任何锁冲突，IX与S冲突，其他都兼容</li>
</ul>
<h2>13.3. InnoDB中行锁定的方式</h2>
<h3>13.3.1. 记录锁（Record Lock）</h3>
<h3>13.3.2. 间隙锁（Gap Lock）</h3>
<h3>13.3.3. 临键锁（Next-Key 锁）</h3>
<ul>
<li>使用用范围条件而不是相等条件检索数据并请求共享或排他锁时，InnoDB会给符合条件的已有数据记录的索引项加锁；也会对键值在条件范围内但并不存在的记录，叫做“间隙(GAP)”，加锁，这种锁机制就是间隙锁（Next-Key锁）</li>
<li>间隙锁的目的，为了防止幻读，以满足相关隔离级别的要求，也为了满足其恢复和复制的需要。</li>
<li>在使用范围条件检索并锁定记录时，InnoDB 这种加锁机制会阻塞符合条件范围内键值的并发插入，往往会造成严重的锁等待。因此，应用开发要尽量优化业务逻辑，尽量使用相等条件来访问更新数据，避免使用范围条件</li>
<li>如果使用相等条件请求给一个不存在的记录加锁，InnoDB也会使用间隙锁！</li>
<li>一个空表只有一个间隙，比如select * from t where id&gt;0 for update;加锁的范围就是next-key lock (-∞, supremum]</li>
</ul>
<h3>13.3.4. 加锁规则</h3>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code># 开启锁监视器
SET GLOBAL innodb_status_output=ON;
SET GLOBAL innodb_status_output_locks=ON;
</code></pre></div><ul>
<li>可重复读隔离级别(repeatable-read)下。遵守两阶段锁协议，所有加锁的资源，都是在事务提交或者回滚的时候才释放的。加锁的基本单位是next-key lock。前开后闭区间，查找过程中访问到的对象才会加锁（limit限制访问对象也会限制锁的范围）</li>
<li>提交隔离级别(read-committed)下，没有间隙锁</li>
<li>根据完整结果集判断加锁规则（受order by条件,where条件，limit等影响）</li>
<li>等值查询（in也是等值查询）
<ul>
<li>记录不存在都是加(x-1,x+1)Gap-key Lock</li>
<li>记录存在
<ul>
<li>聚簇索引：聚簇索引Record Lock（Next-key Lock降级优化为 Record Lock）</li>
<li>唯一索引：唯一索引Record Lock、聚簇索引Record Lock（都是Next-key Lock降级优化为 Record Lock）</li>
<li>普通索引：普通索引(x-1,x]Next-key Lock、(x,x+1)Gap-key Lock、聚簇索引Record Lock</li>
</ul>
</li>
</ul>
</li>
<li>范围查询
<ul>
<li>聚集索引
<ul>
<li>匹配记录加Next-key Lock;：只有&gt;=的等值(=)匹配加Record Lock</li>
<li>对于&lt;和&lt;=：向右扫描直到找到不匹配的索引记录上Next-key Lock.</li>
<li>对于&gt;和&gt;=，会对supremum (上界限伪值) 上Next-key Lock：锁的是聚集索引最大值后面的间隙</li>
</ul>
</li>
<li>唯一索引 和 普通索引：
<ul>
<li>如果走了索引：
<ul>
<li>匹配记录加Next-key Lock，对应的聚集索引上Record Lock;</li>
<li>对于&lt;和&lt;=，向右扫描直到找到不匹配的索引记录上Next-key Lock，对应的聚集索引上Record Lock</li>
<li>对于&gt;和&gt;=，会对supremum (上界限伪值) 上Next-key Lock：锁的是该索引最大值后面的间隙</li>
</ul>
</li>
<li>如果没走索引，那么就会把所有 聚集索引记录和间隙都锁上，就是所谓的锁表，或叫行锁升表锁.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2>13.4. 恢复和复制的需要，对 InnoDB 锁机制的影响</h2>
<ul>
<li>MySQL的恢复机制（复制其实就是在 Slave Mysql 不断做基于 BINLOG 的恢复）有以下特点。
<ul>
<li>MySQL的恢复是重新执行BINLOG中的SQL语句。Oracle是基于数据库文件块的。</li>
<li>MySQL的恢复是按按照事务提交的先后顺序进行的。Oracle的恢复是按系统更新号（System Change Number，SCN）来进行的，每个事务都会分配一个全局唯一的SCN，SCN的顺序与事务开始的时间顺序是一致的</li>
</ul>
</li>
<li>MySQL 的恢复机制要求：在一个事务未提交前，其他并发事务不能插入满足其锁定条件的任何记录，不允许出现幻读，实际上是要求事务要串行化。因此InnoDB要用到间隙锁</li>
<li>对于insert into target_tab select * from source_tab where ...和create table new_tab ...select ... From source_tab where ...(CTAS)语句，InnoDB给source_tab加共享锁，并没有使用多版本数据一致性读技术！为了保证恢复和复制的正确性。不加锁的话，如果在上述语句执行过程中，其他事务对 source_tab 做了更新操作，就可能导致数据恢复的结果错误。因此，INSERT...SELECT...和CREATE TABLE...SELECT...语句，可能会阻止对源表的并发更新，造成对源表锁的等待。如果查询比较复杂的话，会造成严重的性能问题，我们在应用中应尽量避免使用。实际上，MySQL将这种SQL叫作不确定（non-deterministic）的SQL，不推荐使用。</li>
<li>如果应用中一定要用这种 SQL 来实现业务逻辑，又不希望对源表的并发更新产生影响，可通过使用“select * from source_tab ... Into outfile”和“load data infile ...”语句组合来间接实现</li>
</ul>
<h1>14. MYSQL日志</h1>
<ul>
<li>WAL技术(Write-Ahead Logging)：先顺序写日志，再写磁盘.尽量减少随机读写。为了解决MySQL里如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程IO成本很高的问题</li>
</ul>
<h2>14.1. 日志分类</h2>
<h3>14.1.1. mysql配置文件</h3>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code># 搜索mysql配置文件位置 
shell&gt; mysql --help | grep 'Default options' -A 1
Default options are read from the following files in the given order:
/etc/my.cnf /etc/mysql/my.cnf /usr/etc/my.cnf ~/.my.cnf
</code></pre></div><h3>14.1.2. 错误日志</h3>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code># 用--log-error[=file_name]选项启动
shell&gt; $(which mysqld_safe) --log-error=/var/log/newlog.log &amp;

# 查看错误日志位置-&gt;log_error:/var/log/mysqld.log
mysql&gt; show variables like 'log_error';
</code></pre></div><h3>14.1.3. 二进制日志（BINLOG）</h3>
<ul>
<li>binlog是MySQL的Server层实现的，所有引擎都可以使用。</li>
<li>binlog是逻辑日志，记录语句的原始逻辑，比如“给ID=2这一行的c字段加1”</li>
<li>binlog是可以追加写入的。binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志</li>
<li>为什么会有两份日志呢？因为MyISAM没有crash-safe的能力，binlog日志只能用于归档。所以InnoDB使用另外一套redo log来实现crash-safe能力。</li>
<li>binlog的写入机制：事务执行过程中，先把日志写到binlog cache内存(线程私有)，然后write到page cache，事务提交的时候，fsync持久化到binlog文件中。并清空binlog cache。</li>
<li>binlog_cache_size控制单个线程内binlog cache所占内存的大小。如果超过了，就要暂存到磁盘。</li>
<li>sync_binlog控制write和fsync的时机
<ul>
<li>0表示每次提交事务都只write，不fsync；</li>
<li>1表示每次提交事务都会执行fsync持久化到磁盘。保证MySQL异常重启之后binlog不丢失</li>
<li>大于1表示每次提交事务都write，但累积N个事务后才fsync。主机发生异常重启，会丢失最近N个事务的binlog日志</li>
</ul>
</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code># my.cnf配置或者用--log-bin[=file_name]选项启动
# 配置serverid
server-id=1
# 开启binlog日志
log_bin=ON
# binlog日志的基本文件名
log_bin_basename=/var/lib/mysql/mysql-bin
# binlog文件的索引文件，管理所有binlog文件
log_bin_index=/var/lib/mysql/mysql-bin.index
# 设置日志路径，注意路经需要mysql用户有权限写=上面最后三句
# log-bin = /data/mysql/logs/mysql-bin.log
#设置日志三种格式：STATEMENT、ROW、MIXED 。
binlog_format = mixed
#设置binlog清理时间 临时设置binlog文件保留时长，重启失效set global expire_logs_days=30;
expire_logs_days = 7
#binlog每个日志文件大小 临时设置binlog大小，重启失效set global max_binlog_size = 1024;
max_binlog_size = 100m
#binlog缓存大小
binlog_cache_size = 4m
#最大binlog缓存大小
max_binlog_cache_size = 512m

# 重启mysql
1、使用 service 启动：service mysql start
2、使用 mysqld 脚本启动：/etc/inint.d/mysql start
3、使用 safe_mysqld 启动：safe_mysql&amp;
 
1、使用 service 启动：service mysql stop
2、使用 mysqld 脚本启动：/etc/inint.d/mysql stop
3、mysqladmin shutdown
 
1、使用 service 重启：service mysql restart
2、使用 mysqld 脚本重启：/etc/inint.d/mysql restart

# 查看binlog配置
mysql&gt; SHOW VARIABLES LIKE 'log_bin%';

# 查看binlog保留时长
mysql&gt;show variables like 'expire_logs_days';

# 查看binlog文件大小限制
mysql&gt;show variables like 'max_binlog_size';

# 查看日志列表
shell&gt; system ls -ltr /var/lib/mysql/mysql-bin*
# 其中 mysql-bin.index是日志的索引文件，记录了最大的日志序号
mysql&gt; show binary logs;

# 查看binlog内容
shell&gt; mysqlbinlog mysql-bin.000002;
shell&gt; mysqlbinlog --start-datetime="2017-09-17 07:21:09" --stop-datetime="2017-09-19 07:59:50" mysql-bin.000002
shell&gt; mysqlbinlog --start-position=205 --stop-position=2205 mysql-bin.000002
shell&gt; mysqlbinlog --no-defaults -d databasename mysql-bin.000002

mysql&gt; show binlog events in 'mysql-bin.000123';
mysql&gt; show master status;

# 删除日志
## 方法1删除所有 BINLOG 日志，新日志编号从“000001”开始
mysql&gt; reset MASTER;
## 方法2删除编号000006之前的日志
mysql&gt;purge master logs to 'mysql-bin.000006';
## 方法3删除日期为“yyyy-mm-dd hh24:mi:ss”之前产生的所有日志
mysql&gt; purge master logs before '2007-08-10 04:07:00';
## 方法4设置参数--expire_logs_days=#，过了指定的天数后日志将会被自动删除
在 my.cnf 的[mysqld]中加入“expire_logs_day=3”
将系统时间改为 3 天以后
shell&gt; date -s '20071226 14:00:00'
show variables like 'expire_logs_days'; # 查看过期时间
set global expire_logs_days = 30; # 设置过期时间
# 触发日志文件更新
mysql&gt; flush logs

# 修改配置后刷新日志文件
mysql&gt;flush logs

# 其他选项
--binlog-do-db=db_name只记录指定数据库的binlog
--binlog-ignore-db=db_name忽略指定数据库的binlog
--innodb-safe-binlog和--sync-binlog＝N（每写 N 次日志同步磁盘）配合使用，使得事务在日志中的记录更加安全

</code></pre></div><h4>14.1.3.1. binlog日志格式</h4>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code># 当binlog_format=statement时，记录的是SQL原文,减少了日志量，节约了IO，提高性能。此时某些sql会产生warning，因为有可能产生主备不一致的情况，即在主数据库与在从数据库使用的索引不一样导致数据不一致的问题
# 使用以下函数的语句也无法被复制：
- LOAD_FILE()
- UUID()
- USER()
- FOUND_ROWS()
- SYSDATE() (除非启动时启用了 --sysdate-is-now 选项)
- 在 INSERT ...SELECT 会产生比 RBR 更多的行级锁 。
# 当binlog_format=statement时，insert into t values(10,10, now());如果这个binlog过了1分钟才传给备库的话，那主备的数据不就不一致了吗？原来binlog在记录event的时候，多记了一条命令：SET TIMESTAMP=1546103491。约定了接下来的now()函数的返回时间。因此值是固定的。确保了主备数据的一致性
mysql&gt; delete from t /*comment*/ where a&gt;=4 and t_modified&lt;='2018-11-10' limit 1;
mysql&gt; show binlog events in 'master.000001';
+</code></pre></div>]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/5eb3564ceca7b636f4065.png" type="image/png"/>
    </item>
    <item>
      <title>oracle</title>
      <link>https://javaguide.cn/backend/database/oracle.html</link>
      <guid>https://javaguide.cn/backend/database/oracle.html</guid>
      <source url="https://javaguide.cn/rss.xml">oracle</source>
      <description>oralce:大型数据库 oracle 10g 单表查询 select: condition order by group by group by增强 函数：简化操作 单行函数 字符函数 大小写控制函数 字符控制函数 数值函数 日期函数 转换函数 oracle转换函数.png select to_char(sysdate,&amp;apos;yyyy-mm-dd hh2...</description>
      <category>数据库</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>oralce:大型数据库</p>
<!--more-->
<h2>oracle 10g</h2>
<h3>单表查询</h3>
<pre><code>select *|[distinct] colum|expression|function() [as][alias](s)]
	from table[alias](s)|dual
	[where condition(s)]
	[group by column(s)]
	[having condition(s)] 
	[order by column|number|alias|expression 
	[asc|desc] [nulls first|nulls last](s)];
</code></pre>
<h4>select:</h4>
<pre><code>distinct作用与后面所有的列，所有列相同的才会去掉
	alias有特殊符号或者关键字(数字汉字)就要加双引号(pl/sql就不用)，单引号表示日期和字符
	select * from emp;
	select empno,ename,job,mgr,hiredate,sal,comm,deptno from emp;
	select empno as "员工号",ename,sal "月 薪",
	sal*12,comm,sal*12+nvl(comm,0) from emp
	select distinct deptno from emp;
	select distinct deptno,job from emp;
	select ename,sal*12 from emp;
	select ename,sal*12 income,sal*12+comm from emp;
</code></pre>
<h4>condition</h4>
<pre><code>where 中的字母是区分大小写，日期格式必须与数据库一致，默认DD-MON-RR\mysql不区分大小写
	比较运算符=、&lt;&gt;（！=）、&gt;、&gt;=、&lt;=、&lt;、between and （闭区间，小到大、日期也行）
	in（set集合）、not in（set集合）、is null、is not null、like（%、_、日期、\escape）
	lib
	转意字符\紧跟后面的一个按本身，不按特殊字符、   
	select *from emp where ename like '%\_%' escape '\'；
	逻辑运算符
	and（两个考虑between and）、or （多个or考虑in）、not（不大于：not（sal&gt;1500））
	例子
	select * from emp where sal between 1500 and 3000
	select * from emp where sal &gt;1500 and sal&lt;3000
	select * from emp where hiredate bettweeen '1-1月-1981' and '31-12月-1981' 
	select * from emp where empno in (7396,7499,7521)
	select * from emp where ename in('SMITH','ALLEN','WARD')
	select * from emp where comm is not null
	select * from emp where comm is null
	select * from emp where deptno not in (10,20)
	select * from emp where empno=7396 or empno=7499 or empno=7521;
	select * from emp where deptno=10;
	select * from emp where ename='KING'
	select * from emp where ename='King'
	select * from emp where hiredate='17-11月-81';
	select * from emp where hiredate='1981-11-17'
	select * from emp where empno &lt;&gt; 7396;
	select * from emp where empno != 7396;
	select * from emp where empno like '_M%'
	select * from emp where empno like '%M%'
	select last_name, hire_date from employees where hire_date like '% -94'
	select * from emp where ename like '____'
	select * from emp where comm is not null or sal&gt;1500;
	select * from emp where comm is not null and sal&gt;1500;
	select * from emp where comm is not null and not(sal&gt;1500);
</code></pre>
<h4>order by</h4>
<pre><code>①默认升序asc desc 降序  排序放在最后执行，降序只作用与与他最近的列、
	②nulls First和 null last 调节显示位置
	③作用于后面所有的列，先按第一列升序，相同的按第二列降序排列
	④排序后的结果，是否是原来的表？不是，是临时表
	⑤order by 后面  + 列、表达式、别名、序号（第几列、不能超过列数）
	例子
	select * from emp order by sal asc, hiredate desc;
	select * from emp order by sal desc
	select * from emp order by sal
	select empno,ename,sal,sal*12 from emp order by sal*12 desc;
	select empno,ename,sal,sal*12 年薪  from emp order by 年薪 desc
	select empno,ename,sal,sal*12 年薪  from emp order by 4 desc
	select empno,ename,sal,sal*12 年薪 from emp order by 5 desc
	ORDER BY 项必须是 SELECT-list 表达式的数目 
	select * from emp  order by deptno,sal;
	select *  from emp order by deptno,sal desc
	select sal from emp order by sal*12
	select * from emp order by sal nulls first;
	select * from emp order by sal nulls last;
</code></pre>
<h4>group by</h4>
<pre><code>①分组函数只能查出group by 分组条件字段和分组函数的值，不能有其他字段
	不使用group by 只可以查询出来分组函数的值
	②存在于select表中，而未被组函数包含的所有的列都要包含在group by中，
	包含在groupby子句中的列不必包含在select中
	③过滤分组函数的值having 与where的区别，where后面不能有组函数
	④多个列的分组: 先按照第一个列分组，如果相同，再第二个列分组，以此类推
	例子
	select deptno,avg(sal) from emp group by deptno having avg(sal)&gt;2000
	select deptno,avg(sal) from emp  where deptno=10 group by deptno
	select deptno,avg(sal)  from emp  group by deptno  having deptno=10;
	select deptno,job,sum(sal)  from emp group by deptno,job  order by 1;
	select deptno，count（ename）,avg(sal)  from emp group by deptno
</code></pre>
<h4>group by增强</h4>
<pre><code>SQL&gt; group by 的增强oracle才行，做报表
	SQL&gt; select deptno,job,sum(sal) from emp group by deptno,job
	SQL&gt; +
	SQL&gt; select deptno,sum(sal) from emp group by deptno
	SQL&gt; +
	SQL&gt; select sum(sal) from emp
	SQL&gt; 
	SQL&gt; ====
	SQL&gt; select deptno,job,sum(sal) from emp group by rollup(deptno,job)
	SQL&gt; 抽象
	SQL&gt; group by rollup(a,b)
	SQL&gt; =
	SQL&gt; group by a,b
	SQL&gt; +
	SQL&gt; group by a
	SQL&gt; +
	SQL&gt; 没有group by
	oracle的支持报表功能，break on null，相同的不显示，不同部门号，以deptno为标志，
	分组后隔行显示break on deptno skip 2、select可以通过集合运算相加减
</code></pre>
<h2>函数：简化操作</h2>
<h3>单行函数</h3>
<h4>字符函数</h4>
<h5>大小写控制函数</h5>
<pre><code>select lower('HELLO') ,upper('hello'),initcap('hello') from dual (伪表)
</code></pre>
<h5>字符控制函数</h5>
<pre><code>select concat('hello','World') from dual(伪表)
	select '编号是'  || empno  || '的雇员,姓名是'||ename from emp;
	select substr('Hello World',4) 子串 from dual;lo World  
	select substr('Hello World',4,3) 子串 from dual;lo 
	select length('Hello World') 字符,lengthb('Hello World') 字节 from dual;11、11
	select length('北京') 字符,lengthb('北京') 字节 from dual
	2、4英文字符和字节一样，一个汉字两个字节
	select replace('hello','l','x')from dual; hexxo
	select instr('Hello World','ll') 位置 from dual;3
	select lpad('a',1,'*') 左,rpad('abcd',1,'*') 右 from dual;*a a* 左右填充
	select trim('H' from 'Hello WorldH') from dual;ello World 去掉前后指定的字符
	select wm_concat(ename) nameslist from emp group by deptno;  10 CLARK,KING
</code></pre>
<h4>数值函数</h4>
<pre><code>	select round(45.926,2) 一,round(45.926,1) 二,round(45.926,0) 三,
		round(45.926,-1) 四,round(45.926,-2) 五 from dual;
		45.93       45.9         46         50          0   
		select trunc(45.926,2) 一,trunc(45.926,1) 二,trunc(45.926,0) 三,
		trunc(45.926,-1) 四,trunc(45.926,-2) 五 from dual
		45.92       45.9         45         40          0   
		select mod(1600,300) from dual; 100看小数点的位置：向右为正
</code></pre>
<h4>日期函数</h4>
<pre><code>默认含有日期和时间，默认格式DD-MON-RR  mysql date日期、datetime时间
	数学运算：日期加减（没乘除）数字仍为日期，
	日期之差（不加，没意义）为天数（数字）
	天数（数字）可以加减乘除
	select (sysdate-1) 昨天,sysdate 今天,(sysdate+1) 明天 from dual;29-9月 -16 
	select ename,hiredate,(sysdate-hiredate) 天,(sysdate-hiredate)/7 星期,
	(sysdate-hiredate)/30 月,(sysdate-hiredate)/365 年 from emp;
	select to_char(sysdate,'yyyy-mm-dd hh24:mi:ss') from dual;2016-09-29 11:58:32   
	next_day指定日期的 下个日期
	select next_day(sysdate,'礼拜五') from dual 周中的日无效 
	每个星期一自动备份表中的数据 1、分布式数据库，物理上不在一起，逻辑一起的数据库
	2、触发器 快照拷贝数据
	round、trunc
	假设SYSDATE=‘25-JUL-95’
	round(SYSDATE,'MONTH')→01-AUG-95
	round(SYSDATE,'YEAR')→01-JAN-96
	trunc(SYSDATE,'MONTH')→01-JUL-95
	trunc(SYSDATE,'YEAR')→01-JAN-95
	select months_between(sysdate,hiredate),add_months(sysdate,53) ,
	next_day(sysdate,'sunday') ,last_day(sysdate) from emp;计算工龄
</code></pre>
<h4>转换函数</h4>
<pre><code>隐式oracle自动:select * from emp where deptno=10;
	显式:日期转换格式to_char（date，’格式‘）'yyyy-mm-dd'、'fmyyyy-mm-dd'去掉09的0
	可以用来分别取出年、月、日
</code></pre>
<p><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/9988d14146fdb19c78d04.png" alt="oracle转换函数.png"><br>
select to_char(sysdate,'yyyy-mm-dd hh24:mi:ss"今天是"day') from dual;<br>
数字转换格式to_char（number，’格式‘）可以分别取出各个位置的位数	<br>
L本地货币符号，.小数点，千位符$美元符0零9数字<br>
select to_char(sal,'L9,999.99') from emp;￥800.00<br>
字符转换为数字to_number(char[,'格式'])<br>
字符转换成日期to_date(char[,'格式''])</p>
<h4>通用函数:适用于任何数据类型包括null</h4>
<pre><code>nvl（e1,e2）、nvl2（a,b,c）、nullif（a,b）、coalesce（e1,e2）
	nvl2的非null为b，null为c nullif两个表达式相同返回null，否则返回a
	select sal*12+nvl2(comm,comm,0) from emp;
	select nullif('abc','abc') 值 from dual;	
	select comm,sal,coalesce(comm,sal) "第一个不为null的值" from emp;
		  COMM        SAL 第一个不为null的值                                        
</code></pre>
]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/9988d14146fdb19c78d04.png" type="image/png"/>
    </item>
    <item>
      <title>redis</title>
      <link>https://javaguide.cn/backend/database/redis.html</link>
      <guid>https://javaguide.cn/backend/database/redis.html</guid>
      <source url="https://javaguide.cn/rss.xml">redis</source>
      <description>1. NoSQL介绍 2. NoSQL产生原因 3. NoSQL的特点 4. redis介绍 5. Redis数据库 6. 消息订阅与发布 7. 事务 8. 安装与启动 9. jedis的操作 10. redis单机安装 11. Redis集群的搭建 12. java连接则用jedis 1. NoSQL介绍 关系型数据库是基于关系表的数据库，最终会将数...</description>
      <category>后端</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<!-- TOC -->
<ul>
<li><a href="#1-nosql%E4%BB%8B%E7%BB%8D">1. NoSQL介绍</a></li>
<li><a href="#2-nosql%E4%BA%A7%E7%94%9F%E5%8E%9F%E5%9B%A0">2. NoSQL产生原因</a></li>
<li><a href="#3-nosql%E7%9A%84%E7%89%B9%E7%82%B9">3. NoSQL的特点</a></li>
<li><a href="#4-redis%E4%BB%8B%E7%BB%8D">4. redis介绍</a></li>
<li><a href="#5-redis%E6%95%B0%E6%8D%AE%E5%BA%93">5. Redis数据库</a></li>
<li><a href="#6-%E6%B6%88%E6%81%AF%E8%AE%A2%E9%98%85%E4%B8%8E%E5%8F%91%E5%B8%83">6. 消息订阅与发布</a></li>
<li><a href="#7-%E4%BA%8B%E5%8A%A1">7. 事务</a></li>
<li><a href="#8-%E5%AE%89%E8%A3%85%E4%B8%8E%E5%90%AF%E5%8A%A8">8. 安装与启动</a></li>
<li><a href="#9-jedis%E7%9A%84%E6%93%8D%E4%BD%9C">9. jedis的操作</a></li>
<li><a href="#10-redis%E5%8D%95%E6%9C%BA%E5%AE%89%E8%A3%85">10. redis单机安装</a></li>
<li><a href="#11-redis%E9%9B%86%E7%BE%A4%E7%9A%84%E6%90%AD%E5%BB%BA">11. Redis集群的搭建</a></li>
<li><a href="#12-java%E8%BF%9E%E6%8E%A5%E5%88%99%E7%94%A8jedis">12. java连接则用jedis</a></li>
</ul>
<!-- /TOC -->
<!--more-->
<h1>1. NoSQL介绍</h1>
<ul>
<li>关系型数据库是基于关系表的数据库，最终会将数据持久化到磁盘上</li>
<li>nosql数据库是基于特殊的结构，并将数据存储到内存的数据库</li>
<li>从性能上而言，nosql数据库要优于关系型数据库</li>
<li>从安全性上而言关系型数据库要优于nosql数据库</li>
<li>一个项目中nosql和关系型数据库会一起使用，达到性能和安全性的双保证</li>
</ul>
<h1>2. NoSQL产生原因</h1>
<ul>
<li>1.数据库高并发读写需求</li>
<li>2.海量数据高效率存储和访问</li>
<li>3.数据库高扩展性和高可用性</li>
</ul>
<h1>3. NoSQL的特点</h1>
<ul>
<li>易扩展、大数据量，高性能，灵活的数据模型,高可用</li>
</ul>
<h1>4. redis介绍</h1>
<ul>
<li>redis是一种高级的key-value的存储系统</li>
<li>Redis中所有的数据都是字符串。命令不区分大小写，key是区分大小写的。Redis是单线程的。Redis中不适合保存内容大的数据。</li>
</ul>
<h1>5. Redis数据库</h1>
<ul>
<li>多数据库</li>
<li>有0-15数据库，默认为0，选择数据库select n选择n号数据库</li>
<li>移库 move newkey n将当前的key移植到n号库中</li>
</ul>
<h1>6. 消息订阅与发布</h1>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/28327364030668f3c4d44.jpg" alt="消息的订阅与发布.JPG" tabindex="0"><figcaption>消息的订阅与发布.JPG</figcaption></figure>
<h1>7. 事务</h1>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/cc1727548496fd141234c.png" alt="redis事务.png" tabindex="0"><figcaption>redis事务.png</figcaption></figure>
<h1>8. 安装与启动</h1>
<ul>
<li>在redis的bin目录下可以执行./redis-server前端启动方式</li>
<li>在bin下执行命令,/redis-server redis.conf(后端启动)</li>
<li>关闭：关闭进程、在客户端下shutdown</li>
<li>连接redis redis-cli -h ip -p port</li>
</ul>
<h1>9. jedis的操作</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>导包commons-pool2-2.3.jar\jedis2.7.0jar

JedisConfig config=new JedisConfig()；
config.setMaxtotal(30);
config.setMaxIdle(10)
JedisPool pool = new JedisPool(JedisConfig,host,port);
Jedis jedis=null;
jedis=pool.getResource();
jedis.set(key,数据类型)
jedis.get(key,数据类型)

Jedis jedis = new Jedis(host,port);
jedis.set(key,数据类型)
jedis.get(key,数据类型)
</code></pre></div><h1>10. redis单机安装</h1>
<ul>
<li>
<p>Redis是c语言开发的。</p>
</li>
<li>
<p>安装redis需要c语言的编译环境。如果没有gcc需要在线安装。yum install gcc-c++</p>
</li>
<li>
<p>安装步骤：</p>
<ul>
<li>1.redis的源码包上传到linux系统。</li>
<li>2.解压缩redis。</li>
<li>3.编译。进入redis源码目录。make</li>
<li>4.安装。make install PREFIX=/usr/local/redis PREFIX参数指定redis的安装目录。一般软件安装到/usr目录下</li>
<li>5.redis的启动：
<ul>
<li>前端启动：在redis的安装目录下直接启动redis-server</li>
<li>[root@localhost bin]# ./redis-server</li>
<li>后台启动：把/root/redis-3.0.0/redis.conf复制到/usr/local/redis/bin目录下</li>
<li>[root@localhost redis-3.0.0]# cp redis.conf /usr/local/redis/bin/</li>
</ul>
</li>
<li>6.修改配置文件：daemonize no 为yes
<ul>
<li>[root@localhost bin]# ./redis-server redis.conf</li>
</ul>
</li>
<li>查看redis进程：[root@localhost bin]# ps aux|grep redis</li>
</ul>
</li>
<li>
<p>redis-cli连接 : [root@localhost bin]# ./redis-cli 默认连接localhost运行在6379端口的redis服务。</p>
<ul>
<li>[root@localhost bin]# ./redis-cli -h 192.168.25.153 -p 6379<br>
-h：连接的服务器的地址<br>
-p：服务的端口号</li>
</ul>
</li>
<li>
<p>关闭redis：[root@localhost bin]# ./redis-cli shutdown</p>
</li>
<li>
<p>设置密码：config set requirepass pass_123456</p>
</li>
<li>
<p>获取密码：config get requirepass</p>
</li>
<li>
<p>登录：auth password</p>
</li>
</ul>
<h1>11. Redis集群的搭建</h1>
<ul>
<li>
<p>Redis集群中至少应该有三个节点。要保证集群的高可用，需要每个节点有一个备份机。</p>
<ul>
<li>Redis集群至少需要6台服务器。</li>
<li>搭建伪分布式。可以使用一台虚拟机运行6个redis实例。需要修改redis的端口号7001-7006</li>
</ul>
</li>
<li>
<p>集群搭建环境</p>
<ul>
<li>
<p>使用ruby脚本搭建集群。需要ruby的运行环境。</p>
<ul>
<li>yum install ruby</li>
<li>yum install rubygems</li>
</ul>
</li>
<li>
<p>安装ruby脚本运行使用的包。</p>
<ul>
<li>将redis-3.0.0和redis-3.0.0.gem放在一起然后执行</li>
<li>gem install redis-3.0.0.gem</li>
</ul>
</li>
<li>
<p>搭建步骤:需要6个redis实例。需要运行在不同的端口7001-7006</p>
</li>
</ul>
</li>
<li>
<p>第一步：创建6个redis实例，每个实例运行在不同的端口。</p>
<ul>
<li>如果你的节点中包含了appendonly.aof和dump.rdb请删除了，保证节点的干净</li>
<li>需要修改redis.conf配置文件。配置文件中还需要把cluster-enabled yes前的注释去掉。</li>
<li>同时修改port为7001</li>
<li>cp redis/bin /usr/java/redis-cluster/redis07 -r将之前安装好的bin目录一个一个复制到redis-cluster中</li>
</ul>
</li>
</ul>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/5a73634ac3215338bd49b.png" alt="图片7.png" tabindex="0"><figcaption>图片7.png</figcaption></figure>
<ul>
<li>第二步：启动每个redis实例。
<ul>
<li>在redis-cluster目录下创建start-all.sh执行vim start</li>
<li>然后i写入</li>
</ul>
</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>	cd redis01
	./redis-server redis.conf
	cd ..
	cd redis02
	./redis-server redis.conf
	cd ..
	cd redis03
	./redis-server redis.conf
	cd ..
	cd redis04
	./redis-server redis.conf
	cd ..
	cd redis05
	./redis-server redis.conf
	cd ..
	cd redis06
	./redis-server redis.conf
	cd ..
	然后esc，然后：wq退出
	执行chmod u+x start-all.sh授权
	执行./start-all.sh开启所有redis实例
	执行ps aux|grep redis查看所有节点进程看是否成功
	在redis源码的src在有一个文件叫redis-trib.rb
	将它复制到/usr/java/redis-cluster目录下
</code></pre></div><ul>
<li>第三步：使用ruby脚本搭建集群。
<ul>
<li>将它复制到/usr/java/redis-cluster目录下执行</li>
</ul>
</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>	./redis-trib.rb create --replicas 1 192.168.25.153:7001 192.168.25.153:7002 192.168.25.153:7003 192.168.25.153:7004 192.168.25.153:7005 192.168.25.153:7006
</code></pre></div><ul>
<li>这个不要随便乱用！否则要关闭redis所有的节点，然后将每个节点下aof、rdb、nodes.conf本地备份文件删除； 重启所有节点，然后重新执行脚本！
<ul>
<li>创建关闭集群的脚本：</li>
</ul>
</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>[root@localhost redis-cluster]# vim shutdow-all.sh
redis01/redis-cli -p 7001 shutdown
redis01/redis-cli -p 7002 shutdown
redis01/redis-cli -p 7003 shutdown
redis01/redis-cli -p 7004 shutdown
redis01/redis-cli -p 7005 shutdown
redis01/redis-cli -p 7006 shutdown
[root@localhost redis-cluster]# chmod u+x shutdow-all.sh 

集群的使用方法
Redis-cli连接集群。[root@localhost redis-cluster]# redis01/redis-cli -p 7002 -c  -c：代表连接的是redis集群
</code></pre></div><h1>12. java连接则用jedis</h1>
]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/28327364030668f3c4d44.jpg" type="image/jpeg"/>
    </item>
    <item>
      <title>mycat</title>
      <link>https://javaguide.cn/backend/databasemiddleware/mycat.html</link>
      <guid>https://javaguide.cn/backend/databasemiddleware/mycat.html</guid>
      <source url="https://javaguide.cn/rss.xml">mycat</source>
      <description>mycat是用来做数据库集群的 什么是MyCAT？ MyCAT的关键特性 MyCAT架构 图片1.png图片1.png Mycat解决的问题 图片2.png图片2.png Mycat对多数据库的支持 图片3.png图片3.png 分片策略 图片4.png图片4.png Mycat读写分离 图片5.png图片5.png 图片6.png图片6.png</description>
      <category>后端</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>mycat是用来做数据库集群的</p>
<!--more-->
<h2>什么是MyCAT？</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>简单的说，MyCAT就是：
一个彻底开源的，面向企业应用开发的“大数据库集群”
支持事务、ACID、可以替代Mysql的加强版数据库
一个可以视为“Mysql”集群的企业级数据库，用来替代昂贵的Oracle集群
一个融合内存缓存技术、Nosql技术、HDFS大数据的新型SQL Server
结合传统数据库和新型分布式数据仓库的新一代企业级数据库产品
一个新颖的数据库中间件产品
</code></pre></div><h2>MyCAT的关键特性</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>支持 SQL 92标准
支持Mysql集群，可以作为Proxy使用
支持JDBC连接ORACLE、DB2、SQL Server，将其模拟为MySQL  Server使用
支持galera for mysql集群，percona-cluster或者mariadb cluster，提供高可用性数据分片集群
自动故障切换，高可用性
支持读写分离，支持Mysql双主多从，以及一主多从的模式
支持全局表，数据自动分片到多个节点，用于高效表关联查询
支持独有的基于E-R 关系的分片策略，实现了高效的表关联查询
多平台支持，部署和实施简单
</code></pre></div><h2>MyCAT架构</h2>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/be77b7731e8a7d473fae0.png" alt="图片1.png" tabindex="0"><figcaption>图片1.png</figcaption></figure>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>如图所示：MyCAT使用Mysql的通讯协议模拟成了一个Mysql服务器，并建立了完整的Schema（数据库）、Table （数据表）、User(用户)的逻辑模型，
并将这套逻辑模型映射到后端的存储节点DataNode（MySQL Instance）上的真实物理库中，
这样一来，所有能使用Mysql的客户端以及编程语言都能将MyCAT当成是Mysql Server来使用，不必开发新的客户端协议。
</code></pre></div><h2>Mycat解决的问题</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>性能问题
数据库连接过多
E-R分片难处理
可用性问题
成本和伸缩性问题
</code></pre></div><figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/68e7f50ac03acbda118c5.png" alt="图片2.png" tabindex="0"><figcaption>图片2.png</figcaption></figure>
<h2>Mycat对多数据库的支持</h2>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/49b80914303756fdc7d09.png" alt="图片3.png" tabindex="0"><figcaption>图片3.png</figcaption></figure>
<h2>分片策略</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>MyCAT支持水平分片与垂直分片：
水平分片：一个表格的数据分割到多个节点上，按照行分隔。
垂直分片：一个数据库中多个表格A，B，C，A存储到节点1上，B存储到节点2上，C存储到节点3上。
</code></pre></div><figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/3bf27b197b0c27e368119.png" alt="图片4.png" tabindex="0"><figcaption>图片4.png</figcaption></figure>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>MyCAT通过定义表的分片规则来实现分片，每个表格可以捆绑一个分片规则，每个分片规则指定一个分片字段并绑定一个函数，来实现动态分片算法。

Schema：逻辑库，与MySQL中的Database（数据库）对应，一个逻辑库中定义了所包括的Table。
Table：表，即物理数据库中存储的某一张表，表格需要声明其所存储的逻辑数据节点DataNode。在此可以指定表的分片规则。
DataNode：MyCAT的逻辑数据节点，是存放table的具体物理节点，也称之为分片节点，通过DataSource来关联到后端某个具体数据库上
DataSource：定义某个物理库的访问地址，用于捆绑到Datanode上
</code></pre></div><h2>Mycat读写分离</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>数据库读写分离对于大型系统或者访问量很高的互联网应用来说，是必不可少的一个重要功能。对于MySQL来说，标准的读写分离是主从模式，
一个写节点Master后面跟着多个读节点，读节点的数量取决于系统的压力，通常是1-3个读节点的配置
Mycat读写分离和自动切换机制，需要mysql的主从复制机制配合。
</code></pre></div><figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/c4d3eb1798cca24863085.png" alt="图片5.png" tabindex="0"><figcaption>图片5.png</figcaption></figure>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>Mysql的主从复制
主从配置需要注意的地方
1、主DB server和从DB server数据库的版本一致
2、主DB server和从DB server数据库数据一致[ 这里就会可以把主的备份在从上还原，也可以直接将主的数据目录拷贝到从的相应数据目录]
3、主DB server开启二进制日志,主DB server和从DB server的server_id都必须唯一
</code></pre></div><figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/290e0357dc61fcd674032.png" alt="图片6.png" tabindex="0"><figcaption>图片6.png</figcaption></figure>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>Mysql主服务器配置
第一步：修改my.conf文件：
在[mysqld]段下添加：
binlog-do-db=db1
binlog-ignore-db=mysql
#启用二进制日志
log-bin=mysql-bin
#服务器唯一ID，一般取IP最后一段
server-id=134

第二步：重启mysql服务
service mysqld restart

第三步：建立帐户并授权slave
mysql&gt;GRANT FILE ON *.* TO 'backup'@'%' IDENTIFIED BY '123456';
mysql&gt;GRANT REPLICATION SLAVE, REPLICATION CLIENT ON *.* to 'backup'@'%' identified by '123456'; 
#一般不用root帐号，“%”表示所有客户端都可能连，只要帐号，密码正确，此处可用具体客户端IP代替，如192.168.145.226，加强安全。
刷新权限 :FLUSH PRIVILEGES;
查看mysql现在有哪些用户:select user,host from mysql.user;

第四步：查询master的状态
mysql&gt; show master status;
+</code></pre></div>]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/be77b7731e8a7d473fae0.png" type="image/png"/>
    </item>
    <item>
      <title>Git</title>
      <link>https://javaguide.cn/backend/developmenttool/git.html</link>
      <guid>https://javaguide.cn/backend/developmenttool/git.html</guid>
      <source url="https://javaguide.cn/rss.xml">Git</source>
      <description>git代码管理工具 1. 介绍 git仓库组成部分 2. 项目管理 3. git命令 Git 和 SVN 的优缺点？ git如何解决冲突？ 什么是 fork 操作？ 1. 介绍 Git是一个开源的分布式版本控制系统，可以有效、高速的处理从很小到非常大的项目版本管理。 1.png1.png git仓库组成部分 工作区(Working Directory)...</description>
      <category>理论</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>git代码管理工具</p>
<!--more-->
<!-- TOC -->
<ul>
<li><a href="#1-%E4%BB%8B%E7%BB%8D">1. 介绍</a></li>
<li><a href="#git%E4%BB%93%E5%BA%93%E7%BB%84%E6%88%90%E9%83%A8%E5%88%86">git仓库组成部分</a></li>
<li><a href="#2-%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86">2. 项目管理</a></li>
<li><a href="#3-git%E5%91%BD%E4%BB%A4">3. git命令</a></li>
<li><a href="#git-%E5%92%8C-svn-%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9">Git 和 SVN 的优缺点？</a></li>
<li><a href="#git%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E5%86%B2%E7%AA%81">git如何解决冲突？</a></li>
<li><a href="#%E4%BB%80%E4%B9%88%E6%98%AF-fork-%E6%93%8D%E4%BD%9C">什么是 fork 操作？</a></li>
</ul>
<!-- /TOC -->
<h1>1. 介绍</h1>
<p>Git是一个开源的分布式版本控制系统，可以有效、高速的处理从很小到非常大的项目版本管理。</p>
<figure><img src="https://b.bdstatic.com/comment/Y_bZHaS27NSYIAE9PqRzMwac4b6b53d5456c8e13428f6803458191.png" alt="1.png" tabindex="0"><figcaption>1.png</figcaption></figure>
<h1>git仓库组成部分</h1>
<ul>
<li>工作区(Working Directory)：在 Git 管理下的正常目录都算是工作区，我们平时的编辑工作都是在工作区完成。</li>
<li>暂存区(Stage)：临时区域。里面存放将要提交文件的快照。</li>
<li>历史记录区(History)：git commit 后的记录区。</li>
<li>三个区的转换关系以及转换所使用的命令<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/0c8b9d3839f0f3a1b3e90.png" alt="Git仓库组成部分.jpg"></li>
</ul>
<h1>2. 项目管理</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>- 没有仓库时创建仓库并提交代码
echo "# utils" &gt;&gt; README.md
git init
git add README.md
git commit -m "first commit"
git remote add origin https://github.com/HeChuangJun/utils.git
git push -u origin master

- 有仓库时提交代码
git remote add origin https://github.com/HeChuangJun/utils.git
git push -u origin master

- 第二次提交代码
git add .
git commit -m "提交信息"
git push
</code></pre></div><h1>3. git命令</h1>
<ul>
<li>git命令表:<a href="https://gitee.com/liaoxuefeng/learn-java/raw/master/teach/git-cheatsheet.pdf" target="_blank" rel="noopener noreferrer">https://gitee.com/liaoxuefeng/learn-java/raw/master/teach/git-cheatsheet.pdf</a></li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code># 创建版本库
- git clone &lt;ulr&gt; //克隆远程版本库
- git init //初始化本地版本库(当前目录下多了一个.git隐藏目录)

# 修改和提交
- git status //查看文件的提交情况
- git diff [&lt;file&gt;]//查看[文件]变更内容
- git add . //跟踪所有改动文件,提交到暂存区
- git add &lt;file&gt; //跟踪指定文件 文件添加到暂存区.
- git mv &lt;old&gt; &lt;new&gt; //文件改名
- git rm &lt;file&gt; //删除文件
- git rm --cached &lt;file&gt; //停止跟踪文件但不删除
- git commit -m "commit message" //将暂存区的文件添加到仓库
- git commit --amend //修改最后一次提交

- git stash  //暂存。
- git stash pop //恢复最近一次的暂存。
- git stash list//git显示所有备份:
- git stash pop，恢复的备份同时把stash内容也删了
- git stash apply stash@{0} //git恢复单个备份不删除stash的内容:

# 查看提交历史
- git log //显示git最近到最远的提交commit id历史
- git log -p &lt;file&gt; //查看指定文件的提交历史
- git blame &lt;file&gt; //以列表的方式查看指定文件的提交历史
- git show &lt;commit&gt;//查看某次提交内容
- git reflog //显示命令历史
- git log --pretty=oneline //显示git最近一次的commit id历史

# 撤销
- git reset &lt;file&gt; //从暂存区恢复到工作文件。git add &lt;file&gt; 的逆操作。
- git reset --hard HEAD //撤销工作目录中所有未提交文件的修改内容
- git reset --hard HEAD^(^)//回退上(上)个版本
- git reset --hard HEAD~100//回退许多版本
- git reset --hard &lt;commit id&gt;//回退（更新）到指定版本
- git reset HEAD^ ：恢复最近一次提交过的状态，即放弃上次提交后的所有本次修改` 。
- git checkout HEAD &lt;file&gt; //撤销指定的未提交文件的修改内容
- git revert &lt;commit&gt; //撤销指定的提交id

# 分支
- git branch //查看所有本地分支,并显示当前分支
- git branch -r //查看远程分支
- git branch &lt;new-branch&gt; //创建新分支 
- git checkout &lt;branch/tag&gt; //切换分支
- git checkout -b &lt;branch&gt; //git创建分支并切换到分支,相当于 git branch &lt;分支名&gt; + git checkout &lt;分支名&gt;
- git branch -d &lt;branch&gt; //删除本地分支
- git push origin :&lt;branch&gt; //冒号删除远程分支

# 标签
- git tag //查看本地所有tag标签
- gti show &lt;tagname&gt;//查看指定标签
- git tag &lt;tagname&gt; [&lt;commitid&gt;] //基于[提交id]最新提交创建标签
- git tag -a v0.1 -m "version 0.1 released" 1094adb //git打标签指定版本和标签的信息:
- git push origin &lt;tagname&gt;//推送本地标签到远程
- git push origin </code></pre></div>]]></content:encoded>
      <enclosure url="https://b.bdstatic.com/comment/Y_bZHaS27NSYIAE9PqRzMwac4b6b53d5456c8e13428f6803458191.png" type="image/png"/>
    </item>
    <item>
      <title>Maven</title>
      <link>https://javaguide.cn/backend/developmenttool/maven.html</link>
      <guid>https://javaguide.cn/backend/developmenttool/maven.html</guid>
      <source url="https://javaguide.cn/rss.xml">Maven</source>
      <description>maven项目管理工具 1. maven概述 2. maven项目构建过程 3. maven项目依赖管理 4. maven仓库 5. maven工程目录 6. 常用maven命令 7. maven概念模型内容 8. pom.xml基本配置 9. 依赖管理 10. 依赖范围对传递依赖的影响 11. 依赖传递与依赖冲突解决 1. maven概述 apach...</description>
      <category>后端</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>maven项目管理工具</p>
<!-- TOC -->
<ul>
<li><a href="#1-maven%E6%A6%82%E8%BF%B0">1. maven概述</a></li>
<li><a href="#2-maven%E9%A1%B9%E7%9B%AE%E6%9E%84%E5%BB%BA%E8%BF%87%E7%A8%8B">2. maven项目构建过程</a></li>
<li><a href="#3-maven%E9%A1%B9%E7%9B%AE%E4%BE%9D%E8%B5%96%E7%AE%A1%E7%90%86">3. maven项目依赖管理</a></li>
<li><a href="#4-maven%E4%BB%93%E5%BA%93">4. maven仓库</a></li>
<li><a href="#5-maven%E5%B7%A5%E7%A8%8B%E7%9B%AE%E5%BD%95">5. maven工程目录</a></li>
<li><a href="#6-%E5%B8%B8%E7%94%A8maven%E5%91%BD%E4%BB%A4">6. 常用maven命令</a></li>
<li><a href="#7-maven%E6%A6%82%E5%BF%B5%E6%A8%A1%E5%9E%8B%E5%86%85%E5%AE%B9">7. maven概念模型内容</a></li>
<li><a href="#8-pomxml%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE">8. pom.xml基本配置</a></li>
<li><a href="#9-%E4%BE%9D%E8%B5%96%E7%AE%A1%E7%90%86">9. 依赖管理</a></li>
<li><a href="#10-%E4%BE%9D%E8%B5%96%E8%8C%83%E5%9B%B4%E5%AF%B9%E4%BC%A0%E9%80%92%E4%BE%9D%E8%B5%96%E7%9A%84%E5%BD%B1%E5%93%8D">10. 依赖范围对传递依赖的影响</a></li>
<li><a href="#11-%E4%BE%9D%E8%B5%96%E4%BC%A0%E9%80%92%E4%B8%8E%E4%BE%9D%E8%B5%96%E5%86%B2%E7%AA%81%E8%A7%A3%E5%86%B3">11. 依赖传递与依赖冲突解决</a></li>
</ul>
<!-- /TOC -->
<!--more-->
<h1>1. maven概述</h1>
<ul>
<li>apache下的项目管理工具,开源java项目</li>
<li>一步构建项目：项目构建过程标准化，一个命令完成、编译、测试、运行、打包、部署、运行(tomcat:run)</li>
<li>依赖管理：不用手动导入jar包，在pom.xml定义坐标自动从maven仓库中下载，不易出错</li>
<li>跨平台 window 和 linux都可以使用</li>
<li>遵循规范，提高开发效率，降低项目维护成本</li>
</ul>
<h1>2. maven项目构建过程</h1>
<ul>
<li>清理(clean)、编译(commpile)、测试、报告、</li>
<li>打包(package：java→jar、web→war)、部署</li>
<li>运行mavenLtomcat：run、tomcat7:run</li>
<li>一个命令完成构建、运行、方便快捷，每个构建阶段规范，有利于团队开发</li>
</ul>
<h1>3. maven项目依赖管理</h1>
<ul>
<li>通过pom.xml对jar包版本同一管理，避免冲突、可以从maven仓库中下载jar包</li>
</ul>
<h1>4. maven仓库</h1>
<ul>
<li>优先查找本地仓库、没有查远程(可以私服)、最后中央、查到自动下载到本地仓库保存</li>
<li>本地仓库(默认:${usr.dir}/.m2/repository)</li>
<li>远程仓库：互联网或局域网内</li>
<li>中央仓库：http：<a href="//repo1.maven.org/maven2%E3%80%81maven%E5%9B%A2%E9%98%9F%E8%87%AA%E5%B7%B1%E7%BB%B4%E6%8A%A4" target="_blank" rel="noopener noreferrer">//repo1.maven.org/maven2、maven团队自己维护</a></li>
<li>配置本地仓库</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>F:\apache-maven-3.5.3\conf\setting.xml
&lt;localRepository&gt;F:\repository&lt;/localRepository&gt;
</code></pre></div><h1>5. maven工程目录</h1>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/92c263ed3f7d72f7502aa.png" alt="maven工程目录" tabindex="0"><figcaption>maven工程目录</figcaption></figure>
<h1>6. 常用maven命令</h1>
<ul>
<li>mvn compile 将src/main/java下的 文件编译为class文件 并放到target/classes目录下,不编译测试的代码</li>
<li>mvn test 执行src/test/java的单元测试类</li>
<li>mvn clean 删除target目录的内容(包括打包结果和编译结果)，清理后编译</li>
<li>mvn package java工程→jar、web工程→war包，默认jar包名称：artificild-version.jar</li>
<li>mvn install：将maven打成jar包或者war包发布到本地仓库(模块开发的时候使用)安装到仓库/groupId/artifacid/version</li>
<li>tomcat:run 一键启动</li>
</ul>
<h1>7. maven概念模型内容</h1>
<ul>
<li>项目对象模型:pom.xml定义项目坐标、依赖、信息、插件目标</li>
<li>标准集合:标准目录结构、生命周期阶段、依赖管理有标准的坐标定义</li>
<li>项目生命周期:清理(clean)、编译(commpile)、测试(test)、报告、打包(package：java→jar、web→war)、部署 通过命令实现生命周期</li>
<li>依赖管理系统:对jar包同一管理</li>
<li>运行定义在生命周期阶段中插件的目标的逻辑:maven管理项目生命周期过程都是基于插件完成的</li>
</ul>
<h1>8. pom.xml基本配置</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>&lt;project&gt;:文件的根节点
	&lt;modelVersion&gt;:pom.xml使用的对象模型版本
	&lt;groupId&gt;:项目名称：组织名+项目名。类似包名
	&lt;artifactId&gt;:模块名，子项目名或模块名称
	&lt;version&gt;:当前版本号snapshot快照版本非正式版本release为正式发布版
	&lt;packaging&gt;:打包类型jar、war、pom父工程使用这个设置与package有关
	&lt;name&gt;:项目的显示名，常用于maven的生成文档
	&lt;description&gt;:项目描述，常用于maven的生成文档
	&lt;dependencies&gt;:项目依赖构件配置，配置项目依赖构件的坐标
&lt;build&gt;:项目构建配置，配置编译，运行插件等
</code></pre></div><h1>9. 依赖管理</h1>
<ul>
<li>依赖范围(添加依赖jar包格式)</li>
<li>依赖war包、依赖模块\依赖范围由强到弱的顺序是：compile&gt;provided&gt;runtime&gt;test<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/1981723b2ddbd1162469b.png" alt="1.png"><br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/5bc716d0fa32c19a37e1c.png" alt="2.png"><br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/0f9106b3033aecf7b87c6.png" alt="3.png"></li>
</ul>
<h1>10. 依赖范围对传递依赖的影响</h1>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/1b1f8d1ff53575fc3ff22.png" alt="4.png" tabindex="0"><figcaption>4.png</figcaption></figure>
<h1>11. 依赖传递与依赖冲突解决</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>- 调解原则
  - 第一声明者优先原则：谁先声明谁先依赖
  - 路径近者优先原则：谁的依赖层小，谁先被依赖
- 排除依赖
	&lt;dependency&gt;
		&lt;groupId&gt;org.apache.struts&lt;/groupId&gt;
		&lt;artifactId&gt;struts2-spring-plugin&lt;/artifactId&gt;
		&lt;version&gt;2.3.24&lt;/version&gt;
		&lt;exclusions&gt;
			&lt;exclusion&gt;
				&lt;groupId&gt;org.springframework&lt;/groupId&gt;
				&lt;artifactId&gt;spring-beans&lt;/artifactId&gt;
			&lt;/exclusion&gt;
		&lt;/exclusions&gt;
	&lt;/dependency&gt;
- 锁定版本:配置了锁定版本必须相应地配置依赖，但不需要指定版本
	&lt;dependencyManagement&gt;
		&lt;dependencies&gt;
			&lt;dependency&gt;
			&lt;groupId&gt;org.springframework&lt;/groupId&gt;
			&lt;artifactId&gt;spring-bean&lt;/artifactId&gt;
			&lt;version&gt;4.2.4.RELEASE&lt;/version&gt;
			&lt;/dependency&gt;
		&lt;/dependencies&gt;
	&lt;/dependencyManagement&gt;
</code></pre></div><h1>12. maven私服(了解)自己看文档</h1>
<h1>13. springboot设置为windows服务 maven插件</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>&lt;plugin&gt;
	&lt;groupId&gt;cn.joylau.code&lt;/groupId&gt;
	&lt;artifactId&gt;joylau-springboot-daemon-windows&lt;/artifactId&gt;
	&lt;version&gt;1.1.RELEASE&lt;/version&gt;
	&lt;executions&gt;
		&lt;execution&gt;
			&lt;id&gt;make-win-service&lt;/id&gt;
			&lt;phase&gt;install&lt;/phase&gt;
			&lt;goals&gt;
				&lt;goal&gt;make-win-service&lt;/goal&gt;
			&lt;/goals&gt;
		&lt;/execution&gt;
	&lt;/executions&gt;
	&lt;configuration&gt;
	&lt;vmOptions&gt;           
		-Xbootclasspath/a:config/ -Xmx1024m -Xms512m -XX:MaxPermSize=256m -XX:PermSize=128m -Dfile.encoding=UTF-8 -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.port=22221            
	&lt;/vmOptions&gt;
	&lt;arguments&gt;
	&lt;/arguments&gt;
&lt;/configuration&gt;
&lt;/plugin&gt;
</code></pre></div>]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/92c263ed3f7d72f7502aa.png" type="image/png"/>
    </item>
    <item>
      <title>JSP</title>
      <link>https://javaguide.cn/backend/j2ee/jsp.html</link>
      <guid>https://javaguide.cn/backend/j2ee/jsp.html</guid>
      <source url="https://javaguide.cn/rss.xml">JSP</source>
      <description>jsp/el/jstl jsp(Java Server Page) jsp运行原理 文档结构 jsp基本语法 jsp9大内置对象（笔试） el(${el表达式}):Expression Language 11个内置对象(自定义的数据必须放在域中el才能得到) jstl（jsp Standard Tag Library) jsp(Java Server ...</description>
      <category>后端</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>jsp/el/jstl</p>
<!--more-->
<!-- TOC -->
<ul>
<li><a href="#jspjava-server-page">jsp(Java Server Page)</a></li>
<li><a href="#jsp%E8%BF%90%E8%A1%8C%E5%8E%9F%E7%90%86">jsp运行原理</a></li>
<li><a href="#%E6%96%87%E6%A1%A3%E7%BB%93%E6%9E%84">文档结构</a></li>
<li><a href="#jsp%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95">jsp基本语法</a></li>
<li><a href="#jsp9%E5%A4%A7%E5%86%85%E7%BD%AE%E5%AF%B9%E8%B1%A1%E7%AC%94%E8%AF%95">jsp9大内置对象（笔试）</a></li>
<li><a href="#elel%E8%A1%A8%E8%BE%BE%E5%BC%8Fexpression-language">el(${el表达式}):Expression Language</a></li>
<li><a href="#11%E4%B8%AA%E5%86%85%E7%BD%AE%E5%AF%B9%E8%B1%A1%E8%87%AA%E5%AE%9A%E4%B9%89%E7%9A%84%E6%95%B0%E6%8D%AE%E5%BF%85%E9%A1%BB%E6%94%BE%E5%9C%A8%E5%9F%9F%E4%B8%ADel%E6%89%8D%E8%83%BD%E5%BE%97%E5%88%B0">11个内置对象(自定义的数据必须放在域中el才能得到)</a></li>
<li><a href="#jstljsp-standard-tag-library">jstl（jsp Standard Tag Library)</a></li>
</ul>
<!-- /TOC -->
<h1>jsp(Java Server Page)</h1>
<ul>
<li>建立在Servlet规范上的动态网页开发技术本质是servlet（Html + Java）</li>
<li>特点:跨平台、业务代码相分离、JavaBean组件重用、预编译（一个用户只编译一次）</li>
<li>产生原因:html页面输出太麻烦</li>
</ul>
<h1>jsp运行原理</h1>
<ul>
<li>本质就是servlet，第一次被访问的时候被web容器翻译成servlet再执行</li>
<li>helloServlet.jsp→helloServlet_jsp.java源文件→helloServlet_jsp.class字节码文件</li>
<li>被翻译后的servlet在Tomcat的work目录中可以找到</li>
<li>F:\Tomcat\apache-tomcat-7.0.52\work\Catalina\localhost\WEB17\org\apache\jsp</li>
<li>jsp继承了HttpjspBase，HttpjspBase类又继承了HttpServlet，故jsp就是servlet</li>
</ul>
<h1>文档结构</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>&lt;%@ page language="java" contentType="text/html; charset=UTF-8" pageEncoding="UTF-8"%&gt;
&lt;!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd"&gt;
&lt;html&gt;
  &lt;head&gt;
    &lt;meta http-equiv="Content-Type" content="text/html; charset=UTF-8"&gt;
    &lt;title&gt;Insert title here&lt;/title&gt;
  &lt;/head&gt;
  &lt;body&gt;
  &lt;/body&gt;
&lt;/html&gt;
</code></pre></div><h1>jsp基本语法</h1>
<table>
<thead>
<tr>
<th style="text-align:center">脚本分类</th>
<th style="text-align:center">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">&lt;%(变量/方法/语句等)%&gt;</td>
<td style="text-align:center">jspScriptlets：被翻译到Servlet中的service方法的局部变量。调用完则释放内存空间,常用于输出</td>
</tr>
<tr>
<td style="text-align:center">&lt;%=(变量/表达式)%&gt;</td>
<td style="text-align:center">jsp表达式：被翻译成servlet中service方法内部out.print()输出，变量或者表达式后面不能有分号</td>
</tr>
<tr>
<td style="text-align:center">&lt;%!java代码%&gt;</td>
<td style="text-align:center">jsp声明语句:被翻译成servlet类的成员方法/变量/代码块，静态方法/变量/代码块,对整个jsp页面有效</td>
</tr>
</tbody>
</table>
<br>
<table>
<thead>
<tr>
<th style="text-align:center">注释分类</th>
<th style="text-align:center">说明</th>
<th style="text-align:center">可见范围</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Html注释</td>
<td style="text-align:center">&lt;!--注释内容--&gt;</td>
<td style="text-align:center">jsp源码、java源码、html源码</td>
</tr>
<tr>
<td style="text-align:center">java注释</td>
<td style="text-align:center">//单行注释/<em>多行注释</em>/</td>
<td style="text-align:center">java源码、jsp源码</td>
</tr>
<tr>
<td style="text-align:center">jsp注释</td>
<td style="text-align:center">&lt;%--注释内容--%&gt;</td>
<td style="text-align:center">jsp源码</td>
</tr>
</tbody>
</table>
<br>
<table>
<thead>
<tr>
<th style="text-align:center">指令(指导jsp翻译和运行的命令)分类</th>
<th style="text-align:center">属性</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">&lt;%@page 属性名1="属性值1"%&gt;</td>
<td style="text-align:center">language：jsp脚本中可以嵌入的语言种类java</td>
</tr>
<tr>
<td style="text-align:center">属性名称区分大小写</td>
<td style="text-align:center">pageEncoding：读取jsp文件内容采用的编码一定要和保存文件的编码一致--内部可以包含contentType</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">contentType：有效文档类型text/html;</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">session：是否jsp在翻译时自动创建true/false</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">import：导入java的包 可多次，其他只能一次java.util.*</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">errorPage：当当前页面出错后跳转到哪个页面</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">isErrorPage：当前页面是一个处理错误的页面true/false</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">buffer:8kb,jsp缓存大小，也是out的缓冲区大小</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">autoFlush:自动刷新,true/false</td>
</tr>
<tr>
<td style="text-align:center">&lt;%@taglib 属性名1="属性值1" &gt;</td>
<td style="text-align:center">uri：要引入的(jstl、struts2)标签库地址, prefix:前缀 使用<a href="xxx:%E5%89%8D%E7%BC%80">xxx:前缀</a></td>
</tr>
<tr>
<td style="text-align:center">&lt;%@include 属性名1="属性值1"%&gt;</td>
<td style="text-align:center">file:被包含的相对于webcontent文件地址（静态包含）</td>
</tr>
</tbody>
</table>
<h1>jsp9大内置对象（笔试）</h1>
<pre><code>jsp被翻译成servlet后，service方法中有9个对象定义并初始化完毕，jsp脚本可直接使用
所有对象都可以存取数据request.setAttribute("age", 30);
</code></pre>
<table>
<thead>
<tr>
<th style="text-align:center">9大内置对象名称</th>
<th style="text-align:center">类型</th>
<th style="text-align:center">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">request</td>
<td style="text-align:center">HttpServletRequest</td>
<td style="text-align:center">得到用户请求信息</td>
</tr>
<tr>
<td style="text-align:center">response</td>
<td style="text-align:center">HttpServletResponse</td>
<td style="text-align:center">服务器向客户端回应信息</td>
</tr>
<tr>
<td style="text-align:center">config</td>
<td style="text-align:center">ServletConfig</td>
<td style="text-align:center">服务器配置，可以取得初始化参数</td>
</tr>
<tr>
<td style="text-align:center">session</td>
<td style="text-align:center">HttpSession</td>
<td style="text-align:center">保存用户信息</td>
</tr>
<tr>
<td style="text-align:center">application</td>
<td style="text-align:center">ServletContext</td>
<td style="text-align:center">所有用户的共享信息</td>
</tr>
<tr>
<td style="text-align:center">page</td>
<td style="text-align:center">Object</td>
<td style="text-align:center">指当前页面转换后的Servlet类的实例</td>
</tr>
<tr>
<td style="text-align:center">exception</td>
<td style="text-align:center">Throwable</td>
<td style="text-align:center">表示jsp页面所发生的异常，在错误页面中才起作用</td>
</tr>
<tr>
<td style="text-align:center">pageContext</td>
<td style="text-align:center">PageContext</td>
<td style="text-align:center">jsp的页面容器,jsp页面的上下文对象</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">①获得其他8个内置对象：pageContext.getRequest()</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">②域对象:setAttribute(String name,Object obj[,int scope])</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">getAttribute(String name[,int scope])</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">removeAttrbute(String name[,int scope])</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">pageContext.(PAGE/REQUEST/SESSION/APPLICATION)_SCOPE</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">③findAttribute(String name)依次从page，request，session，application域中获取属性</td>
</tr>
<tr>
<td style="text-align:center">out</td>
<td style="text-align:center">jspWriter</td>
<td style="text-align:center">用于页面输出</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">response.getWriter().write("a")，先输出，out.write后输出</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">out.write()先放到jspWriter缓冲区中(默认8kb)</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">若page属性buffer=“0kb” 关闭out缓冲区,则按顺序输出</td>
</tr>
</tbody>
</table>
<br>
<table>
<thead>
<tr>
<th style="text-align:center">jsp标签/动作</th>
<th style="text-align:center">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">&lt;jsp:include /&gt;</td>
<td style="text-align:center">page:被包含的页面的地址 flush:包含页面flush是否将输出内容立即刷新到客户端，默认false，</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">false;等全部加载完了再刷新</td>
</tr>
<tr>
<td style="text-align:center">&lt;jsp:forward /&gt;</td>
<td style="text-align:center">page="要转发请求的资源相对于webcontent地址"</td>
</tr>
</tbody>
</table>
<br>
<table>
<thead>
<tr>
<th style="text-align:center">include指令(静态包含)</th>
<th style="text-align:center">include标签(动态包含)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">引入的资源必须是jsp格式的文件</td>
<td style="text-align:center">引入的资源必须能被web容器独立运行</td>
</tr>
<tr>
<td style="text-align:center">引入的资源是编译前包含的</td>
<td style="text-align:center">引入的资源是编译后包含的</td>
</tr>
<tr>
<td style="text-align:center">不限制改变状态码和设置响应头</td>
<td style="text-align:center">不能改变状态码和设置响应头</td>
</tr>
</tbody>
</table>
<h1>el(${el表达式}):Expression Language</h1>
<pre><code>简单的数据访问语言,使jsp的代码更加简化
</code></pre>
<h1>11个内置对象(自定义的数据必须放在域中el才能得到)</h1>
<table>
<thead>
<tr>
<th style="text-align:center">分类</th>
<th style="text-align:center">内置对象名称</th>
<th style="text-align:center">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">作用域</td>
<td style="text-align:center">pageScope</td>
<td style="text-align:center">page作用域</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">requestScope</td>
<td style="text-align:center">request作用域</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">sessionScope</td>
<td style="text-align:center">session作用域</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">applicationScope</td>
<td style="text-align:center">application作用域</td>
</tr>
<tr>
<td style="text-align:center">请求参数</td>
<td style="text-align:center">param</td>
<td style="text-align:center">获得一个参数</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">paramValues</td>
<td style="text-align:center">获得一组参数</td>
</tr>
<tr>
<td style="text-align:center">请求头</td>
<td style="text-align:center">header</td>
<td style="text-align:center">获得一个请求头</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">headerValues</td>
<td style="text-align:center">获得一组请求头</td>
</tr>
<tr>
<td style="text-align:center">jsp上下文对象</td>
<td style="text-align:center">pageContext</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">全局初始化参数</td>
<td style="text-align:center">initParam</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">cookie</td>
<td style="text-align:center">cookie</td>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
<br>
<table>
<thead>
<tr>
<th style="text-align:center">内置对象使用</th>
<th style="text-align:center">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">${内置对象}</td>
<td style="text-align:center">获得内置对象</td>
</tr>
<tr>
<td style="text-align:center">${内置对象.key}</td>
<td style="text-align:center">获得内置对象数据</td>
</tr>
<tr>
<td style="text-align:center">${内置对象.[key-xxx]}</td>
<td style="text-align:center">获得内置对象有-或者空格的数据</td>
</tr>
<tr>
<td style="text-align:center">${内置对象.key[index]}</td>
<td style="text-align:center">获得内置对象数据为数组,list,map,对象集合的数据</td>
</tr>
<tr>
<td style="text-align:center">${key}</td>
<td style="text-align:center">底层使用findAttribute("name"),依次从page、request、session、application获得数据</td>
</tr>
<tr>
<td style="text-align:center">${pageContext.request}</td>
<td style="text-align:center">pageContext获得其他八大对象</td>
</tr>
<tr>
<td style="text-align:center">$(pageContext.request.contextPath)/XXX</td>
<td style="text-align:center">相当于&lt;%=pageContext.getRequest().getContextPath%&gt;获得WEB应用的名称</td>
</tr>
<tr>
<td style="text-align:center">${表达式}</td>
<td style="text-align:center">el表达式运算</td>
</tr>
</tbody>
</table>
<h1>jstl（jsp Standard Tag Library)</h1>
<ul>
<li>jsp标准标签库，可以嵌入在jsp页面中使用标签的形式完成业务逻辑等功能。</li>
<li>jstl出现的目的同el一样也是要提到jsp页面中的脚本代码</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align:center">jstl使用</th>
<th style="text-align:center">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">导入jstl.jar</td>
<td style="text-align:center">包含JSTL规范中定义的接口和相关类</td>
</tr>
<tr>
<td style="text-align:center">导入standard.jar</td>
<td style="text-align:center">包含用于实现JSTL的.class文件以及JSTL中5个标签库描述符文件（TLD）</td>
</tr>
<tr>
<td style="text-align:center">引入标签库</td>
<td style="text-align:center">&lt;%@taglib uri="<a href="http://java.sun.com/jsp/jstl/core" target="_blank" rel="noopener noreferrer">http://java.sun.com/jsp/jstl/core</a>" prefix="c"%&gt;</td>
</tr>
<tr>
<td style="text-align:center">遍历对象</td>
<td style="text-align:center">&lt;c:forEach begin="0"end="5"var="i" step=“2”&gt;${i}&lt;/c:forEach&gt;</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">&lt;c:forEach items="将要迭代的对象" var="每一个对象的值" [varStatus=""]&gt;</td>
</tr>
<tr>
<td style="text-align:center">获得普通list的值</td>
<td style="text-align:center">&lt;c:forEach items="{str }&lt;/c:forEach&gt;</td>
</tr>
<tr>
<td style="text-align:center">获得list对象的值</td>
<td style="text-align:center">&lt;c:forEach items="{<a href="http://user.name" target="_blank" rel="noopener noreferrer">user.name</a> }${user.age}&lt;/c:forEach&gt;</td>
</tr>
<tr>
<td style="text-align:center">获得普通map的值</td>
<td style="text-align:center">&lt;c:forEach items="{entry.key }==${entry.value }&lt;/c:forEach&gt;</td>
</tr>
<tr>
<td style="text-align:center">获得map对象的值</td>
<td style="text-align:center">&lt;c:forEach items="{<a href="http://entry.value.name" target="_blank" rel="noopener noreferrer">entry.value.name</a> }--${entry.value.password }&lt;/c:forEach&gt;</td>
</tr>
<tr>
<td style="text-align:center">判断条件</td>
<td style="text-align:center">&lt;c:if test="" var="" scope="page"&gt;&lt;/c:if&gt;</td>
</tr>
<tr>
<td style="text-align:center">输出</td>
<td style="text-align:center">&lt;c:out value="hello,world"&gt;</td>
</tr>
</tbody>
</table>
]]></content:encoded>
    </item>
    <item>
      <title>spring</title>
      <link>https://javaguide.cn/backend/j2ee/spring.html</link>
      <guid>https://javaguide.cn/backend/j2ee/spring.html</guid>
      <source url="https://javaguide.cn/rss.xml">spring</source>
      <description>spring 1. spring介绍 4. spring框架使用 5. spring与junit整合测试（常用） 6. applicationContext.xml配置详解 7. spring创建对象的方式 8. SpringAOP 9. spring整合JDBC 10. spring事务 11. spring web项目配置 12. spring整合...</description>
      <category>后端</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>spring</p>
<!--more-->
<!-- TOC -->
<ul>
<li><a href="#1-spring%E4%BB%8B%E7%BB%8D">1. spring介绍</a></li>
<li><a href="#4-spring%E6%A1%86%E6%9E%B6%E4%BD%BF%E7%94%A8">4. spring框架使用</a></li>
<li><a href="#5-spring%E4%B8%8Ejunit%E6%95%B4%E5%90%88%E6%B5%8B%E8%AF%95%E5%B8%B8%E7%94%A8">5. spring与junit整合测试（常用）</a></li>
<li><a href="#6-applicationcontextxml%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3">6. applicationContext.xml配置详解</a></li>
<li><a href="#7-spring%E5%88%9B%E5%BB%BA%E5%AF%B9%E8%B1%A1%E7%9A%84%E6%96%B9%E5%BC%8F">7. spring创建对象的方式</a></li>
<li><a href="#8-springaop">8. SpringAOP</a></li>
<li><a href="#9-spring%E6%95%B4%E5%90%88jdbc">9. spring整合JDBC</a></li>
<li><a href="#10-spring%E4%BA%8B%E5%8A%A1">10. spring事务</a></li>
<li><a href="#11-spring-web%E9%A1%B9%E7%9B%AE%E9%85%8D%E7%BD%AE">11. spring web项目配置</a></li>
<li><a href="#12-spring%E6%95%B4%E5%90%88struts2">12. spring整合struts2</a></li>
<li><a href="#13-spring%E6%95%B4%E5%90%88c3p0%E8%BF%9E%E6%8E%A5%E6%B1%A0">13. spring整合c3p0连接池</a></li>
<li><a href="#14-spring%E6%95%B4%E5%90%88hibernate">14. spring整合hibernate</a></li>
<li><a href="#15-spring%E7%9A%84java%E9%85%8D%E7%BD%AE%E5%A4%9A%E6%95%B0%E6%8D%AE%E6%BA%90">15. spring的java配置多数据源</a></li>
<li><a href="#16-spring4x%E7%9A%84java%E9%85%8D%E7%BD%AE%E6%96%B9%E5%BC%8F%E5%8F%AF%E4%BB%A5%E5%AE%8C%E5%85%A8%E6%9B%BF%E4%BB%A3xml%E9%85%8D%E7%BD%AE">16. Spring4.x的Java配置方式（可以完全替代xml配置）</a></li>
<li><a href="#17-spring4x%E9%85%8D%E7%BD%AE%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0">17. spring4.x配置数据库连接池</a></li>
<li><a href="#spring%E4%B8%8D%E5%90%8C%E7%B1%BB%E5%9E%8B%E7%9A%84%E4%BA%8B%E4%BB%B6">spring不同类型的事件？</a></li>
</ul>
<!-- /TOC -->
<!--more-->
<h1>1. spring介绍</h1>
<ul>
<li>spring框架性质是属于容器性质的.容器中装什么对象就有什么功能.所以可以一站式.不仅不排斥其他框架,还能帮其他框架管理对象.</li>
<li>aop支持\ioc思想'\spring jdbc\aop 事务\junit 测试支持</li>
</ul>
<h1>4. spring框架使用</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>xml配置
导包
com.springsource.org.apache.log4j-1.2.15.jar可选
spring-beans-4.2.4.RELEASE.jar
spring-context-4.2.4.RELEASE.jar
spring-core-4.2.4.RELEASE.jar
spring-expression-4.2.4.RELEASE.jar

com.springsource.org.apache.commons.logging-1.1.1.jar日志包

创建一个对象，set/get方法
在src下的applicationContext.xml中导入约束beans约束,并注册对象
&lt;bean name="" class=""/&gt;
代码测试
@Test
public void fun(){
	ApplicationContext ac = new ClassPathXmlApplicationContext("applicationContext.xml");
	User u = ac.getBean("user");
}
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>注解配置
导包一样
配置applicationContext.xml开启使用注解代理
导入约束spring-context-4.2.xsd
指定扫描该com.junye.bean包及子孙包下所有类中的注解
&lt;context:component-scan base-package="com.junye.bean"&gt;&lt;/context&gt;
在类中使用注解完成配置
将对象注册到容器四个注解没区别，唯一区分就是分层，推荐使用最后三个
@component("user")
@Controller("user")//web层
@Service("user")//service层
@Repository("user")//dao层

修改对象的作用范围(struts中的Action是多例的才线程安全，单例不安全)
@Scope(scopeName="prototype")	

值类型注入
@Value("tom")//通过反射的Field赋值,破坏了封装性
private String name;
通过set方法赋值,推荐使用.
@Value("tom")
public void setName(String name){
	this.name=name;
}

引用类型注入
@Autowired//自动装配,如果匹配多个类型一致的对象，将无法选择注入那个对象
@Qualifier("car2")告诉spring容器自动装配那个名称的对象
private Car car;
@Resource(name="car")手动注入，指定注入那个对象
private Car car;

初始化|销毁方法
@PostConstruct//在对象被创建后调用。init-method
public voud init(){}
@PreDestroy//在销毁之前调用。destory-method
public void destory(){}
</code></pre></div><h1>5. spring与junit整合测试（常用）</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>导包
com.springsource.org.apache.log4j-1.2.15.jar可选
spring-beans-4.2.4.RELEASE.jar
spring-context-4.2.4.RELEASE.jar
spring-core-4.2.4.RELEASE.jar
spring-expression-4.2.4.RELEASE.jar
com.springsource.org.apache.commons.logging-1.1.1.jar
spring-aop-4.2.4.RELEASE.jar

spring-test-4.2.4.RELEASE.jar

配置注解与测试
@RunWith(SpringJUnit4ClassRunner.class)		
@ContextConfiguration("classpath:applicationContext.xml")
public class Demo{
	@Resource(name="user")
	private User u;
	
	@Test
	public void fun1(){
		System.out.println("测试");
	}
}
</code></pre></div><h1>6. applicationContext.xml配置详解</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>&lt;!-- 
Bean元素：描述需要spring容器管理的对象
class属性:被管理对象的完整类名.
name属性:命名被管理的对象.获得对象时根据该名称获得对象.可重复.可用特殊字符（推荐）
id属性: 与name属性一模一样. 名称不可重复.不能使用特殊字符. 
scope属性(整合struts2时,ActionBean必须配置为多例的)
	singleton(默认值):单例对象.被标识为单例的对象在spring容器中只会存在一个实例
	prototype:多例原型.被标识为多例的对象,每次再获得才会创建.每次创建都是新的对象.
	request:web环境下.对象与request生命周期一致.
	session:web环境下,对象与session生命周期一致. 
生命周期属性(需要在相应的类中实现其方法)
	配置生命周期初始化方法.spring会在对象创建之后立即调用.init-method
	配置生命周期的销毁方法.spring容器在关闭并销毁所有容器中的对象之前调用.destory-method	
--&gt;
&lt;bean  id="user" name="user" class="cn.bean.User" scope="singleton" init-method="init" destroy-method="destroy"&gt;&lt;/bean&gt;
&lt;!-- spring的分模块配置(导入其他spring配置文件) --&gt;
&lt;import resource="cn/b_create/applicationContext.xml"/&gt;
</code></pre></div><h1>7. spring创建对象的方式</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>空参构造方式
&lt;bean name="junye" class="cn.junye.hello.Junye"&gt;&lt;/bean&gt;

静态工厂(了解)不需创建即可用类名调用静态方法
public class UserFactory{
	public static User createUser(){
		System.out.println("静态工厂创建User");
		return new User();
	}
}
&lt;bean name="userFactory" class="cn.junye.hello.UserFactory" factory-method="createUser"&gt;&lt;/bean&gt;

实例工厂(了解)
public  User fun(){
	System.out.println("实例工厂创建User");
	return new User();	
}
&lt;!-- 调用UserFactory对象的createUser2方法创建名为user3的对象.放入容器--&gt;
&lt;bean  name="user3" factory-bean="userFactory" factory-method="fun"&gt;&lt;/bean&gt;
&lt;bean  name="userFactory" class="cn.b_create.UserFactory" &lt;/bean&gt;
</code></pre></div><h1>8. SpringAOP</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>xml配置
导包
com.springsource.org.apache.log4j-1.2.15.jar
spring-beans-4.2.4.RELEASE.jar
spring-context-4.2.4.RELEASE.jar
spring-core-4.2.4.RELEASE.jar
spring-expression-4.2.4.RELEASE.jar
com.springsource.org.apache.commons.logging-1.1.1.jar
spring的aop包
spring-aspects-4.2.4.RELEASE.jar
spring-aop-4.2.4.RELEASE.jar
spring需要的第三方aop包
com.springsource.org.aopalliance-1.0.0.jar
com.springsource.org.aspectj.weaver-1.6.8.RELEASE.jar

目标对象(接口实现关系)
public class UserServiceImpl implements UserService {
	@Override
	public void save() {
		System.out.println("保存用户!");
	}
}

准备通知类
public class MyAdvice {
	//前置通知:目标方法运行之前调用
	public void before(){
		System.out.println("这是前置通知!!");
	}
	//环绕通知:在目标方法之前和之后都调用
	public Object around(ProceedingJoinPoint pjp) throws Throwable {
		System.out.println("这是环绕通知之前的部分!!");
		Object proceed = pjp.proceed();//调用目标方法
		System.out.println("这是环绕通知之后的部分!!");
		return proceed;
	}
	//后置通知:在目标方法运行之后调用(如果出现异常不会调用)
	public void afterReturning(){
		System.out.println("这是后置通知(如果出现异常不会调用)!!");
	}
	//后置通知:在目标方法运行之后调用(无论是否出现 异常都会调用)
	public void after(){
		System.out.println("这是后置通知(出现异常也会调用)!!");
	}
	//异常通知:如果出现异常,就会调用
	public void afterException(){
		System.out.println("出事啦!出现异常了!!");
	}
}
配置applicationContext.xml,将通知织入目标对象中
//导入aop约束
&lt;!-- 1.配置目标对象 --&gt;
&lt;bean name="userService" class="cn.itcast.service.UserServiceImpl" &gt;&lt;/bean&gt;

&lt;!-- 2.配置通知对象 --&gt;
&lt;bean name="myAdvice" class="cn.itcast.d_springaop.MyAdvice" &gt;&lt;/bean&gt;

&lt;aop:config&gt;&lt;!--执行顺序为下面那个--&gt;
	&lt;aop:pointcut expression="execution(* cn.service.*ServiceImpl.*(..))" id="pc"/&gt;
	&lt;aop:aspect ref="myAdvice" &gt;
		&lt;aop:before method="before" pointcut-ref="pc" /&gt;
		&lt;aop:around method="around" pointcut-ref="pc" /&gt;
		&lt;aop:after-returning method="afterReturning" pointcut-ref="pc" /&gt;
		&lt;aop:after method="after" pointcut-ref="pc"/&gt;
		&lt;aop:after-throwing method="afterException" pointcut-ref="pc"/&gt;
	&lt;/aop:aspect&gt;
&lt;/aop:config&gt;

&lt;!-- 配置切入点 ，配置要被切的方法通常在service层

public void cn.itcast.service.UserServiceImpl.save() 
void cn.itcast.service.UserServiceImpl.save()
* cn.itcast.service.UserServiceImpl.save()
* cn.itcast.service.UserServiceImpl.*()

* cn.itcast.service.*ServiceImpl.*(..)包括一到多的参数
* cn.itcast.service..*ServiceImpl.*(..)包括所有的子包 --&gt;
测试

@RunWith(SpringJUnit4ClassRunner.class)
@ContextConfiguration("classpath:applicationContext.xml")
public class Demo {
	@Resource(name="myAop")
	private MyAop us;接口
	@Test
	public void fun1(){
		us.save();
	}
}
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>注解配置
导包(一样)
开启使用注解完成织入
&lt;aop:aspectj-autoproxy&gt;&lt;/aop:aspectj-autoproxy&gt;
准备目标对象(一样)	
准备通知(一样)配置目标对象和通知对象（xml中）一样
配置进行织入,将通知织入目标对象中
//通知类
@Aspect
//表示该类是一个通知类
public class MyAdvice {
	@Pointcut("execution(* cn.itcast.service.*ServiceImpl.*(..))")
	public void pc(){}
	//前置通知
	//指定该方法是前置通知,并制定切入点
	@Before("MyAdvice.pc()")
	public void before(){
		System.out.println("这是前置通知!!");
	}
	//后置通知
	@AfterReturning("execution(* cn.itcast.service.*ServiceImpl.*(..))")
	public void afterReturning(){
		System.out.println("这是后置通知(如果出现异常不会调用)!!");
	}
	//环绕通知
	@Around("execution(* cn.itcast.service.*ServiceImpl.*(..))")
	public Object around(ProceedingJoinPoint pjp) throws Throwable {
		System.out.println("这是环绕通知之前的部分!!");
		Object proceed = pjp.proceed();//调用目标方法
		System.out.println("这是环绕通知之后的部分!!");
		return proceed;
	}
	//异常通知
	@AfterThrowing("execution(* cn.itcast.service.*ServiceImpl.*(..))")
	public void afterException(){
		System.out.println("出事啦!出现异常了!!");
	}
	//后置通知
	@After("execution(* cn.itcast.service.*ServiceImpl.*(..))")
	public void after(){
		System.out.println("这是后置通知(出现异常也会调用)!!");
	}
}
@before（Myadvice.pc()指寻找Myadvice的pc方法的pointcut注释，与pc这个方法内容无关）
</code></pre></div><h1>9. spring整合JDBC</h1>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/8a89f9ce1d4d779c62ba4.png" alt="dao.png" tabindex="0"><figcaption>dao.png</figcaption></figure>
<ul>
<li>spring提供了很多模板整合Dao技术</li>
<li>spring中提供了一个可以操作数据库的对象.对象封装了jdbc技术.</li>
<li>JDBCTemplate =&gt; JDBC模板对象与DBUtils中的QueryRunner非常相似.</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>导包
com.springsource.com.mchange.v2.c3p0-0.9.1.2.jar
com.springsource.org.apache.commons.logging-1.1.1.jar
com.springsource.org.apache.log4j-1.2.15.jar
mysql-connector-java-5.1.7-bin.jar
spring-aop-4.2.4.RELEASE.jar
spring-beans-4.2.4.RELEASE.jar
spring-context-4.2.4.RELEASE.jar
spring-core-4.2.4.RELEASE.jar
spring-expression-4.2.4.RELEASE.jar
spring-jdbc-4.2.4.RELEASE.jar
spring-test-4.2.4.RELEASE.jar
spring-tx-4.2.4.RELEASE.jar

准备数据库
application.xml的配置

JdbcTemplate依赖dataSource，UserDao依赖JdbcTemplate

&lt;context:property-placeholder location="classpath:db.properties"  /&gt;
&lt;bean name="dataSource" class="com.mchange.v2.c3p0.ComboPooledDataSource" &gt;
	&lt;property name="jdbcUrl" value="${jdbc.jdbcUrl}" &gt;&lt;/property&gt;
	&lt;property name="driverClass" value="${jdbc.driverClass}" &gt;&lt;/property&gt;
	&lt;property name="user" value="${jdbc.user}" &gt;&lt;/property&gt;
	&lt;property name="password" value="${jdbc.password}" &gt;&lt;/property&gt;
&lt;/bean&gt;
&lt;bean name="jdbcTemplate" class="org.springframework.jdbc.core.JdbcTemplate" &gt;
	&lt;property name="dataSource" ref="dataSource" &gt;&lt;/property&gt;
&lt;/bean&gt;
&lt;bean name="userDao" class="cn.itcast.a_jdbctemplate.UserDaoImpl" &gt;
	&lt;property name="jt" ref="jdbcTemplate" &gt;&lt;/property&gt;
&lt;/bean&gt;

测试
③1、Dao实现类通过定义private JdbcTemplate jt和set方法操作数据库
2、Dao实现类继承jdbcDaoSupport通过super.getJdbcTemplate()操作数据库
public class UserDaoImpl extends JdbcDaoSupport implements UserDao {
	@Override
	public void save(User u) {
		String sql = "insert into t_user values(null,?) ";
		super.getJdbcTemplate().update(sql, u.getName());
	}
	@Override
	public void delete(Integer id) {
		String sql = "delete from t_user where id = ? ";
		super.getJdbcTemplate().update(sql,id);
	}
	@Override
	public void update(User u) {
		String sql = "update  t_user set name = ? where id=? ";
		super.getJdbcTemplate().update(sql, u.getName(),u.getId());
	}
	@Override
	public User getById(Integer id) {
		String sql = "select * from t_user where id = ? ";
		return super.getJdbcTemplate().queryForObject(sql,new RowMapper&lt;User&gt;(){
	@Override
	public User mapRow(ResultSet rs, int arg1) throws SQLException {
		User u = new User();
		u.setId(rs.getInt("id"));
		u.setName(rs.getString("name"));
		return u;
		}}, id);
	}
	@Override
	public int getTotalCount() {
		String sql = "select count(*) from t_user  ";
		Integer count = super.getJdbcTemplate().queryForObject(sql, Integer.class);
		return count;
	}

	@Override
	public List&lt;User&gt; getAll() {
		String sql = "select * from t_user  ";
		List&lt;User&gt; list = super.getJdbcTemplate().query(sql, new RowMapper&lt;User&gt;(){
		@Override
		public User mapRow(ResultSet rs, int arg1) throws SQLException {
			User u = new User();
			u.setId(rs.getInt("id"));
			u.setName(rs.getString("name"));
			return u;
		}});
	return list;
	}
}
</code></pre></div><h1>10. spring事务</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>xml配置(aop)
导包
com.springsource.com.mchange.v2.c3p0-0.9.1.2.jar
com.springsource.org.aopalliance-1.0.0.jar
com.springsource.org.apache.commons.logging-1.1.1.jar
com.springsource.org.apache.log4j-1.2.15.jar
com.springsource.org.aspectj.weaver-1.6.8.RELEASE.jar
mysql-connector-java-5.1.7-bin.jar
spring-aop-4.2.4.RELEASE.jar
spring-aspects-4.2.4.RELEASE.jar
spring-beans-4.2.4.RELEASE.jar
spring-context-4.2.4.RELEASE.jar
spring-core-4.2.4.RELEASE.jar
spring-expression-4.2.4.RELEASE.jar
spring-jdbc-4.2.4.RELEASE.jar
spring-test-4.2.4.RELEASE.jar
spring-tx-4.2.4.RELEASE.jar				

application.xml配置
&lt;!-- 导入新的约束(tx)
beans: 最基本
context:读取properties配置
aop:配置aop
tx:配置事务通知 --&gt;
&lt;!-- 将核心事务管理器配置到spring容器 --&gt;
&lt;bean name="transactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager" &gt;
	&lt;property name="dataSource" ref="dataSource" &gt;&lt;/property&gt;
&lt;/bean&gt;

&lt;!-- 配置通知（环绕通知）会改写数据库的语句增加了read-only的话会报错--&gt;
&lt;tx:advice id="txAdvice" transaction-manager="transactionManager" &gt;
	&lt;tx:attributes&gt;
		&lt;tx:method name="save*" isolation="REPEATABLE_READ" propagation="REQUIRED" read-only="false" /&gt;
	&lt;/tx:attributes&gt;
&lt;/tx:advice&gt;

&lt;!--配置将通知织入目标--&gt;
&lt;aop:config&gt;
	&lt;aop:advisor advice-ref="txAdvice" pointcut="execution(* cn.service.*.*(..))" /&gt;
&lt;/aop:config&gt;
或者
&lt;!-- 配置织入 --&gt;
&lt;aop:config  &gt;
	&lt;!-- 配置切点表达式 --&gt;
	&lt;aop:pointcut expression="execution(* cn.itcast.service.*ServiceImpl.*(..))" id="txPc"/&gt;
	&lt;!-- 配置切面 : 通知+切点 advice-ref:通知的名称pointcut-ref:切点的名称--&gt;
	&lt;aop:advisor advice-ref="txAdvice" pointcut-ref="txPc" /&gt;
&lt;/aop:config&gt;
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>注解配置(aop)
导包（一样）
导入新的约束(tx)(一样)
将核心事务管理器配置到spring容器(一样)
开启注解管理事务&lt;tx:annotation-driven/&gt;
在类或方法上面配置注解
- @Transactional(isolation=Isolation.REPEATABLE_READ,propagation=Propagation.REQUIRED,readOnly=true)					
</code></pre></div><h1>11. spring web项目配置</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>导包(41个)
创建配置文件applicationContext.xml,并导入约束(4个)beans|context|aop|tx
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;beans xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
	xmlns="http://www.springframework.org/schema/beans" 
	xmlns:context="http://www.springframework.org/schema/context"
	xmlns:aop="http://www.springframework.org/schema/aop" 
	xmlns:tx="http://www.springframework.org/schema/tx"
	xsi:schemaLocation="http://www.springframework.org/schema/beans 
	http://www.springframework.org/schema/beans/spring-beans-4.2.xsd 
	http://www.springframework.org/schema/context 
	http://www.springframework.org/schema/context/spring-context-4.2.xsd 
	http://www.springframework.org/schema/aop 
	http://www.springframework.org/schema/aop/spring-aop-4.2.xsd 
	http://www.springframework.org/schema/tx 
	http://www.springframework.org/schema/tx/spring-tx-4.2.xsd "&gt;
&lt;/beans&gt;

配置spring随项目启动(web.xml)
&lt;!-- 让spring随web启动而创建的监听器 --&gt;
&lt;listener&gt;
	&lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt;
&lt;/listener&gt;
&lt;!-- 配置spring配置文件位置参数 --&gt;
&lt;context-param&gt;
	&lt;param-name&gt;contextConfigLocation&lt;/param-name&gt;
	&lt;param-value&gt;classpath:applicationContext.xml&lt;/param-value&gt;
&lt;/context-param&gt;
</code></pre></div><h1>12. spring整合struts2</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>导包
struts.xml配置常量
在/struts2-spring-plugin-2.3.24.jar/struts-plugin.xml
struts.objectFactory = spring	将action的创建交给spring容器(已开)
&lt;constant name="struts.objectFactory" value="spring"&gt;&lt;/constant&gt;

在/struts2-core-2.3.24.jar/default.properties	
struts.objectFactory.spring.autoWire = name spring负责装配Action依赖属性(已开)

	配置struts2主配置文件struts.xml并倒入约束
	&lt;?xml version="1.0" encoding="UTF-8"?&gt;
	&lt;!DOCTYPE struts PUBLIC
	"-//Apache Software Foundation//DTD Struts Configuration 2.3//EN"
	"http://struts.apache.org/dtds/struts-2.3.dtd"&gt;
		&lt;package name="crm" namespace="/" extends="struts-default" &gt;
			&lt;!-- class属性上填写spring中action对象的BeanName完全由spring管理action生命周期,包括Action的创建 注意:需要手动组装依赖属性
			struts.xml，Action中的属性不组装则为null--&gt;
			&lt;action name="UserAction_*" class="userAction" method="{1}" &gt;
				&lt;result name="toHome" type="redirect" &gt;/index.htm&lt;/result&gt;
				&lt;result name="error" &gt;/login.jsp&lt;/result&gt;
			&lt;/action&gt;
		&lt;/package&gt;
	&lt;/struts&gt;


配置applicationContext.xml

&lt;!-- 注意:Action对象作用范围一定是多例的.这样才符合struts2架构 --&gt;
&lt;bean name="userAction" class="cn.action.UserAction" scope="prototype" &gt;
	&lt;property name="userService" ref="userService" &gt;&lt;/property&gt;
&lt;/bean&gt;

配置struts2核心过滤器到web.xml
&lt;filter&gt;
	&lt;filter-name&gt;struts2&lt;/filter-name&gt;
	&lt;filter-class&gt;org.apache.struts2.dispatcher.ng.filter.StrutsPrepareAndExecuteFilter&lt;/filter-class&gt;
&lt;/filter&gt;
&lt;filter-mapping&gt;
	&lt;filter-name&gt;struts2&lt;/filter-name&gt;
	&lt;url-pattern&gt;/*&lt;/url-pattern&gt;
&lt;/filter-mapping&gt;
</code></pre></div><h1>13. spring整合c3p0连接池</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>配置db.properties
jdbc.jdbcUrl=jdbc:mysql:///crm_32
jdbc.driverClass=com.mysql.jdbc.Driver
jdbc.user=root
jdbc.password=1234

引入连接池到spring中
	&lt;!-- 读取db.properties文件 --&gt;
	&lt;context:property-placeholder location="classpath:db.properties" /&gt;
	&lt;bean name="dataSource" class="com.mchange.v2.c3p0.ComboPooledDataSource" &gt;
		&lt;property name="jdbcUrl" value="${jdbc.jdbcUrl}" &gt;&lt;/property&gt;
		&lt;property name="driverClass" value="${jdbc.driverClass}" &gt;&lt;/property&gt;
		&lt;property name="user" value="${jdbc.user}" &gt;&lt;/property&gt;
		&lt;property name="password" value="${jdbc.password}" &gt;&lt;/property&gt;
	&lt;/bean&gt;


	将连接池注入给SessionFactory
	&lt;bean name="sessionFactory" class="org.springframework.orm.hibernate5.LocalSessionFactoryBean" &gt;
	&lt;!-- 将连接池注入到sessionFactory, hibernate会通过连接池获得连接 --&gt;
	&lt;property name="dataSource" ref="dataSource" &gt;&lt;/property&gt;
</code></pre></div><h1>14. spring整合hibernate</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>导入实体类&amp;orm元数据
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;!DOCTYPE hibernate-mapping PUBLIC 
"-//Hibernate/Hibernate Mapping DTD 3.0//EN"
"http://www.hibernate.org/dtd/hibernate-mapping-3.0.dtd"&gt;
&lt;hibernate-mapping package="" &gt;
	&lt;class name="" table="" &gt;
	&lt;id name="" column="" &gt;
		&lt;generator class="native|assigned|uuid|increment|hilo|identity|sequence"&gt;&lt;/generator&gt;
	&lt;/id&gt;
	&lt;property name="" column="" &gt;&lt;/property&gt;

	&lt;set name="" inverse="true|false" cascade="save-update|delete|all" 
	lazy="true|false|extra" fetch="select/join/subselect" batch-size="3"&gt;
	&lt;key column="" &gt;&lt;/key&gt;
		&lt;one-to-many class="" /&gt;
	&lt;/set&gt;
	&lt;many-to-one name="" column="" class="" inverse="false|true" cascade="save-update|delete|all" 
		lazy="false/proxy" fetch="select/join"&gt;
	&lt;/many-to-one&gt;

	&lt;set name="" table="" inverse="true|false" cascade="save-update|delete|all"
		lazy="true|false|extra" fetch="select/join/subselect"&gt;
		&lt;key column="" &gt;&lt;/key&gt;
		&lt;many-to-many class="" column="" &gt;&lt;/many-to-many&gt;
	&lt;/set&gt;
	&lt;/class&gt;
&lt;/hibernate-mapping&gt;

在spring配置中放置hibernate配置信息
//将sessionFactory交给spring代替配置主配置文件
&lt;bean name="sessionFactory" class="org.springframework.orm.hibernate5.LocalSessionFactoryBean" &gt;
&lt;!-- 将连接池注入到sessionFactory, hibernate会通过连接池获得连接 --&gt;
	&lt;property name="dataSource" ref="dataSource" &gt;&lt;/property&gt;
	&lt;property name="hibernateProperties"&gt;
	&lt;props&gt;
		&lt;prop key="hibernate.connection.driver_class" &gt;com.mysql.jdbc.Driver&lt;/prop&gt;
		&lt;prop key="hibernate.connection.url" &gt;jdbc:mysql:///crm&lt;/prop&gt;
		&lt;prop key="hibernate.connection.username" &gt;root&lt;/prop&gt;
		&lt;prop key="hibernate.connection.password" &gt;1234&lt;/prop&gt; --&gt;
		&lt;prop key="hibernate.dialect" &gt;org.hibernate.dialect.MySQL5Dialect&lt;/prop&gt;

		&lt;prop key="hibernate.show_sql" &gt;true&lt;/prop&gt;
		&lt;prop key="hibernate.format_sql" &gt;true&lt;/prop&gt;
		&lt;prop key="hibernate.hbm2ddl.auto" &gt;update&lt;/prop&gt;
	&lt;/props&gt;
	&lt;!-- ①引入orm元数据,指定orm元数据所在的包路径,spring会自动读取包中的所有配置 --&gt;
	&lt;/property&gt;
		&lt;property name="mappingDirectoryLocations" value="classpath:cn/itcast/domain" &gt;
	&lt;/property&gt;
	&lt;!--②引入orm元数据,指定orm元数据所在的包路径,spring会自动读取包中的所有配置--&gt;
	&lt;!--&lt;property name="mappingLocations"&gt;
		&lt;list&gt;
			&lt;value&gt;classpath:com/itheima/bos/domain/*.xml&lt;/value&gt;
		&lt;/list&gt;
	&lt;/property&gt;--&gt;
&lt;/bean&gt;

&lt;!-- 为dao注入sessionFactory --&gt;
&lt;bean name="userDao" class="cn.itcast.dao.impl.UserDaoImpl" &gt;
	&lt;property name="sessionFactory" ref="sessionFactory" &gt;&lt;/property&gt;
&lt;/bean&gt;

hibernate操作数据库

dao实现类继承HibernateDaoSupport操作HIbernateTemplate
增删改
this.getHibernateTemplate().save(entity);
this.getHibernateTemplate().delete(entity);
this.getHibernateTemplate().update(entity);
this.getHibernateTemplate().get(entityClass, id);

spring中hibernate的aop事务

配置事务管理器(xml和注解都要配置)
&lt;bean name="transactionManager" class="org.springframework.orm.hibernate5.HibernateTransactionManager" &gt;
	&lt;property name="sessionFactory" ref="sessionFactory" &gt;&lt;/property&gt;
&lt;/bean&gt;

1、xml配置aop事务
配置通知
&lt;tx:advice id="txAdvice" transaction-manager="transactionManager" &gt;
	&lt;tx:attributes&gt;
		&lt;tx:method name="save*" isolation="REPEATABLE_READ" propagation="REQUIRED" read-only="false" /&gt;
	&lt;/tx:attributes&gt;
&lt;/tx:advice&gt;


配置将通知织入目标对象，配置切点，配置切面 
&lt;aop:config&gt;
	&lt;aop:pointcut expression="execution(* com.serviceimpl.*ServiceImpl.*(..))" id="txPc"/&gt;
	&lt;aop:advisor advice-ref="txAdvice" pointcut-ref="txPc" /&gt;
&lt;/aop:config&gt; 

2、注解配置aop事务
开启注解事务&lt;tx:annotation-driven transaction-manager="transactionManager" /&gt;	


Service类、方法中使用注解
@Transactional(isolation=Isolation.REPEATABLE_READ,
propagation=Propagation.REQUIRED,readOnly=false)					

为了避免使用懒加载时出现no-session问题.需要扩大session的作用范围
注意: 任何filter一定要在struts的filter之前调用，在struts2过滤器前面
配置web.xml
&lt;filter&gt;
	&lt;filter-name&gt;openSessionInView&lt;/filter-name&gt;
	&lt;filter-class&gt;org.springframework.orm.hibernate5.support.OpenSessionInViewFilter&lt;/filter-class&gt;
&lt;/filter&gt;
&lt;filter-mapping&gt;
	&lt;filter-name&gt;openSessionInView&lt;/filter-name&gt;
	&lt;url-pattern&gt;/*&lt;/url-pattern&gt;
&lt;/filter-mapping&gt;
</code></pre></div><h1>15. spring的java配置多数据源</h1>
<h1>16. Spring4.x的Java配置方式（可以完全替代xml配置）</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>	编写SpringConfig 用于实例化Spring容器，整个文件相当于applicationContext.xml
	@Configuration //通过该注解来表明该类是一个Spring的配置，相当于一个xml文件
		@ComponentScan(basePackages = "cn.itcast.springboot.javaconfig") //配置扫描包，扫描组件
		//@PropertySource可以指定读取的配置文件，通过@Value注解获取值
		@PropertySource(value= {"classpath:jdbc.properties","xxxx"},ignoreResourceNotFound=true)
		public class SpringConfig {
		@Value("${jdbc.url}")
		private String jdbcUrl;	
		@Bean // 通过该注解来表明是一个Bean对象，相当于xml中的&lt;bean&gt;
		public UserDAO getUserDAO(){
			return new UserDAO(); // 直接new对象做演示
		}
	}
</code></pre></div><h1>17. spring4.x配置数据库连接池</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>	导入依赖：
		&lt;!-- 连接池 --&gt;
		&lt;dependency&gt;
		&lt;groupId&gt;com.jolbox&lt;/groupId&gt;
		&lt;artifactId&gt;bonecp-spring&lt;/artifactId&gt;
		&lt;version&gt;0.8.0.RELEASE&lt;/version&gt;
		&lt;/dependency&gt;

	xml配置改造成java配置方式：
	@Value("${jdbc.url}")
		private String jdbcUrl;

		@Value("${jdbc.driverClassName}")
		private String jdbcDriverClassName;

		@Value("${jdbc.username}")
		private String jdbcUsername;

		@Value("${jdbc.password}")
		private String jdbcPassword;

		@Bean(destroyMethod = "close")
		public DataSource dataSource() {
		BoneCPDataSource boneCPDataSource = new BoneCPDataSource();
		boneCPDataSource.setDriverClass(jdbcDriverClassName);
		boneCPDataSource.setJdbcUrl(jdbcUrl);
		boneCPDataSource.setUsername(jdbcUsername);
		boneCPDataSource.setPassword(jdbcUsername);
		// 检查数据库连接池中空闲连接的间隔时间，单位是分，默认值：240，如果要取消则设置为0
		boneCPDataSource.setIdleConnectionTestPeriodInMinutes(60);
		// 连接池中未使用的链接最大存活时间，单位是分，默认值：60，如果要永远存活设置为0
		boneCPDataSource.setIdleMaxAgeInMinutes(30);
		// 每个分区最大的连接数
		boneCPDataSource.setMaxConnectionsPerPartition(100);
		// 每个分区最小的连接数    
		boneCPDataSource.setMinConnectionsPerPartition(5);
		return boneCPDataSource;
		}
</code></pre></div><h1>spring不同类型的事件？</h1>
<ul>
<li>Spring 的 ApplicationContext 提供了支持事件和代码中监听器的功能,Spring 提供了以下五种标准的事件：</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>//监听系统事件
上下文更新事件（ContextRefreshedEvent）：该事件会在ApplicationContext 被初始化或者更新时发布。也可以在调用ConfigurableApplicationContext 接口中的 #refresh() 方法时被触发。
上下文开始事件（ContextStartedEvent）：当容器调用ConfigurableApplicationContext 的 #start() 方法开始/重新开始容器时触发该事件。
上下文停止事件（ContextStoppedEvent）：当容器调用 ConfigurableApplicationContext 的 #stop() 方法停止容器时触发该事件。
上下文关闭事件（ContextClosedEvent）：当ApplicationContext 被关闭时触发该事件。容器被关闭时，其管理的所有单例 Bean 都被销毁。
请求处理事件（RequestHandledEvent）：在 We b应用中，当一个HTTP 请求（request）结束触发该事件。
public class AllApplicationEventListener implements ApplicationListener&lt;ApplicationEvent&gt; {  
    @Override  
    public void onApplicationEvent(ApplicationEvent applicationEvent) {}
}
//自定义事件
public class CustomApplicationEvent extends ApplicationEvent{  
    public CustomApplicationEvent(Object source, final String msg) {  
        super(source);
    }  
}
//监听自定义事件
public class CustomEventListener implements ApplicationListener&lt;CustomApplicationEvent&gt; {
    @Override  
    public void onApplicationEvent(CustomApplicationEvent applicationEvent) {}
}
//发布自定义事件
// 创建 CustomApplicationEvent 事件
CustomApplicationEvent customEvent = new CustomApplicationEvent(applicationContext, "Test message");
// 发布事件
applicationContext.publishEvent(customEvent);
</code></pre></div><p>@ConditionalOnMissingBean条件注解最好在@AutoConfiguration里面的@Bean上面使用，同时将该配置类注册为自动配置类，才能保证100%生效，否则会被另外的配置类覆盖</p>
]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/8a89f9ce1d4d779c62ba4.png" type="image/png"/>
    </item>
    <item>
      <title>springboot</title>
      <link>https://javaguide.cn/backend/j2ee/springboot.html</link>
      <guid>https://javaguide.cn/backend/j2ee/springboot.html</guid>
      <source url="https://javaguide.cn/rss.xml">springboot</source>
      <description>springboot 1. SpringBoot 2. springboot2程序入门 3. Spring Boot API 4. 自定义SpringMVC的配置(拦截器) 5. Mybatis和Spring Boot整合(两种方式) 6. Spring的整合Redis 7. Spring的整合Httpclient 8. Spring的整合Rabbit...</description>
      <category>后端</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>springboot</p>
<!--more-->
<!-- TOC -->
<ul>
<li><a href="#1-springboot">1. SpringBoot</a></li>
<li><a href="#2-springboot2%E7%A8%8B%E5%BA%8F%E5%85%A5%E9%97%A8">2. springboot2程序入门</a></li>
<li><a href="#3-spring-boot-api">3. Spring Boot API</a></li>
<li><a href="#4-%E8%87%AA%E5%AE%9A%E4%B9%89springmvc%E7%9A%84%E9%85%8D%E7%BD%AE%E6%8B%A6%E6%88%AA%E5%99%A8">4. 自定义SpringMVC的配置(拦截器)</a></li>
<li><a href="#5-mybatis%E5%92%8Cspring-boot%E6%95%B4%E5%90%88%E4%B8%A4%E7%A7%8D%E6%96%B9%E5%BC%8F">5. Mybatis和Spring Boot整合(两种方式)</a></li>
<li><a href="#6-spring%E7%9A%84%E6%95%B4%E5%90%88redis">6. Spring的整合Redis</a></li>
<li><a href="#7-spring%E7%9A%84%E6%95%B4%E5%90%88httpclient">7. Spring的整合Httpclient</a></li>
<li><a href="#8-spring%E7%9A%84%E6%95%B4%E5%90%88rabbitmq">8. Spring的整合RabbitMQ</a></li>
<li><a href="#9-spring%E6%95%B4%E5%90%88servletfilterlistener">9. spring整合Servlet、Filter、Listener</a></li>
<li><a href="#10-springboot%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98">10. springboot常见问题</a></li>
</ul>
<!-- /TOC -->
<!--more-->
<h1>1. SpringBoot</h1>
<p>springboot快速创建一个独立运行、准生产级别的基于spring框架的项目<br>
springboot其实包含了springmvc等许多的组件，还允许自动配置，省事</p>
<h1>2. springboot2程序入门</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>创建maven项目，打包方式选择war，跳过骨架
配置pom.xml（注意编译jdk版本和运行的jdk版本匹配）
	&lt;project xmlns="http://maven.apache.org/POM/4.0.0" 
		xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
		xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 
		http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;
		&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;
		&lt;groupId&gt;com.junye&lt;/groupId&gt;
		&lt;artifactId&gt;testspringboot&lt;/artifactId&gt;
		&lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;
		&lt;!--打包的方式为war，自动生成jar包--&gt;
		&lt;packaging&gt;war&lt;/packaging&gt;
		&lt;name&gt;testspringboot&lt;/name&gt;
		&lt;description&gt;AAA&lt;/description&gt;
		&lt;!-- 定义公共资源版本 --&gt;
		&lt;parent&gt;
			&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
			&lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;
			&lt;version&gt;2.0.2.RELEASE&lt;/version&gt;
		&lt;/parent&gt;
		&lt;!--设置资源的版本--&gt;
		&lt;properties&gt;
		&lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;
		&lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt;
		&lt;java.version&gt;1.8&lt;/java.version&gt;
		&lt;/properties&gt;
		
		&lt;dependencies&gt;
		&lt;dependency&gt;
		&lt;!-- 上边引入 parent，因此 下边无需指定版本，相当于配置了springmvc --&gt;
		&lt;!-- 包含 mvc,aop 等jar资源 --&gt;
		&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
		&lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
		&lt;!--使用别的服务器，如undertow
		&lt;exclusions&gt;
		&lt;exclusion&gt;
		&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
		&lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt;
		&lt;/exclusion&gt;
		&lt;/exclusions&gt;
		&lt;/dependency&gt;
		指定特定的服务器
		&lt;dependency&gt;
		   &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
		   &lt;artifactId&gt;spring-boot-starter-undertow&lt;/artifactId&gt;
		&lt;/dependency&gt;--&gt;
		&lt;/dependencies&gt;
		&lt;build&gt;
		&lt;!--指定springboot的maven插件--&gt;
		&lt;plugins&gt;
		&lt;plugin&gt;
		&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
		&lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;
		&lt;/plugin&gt;
		&lt;/plugins&gt;
		&lt;/build&gt;
		&lt;/project&gt;
src/main/java下的程序入口：Chapter1Application（必须）
	run中传入的名字必须与类名一致
		package com.junye.test;
		import org.springframework.boot.SpringApplication;
		import org.springframework.boot.autoconfigure.SpringBootApplication;
		@SpringBootApplication
		public class Chapter1Application {
			public static void main(String[] args) {
				SpringApplication.run(Chapter1Application.class, args);
			}
		}


src/main/java下的controller层（必须）
	package com.junye.test;
		import org.springframework.stereotype.Controller;
		import org.springframework.ui.Model;
		import org.springframework.web.bind.annotation.RequestMapping;
		import org.springframework.web.bind.annotation.RestController;
		@RestController//自动返回json数据
		public class HelloController {
		@RequestMapping("/hello")
		public String index() {
		return "Hello World";
		}
		}
	
启动项目的方法
	Debug Run或者运行主函数或者maven的spring-boot：run
	完成上述步骤访问：http://localhost:8080/hello即可显示helloworld
springboot参数接收与返回与springmvc一致
</code></pre></div><h1>3. Spring Boot API</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>入口类和@SpringBootApplication
Spring Boot的项目一般都会有*Application的入口类，入口类中会有main方法，这是一个标准的Java应用程序的入口方法。
@SpringBootApplication注解是Spring Boot的核心注解，它其实是一个组合注解

@SpringBootConfiguration=&gt;@Configuration
@EnableAutoConfiguration 启用自动配置使项目中依赖的jar包自动配置项目的配置项
@ComponentScan(
    excludeFilters = {@Filter(
    type = FilterType.CUSTOM,
    classes = {TypeExcludeFilter.class}
), @Filter(
    type = FilterType.CUSTOM,
    classes = {AutoConfigurationExcludeFilter.class}
)}//默认扫描@SpringBootApplication所在类的同级目录以及它的子目录

关闭自动配置
spring-boot-autoconfigure-xxx.jar
@SpringBootApplication(exclude={RedisAutoConfiguration.class})

自定义Banner(spring启动图案)
http://patorjk.com/software/taag/#p=display&amp;f=Graffiti&amp;t=Type%20Something%20
拷贝生成的字符到一个文本文件中，并且将该文件命名为banner.txt，将banner.txt拷贝到maven项目的resources目录中即可
关闭Banner application.properties
spring.main.banner-mode = off

全局配置文件application.properties或者application.yml，在resources目录下或者类路径下的/config下，
server.port=8088 #tomcat端口
server.servlet-path=*.html # 修改进入DispatcherServlet的规则为：*.html
    
设置日志级别
logging.level.org.springframework=DEBUG

静态资源路径
spring.resources.static-locations=classpath:/META-INF/resources/,classpath:/resources/,classpath:/static/,classpath:/public/

mvc视图
spring.mvc.view.prefix=/WEB-INF/views/
spring.mvc.view.suffix=.jsp

# springboot设置session过期的时间
server.session.timeout=120

springbootjava配置和application.properties配置冲突优先java配置
springboot的@component配置导致数据源配置不可用，说明springboot的配置是先加载component然后再加configuration

引入xml配置文件
@ImportResource({"classpath:xxx-context.xml"})

读取外部的配置文件
@PropertySource(value = { "classpath:jdbc.properties", "classpath:env.properties"})
</code></pre></div><h1>4. 自定义SpringMVC的配置(拦截器)</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>继承WebMvcConfigurerAdapter,然后重写父类中的方法进行扩展。
import java.nio.charset.Charset;
import java.util.List;

import javax.servlet.http.HttpServletRequest;
import javax.servlet.http.HttpServletResponse;

import org.springframework.context.annotation.Configuration;
import org.springframework.http.converter.HttpMessageConverter;
import org.springframework.http.converter.StringHttpMessageConverter;
import org.springframework.web.servlet.HandlerInterceptor;
import org.springframework.web.servlet.ModelAndView;
import org.springframework.web.servlet.config.annotation.InterceptorRegistry;
import org.springframework.web.servlet.config.annotation.WebMvcConfigurerAdapter;

@Configuration
public class MySrpingMVCConfig extends WebMvcConfigurerAdapter{
	// 自定义拦截器
	@Override
	public void addInterceptors(InterceptorRegistry registry) {
		HandlerInterceptor handlerInterceptor = new HandlerInterceptor() {
			@Override
			public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler)
			throws Exception {
				System.out.println("自定义拦截器............");
				return true;
			}
			@Override
			public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler,
			ModelAndView modelAndView) throws Exception {

			}

			@Override
			public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler,
			Exception ex) throws Exception {
			}
		};
		//注册拦截器     
		registry.addInterceptor(handlerInterceptor).addPathPatterns("/**");
	}

	// 自定义消息转化器的第二种方法
	@Override
	public void configureMessageConverters(List&lt;HttpMessageConverter&lt;?&gt;&gt; converters) {
		StringHttpMessageConverter converter  = new StringHttpMessageConverter(Charset.forName("UTF-8"));
		converters.add(converter);
	}

}
</code></pre></div><h1>5. Mybatis和Spring Boot整合(两种方式)</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>使用mybatis官方提供的Spring Boot整合包实现https://github.com/mybatis/spring-boot-starter
&lt;!--三包合一，包括mybatis、整合包和事务包--&gt;
&lt;dependency&gt;
	&lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt;
	&lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt;
	&lt;version&gt;1.3.0&lt;/version&gt;
&lt;/dependency&gt;
@Mapper（在接口上面注解即可）或者直接扫描包
@MapperScan(basePackages= {"com.junye.testspringbootMybaits"})
@Transactional（service层上面注册）
java配置sqlfactorysession和数据源
@Bean
//@Primary//设置优先,多数据源的时候使用就是当遇到数据对接的时候用
public ComboPooledDataSource getComboPooledDataSource() throws PropertyVetoException{
	ComboPooledDataSource cd=new ComboPooledDataSource();
	cd.setDriverClass("com.mysql.cj.jdbc.Driver");
	cd.setJdbcUrl("jdbc:mysql://localhost:3306/testmybatis?useSSL=true&amp;serverTimezone=GMT%2B8");
	cd.setUser("root");
	cd.setPassword("1105128664");
	return cd;
}

@Bean(name="sqlSessionFactory")
public SqlSessionFactoryBean getSqlSessionFactoryBean() throws Exception{
	SqlSessionFactoryBean sf = new SqlSessionFactoryBean();
	sf.setDataSource(getComboPooledDataSource());
	sf.setMapperLocations(new PathMatchingResourcePatternResolver().getResources("classpath:match2/test/*.xml"));
	sf.setTypeAliasesPackage("com.junye.test");//设置包的别名
	//下面的配置可有可无，毕竟设置包的别名已经设计好了
	//sf.setConfigLocation(new PathMatchingResourcePatternResolver().getResource("classpath:mybatis-configuration.xml"));
	return sf;
}

使用mybatis-spring整合的方式（推荐）
&lt;!--mybatis核心包--&gt;
&lt;dependency&gt;
	&lt;groupId&gt;org.mybatis&lt;/groupId&gt;
	&lt;artifactId&gt;mybatis&lt;/artifactId&gt;
	&lt;version&gt;3.2.8&lt;/version&gt;
&lt;/dependency&gt;
&lt;!--整合包--&gt;
&lt;dependency&gt;
	&lt;groupId&gt;org.mybatis&lt;/groupId&gt;
	&lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt;
	&lt;version&gt;1.2.2&lt;/version&gt;
&lt;/dependency&gt; 
&lt;!--整合事务--&gt;
&lt;dependency&gt;
	&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
	&lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt;
&lt;/dependency&gt;
java配置类
import javax.sql.DataSource;
import org.mybatis.spring.SqlSessionFactoryBean;
import org.springframework.boot.autoconfigure.condition.ConditionalOnMissingBean;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.core.io.Resource;
import org.springframework.core.io.support.PathMatchingResourcePatternResolver;
import org.springframework.core.io.support.ResourcePatternResolver;
import org.mybatis.spring.mapper.MapperScannerConfigurer;
@Configuration
public class MyBatisConfig {
@Bean
@ConditionalOnMissingBean //当容器里没有指定的Bean的情况下创建该对象
public SqlSessionFactoryBean sqlSessionFactory(DataSource dataSource) {
	SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean();
	sqlSessionFactoryBean.setDataSource(dataSource);
	ResourcePatternResolver resolver = new PathMatchingResourcePatternResolver();
	Resource mybatisConfigXml = resolver.getResource("classpath:mybatis/mybatis-config.xml");
	sqlSessionFactoryBean.setConfigLocation(mybatisConfigXml);
	sqlSessionFactoryBean.setTypeAliasesPackage("com.taotao.cart.pojo");
	return sqlSessionFactoryBean;
}
// mapper接口的扫描器，可用@MapperScan代替
@Bean
public MapperScannerConfigurer mapperScannerConfigurer() {
	MapperScannerConfigurer mapperScannerConfigurer = new MapperScannerConfigurer();
	mapperScannerConfigurer.setBasePackage("com.taotao.cart.mapper");
	return mapperScannerConfigurer;
	}
}

事务管理
在Spring Boot中推荐使用@Transactional注解来申明事务。
当引入jdbc依赖之后，Spring Boot会自动默认分别注入DataSourceTransactionManager
或JpaTransactionManager，所以我们不需要任何额外配置就可以用@Transactional注解进行事务的使用。
在Service中添加@Transactional注解：

</code></pre></div><h1>6. Spring的整合Redis</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>	在Spring Boot中提供了RedisTempplate的操作，
	import java.util.ArrayList;
	import java.util.List;

	import org.springframework.beans.factory.annotation.Value;
	import org.springframework.context.annotation.Bean;
	import org.springframework.context.annotation.Configuration;
	import org.springframework.context.annotation.PropertySource;

	import redis.clients.jedis.JedisPoolConfig;
	import redis.clients.jedis.JedisShardInfo;
	import redis.clients.jedis.ShardedJedisPool;

	@Configuration
	@PropertySource(value = "classpath:redis.properties")
	public class RedisSpringConfig {

	@Value("${redis.maxTotal}")
	private Integer redisMaxTotal;

	@Value("${redis.node1.host}")
	private String redisNode1Host;

	@Value("${redis.node1.port}")
	private Integer redisNode1Port;

	private JedisPoolConfig jedisPoolConfig() {
		JedisPoolConfig jedisPoolConfig = new JedisPoolConfig();
		jedisPoolConfig.setMaxTotal(redisMaxTotal);
		return jedisPoolConfig;
	}

	@Bean
	public ShardedJedisPool shardedJedisPool() {
		List&lt;JedisShardInfo&gt; jedisShardInfos = new ArrayList&lt;JedisShardInfo&gt;();
		jedisShardInfos.add(new JedisShardInfo(redisNode1Host, redisNode1Port));
		return new ShardedJedisPool(jedisPoolConfig(), jedisShardInfos);
		}
	}
</code></pre></div><h1>7. Spring的整合Httpclient</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>import org.apache.http.client.config.RequestConfig;
import org.apache.http.impl.client.CloseableHttpClient;
import org.apache.http.impl.client.HttpClients;
import org.apache.http.impl.conn.PoolingHttpClientConnectionManager;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.context.annotation.PropertySource;
import org.springframework.context.annotation.Scope;

import com.taotao.common.httpclient.IdleConnectionEvictor;

@Configuration
@PropertySource(value = "classpath:httpclient.properties")
public class HttpclientSpringConfig {

@Value("${http.maxTotal}")
private Integer httpMaxTotal;

@Value("${http.defaultMaxPerRoute}")
private Integer httpDefaultMaxPerRoute;

@Value("${http.connectTimeout}")
private Integer httpConnectTimeout;

@Value("${http.connectionRequestTimeout}")
private Integer httpConnectionRequestTimeout;

@Value("${http.socketTimeout}")
private Integer httpSocketTimeout;

@Value("${http.staleConnectionCheckEnabled}")
private Boolean httpStaleConnectionCheckEnabled;

@Autowired
private PoolingHttpClientConnectionManager manager;

@Bean
public PoolingHttpClientConnectionManager poolingHttpClientConnectionManager() {
	PoolingHttpClientConnectionManager poolingHttpClientConnectionManager = new PoolingHttpClientConnectionManager();
	// 最大连接数
	poolingHttpClientConnectionManager.setMaxTotal(httpMaxTotal);
	// 每个主机的最大并发数
	poolingHttpClientConnectionManager.setDefaultMaxPerRoute(httpDefaultMaxPerRoute);
	return poolingHttpClientConnectionManager;
}

// 定期关闭无效连接
@Bean
public IdleConnectionEvictor idleConnectionEvictor() {
	return new IdleConnectionEvictor(manager);
}

// 定义Httpclient对
@Bean
@Scope("prototype")
public CloseableHttpClient closeableHttpClient() {
	return HttpClients.custom().setConnectionManager(this.manager).build();
}

// 请求配置
@Bean
public RequestConfig requestConfig() {
	return RequestConfig.custom().setConnectTimeout(httpConnectTimeout) // 创建连接的最长时间
	.setConnectionRequestTimeout(httpConnectionRequestTimeout) // 从连接池中获取到连接的最长时间
	.setSocketTimeout(httpSocketTimeout) // 数据传输的最长时间
	.setStaleConnectionCheckEnabled(httpStaleConnectionCheckEnabled) // 提交请求前测试连接是否可用
	.build();
}

}
</code></pre></div><h1>8. Spring的整合RabbitMQ</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>导入spring-boot-starter-amqp的依赖
&lt;dependency&gt;
	&lt;groupId&gt;org.springframeword.boot&lt;/groupId&gt;
	&lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;
&lt;/dependency&gt;
application.properties文件中配置RabbitMQ的连接信息
spring.rabbitmq.host=127.0.0.1
spring.rabbitmq.port=5672
spring.rabbitmq.password=root
spring.rabbitmq.username=test
spring.rabbitmq.virtual-hos=/test

编写Rabbit的Spring配置类
import org.springframework.amqp.core.Queue;
import org.springframework.amqp.rabbit.connection.ConnectionFactory;
import org.springframework.amqp.rabbit.core.RabbitAdmin;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

@Configuration
public class RabbitMQSpringConfig {

@Autowired
private ConnectionFactory connectionFactory;

// 管理
@Bean
public RabbitAdmin rabbitAdmin() {
	return new RabbitAdmin(connectionFactory);
}

// 声明队列
@Bean
public Queue taotaoCartLoginQueue() {
	// 默认就是自动声明的
	return new Queue("TAOTAO-CART-LOGIN-QUEUE", true);
}

// 声明队列
@Bean
public Queue taotaoCartOrderSuccessQueue() {
	// 默认就是自动声明的
	return new Queue("TAOTAO-CART-ORDER-SUCCESS-QUEUE", true);
}

}
设置监听
@Component
public class Test{
	@RabbitListener(queues = "xxxx")
	public void fun(){}
}
</code></pre></div><h1>9. spring整合Servlet、Filter、Listener</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>注册Servlet
①使用ServletRegistrationBean注册
使用ServletRegistrationBean注册只需要在@Configuration类中加入即可
@Configuration
public class Registration{
@Bean  
public ServletRegistrationBean myServlet() {  
	ServletRegistrationBean myServlet = new ServletRegistrationBean();  
	myServlet.addUrlMappings("/servlet");  
	myServlet.setServlet(new MyServlet());  
	return myServlet;  
}
}
②使用@WebServlet
使用@WebServlet注册，需要在Servlet类上使用该注解即可，
但是需要在@Configuration类中使用@ServletComponentScan扫描注册相应的Servlet
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>注册Filter
注意注册多个filter要自己一个个注册不要挤在一起
①使用FilterRegistrationBean注册
使用FilterRegistrationBean注册Filter，只需要在@Configuration类中加入即可
@Bean  
public FilterRegistrationBean myFilter() {  
	FilterRegistrationBean myFilter = new FilterRegistrationBean();  
	myFilter.addUrlPatterns("/*");  
	myFilter.setFilter(new MyFilter());  
	return myFilter;  
}  
②使用@WebFilter
使用@WebFilter注册，需要在Filter类上使用该注解即可，
但是需要在@Configuration类中使用@ServletComponentScan扫描注册相应的Filter。
 
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>注册Listener
①使用ServletListenerRegistrationBean注册
使用ServletListenerRegistrationBean注册Listener只需要在@Configuration类中加入即可
@Bean  
public ServletListenerRegistrationBean&lt;MyListener&gt; myServletListener() {  
	ServletListenerRegistrationBean&lt;MyListener&gt; myListener = 
	new ServletListenerRegistrationBean&lt;MyListener&gt;();
	myListener.setListener(new MyListener());  
	return myListener;  
}  
②使用@WebListener
使用@WebListener注册，需要在Filter类上使用该注解即可，
但是需要在@Configuration类中使用Spring Boot提供的注解
@ServletComponentScan扫描注册相应的Listener
</code></pre></div><h1>10. springboot常见问题</h1>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/03d148b38878303db4ee4.png" alt="47.png" tabindex="0"><figcaption>47.png</figcaption></figure>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>Slf4j日志警告
提示我们当前的项目中slf4j引入了2个，导致了jar冲突。
解决：删除自己引入到slf4j的依赖
&lt;dependency&gt;
	&lt;groupId&gt;org.slf4j&lt;/groupId&gt;
	&lt;artifactId&gt;slf4j-log4jl2&lt;/artifactId&gt;
&lt;/dependency&gt;

jsp访问404的问题
由于Spring boot使用的内嵌的tomcat，而内嵌的tamcat是不支持jsp页面的，
导包
&lt;dependency&gt;
	&lt;groupId&gt;org.apache.tomcat.embed&lt;/groupId&gt;
	&lt;artifactId&gt;tomcat-embed-jasper&lt;/artifactId&gt;
	&lt;scope&gt;provided&lt;/scope&gt;
&lt;/dependency&gt;
</code></pre></div>]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/03d148b38878303db4ee4.png" type="image/png"/>
    </item>
    <item>
      <title>SpringCloud</title>
      <link>https://javaguide.cn/backend/j2ee/springcloud.html</link>
      <guid>https://javaguide.cn/backend/j2ee/springcloud.html</guid>
      <source url="https://javaguide.cn/rss.xml">SpringCloud</source>
      <description>1. springcloud常用组件 1.1. 服务发现与注册ZooKeeper、Eureka、consoul 1.2. 服务间调用Feign与断路器Hystrix 1.3. 网关Zuul、gatyway 1.4. 分布式配置consul 1.5. 负载均衡Ribbon 1. springcloud常用组件 1.1. 服务发现与注册ZooKeeper、...</description>
      <category>后端</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<!-- TOC -->
<ul>
<li><a href="#1-springcloud%E5%B8%B8%E7%94%A8%E7%BB%84%E4%BB%B6">1. springcloud常用组件</a>
<ul>
<li><a href="#11-%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0%E4%B8%8E%E6%B3%A8%E5%86%8Czookeepereurekaconsoul">1.1. 服务发现与注册ZooKeeper、Eureka、consoul</a></li>
<li><a href="#12-%E6%9C%8D%E5%8A%A1%E9%97%B4%E8%B0%83%E7%94%A8feign%E4%B8%8E%E6%96%AD%E8%B7%AF%E5%99%A8hystrix">1.2. 服务间调用Feign与断路器Hystrix</a></li>
<li><a href="#13-%E7%BD%91%E5%85%B3zuulgatyway">1.3. 网关Zuul、gatyway</a></li>
<li><a href="#14-%E5%88%86%E5%B8%83%E5%BC%8F%E9%85%8D%E7%BD%AEconsul">1.4. 分布式配置consul</a></li>
<li><a href="#15-%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1ribbon">1.5. 负载均衡Ribbon</a></li>
</ul>
</li>
</ul>
<!-- /TOC -->
<!--more-->
<h1>1. springcloud常用组件</h1>
<h2>1.1. 服务发现与注册ZooKeeper、Eureka、consoul</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>//只需要使用 @EnableEurekaServer 注解就可以让应用变为 Eureka Server
@EnableEurekaServer
@SpringBootApplication
public class EurekaApplication {
    public static void main(String[] args) {
        SpringApplication.run(EurekaApplication.class, args);
    }
}

eureka:
  instance:
    hostname: localhost
  client:
    # eureka.client.fetch-registry: 表示是否从 Eureka Server 获取注册信息，默认为true。如果这是一个单点的 Eureka Server，不需要同步其他节点的数据，设为false
    fetch-registry: false
    # eureka.client.register-with-eureka: 表示是否将自己注册到 Eureka Server, 默认为true。由于当前应用就是 Eureka Server, 因此设为 false
    register-with-eureka: false
    # 设置 Eureka Server 所在的地址，查询服务和注册服务都需要依赖这个地址
    service-url:
      defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/

pom.xml
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre></div><ul>
<li>Eureka client</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>//只需要使用 @EnableEurekaClient 注解就可以让应用变为 Eureka Client
@EnableEurekaClient
@SpringBootApplication
public class HomepageCourseApplication {
    public static void main(String[] args) {
        SpringApplication.run(HomepageCourseApplication.class, args);
    }
}

eureka:
  client:
    service-url:
      defaultZone: http://localhost:8000/eureka/

pom.xml
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre></div><ul>
<li>服务注册与发现consul</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>默认端口8500
启动命令consul agent -client 0.0.0.0 -dev -config-dir=config-dev
mysql.json
{
	"service": 
	{
		"id": "mysql",
		"name": "mysql",
		"tags": ["mysql"],
		"address": "127.0.0.1",
		"port": 3306,
		"checks": 
		[
			{
				"id": "mysql",
    			"name": "mysql",
    			"tcp": "127.0.0.1:3306",
    			"interval": "60s",
    			"timeout": "2s"
			}
		]
	}
}

java注册
@EnableDiscoveryClient
@RestController

spring.cloud.consul.enabled=true
spring.cloud.consul.host=localhost
spring.cloud.consul.port=8500
spring.cloud.consul.discovery.serviceName=xlsys-hscl-distributed-server
spring.cloud.consul.discovery.tags=xlsys,xlsys-server,xlsys-hscl-distributed-server
spring.cloud.consul.discovery.prefer-ip-address=true
spring.cloud.consul.discovery.instance-id=server2
spring.cloud.consul.discovery.healthCheckPath=/xlsys-check
spring.cloud.consul.discovery.healthCheckInterval=2s
</code></pre></div><h2>1.2. 服务间调用Feign与断路器Hystrix</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>@EnableFeignClients
@EnableCircuitBreaker
@EnableEurekaClient
@SpringBootApplication
public class HomepageUserApplication {

    public static void main(String[] args) {

        SpringApplication.run(HomepageUserApplication.class, args);
    }
}
与spring:application:name: eureka-client-homepage-course对应CourseClientHystrix熔断降级策略
@FeignClient(value = "eureka-client-homepage-course", fallback = CourseClientHystrix.class)
public interface CourseClient {

    @RequestMapping(value = "/homepage-course/get/course", method = RequestMethod.GET)
    CourseInfo getCourseInfo(Long id);

    @RequestMapping(value = "/homepage-course/get/courses", method = RequestMethod.POST)
    List&lt;CourseInfo&gt; getCourseInfos(@RequestBody CourseInfosRequest request);
}

@Component
public class CourseClientHystrix implements CourseClient {

    @Override
    public CourseInfo getCourseInfo(Long id) {
        return CourseInfo.invalid();
    }

    @Override
    public List&lt;CourseInfo&gt; getCourseInfos(CourseInfosRequest request) {
        return Collections.emptyList();
    }
}

feign:
  hystrix:
    enabled: true
hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds=180000
&lt;!-- 引入 Feign, 可以以声明的方式调用微服务 --&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;
&lt;/dependency&gt;
&lt;!-- 引入服务容错 Hystrix 的依赖 --&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre></div><h2>1.3. 网关Zuul、gatyway</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>//SpringCloudApplication = @SpringBootApplication + @EnableDiscoveryClient + @EnableCircuitBreaker
@EnableZuulProxy
@SpringCloudApplication
public class ZuulGatewayApplication {

    public static void main(String[] args) {

        SpringApplication.run(ZuulGatewayApplication.class, args);
    }
}
server:
  port: 9000

zuul:
  prefix: /imooc
  routes:
    course:
      path: /homepage-course/** ==&gt;server.servlet.context-path:/homepage-course
      serviceId: eureka-client-homepage-course ==&gt;spring.application.name:eureka-client-homepage-course
      strip-prefix: false
    user:
      path: /homepage-user/**
      serviceId: eureka-client-homepage-user
      strip-prefix: false
访问网关：http://网关服务ip:网关服务的端口号/imooc/....
不访问网关：http://普通服务ip:普通服务的端口号/....

pom.xml
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre></div><ul>
<li>网关gateway</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>spring.cloud.gateway.discovery.locator.enabled=true
spring.cloud.gateway.discovery.locator.lower-case-service-id=true
spring.cloud.gateway.httpclient.ssl.useInsecureTrustManager=true
spring.cloud.gateway.httpclient.ssl.handshake-timeout-millis=10000
spring.cloud.gateway.httpclient.ssl.close-notify-flush-timeout-millis=3000
spring.cloud.gateway.httpclient.ssl.close-notify-read-timeout-millis=0
</code></pre></div><h2>1.4. 分布式配置consul</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>spring.cloud.consul.config.enabled=true
spring.cloud.consul.config.format=PROPERTIES
spring.cloud.consul.config.prefix=config
spring.cloud.consul.config.data-key=data

@EnableFeignClients //启用OpenFeign

服务间调用
@FeignClient("server2")
public interface OpenFeginDemo {
    @GetMapping("/testserver2")
    public String test();
}
</code></pre></div><h2>1.5. 负载均衡Ribbon</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>ribbon.ConnectTimeout=30000
ribbon.ReadTimeout=60000
ribbon.SocketTimeout=60000
</code></pre></div>]]></content:encoded>
    </item>
    <item>
      <title>SpringCloudAlibaba</title>
      <link>https://javaguide.cn/backend/j2ee/springcloudalibaba.html</link>
      <guid>https://javaguide.cn/backend/j2ee/springcloudalibaba.html</guid>
      <source url="https://javaguide.cn/rss.xml">SpringCloudAlibaba</source>
      <description>利用Spring官方向导构建Spring Cloud Alibaba idea-&amp;gt;new Project-&amp;gt;选择springboot版本-&amp;gt;Web-&amp;gt;Spring Web-&amp;gt;create 1.pom.xml加入版本参数和依赖管理器和nacos 2.application.properties newproject.pngnewproject.png n...</description>
      <category>后端</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<!-- TOC -->
<h1>利用Spring官方向导构建Spring Cloud Alibaba</h1>
<ul>
<li>idea-&gt;new Project-&gt;选择springboot版本-&gt;Web-&gt;Spring Web-&gt;create</li>
<li>1.pom.xml加入版本参数和依赖管理器和nacos</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>&lt;properties&gt;
    &lt;java.version&gt;17&lt;/java.version&gt;
    &lt;!--1.加入下面2个--&gt;
    &lt;spring-cloud.version&gt;2022.0.1&lt;/spring-cloud.version&gt;
    &lt;spring-cloud-alibaba.version&gt;2022.0.0.0-RC1&lt;/spring-cloud-alibaba.version&gt;
&lt;/properties&gt;

&lt;dependencies&gt;
  &lt;dependency&gt;
        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
        &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
        &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;
        &lt;scope&gt;test&lt;/scope&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;
        &lt;artifactId&gt;lombok&lt;/artifactId&gt;
    &lt;/dependency&gt;
    &lt;!--3.引入nacos--&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;
        &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;
    &lt;/dependency&gt;
&lt;/dependencies&gt;

&lt;dependencyManagement&gt;
    &lt;dependencies&gt;
        &lt;!--2.加入2个依赖管理器--&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt;
            &lt;version&gt;${spring-cloud.version}&lt;/version&gt;
            &lt;type&gt;pom&lt;/type&gt;
            &lt;scope&gt;import&lt;/scope&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt;
            &lt;version&gt;${spring-cloud-alibaba.version}&lt;/version&gt;
            &lt;type&gt;pom&lt;/type&gt;
            &lt;scope&gt;import&lt;/scope&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;
&lt;/dependencyManagement&gt;
</code></pre></div><ul>
<li>2.application.properties</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>
server.port=80
# nacos参数
spring.application.name=first-microservice
spring.cloud.nacos.discovery.username=nacos
spring.cloud.nacos.discovery.password=nacos
spring.cloud.nacos.discovery.server-addr=nacos:8848
spring.cloud.nacos.discovery.namespace=public
</code></pre></div><figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/a05791cc2ebf7434eb2aa.jpg" alt="newproject.png" tabindex="0"><figcaption>newproject.png</figcaption></figure>
<h1>nacos心跳机制</h1>
<ul>
<li>健康检查机制：客户端主动上报或者服务端主动向客户端探测</li>
<li>主流的注册中心，包括nacos的健康检查机制主要都采用了 TTL（Time To Live）机制，即客户端在⼀定时间没有向注册中心发送心跳，那么注册中心会认为此服务不健康，进而触发后续的剔除逻辑</li>
<li>Nacos 提供了两种服务类型供用户注册实例时选择，实例分为临时实例和永久实例。
<ul>
<li>临时实例只是临时存在于注册中心中，会在服务下线或不可用时被注册中心剔除，
<ul>
<li>OpenAPI 进行服务注册。实际是用户根据自身需求调用 Http 接口对服务进行注册，然后通过 Http 接口发送心跳到注册中心。在注册服务的同时会注册⼀个全局的客户端心跳检测的任务。在服务⼀段时间没有收到来自客户端的心跳后，该任务会将其标记为不健康，如果在间隔的时间内还未收到心跳，那么该任务会将其剔除。</li>
<li>SDK 的注册方式实际是通过 RPC 与注册中心保持连接。客户端会定时的通过 RPC 连接向 Nacos 注册中心发送心跳，保持连接的存活。如果客户端和注册中心的连接断开，那么注册中心会主动剔除该 client 所注册的服务，达到下线的效果。</li>
</ul>
</li>
<li>永久实例健康检查机制：永久实例永不提除但是会心跳失败。Nacos 中使用 SDK 对于永久实例的注册实际也是使用 OpenAPI 的方式进行注册，这样可以保证即使是客户端下线后也不会影响永久实例的健康检查。Nacos 采用的是注册中心探测机制，注册中心会在永久服务初始化时根据客户端选择的协议类型注册探活的定时任务。Nacos 现在内置提供了三种探测的协议，即Http、TCP 以及 MySQL 。⼀般而言 Http 和 TCP 已经可以涵盖绝大多数的健康检查场景。</li>
</ul>
</li>
<li>对于集群下的服务，Nacos ⼀个服务只会被 Nacos 集群中的⼀个注册中心所负责，其余节点的服务信息只是集群副本，用于订阅者在查询服务列表时，始终可以获取到全部的服务列表。临时实例只会对其被负责的注册中心节点发送心跳信息，注册中心服务节点会对其负责的永久实例进行健康探测，在获取到健康状态后由当前负责的注册中心节点将健康信息同步到集群中的其他的注册中心。</li>
<li>在 Nacos 中，服务的注册我们从注册方式维度实际可以分为两大类。
<ul>
<li>SDK RPC 连接进行注册，客户端会和注册中心保持链接。只需要和注册中心集群中的任意⼀台节点建立联系，那么由这个节点负责这个客户端就可以了。注册中心会在启动时注册⼀个全局的同步任务，用于将其当前负责的所有节点信息同步到集群中的其他节点，其他非负责的节点也会创建该客户端的信息，在非负责的节点上，连接类型的客户端，会有⼀个续约时间的概念，在收到其他节点的同步信息时，更新续约时间为当前时间，如果在集群中的其他节点在⼀段时间内没有收到不是自己的负责的节点的同步信息，那么认为此节点已经不健康，从而达到对不是自己负责的节点健康状态检查。</li>
<li>OpenAPI 进行 IP 和端口注册。OpenAPI 注册的临时实例也是通过同步自身负责的节点到其他节点来更新其他节点的对应的临时实例的心跳时间，保证其他节点不会删除或者修改此实例的健康状态。前面我们特别指明了是临时实例而没有说所有实例，你应该也可能会想到这种方式对于持久化节点会显得多余，永久实例会在被主动删除前⼀直存在于注册中心，那么我们健康检查并不会去删除实例，所以我们只需要在负责的节点永久实例健康状态变更的时候通知到其余的节点即可。</li>
</ul>
</li>
<li>最后。如果不是给集群中raft算法节点的leader发送请求，则该节点会转发到leader去，leader判断完再同步到当前节点</li>
</ul>
<h1>临时节点与永久节点配置</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code># 默认临时节点
# 开启查看心跳包日志
logging.level.root=debug
# 临时节点基于心跳包形式向Nacos发送，每5秒发送一次
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>
logging.level.root=debug
# 开启永久节点
spring.cloud.nacos.discovery.ephemeral=false
# 一定要配置这个ip段，否则nacos服务端对客户端探测再多网卡情况下不知道对走哪个网卡
spring.cloud.inetutils.preferred-networks=192.168.31
# 永久节点每秒会接收到来自Nacos的探查
</code></pre></div><h1>Raft算法与Distro算法</h1>
<p>Raft算法用于服务数据持久化，保证一致性，首先低频，需要关注所有节点数据一致性<br>
Distro算法用于服务注册，关注性能而不太关注数据库，而且Raft算法如果3个节点有2个挂了就挂了，显然不合理</p>
<h1>客户端负载均衡器与Spring Cloud Loadbalancer</h1>
<ul>
<li>Spring Cloud Loadbalancer不用写ip只用写服务名</li>
<li>Spring Cloud Loadbalancer初始化时去注册中心查询可用服务列表并保存到内存，服务上下线时注册中心会推送消息Spring Cloud Loadbalancer并更新可用服务列表</li>
</ul>
<h1>OpenFeign</h1>
<ul>
<li>OpenFeign是Spring Cloud项目中的一个模块，它是基于Feign开发的，可以看作是对Feign的进一步封装和增强。Feign是一个声明式、模板化的HTTP客户端，它的目标是简化HTTP API开发。OpenFeign在Feign的基础上增加了对Spring MVC注解、Spring Boot自动配置等特性的支持，并且集成了Spring Cloud的服务发现和负载均衡功能。相比于Feign，OpenFeign更适合在Spring Cloud微服务架构中使用。</li>
<li>1.依赖</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-starter-loadbalancer&lt;/artifactId&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre></div><ul>
<li>2.config类增加@EnableFeignClients注解</li>
<li>3.一个基于Spring Cloud的Feign客户端接口。其中，@FeignClient(name = "provider-service")标注表示该接口是对名为"provider-service"的服务进行调用，这个服务名称通常是在配置文件中指定的，用于实现服务发现。<br>
接口中定义了三个方法，它们对应着服务提供者中的三个API接口。</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>package com.itlaoqi.consumerserviceopenfeign.feignclient;

import com.itlaoqi.consumerserviceopenfeign.dto.User;
import org.springframework.cloud.openfeign.FeignClient;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.PathVariable;
import org.springframework.web.bind.annotation.PostMapping;
import org.springframework.web.bind.annotation.RequestBody;
import org.springframework.web.bind.annotation.RequestParam;

import java.util.List;
import java.util.Map;

@FeignClient(name = "provider-service")
public interface ProviderServiceFeignClient {

    @GetMapping("/hello")
    Map&lt;String, Object&gt; sendMessage();

    @PostMapping("/user/{uid}")
    User createUser(@PathVariable("uid") String uid, @RequestBody User user);

    @GetMapping("/list")
    List&lt;User&gt; query(@RequestParam("page") int page, @RequestParam("rows") int rows);
}

</code></pre></div><ul>
<li>4.使用</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>package com.itlaoqi.consumerserviceopenfeign.controller;

import com.itlaoqi.consumerserviceopenfeign.dto.User;
import com.itlaoqi.consumerserviceopenfeign.feignclient.ProviderServiceFeignClient;
import jakarta.annotation.Resource;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.RestController;

import java.util.List;

@RestController
public class ConsumerController {
    @Resource
    private ProviderServiceFeignClient providerServiceFeignClient;
    @GetMapping("/do1")
    public List doSth1(){
        List&lt;User&gt; userList = providerServiceFeignClient.query(1, 10);
        return userList;
    }

    @GetMapping("/do2")
    public User doSth2(){
        String uid="10";
        User user = providerServiceFeignClient.createUser(uid, new User(uid, "testUser", "testPassword", "testNickname"));
        return user;
    }

    @GetMapping("/do3")
    public String doSth3(){
        String result = providerServiceFeignClient.hello();
        return result;
    }
}

</code></pre></div><h1>gateway</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>  &lt;dependency&gt;
      &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
      &lt;artifactId&gt;spring-cloud-starter-loadbalancer&lt;/artifactId&gt;
  &lt;/dependency&gt;

  &lt;dependency&gt;
      &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
      &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;
  &lt;/dependency&gt;
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>spring:
  application:
    name: gateway
  cloud:
    nacos:
      discovery:
        username: nacos
        password: nacos
        server-addr: nacos:8848
    gateway:#自动根据服务名匹配
      discovery:
        locator:
          enabled: true
server:
  port: 80


</code></pre></div><h1>gateway自定义谓词</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code># TokenHeader为谓词前缀，Springcloud会自动将RoutePredicateFactory后缀注册为谓词
package com.itlaoqi.gateway.predicate;

import org.springframework.cloud.gateway.handler.predicate.AbstractRoutePredicateFactory;
import org.springframework.http.HttpHeaders;
import org.springframework.stereotype.Component;
import org.springframework.web.server.ServerWebExchange;

import java.util.Arrays;
import java.util.List;
import java.util.Map;
import java.util.Set;
import java.util.function.Predicate;

@Component
public class TokenHeaderRoutePredicateFactory extends AbstractRoutePredicateFactory&lt;TokenHeaderRoutePredicateFactory.Config&gt; {

    public TokenHeaderRoutePredicateFactory() {
        super(Config.class);
    }

    @Override
    public Predicate&lt;ServerWebExchange&gt; apply(Config config) {
        return exchange -&gt; {
            Set&lt;Map.Entry&lt;String, List&lt;String&gt;&gt;&gt; headers = exchange.getRequest().getHeaders().entrySet();
            for(Map.Entry me : headers){
                if(me.getKey().equals(config.getHeaderName())){
                    return true;
                }
            }
            return false;
        };
    }

    public static class Config {
        private String headerName;

        public String getHeaderName() {
            return headerName;
        }

        public void setHeaderName(String headerName) {
            this.headerName = headerName;
        }
    }

    @Override
    public List&lt;String&gt; shortcutFieldOrder() {
        return Arrays.asList("headerName");
    }
}

</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>spring:
    ...
    gateway:
      discovery:
        locator:
          enabled: false
      routes:
        - id: route_user_service 
          uri: lb://gateway-user-service
          predicates:
            - Path=/user/** 
            - TokenHeader=Token # 谓词前缀与谓词名称
          filters:
            - StripPrefix=1
</code></pre></div><h1>nacos config</h1>
<p>grpc长连接监听</p>
<div class="language-pom.xml" data-ext="pom.xml" data-title="pom.xml"><pre class="language-pom.xml"><code>&lt;!-- Nacos配置中心starter --&gt;
&lt;dependency&gt;
  &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;
  &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
  &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
  &lt;artifactId&gt;spring-cloud-starter-bootstrap&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre></div><p>tax-service-dev.yaml</p>
<div class="language-bootstrap.yml" data-ext="bootstrap.yml" data-title="bootstrap.yml"><pre class="language-bootstrap.yml"><code>spring:
  application:
    name: tax-service
  profiles:
    active: dev
  cloud:
    nacos:
      config:
        file-extension: yml
        server-addr: 192.168.31.231:8848
        username: nacos
        password: nacos
logging:
  level:
    root: info

</code></pre></div><p>@RefreshScope</p>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>package com.itlaoqi.nacosconfig.config;

import lombok.Data;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.cloud.context.config.annotation.RefreshScope;
import org.springframework.context.annotation.Configuration;

@Configuration
@RefreshScope
@Data
public class Setting {
    @Value("${setting.upload-addr}")
    private String uploadAddr;
    @Value("${setting.path}")
    private String path;
}
</code></pre></div>]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/a05791cc2ebf7434eb2aa.jpg" type="image/jpeg"/>
    </item>
    <item>
      <title>web</title>
      <link>https://javaguide.cn/backend/j2ee/web.html</link>
      <guid>https://javaguide.cn/backend/j2ee/web.html</guid>
      <source url="https://javaguide.cn/rss.xml">web</source>
      <description>web 1. WEB三大规范 2. javax.servlet.Servlet servlet 3. javax.servlet.http.HttpServlet 4. javax.servlet.ServletRequest 5. javax.servlet.http.HttpServletRequest 6. javax.servlet.Servl...</description>
      <category>后端</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>web</p>
<!--more-->
<!-- TOC -->
<ul>
<li><a href="#1-web%E4%B8%89%E5%A4%A7%E8%A7%84%E8%8C%83">1. WEB三大规范</a></li>
<li><a href="#2-javaxservletservlet-servlet">2. javax.servlet.Servlet servlet</a></li>
<li><a href="#3-javaxservlethttphttpservlet">3. javax.servlet.http.HttpServlet</a></li>
<li><a href="#4-javaxservletservletrequest">4. javax.servlet.ServletRequest</a></li>
<li><a href="#5-javaxservlethttphttpservletrequest">5. javax.servlet.http.HttpServletRequest</a></li>
<li><a href="#6-javaxservletservletresponse">6. javax.servlet.ServletResponse</a></li>
<li><a href="#7-javaxservlethttphttpservletresponse">7. javax.servlet.http.HttpServletResponse</a></li>
<li><a href="#8-javaxservletservletcontext">8. javax.servlet.ServletContext</a></li>
<li><a href="#9-javaxservletservletconfig">9. javax.servlet.ServletConfig</a></li>
<li><a href="#10-javaxservlethttpcookie">10. javax.servlet.http.Cookie</a></li>
<li><a href="#11-javaxservlethttphttpsession">11. javax.servlet.http.HttpSession</a></li>
<li><a href="#12-javautileventlistener">12. java.util.EventListener</a></li>
<li><a href="#13-javaxservletservletcontextlistener">13. javax.servlet.ServletContextListener</a></li>
<li><a href="#14-javaxservlethttphttpsessionlistener">14. javax.servlet.http.HttpSessionListener</a></li>
<li><a href="#15-javaxservletservletrequestlistener">15. javax.servlet.ServletRequestListener</a></li>
<li><a href="#16-javaxservletservletcontextattributelistener">16. javax.servlet.ServletContextAttributeListener</a></li>
<li><a href="#17-javaxservlethttphttpsessionattributelistener">17. javax.servlet.http.HttpSessionAttributeListener</a></li>
<li><a href="#18-javaxservletservletrequestattributelistener">18. javax.servlet.ServletRequestAttributeListener</a></li>
<li><a href="#19-javaxservlethttphttpsessionbindinglistener">19. javax.servlet.http.HttpSessionBindingListener</a></li>
<li><a href="#20-javaxservlethttphttpsessionactivationlistener">20. javax.servlet.http.HttpSessionActivationListener</a></li>
<li><a href="#21-javaxservletfilter">21. javax.servlet.Filter</a></li>
<li><a href="#22-webxml%E9%85%8D%E7%BD%AE">22. web.xml配置</a></li>
<li><a href="#23-%E6%96%87%E4%BB%B6%E4%B8%8B%E8%BD%BD">23. 文件下载</a></li>
<li><a href="#24-mail">24. mail</a></li>
<li><a href="#25-%E8%BD%AC%E5%8F%91%E4%B8%8E%E9%87%8D%E5%AE%9A%E5%90%91%E7%9A%84%E5%8C%BA%E5%88%AB">25. 转发与重定向的区别</a></li>
<li><a href="#26-javaee%E5%AF%B9%E8%B1%A1%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F">26. javaee对象生命周期</a></li>
</ul>
<!-- /TOC -->
<h1>1. WEB三大规范</h1>
<ul>
<li>servlet、filter、listener</li>
<li>request客户端发送的参数 到服务器端都是字符串</li>
</ul>
<h1>2. javax.servlet.Servlet servlet</h1>
<ul>
<li>用于获取请求数据、处理请求、完成响应</li>
<li>使用servlet可以实现servlet接口并配置web.xml，但是不推荐</li>
<li>init(ServletConfig config);//servlet对象创建的时候执行ServletConfig:代表的是该servlet对象的配置信息</li>
<li>service(ServletRequest request,ServletResponse response);//每次请求都会执行</li>
<li>destroy();//servlet销毁的时候执行</li>
</ul>
<h1>3. javax.servlet.http.HttpServlet</h1>
<ul>
<li>使用servlet可以继承HttpServlet并复写HttpServlet类的doGet、doPost方法并配置web.xml</li>
<li>init();//servlet对象创建的时候执行</li>
<li>doGet(HttpServletRequest request,HttpServletResponse response);//每次get请求都会执行</li>
<li>doPost(HttpServletRequest request,HttpServletResponse response);//每次post请求都会执行</li>
<li>destroy();//servlet销毁的时候执行</li>
</ul>
<h1>4. javax.servlet.ServletRequest</h1>
<h1>5. javax.servlet.http.HttpServletRequest</h1>
<ul>
<li>获得请求行
<ul>
<li>String getContextPath()获得”/“+web应用名称,例如/WEB15_request</li>
<li>String getMethod()</li>
<li>String getRequestURI()获得相对web应用地址/WEB15_request/line</li>
<li>String getRequestURL()获得绝对路径<a href="http://localhost:8080/WEB15_request/line" target="_blank" rel="noopener noreferrer">http://localhost:8080/WEB15_request/line</a></li>
<li>String getRemoteAddr()获得访问的客户端IP地址</li>
<li>String getQueryString()get提交url地址后的参数字符串username=lisi&amp;password=123</li>
<li>String getProtocol();获取请求行中的协议名和版本</li>
<li>String getServletPath();</li>
<li>String getRemotePort();</li>
<li>String getRemoteHost();</li>
<li>String getLocalAddr();</li>
<li>String getLocalName();</li>
<li>String getLocalHost();</li>
<li>int getLocalPort();</li>
<li>String getServerName();</li>
<li>int getServerPort();</li>
<li>String getScheme();//获取请求协议名</li>
<li>StringBuffer getRequestURL();</li>
</ul>
</li>
<li>获得请求头
<ul>
<li>String getHeader（String name）</li>
<li>Enumeration getHeaders(String name)</li>
<li>Enumeration getHeaderNames()</li>
<li>Long getDateHeader(String name)</li>
<li>int getIntHeader(String name)</li>
<li>String getContentType()</li>
<li>int getContentLength()</li>
<li>String getCharacterEncoding()</li>
</ul>
</li>
<li>获得请求体
<ul>
<li>String getParameter(String name) 多个只获得一个，没有则返回null</li>
<li>Map&lt;String,String[]&gt; getParameterMap()获得指定参数名对应的所有键值</li>
<li>String[] getParameterValues(String name)获得指定参数名对应的所有值（少用）</li>
<li>Enumeration getParameterNames()</li>
</ul>
</li>
<li>乱码：浏览器的中文用UTF-8编码，而HTTP协议使用iSO8859-1编码。不同的浏览器接收和发送数据取决于浏览器类型，通过Http请求体中的User-Agent属性可以辨别
<ul>
<li>post乱码 request.setCharacterEncoding("UTF-8");</li>
<li>get乱码 String parameter=new String(parameter.getbytes("iso8859-1"),"utf-8");</li>
</ul>
</li>
<li>转发 request.getRequestDispatcher(”/?”).forward(req,resp);</li>
<li>域对象
<ul>
<li>Object setAttribute (String name, Object o)set注意名字相同时则覆盖</li>
<li>String getAttribute(String name)</li>
<li>void removeAttribute(String name)</li>
</ul>
</li>
</ul>
<h1>6. javax.servlet.ServletResponse</h1>
<h1>7. javax.servlet.http.HttpServletResponse</h1>
<ul>
<li>设置响应行
<ul>
<li>void setStatus(int sc)</li>
<li>void sendError(int sc,[String messge])</li>
</ul>
</li>
<li>设置响应头(值不重复)
<ul>
<li>void addHeader(String name, String value)</li>
<li>void setHeader(String name, String value);</li>
</ul>
</li>
<li>设置定时刷新的头:setHeader("refresh", "5;url=<a href="http://www.baidu.com" target="_blank" rel="noopener noreferrer">http://www.baidu.com</a>");
<ul>
<li>void addIntHeader(String name, int value)</li>
<li>void setIntHeader(String name, int value)</li>
<li>void addDateHeader(String name, long date)</li>
<li>void setDateHeader(String name, long date)</li>
<li>void setContentLength(int len)</li>
<li>void setContentType(String type)</li>
<li>void setLocale(Locale loc)</li>
<li>void setCharacterEncoding(String charset)</li>
</ul>
</li>
<li>设置响应体
<ul>
<li>getWriter().write("")字符串，可以插入标签</li>
<li>getOutputStream().write(byte[] bytes) 因为getWriter()之前已调用getOutputStream(),故两者不能同时使用</li>
<li>setHeader("content-Type","text/html;charset=utf-8");中文乱码</li>
<li>sendRedirect("/WEB14/servlet2");重定向</li>
<li>setStatus(302);setHeader("Location", "/WEB14/servlet2");</li>
</ul>
</li>
</ul>
<h1>8. javax.servlet.ServletContext</h1>
<ul>
<li>获得ServletContext
<ul>
<li>ServletConfig.getServletContext();</li>
<li>this.getServletContext();（推荐）</li>
</ul>
</li>
<li>获得web.xml全局的初始化参数 getInitParameter(String name);</li>
<li>域对象(整个web应用)
<ul>
<li>void setAtrribute(String name,Object obj);</li>
<li>Object getAttribute(String name);</li>
<li>void removeAttribute(String name);</li>
</ul>
</li>
<li>WebContext目录内任何资源绝对路径
<ul>
<li>String getRealPath(String path);//:/WEB-INF/</li>
<li>InputStream getResourceAsStream(String path); 以/开头path相对WebContext目录InputStream</li>
</ul>
</li>
</ul>
<h1>9. javax.servlet.ServletConfig</h1>
<ul>
<li>获得该servlet在web.xml上的name String getServletName();</li>
<li>获得该servlet的初始化的参数
<ul>
<li>String getInitParameter(String name);</li>
<li>Enumeration getInitParameterNames();</li>
</ul>
</li>
<li>获得Servletcontext对象 ServletContext getServletContext();</li>
</ul>
<h1>10. javax.servlet.http.Cookie</h1>
<ul>
<li>cookie会以响应头的形式发送给客户端：set-cookie:”name=zhengsan”</li>
<li>cookie不能存储中文、它是浏览器缓存的一部分。</li>
<li>cookie数据存储在客户端本地，减少服务器端的存储的压力，安全性不好，客户端可以清除cookie,有大小和个数的限制</li>
<li>会话级别cookie：不设置cookie会存储在浏览器的内存中，随浏览器关闭销毁</li>
<li>持久级别cookie：设置cookie信息会被持久化到浏览器的磁盘文件里，过期浏览器自动删除</li>
<li>创建CookieCookie cookie = new Cookie(name,value)</li>
<li>持久化时间cookie.setMaxAge(秒);</li>
<li>请求时cookie被携带路径
<ul>
<li>cookie.setPath();不设置，cookie信息会在访问产生该cookie的web资源所在的路径都携带cookie信息，会覆盖</li>
<li>cookie.setPath("/WEB");访问WEB应用中的任何资源都携带cookie</li>
<li>cookie.setPath("/WEB/cookieServlet");访问WEB16中的cookieServlet时才携带cookie信息</li>
<li>cookie.setPath("/");代表访问tomcat下所有的web项目的cookie信息</li>
</ul>
</li>
<li>向客户端发送cookie response.addCookie(Cookie cookie);//如果路径和名称一样，两次add会覆盖</li>
<li>获得客户端的cookie Cookie[] cookies = request.getCookies();</li>
<li>获得cookie的键值 cookie.getName();cookie.getValue();</li>
<li>删除cookie
<ul>
<li>Cookie cookie = new Cookie("name","");//将cookie的name设置与删除的cookie一致</li>
<li>cookie.setPath("/WEB16");//将path设置成与要删除cookie的path一致</li>
<li>cookie.setMaxAge(0);//设置时间是0;</li>
<li>response.addCookie(cookie);</li>
</ul>
</li>
</ul>
<h1>11. javax.servlet.http.HttpSession</h1>
<ul>
<li>session将数据存储到服务器端，安全性相对好，增加服务器的压力，没有大小和个数限制</li>
<li>session会为每个客户端都创建一块内存空间存储客户的数据,但客户端需要每次都携带一个标识ID去服务器中寻找属于自己的内存空间。</li>
<li>所以说Session的实现是基于Cookie，Session需要借助于Cookie存储客户的唯一性标识JSESSIONID来辨别是哪个客户端</li>
<li>获得Session request.getSession([boolean create])</li>
<li>获得sessionid String getId()</li>
<li>设置session空闲时间 void setMaxInactiveInterval(int interval)</li>
<li>获得servletcontext ServletContext getServletContext()</li>
<li>session域
<ul>
<li>void setAttribute(String name,Object obj);</li>
<li>Object getAttribute(String name);</li>
<li>void removeAttribute(String name);</li>
</ul>
</li>
<li>销毁session void invalidate();</li>
</ul>
<h1>12. java.util.EventListener</h1>
<h1>13. javax.servlet.ServletContextListener</h1>
<ul>
<li>contextInitialized(ServlertContextEvent sre)</li>
<li>contextDestroyed(ServlertContextEvent sre)</li>
<li>ServletContext context = ServlertContextEvent.getServletContext();
<ul>
<li>①初始化：对象、数据、加载数据库驱动，连接池的初始化</li>
<li>②加载一些初始化的配置文件</li>
</ul>
</li>
</ul>
]]></content:encoded>
    </item>
    <item>
      <title>AbstractQueuedSynchronizer</title>
      <link>https://javaguide.cn/backend/java/aqs.html</link>
      <guid>https://javaguide.cn/backend/java/aqs.html</guid>
      <source url="https://javaguide.cn/rss.xml">AbstractQueuedSynchronizer</source>
      <description>AbstractQueuedSynchronizer</description>
      <category>源码</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>AbstractQueuedSynchronizer</p>
<!-- more -->
<h1>48. AQS 的原理是什么？共享模式有哪些？</h1>
<ul>
<li>
<p>AQS用来构建锁和同步器的框架，如ReentrantLock、ReentrantReadWriteLock，FutureTask等等皆是基于AQS的</p>
</li>
<li>
<p>思想：如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，阻塞该线程然后加入到CLH队列中等待被唤醒。AQS使用一个int成员变量(state) 来表示同步状态，通过内置的 FIFO 队列来完成获取资源线程的排队工作。使用 CAS 对该同步状态进行原子操作实现对其值的修改。</p>
</li>
<li>
<p>AQS资源共享方式</p>
<ul>
<li>Exclusive（独占）：只有一个线程能执行，如ReentrantLock。又可分为公平锁和非公平锁</li>
<li>Share（共享）：多个线程可同时执行，如Semaphore、CountDownLatch、CyclicBarrier、ReadWriteLock</li>
</ul>
</li>
<li>
<p>AQS的模板方法设计模式，推荐定义为静态内部类并按需要重写下面几个模板方法；这些方法的实现必须是内部线程安全的，非阻塞</p>
<ul>
<li>isHeldExclusively()//该线程是否正在独占资源。只有用到condition才需要去实现它</li>
<li>tryAcquire(int)//独占方式。尝试获取资源，成功则返回true，失败则返回false</li>
<li>tryRelease(int)//独占方式。尝试释放资源，成功则返回true，失败则返回false</li>
<li>tryAcquireShared(int)//共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源</li>
<li>tryReleaseShared(int)//共享方式。尝试释放资源，成功则返回true，失败则返回false</li>
</ul>
</li>
<li>
<p>在获取锁时，AQS维护一个双向同步队列，获取锁失败的线程会加入到队列中进行自旋直到获取锁退出，期间如果前驱节点被成功设置为signal则阻塞当前线程</p>
</li>
<li>
<p>在释放锁时，AQS会调用unparkSuccessor()方法唤醒后继节点</p>
</li>
</ul>
<h1>2. 同步队列节点(双向链表)</h1>
<ul>
<li>同步器依赖内部的同步CLH(Craig,Landin,and Hagersten)队列（一个FIFO双向队列）来完成同步状态的管理，将每条请求共享资源的线程封装成一个CLH锁队列的一个结点（Node）来实现锁的分配。当前线程获取同步状态成功时，将会被设置为同步队列首节点，由于已经获取同步状态成功，因此设置头节点的方法并不需要使用CAS来保证，它只需要将首节点设置成为原首节点的后继节点并断开原首节点的next引用即可。获取同步状态失败时，同步器会将当前线程以及等待状态等信息构造成为一个节点（Node）并将其加入同步队列尾部，同时会阻塞当前线程，加入队列的过程必须要保证线程安全，因此同步器提供了一个基于CAS的设置尾节点的方法：compareAndSetTail(Node expect,Node update)，它需要传递当前线程“认为”的尾节点和当前节点，只有设置成功后，当前节点才正式与之前的尾节点建立关联。当同步状态释放时，会把等待队列中后继节点线程唤醒，使其再次尝试获取同步状态。<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/e9915cfd1e0090d670830.jpg" alt="同步队列的基本结构.png"></li>
<li>同步队列中的节点（Node）用来保存获取同步状态失败的线程引用、等待状态以及前驱和后继节点</li>
<li>同步状态的管理volatile int state，通过getState，setState，compareAndSetState使用CAS对该同步状态进行原子操作实现对其值的修改</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer implements java.io.Serializable{

    static final class Node {
        static final Node SHARED = new Node();//节点在共享模式中等待
        static final Node EXCLUSIVE = null;//节点在独享模式等待

        static final int CANCELLED =  1;//当前节点的线程被取消（当前线程在同步队列中等待超时或者被中断）节点进入该状态将不会变化，线程也不会再阻塞/等待
        static final int SIGNAL    = -1;//当前节点的后继节点处于阻塞/等待状态，当前节点必须在释放或者被取消时通过signal方法唤醒后续节点，获得锁的方法acquire在signal方法后调用，为了避免竞争，必须重试原子获取锁，失败则阻塞
        static final int CONDITION = -2;//当前节点在等待Condition等待队列中等待被唤醒
        static final int PROPAGATE = -3;//表示下一次共享式同步状态获取将会无条件传播下去 
        volatile int waitStatus;//compareAndSetWaitStatus//同步队列的等待状态默认0;

        volatile Node prev;//predecessor 当前节点的前驱节点 当节点加入同步队列时被设置(尾部添加)
        volatile Node next;//successor 当前节点的后继节点
        volatile Thread thread;//加入同步队列的线程引用
        Node nextWaiter;//指向条件等待的下一个节点，或者特定的分享节点SHARED，节点类型(独占和共享)和等待队列中的后继节点共用同一个字段

        final boolean isShared() {//判断当前节点是不是在共享模式中等待
            return nextWaiter == SHARED;
        }

        final Node predecessor() throws NullPointerException {
            Node p = prev;
            if (p == null)
                throw new NullPointerException();
            else
                return p;
        }

        Node() {}    // Used to establish initial head or SHARED marker
    
        Node(Thread thread, Node mode) {     // Used by addWaiter
            this.nextWaiter = mode;
            this.thread = thread;
        }

        Node(Thread thread, int waitStatus) { // Used by Condition
            this.waitStatus = waitStatus;
            this.thread = thread;
        }
    }

    private transient volatile Node head;//compareAndSetHead
    private transient volatile Node tail;//compareAndSetTail

    private volatile int state;//set/get/compareAndSetState

}
</code></pre></div><h1>3. 独占锁的获取acquire(int arg)和释放release(int arg)</h1>
<ul>
<li>通过调用同步器的acquire(int arg)方法可以获取同步状态，该方法对中断不敏感，也就是由于线程获取同步状态失败后进入同步队列中，后续对线程进行中断操作时，线程不会从同步队列中移出，<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/3587c268ff7987d7194c7.jpg" alt="节点自旋获取同步状态.png"><br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/0dea4caed6f09b4eb4cad.jpg" alt="独占式同步状态获取流程.png"></li>
<li>独占式同步状态获取和释放过程总结：在获取同步状态时，同步器维护一个同步队列，获取状态失败的线程都会被加入到队列中并在队列中进行自旋；移出队列（或停止自旋）的条件是前驱节点为头节点且成功获取了同步状态。在释放同步状态时，同步器调用tryRelease(int arg)方法释放同步状态，然后唤醒头节点的后继节点。</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>    /*
    * 独占锁的获取
    *    尝试获取锁，失败则自旋加入同步队列队尾直到成功为止
    *    然后自旋尝试获取锁返回中断状态并退出，期间如果将前驱节点状态成功设置为signal后挂起当前线程，被唤醒后判断中断状态在获取锁后返回
    * 1 调用tryAcquire自定义同步器实现的子类方法，需要保证线程安全地获取锁，成功则返回，失败执行2
    * 2 调用addWaiter()将当前线程构造成独享类型的Node加入队列，并返回构造的节点Node，继续执行3
    * 3 调用acquireQueued()无限循环尝试获取锁，成功则返回中断状态，失败则将Node的前驱节点置为Sginal后挂起当前线程，被唤醒后判断当前线程的中断状态在成功获取锁后返回
    * 4 acquireQueued()返回true时，中断（停止）当前线程Thread.currentThread().interrupt()
    */
    public final void acquire(int arg) {
        if (!tryAcquire(arg)//1
            &amp;&amp; acquireQueued( //3
                addWaiter(Node.EXCLUSIVE),//2
            arg))
        selfInterrupt();//4
    }

    /*
    * 根据当前线程和mode构造Node加入同步队列尾部，并返回构造的节点Node
    * 2.1 根据当前线程和mode构造独占模式的节点Node
    * 2.2 若tail节点不为null则使用CAS操作compareAndSetTail将Node加入到队尾；快速入队成功则返回node，失败则执行3
    * 2.3 调用enq()无限循环初始化队头空节点或者使用CAS操作直到compareAndSetTail将Node加入到队尾中(自旋)
    *    2.3.1 如果tail为null，构造新的空节点，并将其设置为队列的Head，此时head=tail=new Node();
    *    2.3.2 如果tail不为null，使用CAS操作compareAndSetTail将Node加入到队尾(跟2一样)
    */
    private Node addWaiter(Node mode) {
        Node node = new Node(Thread.currentThread(), mode);//2.1
        Node pred = tail;
        if (pred != null) {//2.2
            node.prev = pred;
            /**
             * 基于CAS将node设置为尾节点，如果设置失败，说明在当前线程获取尾节点到现在这段过程中已经有其他线程将尾节点给替换过了，确保节点能够被线程安全添加
             * 假设有链表node1--&gt;node2--&gt;pred（当然是双链表，这里画成双链表才合适）,
             * 通过CAS将pred替换成了node节点，即当下的链表为node1--&gt;node2--&gt;node,
             * 然后根据上边的"node.prev = pred"与下边的"pred.next = node"将pred插入到双链表中去，组成最终的链表如下：
             * node1--&gt;node2--&gt;pred--&gt;node
             * 这样的话，实际上我们发现没有指定node2.next=pred与pred.prev=node2，这是为什么呢？
             * 因为在之前这两句就早就执行好了，即node2.next和pred.prev这两个属性之前就设置好了
             */
            if (compareAndSetTail(pred, node)) {
                pred.next = node;
                return node;
            }
        }
        enq(node);//2.3
        return node;
    }
    //同步器通过“死循环”来保证节点的正确添加，只有通过CAS将节点设置成为尾节点之后，当前线程才能从该方法返回，否则，当前线程不断地尝试设置。enq(final Node node)方法将并发添加节点的请求通过CAS变得“串行化”了。
    private Node enq(final Node node) {//2.3
        for (;;) {//2.3
            Node t = tail;
            if (t == null) { //2.3.1
                /*
                * 基于CAS将新节点（dummy节点）设置到头上head去，如果设置失败，则说明，在这个过程中，已经有其他线程设置过了
                * 如果设置成功则head=tail=new Node()，之后有新节点入队的话，就插入到该dummy之后
                */
                if (compareAndSetHead(new Node()))//空白的节点用来新建新的节点
                    tail = head;
            } else {//3.2
                node.prev = t;
                if (compareAndSetTail(t, node)) {
                    t.next = node;
                    return t;
                }
            }
        }
    }
    /* 
    * 节点进入同步队列后无限循环(自旋)直至获取锁退出，如果获取不到则阻塞，而被阻塞线程的唤醒主要依靠前驱节点的出队或阻塞线程被中断来实现。如果将Node的前置节点置为Sginal成功后挂起当前线程，线程被唤醒后判断中断状态
    * 1 无限循环
    * 2 同步队列获得锁的条件：如果当前驱节点为Head节点(保证FIFO和前驱节点不是头节点的线程由于中断而被唤醒情况)并且获取锁成功(注意异常)，将Node设置为头节点并返回是否中断的结果退出循环，否则执行3
    * 3 调用shouldParkAfterFailedAcquire()去掉在队列中前驱节点的CANCELLED状态的节点，借助无限循环将前驱节点状态通过CAS操作设置为SIGNAL，成功则执行4
    * 4 调用parkAndCheckInterrupt()挂起当前节点所在的线程并在被唤醒后判断线程中断状态
    * 5 finally调用cancelAcquire(node)将node从队列中去掉或者如果当前节点是头结点则唤醒后置节点
    */
    final boolean acquireQueued(final Node node, int arg) {
        boolean failed = true;
        try {
            boolean interrupted = false;
            for (;;) {//1
                final Node p = node.predecessor();
                if (p == head &amp;&amp; tryAcquire(arg)) {//2
                    setHead(node);
                    p.next = null; // help GC
                    failed = false;
                    return interrupted;
                }
                if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; //3
                    parkAndCheckInterrupt())//4
                    interrupted = true;
            }
        } finally {
            if (failed)
                cancelAcquire(node);//5
        }
    }
    /*
    *  判断前驱节点是否为signal并通过CAS操作将前驱节点的等待状态设置为signal
    *  1 如果前继节点状态为SIGNAL，表明当前节点需要被unpark(唤醒)，此时则返回true。
    *  2 如果前继节点状态为CANCELLED(ws&gt;0)，说明前继节点已经被取消，则通过先前回溯找到一个有效(非CANCELLED状态)的节点，并返回false。
    *  3 如果前继节点状态为非SIGNAL、非CANCELLED，则设置前继的状态为SIGNAL，并返回false
    */
    private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) {
        int ws = pred.waitStatus;
        if (ws == Node.SIGNAL)//1
            return true;
        if (ws &gt; 0) {//2
            do {
                //==&gt;pred = pred.prev;node.prev = pred;将当前节点的前驱节点换成前驱节点的前驱节点
                node.prev = pred = pred.prev;
            } while (pred.waitStatus &gt; 0);
            pred.next = node;
        } else {//3
            /*
             * 1/这为什么用CAS，现在已经入队成功了，前驱节点就是pred，除了node外应该没有别的线程在操作这个节点了，那为什么还要用CAS？而不直接赋值呢？
             * （解释：因为pred可以自己将自己的状态改为cancel，也就是pred的状态可能同时会有两条线程（pred和node）去操作）
             * 2/既然前驱节点已经设为SIGNAL了，为什么最后还要返回false
             * （因为CAS可能会失败，这里不管失败与否，都返回false，下一次执行该方法的之后，pred的等待状态就是SIGNAL了）
             */
            compareAndSetWaitStatus(pred, ws, Node.SIGNAL);//调用下面的
        }
        return false;
    }
    
    //挂起当前线程并返回中断状态
    private final boolean parkAndCheckInterrupt() {
        LockSupport.park(this);
        return Thread.interrupted();
    }

    /*
    * 将node从队列中去掉或者如果当前节点是头结点则唤醒后置节点
    * 1 如果node为null，则忽略(被GC回收了)
    * 2 将node的thread置为null
    * 3 如果node状态为CANCELLED，则通过回溯找到一个有效(非CANCELLED状态)的节点作为前驱节点
    * 4 将node状态设置为CANCELLED
    * 5 如果node是tail节点，则直接将前驱节点的后置节点设置为null
    * 6 如果当前节点Node不是tail节点
    *   6.1 如果当前节点的前驱节点不是head节点，则将当前节点Node的后置节点与前置节点通过CAS操作连接起来
    *   6.2 如果当前节点的前驱节点是head节点，则调用unparkSuccessor唤醒当前节点的后置节点
    */
    private void cancelAcquire(Node node) {
        if (node == null) return;//1

        node.thread = null;//2

        Node pred = node.prev;//3
        while (pred.waitStatus &gt; 0)
            node.prev = pred = pred.prev;

        Node predNext = pred.next;

        node.waitStatus = Node.CANCELLED;//4

        if (node == tail &amp;&amp; compareAndSetTail(node, pred)) {//5
            compareAndSetNext(pred, predNext, null);
        } else {
            int ws;
            if (pred != head &amp;&amp;
                ((ws = pred.waitStatus) == Node.SIGNAL ||
                 (ws &lt;= 0 &amp;&amp; compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) &amp;&amp;
                pred.thread != null) {
                Node next = node.next;
                if (next != null &amp;&amp; next.waitStatus &lt;= 0)
                    compareAndSetNext(pred, predNext, next);
            } else {
                unparkSuccessor(node);//6.2
            }

            node.next = node; // help GC
        }
    }
    /*
    * 功能 唤醒当前节点的后置节点
    * 1 Node节点的WaitStatus如果是非CANCELLED则尝试设置为0，设置成不成功无所谓
    * 2 找出Node节点的下一个节点，如果为null或者被CANCELLED则从尾结点轮询到头结点选出一个未被CANCELLED结点
    * 3 如果找到的Node节点不为null则直接唤醒该节点所在的线程
    */
    private void unparkSuccessor(Node node) {
        int ws = node.waitStatus;
        if (ws &lt; 0)
            compareAndSetWaitStatus(node, ws, 0);//1
            
        Node s = node.next;//2
        if (s == null || s.waitStatus &gt; 0) {
            s = null;
            for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev)
                if (t.waitStatus &lt;= 0)
                    s = t;
        }
        if (s != null)
            LockSupport.unpark(s.thread);//3
    }
    /*
    * 独占锁的释放
    *   1 调用子类tryRelease
    *   2 头结点不为空则唤醒头节点后继节点
    */
    public final boolean release(int arg) {
        if (tryRelease(arg)) {//1
            Node h = head;
            if (h != null &amp;&amp; h.waitStatus != 0)//2
                unparkSuccessor(h);
            return true;
        }
        return false;
    }
</code></pre></div><h1>5. 可中断式获取锁acquireInterruptibly(int arg)</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>    /*
    * 1 与acquire区别线程唤醒后如果处于中断状态则抛出中断异常
    */
    public final void acquireInterruptibly(int arg) throws InterruptedException {
        if (Thread.interrupted()) throw new InterruptedException();
        if (!tryAcquire(arg))
            doAcquireInterruptibly(arg);//3
    }
    private void doAcquireInterruptibly(int arg)
        throws InterruptedException {
        //将节点插入到同步队列中
        final Node node = addWaiter(Node.EXCLUSIVE);
        boolean failed = true;
        try {
            for (;;) {
                final Node p = node.predecessor();
                if (p == head &amp;&amp; tryAcquire(arg)) {
                    setHead(node);
                    p.next = null;
                    failed = false;
                    return;
                }
                if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;
                    parkAndCheckInterrupt())
                    throw new InterruptedException();//1
            }
        } finally {
            if (failed)
                cancelAcquire(node);
        }
    }

</code></pre></div><h1>6. 超时等待式获取锁tryAcquireNanos(int arg, long nanosTimeout)</h1>
<ul>
<li>doAcquireNanos(int arg,long nanosTimeout)方法可以超时获取同步状态，即在指定的时间段内获取同步状态，如果获取到同步状态则返回true，否则，返回false。如果当前线程被中断，会立刻返回，并抛出InterruptedException。而synchronized不具备该特性</li>
<li>独占式超时获取同步状态doAcquireNanos(int arg,long nanosTimeout)和独占式获取同步状态acquire(int args)在流程上非常相似，当节点的前驱节点为头节点时尝试获取同步状态，如果获取成功则从该方法返回，其主要区别在于未获取到同步状态时的处理逻辑。acquire(int args)在未获取到同步状态时，将会使当前线程一直处于等待状态，而doAcquireNanos(int arg,long nanosTimeout)会判断是否超时（nanosTimeout小于等于0表示已经超时），如果没有超时，重新计算超时间隔nanosTimeout，然后使当前线程等待nanosTimeout纳秒，如果当前线程在nanosTimeout纳秒内没有获取到同步状态，将会从等待逻辑LockSupport.parkNanos(Object blocker,long nanos)中自动返回。</li>
<li>如果nanosTimeout小于等于spinForTimeoutThreshold（1000纳秒）时，将不会使该线程进行超时等待，而是进入快速的自旋过程。原因在于，非常短的超时等待无法做到十分精确，如果这时再进行超时等待，相反会让nanosTimeout的超时从整体上表现得反而不精确。因此，在超时非常短的场景下，同步器会进入无条件的快速自旋。<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/4eeae1acd7ba26e380300.jpg" alt="独占式超时获取同步状态流程.png"></li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>    /*
    * 与acquireInterruptibly区别挂起条件添加一条：剩余时间大于1秒则按剩余时间阻塞当前线程
    */
    public final boolean tryAcquireNanos(int arg, long nanosTimeout)
            throws InterruptedException {
        if (Thread.interrupted()) throw new InterruptedException();
        return tryAcquire(arg) || doAcquireNanos(arg, nanosTimeout);
    }

    static final long spinForTimeoutThreshold = 1000L;

    private boolean doAcquireNanos(int arg, long nanosTimeout)
            throws InterruptedException {
        if (nanosTimeout &lt;= 0L)
            return false;
        final long deadline = System.nanoTime() + nanosTimeout;
        final Node node = addWaiter(Node.EXCLUSIVE);
        boolean failed = true;
        try {
            for (;;) {
                final Node p = node.predecessor();
                if (p == head &amp;&amp; tryAcquire(arg)) {
                    setHead(node);
                    p.next = null; // help GC
                    failed = false;
                    return true;
                }
                nanosTimeout = deadline - System.nanoTime();
                //计算时间，当前时间now减去睡眠之前的时间lastTime得到已经睡眠
                //的时间delta，然后被原有超时时间nanosTimeout减去，得到了
                //还应该睡眠的时间
                if (nanosTimeout &lt;= 0L) return false;
                    
                if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; 
                    nanosTimeout &gt; spinForTimeoutThreshold) 
                    LockSupport.parkNanos(this, nanosTimeout);
                if (Thread.interrupted())
                    throw new InterruptedException();
            }
        } finally {
            if (failed)
                cancelAcquire(node);
        }
    }
</code></pre></div><h1>7. 共享锁的获取acquireShared(int arg)和释放releaseShared(int arg)</h1>
<ul>
<li>共享式获取与独占式获取最主要的区别在于同一时刻能否有多个线程同时获取到同步状态。写操作要求对资源的独占式访问，而读操作可以是共享式访问，</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>    /*
    * tryAcquireShared(int arg)返回值大于等于0时，表示能够获取到同步状态
    * 与独占锁的区别
    * 1 获取锁成功后当tryAcquireShared&gt;0或者新旧头结点的waitStatus为signal或者propagate唤醒后继节点
    */
    public final void acquireShared(int arg) {
        if (tryAcquireShared(arg) &lt; 0)
            doAcquireShared(arg);
    }

    private void doAcquireShared(int arg) {
        final Node node = addWaiter(Node.SHARED);
        boolean failed = true;
        try {
            boolean interrupted = false;
            for (;;) {
                final Node p = node.predecessor();
                if (p == head) {
                    int r = tryAcquireShared(arg);
                    if (r &gt;= 0) {
                        setHeadAndPropagate(node, r);
                        p.next = null; // help GC
                        if (interrupted)
                            selfInterrupt();
                        failed = false;
                        return;
                    }
                }
                if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;
                    parkAndCheckInterrupt())
                    interrupted = true;
            }
        } finally {
            if (failed)
                cancelAcquire(node);
        }
    }

    private void setHeadAndPropagate(Node node, int propagate) {
        Node h = head; // Record old head for check below
        setHead(node);
        //1
        if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0 ||
            (h = head) == null || h.waitStatus &lt; 0) {
            Node s = node.next;
            if (s == null || s.isShared())
                doReleaseShared();
        }
    }

    /*
    * 共享锁唤醒后继节点
    * 1 调用时机：
    *    刚获取共享锁的线程并且tryAcquireShared&gt;0或者waitStatus为signal或者propagate时
    *    已经持有共享锁的线程释放锁
    * 2 目的：唤醒头结点的下一个节点
    * 3 唤醒下一个节点的条件？头结点为SIGNAL且CAS操作头结点的WaitStatus设置为0成功
    * 4 PROPAGATE的作用?解决并发释放信号量所导致部分请求信号量的线程无法被唤醒的问题
    *    https://bugs.java.com/bugdatabase/view_bug.do?bug_id=6801020
    *    当线程调用tryAcquireShared返回0并将头的waitstatus设置为0时并不唤醒后继节点的瞬间
    *    线程2调用doReleaseShared释放锁，并读取到头的waitstatus为0时也不唤醒后继节点，导致队列等待线程无法被唤醒
    * 5 退出条件为什么是h == head?
    *   配合for(;;)加快唤醒后继节点的速度，即提供多线程竞争
    */
    private void doReleaseShared() {
        for (;;) {
            Node h = head;
            if (h != null &amp;&amp; h != tail) {
                int ws = h.waitStatus;
                if (ws == Node.SIGNAL) {
                    if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0))
                        continue;            // loop to recheck cases
                    unparkSuccessor(h);
                }
                else if (ws == 0 &amp;&amp;
                         !compareAndSetWaitStatus(h, 0, Node.PROPAGATE))
                    continue;                // loop on failed CAS
            }
            if (h == head)                   // loop if head changed
                break;
        }
    }
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>    /*
    * tryReleaseShared(int arg)方法必须确保同步状态（或者资源数）线程安全释放，一般是通过循环和CAS来保证的，因为释放同* 步状态的操作会同时来自多个线程。
    * 共享锁的释放
    * 1 调用子类tryReleaseShared
    * 2 成功则调用doReleaseShared 唤醒下一个线程或者设置传播状态。
    */
    public final boolean releaseShared(int arg) {
        if (tryReleaseShared(arg)) {//1
            doReleaseShared();//2
            return true;
        }
        return false;
    }
</code></pre></div><h1>9. 可中断acquireSharedInterruptibly()一样</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>    private void doAcquireSharedInterruptibly(int arg)
            throws InterruptedException {
        final Node node = addWaiter(Node.SHARED);
        boolean failed = true;
        try {
            for (;;) {
                final Node p = node.predecessor();
                if (p == head) {
                    int r = tryAcquireShared(arg);
                    if (r &gt;= 0) {
                        setHeadAndPropagate(node, r);
                        p.next = null; // help GC
                        failed = false;
                        return;
                    }
                }
                if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;
                    parkAndCheckInterrupt())
                    throw new InterruptedException();
            }
        } finally {
            if (failed)
                cancelAcquire(node);
        }
    }
</code></pre></div><h1>10. 超时等待tryAcquireSharedNanos()一样</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>    private boolean doAcquireSharedNanos(int arg, long nanosTimeout)
            throws InterruptedException {
        if (nanosTimeout &lt;= 0L)
            return false;
        final long deadline = System.nanoTime() + nanosTimeout;
        final Node node = addWaiter(Node.SHARED);
        boolean failed = true;
        try {
            for (;;) {
                final Node p = node.predecessor();
                if (p == head) {
                    int r = tryAcquireShared(arg);
                    if (r &gt;= 0) {
                        setHeadAndPropagate(node, r);
                        p.next = null; // help GC
                        failed = false;
                        return true;
                    }
                }
                nanosTimeout = deadline - System.nanoTime();
                if (nanosTimeout &lt;= 0L)
                    return false;
                if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;
                    nanosTimeout &gt; spinForTimeoutThreshold)
                    LockSupport.parkNanos(this, nanosTimeout);
                if (Thread.interrupted())
                    throw new InterruptedException();
            }
        } finally {
            if (failed)
                cancelAcquire(node);
        }
    }
</code></pre></div><h1>自定义同步组件——TwinsLock</h1>
<ul>
<li>设计一个同步工具：同一时刻，只允许至多两个线程同时访问，超过两个线程的访问将被阻塞</li>
<li>首先，确定访问模式。TwinsLock能够在同一时刻支持多个线程的访问，这显然是共享式访问，因此，需要使用同步器提供的acquireShared(int args)方法等和Shared相关的方法，这就要求TwinsLock必须重写tryAcquireShared(int args)方法和tryReleaseShared(int args)方法，这样才能保证同步器的共享式同步状态的获取与释放方法得以执行。</li>
<li>其次，定义资源数。TwinsLock在同一时刻允许至多两个线程的同时访问，表明同步资源数为2，这样可以设置初始状态status为2，当一个线程进行获取，status减1，该线程释放，则status加1，状态的合法范围为0、1和2，其中0表示当前已经有两个线程获取了同步资源，此时再有其他线程对同步状态进行获取，该线程只能被阻塞。在同步状态变更时，需要使用compareAndSet(int expect,int update)方法做原子性保障。</li>
<li>最后，组合自定义同步器。前面的章节提到，自定义同步组件通过组合自定义同步器来完成同步功能，一般情况下自定义同步器会被定义为自定义同步组件的内部类。</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class TwinsLock implements Lock {
    private final Sync sync = new Sync(2);
    private static final class Sync extends AbstractQueuedSynchronizer {
        Sync(int count) {
            if (count &lt;= 0) {
                throw new IllegalArgumentException("count must large
                than zero.");
            }
            setState(count);
        }
        public int tryAcquireShared(int reduceCount) {
            for (;;) {
                int current = getState();
                int newCount = current - reduceCount;
                if (newCount &lt; 0 || compareAndSetState(current,newCount)) {
                    return newCount;
                }
            }
        }
        public boolean tryReleaseShared(int returnCount) {
            for (;;) {
                int current = getState();
                int newCount = current + returnCount;
                if (compareAndSetState(current, newCount)) {
                    return true;
                }
            }
        }
    }
    public void lock() {
        sync.acquireShared(1);
    }
    public void unlock() {
        sync.releaseShared(1);
    }
}
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class TwinsLockTest {
    @Test
    public void test() {
        final Lock lock = new TwinsLock();
        class Worker extends Thread {
            public void run() {
                while (true) {
                    lock.lock();
                    try {
                        SleepUtils.second(1);
                        System.out.println(Thread.currentThread().getName());
                        SleepUtils.second(1);
                    } finally {
                        lock.unlock();
                    }
                }
            }
        }
        // 启动10个线程
        for (int i = 0; i &lt; 10; i++) {
            Worker w = new Worker();
            w.setDaemon(true);
            w.start();
        }
        // 每隔1秒换行
        for (int i = 0; i &lt; 10; i++) {
            SleepUtils.second(1);
            System.out.println();
        }
    }
}
</code></pre></div>]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/e9915cfd1e0090d670830.jpg" type="image/jpeg"/>
    </item>
    <item>
      <title>集合</title>
      <link>https://javaguide.cn/backend/java/collection.html</link>
      <guid>https://javaguide.cn/backend/java/collection.html</guid>
      <source url="https://javaguide.cn/rss.xml">集合</source>
      <description>Collection 集合与数组的异同 数组的长度是固定的。集合的长度是可变的。 数组可以存储基本数据类型和引用数据类型；集合中存储的元素必须是引用类型数据 数组存储的元素必须是同一个数据类型；集合存储的对象可以是不同数据类型 集合中存储其实都是对象的地址 集合中可以存储基本数值吗？可以通过基本类型包装类，自动装箱操作存储 没指定&amp;lt;&amp;gt;时，元素存储时自动...</description>
      <category>后端</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>Collection</p>
<!--more-->
<h2>集合与数组的异同</h2>
<ul>
<li>数组的长度是固定的。集合的长度是可变的。</li>
<li>数组可以存储基本数据类型和引用数据类型；集合中存储的元素必须是引用类型数据</li>
<li>数组存储的元素必须是同一个数据类型；集合存储的对象可以是不同数据类型</li>
<li>集合中存储其实都是对象的地址</li>
<li>集合中可以存储基本数值吗？可以通过基本类型包装类，自动装箱操作存储</li>
<li>没指定&lt;&gt;时，元素存储时自动提升为Object。取出时要使用元素的特有内容，必须向下转型</li>
<li>如果集合中存放的是多个对象，这时进行向下转型会发生类型转换异常</li>
<li>Iterator接口使用&lt;&gt;控制迭代元素的类型就不需要强转了.获取到的元素直接就是元素类型</li>
</ul>
<h2>Iterable</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code># ArrayList迭代
for (int i = 0; i &lt; list.size(); i++) {
	String str = list.get(i);
}
for (Iterator&lt;String&gt; it2 = coll.iterator(); it2.hasNext();) {
	System.out.println(it2.next());
} 
Iterator&lt;String&gt; it=list.iterator();
while(it.hasNext()){
	String str=it.next();
	it.remove();//遍历删除
}

# Vector枚举迭代
Enumeration&lt;String&gt; en=list.elements();
while(en.hasMoreElements()){
	String str=en.nextElement();
}
# Map迭代
# 推荐使用 entrySet 遍历 Map 类集合 KV，而不是 keySet 方式进行遍历。keySet 其实是遍历了2次，一次是转为Iterator对象，另一次是从 hashMap中取出key所对应的value。而entrySet只是遍历了一次就把key和value都放到了entry中，效率更高

①Entry键值对对象方式
Map&lt;String, String&gt; map = new HashMap&lt;String,String&gt;();
Iterator&lt;Map.Entry&lt;String,String&gt;&gt; it = map.entrySet().iterator();
while(it.hasNext()){
	Map.Entry&lt;String,String&gt; entry = it.next();//得到每一对对应关系
	String key = entry.getKey();//通过每一对对应关系获取对应的key
	String value = entry.getValue();//通过每一对对应关系获取对应的value
	System.out.println(key+"="+value);
}
for (Map.Entry&lt;Integer, Integer&gt; entry : map.entrySet()) {  
	System.out.println("Key=" + entry.getKey() + ",Value =" +entry.getValue());  
}

②遍历键找值方式
Map&lt;String, String&gt; map = new HashMap&lt;String,String&gt;();
Iterator&lt;String&gt; it =map.keySet().iterator();
while(it.hasNext()){
	String key = it.next();//得到每一个key
	String value = map.get(key);//通过key获取对应的value
}

for (String key : map.keySet()) {
	System.out.println("key:" + key + ",value:" + map.get(key));
}

③遍历所有的value
for (String value : map.values()) {
	System.out.println("value:" + value);
}
map.forEach((key, value) -&gt; {
	System.out.println("key=" + key + ",value=" + value);
});
# 增强for:没有索引,不能操作容器里面的元素
for(元素类型  变量名 : 数组或者集合 ){
	sop(变量);//相当于直接每次循环将集合或者数组中的元素赋给变量
}
</code></pre></div><h2>泛型</h2>
<ul>
<li>泛型实现了参数化类型的概念，使代码可以应用于多种类型</li>
<li>泛型可以用于内部类</li>
<li>泛型概念
<ul>
<li>指明了集合中存储数据的类型  &lt;数据类型&gt;(安全简单)。在编译的时候检查类型安全，避免了迭代时类型强转的麻烦</li>
</ul>
</li>
<li>泛型声明
<ul>
<li>泛型类 修饰符  <code> class 类名&lt;代表泛型的变量&gt; {}</code></li>
<li>泛型方法 修饰符 &lt;代表泛型的变量&gt; 返回值类型 方法名(参数){} <code>public &lt;T&gt; T[] toArray(T[] a){} </code></li>
<li>泛型接口 <code>public interface List &lt;E&gt;{abstract boolean add(E e);}</code></li>
</ul>
</li>
<li>泛型擦除：使得泛化的客户端可以用非泛化的类库来使用
<ul>
<li>泛型只在编译时存在,编译后就被擦除,在编译之前我们就可以限制集合的类型,起到作用</li>
<li>例如:<code>ArrayList&lt;String&gt; al=new ArrayList&lt;String&gt;()</code>;编译后:ArrayList al=new ArrayList();</li>
<li>获得泛型声明所声明的类型参数：<code>TypeVariable&lt;Class&lt;T&gt;&gt;[] typeParameters = al.getClass().getTypeParameters();</code></li>
</ul>
</li>
<li>通配符和泛型的限定：为了传入泛型后能做到调用具体类型的方法，必须做限定
<ul>
<li>Iterator&lt;?&gt; it = coll.iterator()泛型的通配,匹配所有的数据类型，被擦除成Object</li>
<li><code>&lt;? extends Employee&gt;</code> 限制的是父类, 上限限定, 可以传递Employee，传递他的子类对象，被擦除成Employee</li>
<li><code>&lt;? super   Employee&gt;</code> 限制的是子类, 下限限定, 可以传递Employee，传递他的父类对象，被擦除成Employee</li>
<li><code>&lt;? extends class &amp; interface&gt;</code>//多个限定</li>
</ul>
</li>
<li>元组
<ul>
<li>将一组对象之间打包存储于其中的一个单一对象，这个容器对象允许读取其中元素，但是不允许向其中存放新的对象</li>
<li>元组可以有任意长度，元组中的对象可以是任意不同的类型，</li>
<li>元组可以实现一次方法调用返回多个对象，并且在编译期就能确保类型安全。当然也可以创建一个对象，持有返回的多个对象</li>
</ul>
</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class TwoTuple&lt;A,B&gt;{
	public final A first;
	public final B second;
	public TwoTuple(A a,B b){
		this.first = a;
		this.second = b;
	}
}
</code></pre></div><ul>
<li>泛型类型参数推断
<ul>
<li>声明变量的的时候已经指明了参数类型，初始化对象时还需指定（jdk7后不用）<code>Map&lt;String,Object&gt; myMap = new HashMap&lt;String,Object&gt;();</code>jdk7后=&gt;<code>HashMap&lt;String,Object&gt; map = new HashMap&lt;&gt;();</code></li>
</ul>
</li>
<li>泛型构造器</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>//泛型必须有无参构造函数
public class Generator&lt;T&gt; {
    private Class&lt;T&gt; type;
    public Generator(Class&lt;T&gt; type){this.type = type;}
    public T get(){
        try {
            return (T) type.newInstance();
        } catch (InstantiationException e) {
            e.printStackTrace();
        } catch (IllegalAccessException e) {
            e.printStackTrace();
        }
        return null;
    }
    public T[] getArray(int size){
        return (T[]) Array.newInstance(this.type,size);
    }
    public static &lt;T&gt; Generator&lt;T&gt; create(Class&lt;T&gt; type){
        type.getTypeParameters();
        return  new Generator&lt;&gt;(type);
    }
	public static void main(String[] args) {
        System.out.println(Generator.create(Test.class).get());
		System.out.println(Generator.create(Test.class).getArray(10));
    }
}
</code></pre></div><h2>动态获得子类的类型</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>//在父类(IBaseDaoImpl)的构造方法中动态获得entityClass字节码对象
public IBaseDaoImpl() {
  //获得T
  ParameterizedType Superclass = (ParameterizedType) this.getClass().getGenericSuperclass();
  //获得父类上声明的泛型数组
  Type[] actualTypeArguments = Superclass.getActualTypeArguments();
  entityClass=(Class&lt;T&gt;) actualTypeArguments[0];
}
</code></pre></div>]]></content:encoded>
    </item>
    <item>
      <title>ConcurrentHashMap</title>
      <link>https://javaguide.cn/backend/java/concurrentHashMap.html</link>
      <guid>https://javaguide.cn/backend/java/concurrentHashMap.html</guid>
      <source url="https://javaguide.cn/rss.xml">ConcurrentHashMap</source>
      <description>ConcurrentHashMap ConcurrentHashMap 产生原因： 并发编程中使用HashMap可能导致程序死循环。导致HashMap的Entry链表形成环形数据结构，一旦形成环形数据结构，Entry的next节点永远不为空，就会产生死循环获取Entry。 而使用线程安全的HashTable效率低。HashTable容器使用synchr...</description>
      <category>源码</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>ConcurrentHashMap</p>
<h1>ConcurrentHashMap</h1>
<h2>产生原因：</h2>
<ul>
<li>并发编程中使用HashMap可能导致程序死循环。导致HashMap的Entry链表形成环形数据结构，一旦形成环形数据结构，Entry的next节点永远不为空，就会产生死循环获取Entry。</li>
<li>而使用线程安全的HashTable效率低。HashTable容器使用synchronized来保证线程安全，竞争越激烈效率越低</li>
</ul>
<h2>实现高性能原理</h2>
<ul>
<li>ConcurrentHashMap使用分段锁来保证在多线程下的性能。一次锁住一个桶。将hash表分为16个桶，诸如 get,put,remove 等常用操作只锁当前需要用到的桶</li>
<li>ConcurrentHashMap使用了一种不同的迭代方式。当 iterator被创建后集合再发生改变就不再是抛出ConcurrentModificationException异常，而是在改变时new新的数据从而不影响原有的数据，iterator完成后再将头指针替换为新的数据 ，这样iterator线程可以使用原来老的数据，而写线程也可以并发的完成改变</li>
</ul>
<h2>ConcurrentHashMap的结构</h2>
<ul>
<li>ConcurrentHashMap是由Segment（ReentrantLock）数组结构和HashEntry(存储键值对数据)数组结构组成。一个ConcurrentHashMap里包含一个Segment数组。一个Segment里包含一个HashEntry数组，每个Segment守护着一个HashEntry数组里的元素，当对HashEntry数组的数据进行修改时，必须首先获得与它对应的Segment锁</li>
<li>Segment与HashMap类似，是一种数组和链表结构。每个HashEntry是一个链表结构的元素</li>
</ul>
<h2>ConcurrentHashMap的初始化</h2>
<ul>
<li>ConcurrentHashMap初始化方法是通过initialCapacity、loadFactor和concurrencyLevel等几个参数来初始化segment数组、段偏移量segmentShift、段掩码segmentMask和每个segment里的HashEntry数组来实现</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>//负载因子，默认值75%。当table使用率达到75%，为减少hash碰撞，将table的长度扩容一倍。
private static final float LOAD_FACTOR = 0.75f;

//默认值为8。当链表的长度大于8时，结构由链表转为红黑树。
static final int TREEIFY_THRESHOLD = 8;

//默认值为6，红黑树转为链表的阈值。
static final int UNTREEIFY_THRESHOLD = 6;

//默认值16.当table扩容时，每个线程最少迁移table的槽位数。
private static final int MIN_TRANSFER_STRIDE = 16;

//table迁移过程的临时变量，在迁移过程中将元素全都迁移到nextTable上。
private transient volatile Node&lt;K,V&gt;[] nextTable;

//表示table容量从n扩容到2n时，是从索引n-&gt;1元素开始迁移， transferIndex代表当前已经迁移的元素的下标。
private transient volatile int transferIndex; 

//一个特殊的Node节点，其hashcode=MOVED，代表此时table正在做扩容。当下一个线程向这个元素插入数据时，检查hashcode=MOVED，就会帮着扩容。
ForwardingNode ：


//2^30而不是2^31原因在于int的范围是 -2^31~2^31-1，所以会越界(容量是要为 2^n)
private static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;

/* 表初始化和调整大小控件。
* 如果sizeCtl = 0，表示哈希表未初始化，并且数组的初始容量是16；
* 如果sizeCtl = -1,表示哈希表正在进行初始化；
* 如果sizeCtl &lt; 0并且sizeCtl != -1，表示哈希表正在扩容，二进制的低16位数值为 M=(sizeCtl&amp;31)，此时有M-1个线程进行扩容
* sizeCtl高16位表示扩容标记，低16位表示并行扩容的线程数，（16位）
* 初始化后，保存要调整表大小的下一个元素计数值。
*/
private transient volatile int sizeCtl;


public ConcurrentHashMap(int initialCapacity) {
    //校验指定的初始容量大小是否大于等于最大容量大小的一半
    //如果大于等于最大容量大小的一半则在后续第一次添加元素的时候使用最大容量大小创建数组
    //如果小于最大容量大小的一半则根据指定容量来计算最接近指定容量大小并大于指定容量的2的次方
    //指定容量大小如果等于最大容量大小的一半则说明指定容量大小是2的29次方,为什么不使用指定容量大小,而是使用最大的容量大小?因为如果使用的话就会越界
    if (initialCapacity &lt; 0)
        throw new IllegalArgumentException();
    int cap = ((initialCapacity &gt;= (MAXIMUM_CAPACITY &gt;&gt;&gt; 1)) ?
                MAXIMUM_CAPACITY :
                tableSizeFor(initialCapacity + (initialCapacity &gt;&gt;&gt; 1) + 1));
    this.sizeCtl = cap;
}

/**
* 获得n最大的2^n数
* 思路：2^n本质是1&gt;&gt;&gt;n(1后面全部是0)，可以由n-1个1组成的数加1得到，即先求2^n-1最后再+1
* 实现：使用了或运算性质将某些位置为1，然后每次翻倍将数据置为1
* 之所以在开始移位前先将容量-1，是为了避免给定容量已经是8,16这样2的幂时，不减一直接移位会导致得到的结果比预期大。比如预期16得到应该是16，直接移位的话会得到32。在上图中就是所有x本身已经是0的情况下，不减1得到的结果变大了。
*/
private static final int tableSizeFor(int c) {
    int n = c - 1;
    n |= n &gt;&gt;&gt; 1;
    n |= n &gt;&gt;&gt; 2;
    n |= n &gt;&gt;&gt; 4;
    n |= n &gt;&gt;&gt; 8;
    n |= n &gt;&gt;&gt; 16;
    return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;
}

</code></pre></div><figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/1e11ee1378bca91c1d8d8.jpg" alt="tableSizeFor原理.png" tabindex="0"><figcaption>tableSizeFor原理.png</figcaption></figure>
<h2>ConcurrentHashMap的put方法</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>//值为-1。当Node.hash为MOVED时，代表table正在扩容。
static final int MOVED = -1;

//值为-2。代表此元素后接红黑树
static final int TREEBIN = -2;

public V put(K key, V value) {
    return putVal(key, value, false);
}

/** Implementation for put and putIfAbsent */
final V putVal(K key, V value, boolean onlyIfAbsent) {
    if (key == null || value == null) throw new NullPointerException();
    int hash = spread(key.hashCode());
    int binCount = 0;
    for (Node&lt;K,V&gt;[] tab = table;;) {
        Node&lt;K,V&gt; f; int n, i, fh;
        if (tab == null || (n = tab.length) == 0)
            tab = initTable();
            // key所在的桶没有一个元素，那就直接将当前key作为头节点，put操作完成
        else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) {
            // CAS设置头节点，因为可能有其它线程也在设置该头节点
            if (casTabAt(tab, i, null,
                            new Node&lt;K,V&gt;(hash, key, value, null)))
                break;                   // no lock when adding to empty bin
        }
        //如果桶中的元素不为空，那就需要从头节点开始遍历，注意，这里遍历的可能是链表也可能是红黑树。
        //当 put 的时候如果发现正在扩容，则需要帮助 map 完成扩容，相当于扩容可能由多个线程来完成，
        else if ((fh = f.hash) == MOVED)//-1
            tab = helpTransfer(tab, f);
        else {
            //接下来就要从头节点开始遍历了，链表使用的是尾插法，即新节点作为链表最后一个节点。
            V oldVal = null;
            synchronized (f) {
                if (tabAt(tab, i) == f) {
                    if (fh &gt;= 0) {//fh=f.hash如果=-1则在扩容，=-2则是红黑树，所以&gt;=0是链表
                        binCount = 1;
                        for (Node&lt;K,V&gt; e = f;; ++binCount) {
                            K ek;
                            //如果比较hash与equals方法有值则返回
                            if (e.hash == hash &amp;&amp;
                                ((ek = e.key) == key ||
                                    (ek != null &amp;&amp; key.equals(ek)))) {
                                oldVal = e.val;
                                if (!onlyIfAbsent)
                                    e.val = value;
                                break;
                            }
                            //值不存在则放入链表尾部
                            Node&lt;K,V&gt; pred = e;
                            if ((e = e.next) == null) {
                                pred.next = new Node&lt;K,V&gt;(hash, key,
                                                            value, null);
                                break;
                            }
                        }
                    }
                    else if (f instanceof TreeBin) {//红黑树
                        Node&lt;K,V&gt; p;
                        binCount = 2;
                        if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key,
                                                        value)) != null) {
                            oldVal = p.val;
                            if (!onlyIfAbsent)
                                p.val = value;
                        }
                    }
                }
            }
            if (binCount != 0) {
                if (binCount &gt;= TREEIFY_THRESHOLD)
                    treeifyBin(tab, i);
                if (oldVal != null)
                    return oldVal;
                break;
            }
        }
    }
    addCount(1L, binCount);
    return null;
}
//将key本身的hash值的高16位参加运算获取到新的hash值,如果数组的长度的二进制是在低16位二进制中就会导致key高16位的二进制没有参加运算
//容易导致运算后的key的索引位置发生冲突,所以需要将高16位二进制无符号右移16位与原hash值的二进制进行运算减少索引冲突。
//static final int HASH_BITS = 0x7fffffff;
static final int spread(int h) {
    return (h ^ (h &gt;&gt;&gt; 16)) &amp; HASH_BITS;
}

private final Node&lt;K,V&gt;[] initTable() {
    Node&lt;K,V&gt;[] tab; int sc;
    //第《1》步，判断数组是否未初始化
    while ((tab = table) == null || tab.length == 0) {
        //第《2》步，用sc保存sizeCtl的值，作为后面CAS的预期值
        //第《3》步判断sizeCtl的值是否&lt;0，是的话则发现有其他线程在做数据的初始化，让出CPU
        if ((sc = sizeCtl) &lt; 0)
            Thread.yield();
        //走到这里，说明sizeCtl&gt;=0，则有两种清况：一是数组未初始化。
        //二是有其他线程在第《1》步之后，第《2》步之前将数组初始化完成，此时sizeCtl为数组的扩容阈值.

        //第《4》步，CAS将SIZECTL值修改为-1，表示本线程开始进行数组的初始化
        //如果修改成功，开始初始化操作；如果修改失败，则表示有其他线程在《1》《2》之后抢先修改了SIZECTL
        else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) {//竞争锁，与ReentrantLock相似
            try {
                 /*第《5》步，double check数组是否初始化，这里为什么要采用双重校验呢？
                *因为在数组初始化完成之后，sizeCtl的值会，被改成数组的扩容阈值，会是一个大于0的值。
                *所以完全有可能本线程在《1》之后，有其他线程完成了数组的初始化全过程，
                * 使得本线程也能进到这个代码块里来。
                */
                if ((tab = table) == null || tab.length == 0) {
                    //第《6》步，执行哈希表的创建工作，
                    //确定哈希表的容量
                    int n = (sc &gt; 0) ? sc : DEFAULT_CAPACITY;
                    @SuppressWarnings("unchecked")
                    Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n];
                    table = tab = nt;
                    sc = n - (n &gt;&gt;&gt; 2);//第sc=n-n/4，作为扩容的阈值，赋值给sc
                }
            } finally {
                //第《7》步，如果初始化完成，sizeCtl记录的是扩容阈值；
                //如果初始化失败，则还原sizeCtl
                sizeCtl = sc;
            }
            //走到这里，说明本线程初始化完成了或者其他线程在本线程的
            //《1》、《2》两步之间完成了哈希表的初始化全过程，此时结束循环
            break;
        }
        //走到这里，说明在发现数组未初始化之后，准确初始化之前，
        //有其他线程已经抢先开始初始化了
        //但是其他线程是否将初始化的工作全部正确的完成，并不知道，所以重新开始循环检查
    }
    return tab;
}
// 获取obj对象中offset偏移地址对应的object型field的值,支持volatile load语义。
public native Object getObjectVolatile(Object obj, long offset);

//获取数组中第一个元素的偏移量,与arrayIndexScale配合访问数组指定元素
public native int arrayBaseOffset(java.lang.Class aClass);

//获取数组中一个元素的大小
public native int arrayIndexScale(java.lang.Class aClass);

/**
* ABASE = U.arrayBaseOffset(Node[].class);//Node[].class数组中第一个元素的偏移量
* ASHIFT = 31 - Integer.numberOfLeadingZeros(U.arrayIndexScale(Node[].class));//int范围2^31-1，31-前缀0个数得到每个元素实际位数
* 数组的元素位置=数组第一个元素偏移量+索引i * 每个元素实际位数
*/
static final &lt;K,V&gt; Node&lt;K,V&gt; tabAt(Node&lt;K,V&gt;[] tab, int i) {
    return (Node&lt;K,V&gt;)U.getObjectVolatile(tab, ((long)i &lt;&lt; ASHIFT) + ABASE);
}
//返回无符号整型i的最高非零位前面的n个0的个数，包括符号位。如果i小于0则返回0，等于0则返回32。
//例：10的二进制为：0000 0000 0000 0000 0000 0000 0000 1010 java的int长度为32位，方法返回的就是28。
public static int numberOfLeadingZeros(int i) {
    // HD, Figure 5-6
    if (i == 0)
        return 32;
    int n = 1;
    if (i &gt;&gt;&gt; 16 == 0) { n += 16; i &lt;&lt;= 16; }//二分法32/2=16
    if (i &gt;&gt;&gt; 24 == 0) { n +=  8; i &lt;&lt;=  8; }//二分法16/2=8 + 16
    if (i &gt;&gt;&gt; 28 == 0) { n +=  4; i &lt;&lt;=  4; }//二分法 8/2=4 + 8 + 16
    if (i &gt;&gt;&gt; 30 == 0) { n +=  2; i &lt;&lt;=  2; }//二分法 4/2=2 + 4 + 8 + 16
    n -= i &gt;&gt;&gt; 31; //2/2=1 + 2 + 4 + 8 + 16
    return n;
}

static final &lt;K,V&gt; boolean casTabAt(Node&lt;K,V&gt;[] tab, int i,
                                    Node&lt;K,V&gt; c, Node&lt;K,V&gt; v) {
    return U.compareAndSwapObject(tab, ((long)i &lt;&lt; ASHIFT) + ABASE, c, v);
}
/**
* 判断是否需要扩容
*/
private final void addCount(long x, int check) {
    CounterCell[] as; long b, s;
    if ((as = counterCells) != null ||
        !U.compareAndSwapLong(this, BASECOUNT, b = baseCount, s = b + x)) {
        CounterCell a; long v; int m;
        boolean uncontended = true;
        if (as == null || (m = as.length - 1) &lt; 0 ||
            (a = as[ThreadLocalRandom.getProbe() &amp; m]) == null ||
            !(uncontended =
                U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x))) {
            fullAddCount(x, uncontended);
            return;
        }
        if (check &lt;= 1)
            return;
        s = sumCount();
    }
    if (check &gt;= 0) {
        Node&lt;K,V&gt;[] tab, nt; int n, sc;
        while (s &gt;= (long)(sc = sizeCtl) &amp;&amp; (tab = table) != null &amp;&amp;
                (n = tab.length) &lt; MAXIMUM_CAPACITY) {
            int rs = resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT;
            if (sc &lt; 0) {
                if (sc == rs + MAX_RESIZERS || sc == rs + 1 ||
                    (nt = nextTable) == null || transferIndex &lt;= 0)
                    break;
                if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1))
                    transfer(tab, nt);
            }
            else if (U.compareAndSwapInt(this, SIZECTL, sc, rs + 2))
                transfer(tab, null);
            s = sumCount();
        }
    }
}
//桶进行树化的最小表容量。(如果一个bin中的节点太多，则会调整表的大小)该值应至少为4 * TREEIFY_THRESHOLD，以避免调整大小阈值与树化阈值之间的冲突。
static final int MIN_TREEIFY_CAPACITY = 64;

private final void treeifyBin(Node&lt;K,V&gt;[] tab, int index) {
    Node&lt;K,V&gt; b; int n, sc;
    if (tab != null) {
        if ((n = tab.length) &lt; MIN_TREEIFY_CAPACITY)
            tryPresize(n &lt;&lt; 1);
        else if ((b = tabAt(tab, index)) != null &amp;&amp; b.hash &gt;= 0) {
            synchronized (b) {
                if (tabAt(tab, index) == b) {
                    TreeNode&lt;K,V&gt; hd = null, tl = null;
                    for (Node&lt;K,V&gt; e = b; e != null; e = e.next) {
                        TreeNode&lt;K,V&gt; p =
                            new TreeNode&lt;K,V&gt;(e.hash, e.key, e.val,
                                                null, null);
                        if ((p.prev = tl) == null)
                            hd = p;
                        else
                            tl.next = p;
                        tl = p;
                    }
                    setTabAt(tab, index, new TreeBin&lt;K,V&gt;(hd));
                }
            }
        }
    }
}


//2次方个数的数组
transient volatile Node&lt;K,V&gt;[] table;

//在sizeCtl中用于生成戳的位数。对于32位数组，必须至少为6。无法修改
private static int RESIZE_STAMP_BITS = 16;

//在sizeCtl中记录生成戳的位移。无法修改
private static final int RESIZE_STAMP_SHIFT = 32 - RESIZE_STAMP_BITS;

//尝试调整表的大小以容纳给定数量的元素。
private final void tryPresize(int size) {
    //获得n最接近的2^n ，其中size在传入之前就已经翻倍了，最终c是一个大于等于（size * 1.5 + 1）的2的幂次方数
    int c = (size &gt;= (MAXIMUM_CAPACITY &gt;&gt;&gt; 1)) ? MAXIMUM_CAPACITY :
        tableSizeFor(size + (size &gt;&gt;&gt; 1) + 1);
    int sc;
    while ((sc = sizeCtl) &gt;= 0) {
        Node&lt;K,V&gt;[] tab = table; int n;
        if (tab == null || (n = tab.length) == 0) {//如果临时数组为null，则初始化临时数组，尝试将SIZECTL变为-1扩容中
            n = (sc &gt; c) ? sc : c;
            if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) {
                try {
                    if (table == tab) {
                        @SuppressWarnings("unchecked")
                        Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n];
                        table = nt;
                        sc = n - (n &gt;&gt;&gt; 2);
                    }
                } finally {
                    sizeCtl = sc;
                }
            }
        }
        else if (c &lt;= sc || n &gt;= MAXIMUM_CAPACITY)//容量小于控制容量，或者大于桶最大容量则跳出循环
            break;
        else if (tab == table) {
             /**
             *  返回值作为正在扩容数组的长度n的一个标志位,并且当向左移RESIZE_STAMP_SHIFT=16位时得到一个负数
             * 扩容戳为啥这么设置未知
             * static final int resizeStamp(int n) {
             *   return Integer.numberOfLeadingZeros(n) | (1 &lt;&lt; (RESIZE_STAMP_BITS - 1));
             * }
             *   Integer.numberOfLeadingZeros(n)在指定 int 值的二进制补码表示形式中最高位（最左边）的 1 位之前，返回零位的数量
             * 例如 n为16 0001 0000 则Integer.numberOfLeadingZeros(n)为27，因为n为2的幂次方，因此不同的n此结果也不同
             * 然后与(1 &lt;&lt; (RESIZE_STAMP_BITS - 1)) | ，相当于2^15 | n中左边0的个数。
             * (因此其左移16位后符号位为1，结果肯定是个负数)
             */
            int rs = resizeStamp(n);
            if (sc &lt; 0) {//表明在-1初始化中或者-2树状态
                Node&lt;K,V&gt;[] nt;
                /**1.第一个判断 sc右移RESIZE_STAMP_SHIFT位，也就是比较高ESIZE_STAMP_BITS位生成戳和rs是否相等
                    * 相等则代表是同一个n，是在同一容量下进行的扩容，
                    *  2.第二个和第三个判断 判断当前帮助扩容线程数是否已达到MAX_RESIZERS最大扩容线程数
                    *  3.第四个和第五个判断 为了确保transfer()方法初始化完毕
                    */
                if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 ||
                    sc == rs + MAX_RESIZERS || (nt = nextTable) == null ||
                    transferIndex &lt;= 0)
                    break;
                if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1))
                    transfer(tab, nt);
            }
             /**如果没有线程在进行扩容，那么cas修改sizeCtl值，作为扩容的发起，rs左移RESIZE_STAMP_SHIFT位+2
            * 上面说了，左移RESIZE_STAMP_SHIFT位，肯定是个负数，代表有一个线程正在进行扩容
            * 此时sizeCtl高RESIZE_STAMP_BITS位为生成戳，低RESIZE_STAMP_SHIFT位为扩容线程数
            * +2原因未知
            */
            else if (U.compareAndSwapInt(this, SIZECTL, sc,
                                            (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2))
                transfer(tab, null);
        }
    }
}

</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>static final int NCPU = Runtime.getRuntime().availableProcessors();

//每个转换红黑树步骤的最小重新绑定数。范围被细分以允许多个调整大小线程。此值用作下限，以避免调整大小器遇到过多的内存争用。该值至少为DEFAULT_CAPACITY。
private static final int MIN_TRANSFER_STRIDE = 16;

private static final long TRANSFERINDEX = U.objectFieldOffset(k.getDeclaredField("transferIndex"));

private final void transfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt;[] nextTab) {
    int n = tab.length, stride;
    //将 (n&gt;&gt;&gt;3相当于 n/8) 然后除以 CPU核心数。如果得到的结果小于 16，那么就使用16
    //stride每个线程负责迁移数据的区域长度；目的是让每个 CPU 处理的桶一样多，避免出现转移任务不均匀的现象，默认16
    if ((stride = (NCPU &gt; 1) ? (n &gt;&gt;&gt; 3) / NCPU : n) &lt; MIN_TRANSFER_STRIDE)
        stride = MIN_TRANSFER_STRIDE; // subdivide range
         //nextTab未初始化，nextTab是用来扩容的node数组
    if (nextTab == null) {            // initiating
        try {
            @SuppressWarnings("unchecked")
            //扩容2倍
            Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n &lt;&lt; 1];
            nextTab = nt;
        } catch (Throwable ex) {      // try to cope with OOME
            //扩容失败，sizeCtl使用int的最大值
            sizeCtl = Integer.MAX_VALUE;
            return;
        }
        nextTable = nextTab;//赋值给临时table，在扩容时，由创建新数组的线程初始化这个变量；扩容完成后，将其设置为null；
        transferIndex = n;//记录下一个线程迁移数据的起始位置；transferIndex-1就是下一个线程迁移数据的起始下标；
    }
    int nextn = nextTab.length;
    //创建一个 fwd 节点，表示一个正在被迁移的Node，并且它的hash值为-1(MOVED)，putval方法会有一个判断MOVED的逻辑。它的作用是用来占位，表示原数组中位置i处的节点完成迁移以后，就会在i位置设置一个fwd来告诉其他线程这个位置已经处理过了
    ForwardingNode&lt;K,V&gt; fwd = new ForwardingNode&lt;K,V&gt;(nextTab);
    boolean advance = true;
    boolean finishing = false; // to ensure sweep before committing nextTab
    for (int i = 0, bound = 0;;) {
        Node&lt;K,V&gt; f; int fh;
        // 这个循环使用CAS不断尝试为当前线程分配任务 直到分配成功或任务队列已经被全部分配完毕
        // 如果当前线程已经被分配过bucket区域 那么会通过--i指向下一个待处理bucket然后退出该循环
        while (advance) {
            //nextIndex=transferIndex，数据迁移的起始下标
            //nextBound=transferIndex-stride或者0下一个线程处理的起始位置
            //bound(边界)=nextBound/0是线程迁移数据的结束位置；等于0或者
            int nextIndex, nextBound;
            //i=nextIndex-1是每个待处理节点区间的索引，从尾部开始遍历 --i表示下一个待处理的bucket，如果它&gt;=bound,表示当前线程已经分配过bucket区域，退出while循环
            //finishing是迁移数据结束后的标志
            if (--i &gt;= bound || finishing)
                advance = false;
            //表示所有bucket已经被分配完毕 给nextIndex赋予初始值 = 16(nextIndex=transferIndex=n=tab.length) =24    
            else if ((nextIndex = transferIndex) &lt;= 0) {
                i = -1;
                advance = false;
            }
            //通过cas来修改TRANSFERINDEX(其实就是transferIndex),为当前线程分配任务,确定处理的节点区间为[nextBound,nextIndex] =&gt; [bound,i=nextIndex-1]  
            //transferIndex修改之前的值是迁移数据的起始位置，修改之后的值是结束位置；也作为下一个线程的迁移数据的起始位置；
            else if (U.compareAndSwapInt
                        (this, TRANSFERINDEX, nextIndex,
                        nextBound = (nextIndex &gt; stride ? nextIndex - stride : 0))) {
                bound = nextBound;
                i = nextIndex - 1;
                advance = false;
            }
        }
        //i&lt;0说明已经遍历完旧的数组，也就是当前线程已经处理完所有负责的bucket
        if (i &lt; 0 || i &gt;= n || i + n &gt;= nextn) {
            int sc;
             //如果完成了扩容
            if (finishing) {
                //删除成员变量
                nextTable = null;
                //更新table数组
                table = nextTab;
                //更新阈值 翻倍减去 0.25 ，为新数组大小的 0.75 倍的阈值
                sizeCtl = (n &lt;&lt; 1) - (n &gt;&gt;&gt; 1);
                return;
            }
            // sizeCtl 在迁移前会设置为 (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2
            // 然后，每增加一个线程参与迁移就会将 sizeCtl 加 1，
            // 这里使用 CAS 操作对 sizeCtl 的低16位进行减 1，代表做完了属于自己的任务
            if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) {
                //第一个扩容的线程，执行transfer方法之前，会设置 sizeCtl = (resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) + 2
                //后续帮其扩容的线程，执行transfer方法之前，会设置 sizeCtl = sizeCtl+1
                //每一个退出transfer的方法的线程，退出之前，会设置 sizeCtl = sizeCtl-1
                //那么最后一个线程退出时：必然有
                //sc == (resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) + 2，即 (sc - 2) == resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT
                // 如果 sc - 2 不等于标识符左移 16 位。如果他们相等了，说明没有线程在帮助他们扩容了。也就是说，扩容结束了。
                if ((sc - 2) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT)
                    return;
                // 如果相等，扩容结束了，更新 finising 变量
                finishing = advance = true;
                // 再次循环检查一下整张表
                i = n; // recheck before commit
            }
        }
         // 如果位置 i 处是空的，没有任何节点，那么放入刚刚初始化的 ForwardingNode ”空节点“
        else if ((f = tabAt(tab, i)) == null)
            advance = casTabAt(tab, i, null, fwd);
        //表示该位置已经完成了迁移，也就是如果线程A已经处理过这个节点，那么线程B处理这个节点时，hash值一定为MOVED    
        else if ((fh = f.hash) == MOVED)
            advance = true; // already processed
        else {
            //处理节点
            synchronized (f) {
                if (tabAt(tab, i) == f) {//双重校验
                    Node&lt;K,V&gt; ln, hn;
                    if (fh &gt;= 0) {//fh=f.hash如果=-1则在扩容，=-2则是红黑树，所以&gt;=0是链表
                        int runBit = fh &amp; n;//只有0 和n两种取值；结果是0，表示扩容后位置不变；结果不为0，表示扩容后位置：i+n；
                        //链表上的节点，在扩容之后会分成2条链表.而这条链表上有哪些节点扩容之后位置要改变的哪些节点位置是不改变的，这两种节点在链表上的分布是不确定的；
                        //可以将连续相同的节点看作是一段链表（一个节点也是一段链表），那么这条链表就可以看作2种链表组合组成的；
                        //而lastRun，是指向最后一段链表的头节点；再配合runBit（偏移量）就可以确定最后一段链表属于哪种节点；因此可以看到再次遍历数组时，遍历到lastRun就结束遍历；
                        Node&lt;K,V&gt; lastRun = f;
                        for (Node&lt;K,V&gt; p = f.next; p != null; p = p.next) {
                            int b = p.hash &amp; n;
                            if (b != runBit) {
                                runBit = b;
                                lastRun = p;
                            }
                        }
                        if (runBit == 0) {//fh &amp; n = 0；扩容后下标不变；fh &amp; n = n；扩容后下标位置改变（i + n）；
                            ln = lastRun;
                            hn = null;
                        }
                        else {
                            hn = lastRun;
                            ln = null;
                        }
                        //从头遍历每个链表 ln为原链表，hn为扩容后链表
                        for (Node&lt;K,V&gt; p = f; p != lastRun; p = p.next) {
                            int ph = p.hash; K pk = p.key; V pv = p.val;
                            if ((ph &amp; n) == 0) //头插法，p.next = ln 然后 ln = p ，组成ln链表
                                ln = new Node&lt;K,V&gt;(ph, pk, pv, ln);
                            else //头插法，p.next = hn 然后 hn = p ，组成hn链表
                                hn = new Node&lt;K,V&gt;(ph, pk, pv, hn);
                        }
                        //遍历完旧数组的链表后，重新生成了ln，hn 2条链表；
                        //ln链表插入到新数组的下标：i
                        setTabAt(nextTab, i, ln);
                        // hn插入到：i+n位置；
                        setTabAt(nextTab, i + n, hn);
                        setTabAt(tab, i, fwd);
                        advance = true;
                    }
                    else if (f instanceof TreeBin) {
                        TreeBin&lt;K,V&gt; t = (TreeBin&lt;K,V&gt;)f;
                        //lo：TreeNode链表表头：下标位置不变：i
                        //loTail:表尾，每次插入节点都在表尾插入
                        TreeNode&lt;K,V&gt; lo = null, loTail = null;
                        //hi：TreeNode链表表头：下标位置：i+n;
                        //hiTail :表尾，每次插入节点都在表尾插入
                        TreeNode&lt;K,V&gt; hi = null, hiTail = null;
                        int lc = 0, hc = 0;
                        for (Node&lt;K,V&gt; e = t.first; e != null; e = e.next) {
                            int h = e.hash;
                            TreeNode&lt;K,V&gt; p = new TreeNode&lt;K,V&gt;
                                (h, e.key, e.val, null, null);
                            if ((h &amp; n) == 0) {//h &amp; n = 0；扩容后下标不变；h &amp; n = n；扩容后下标位置改变（i + n）；
                                if ((p.prev = loTail) == null)
                                    lo = p;
                                else
                                    loTail.next = p;//lo链表插入表尾
                                loTail = p;//更新lo链表表尾
                                ++lc;//记录lo链表节点个数
                            }
                            else {
                                if ((p.prev = hiTail) == null)
                                    hi = p;
                                else
                                    hiTail.next = p;
                                hiTail = p;
                                ++hc;
                            }
                        }
                        //分别判断ln，hn节点个数是否满足生成红黑树的条件；
                        //不满足则将TreeNode链表转换成Node链表；
                        //满足则将TreeNode节点重新生成红黑树；
                        ln = (lc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(lo) :
                            (hc != 0) ? new TreeBin&lt;K,V&gt;(lo) : t;
                        hn = (hc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(hi) :
                            (lc != 0) ? new TreeBin&lt;K,V&gt;(hi) : t;
                        setTabAt(nextTab, i, ln);
                        setTabAt(nextTab, i + n, hn);
                        setTabAt(tab, i, fwd);
                        advance = true;
                    }
                }
            }
        }
    }
}
//Helps transfer if a resize is in progress.
final Node&lt;K,V&gt;[] helpTransfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt; f) {
    Node&lt;K,V&gt;[] nextTab; int sc;
    if (tab != null &amp;&amp; (f instanceof ForwardingNode) &amp;&amp;
        (nextTab = ((ForwardingNode&lt;K,V&gt;)f).nextTable) != null) {
        int rs = resizeStamp(tab.length) &lt;&lt; RESIZE_STAMP_SHIFT;
        while (nextTab == nextTable &amp;&amp; table == tab &amp;&amp;
                (sc = sizeCtl) &lt; 0) {
            if (sc == rs + MAX_RESIZERS || sc == rs + 1 ||
                transferIndex &lt;= 0)
                break;
            if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) {
                transfer(tab, nextTab);
                break;
            }
        }
        return nextTab;
    }
    return table;
}
//将treenode链表换成非treenode链表
static &lt;K,V&gt; Node&lt;K,V&gt; untreeify(Node&lt;K,V&gt; b) {
    //hd头节点，tl辅助指向p的指针 hd=p =&gt; tl=p =&gt; tl.next=p =&gt; tl=p
    Node&lt;K,V&gt; hd = null, tl = null;
    for (Node&lt;K,V&gt; q = b; q != null; q = q.next) {
        Node&lt;K,V&gt; p = new Node&lt;K,V&gt;(q.hash, q.key, q.val);
        if (tl == null)
            hd = p;
        else
            tl.next = p;
        tl = p;
    }
    return hd;
}

</code></pre></div><h1>get方法</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public V get(Object key) {
    Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; int n, eh; K ek;
    //根据key.hashCode()计算hash: 扰动运算后得到得到更散列的hash值
    int h = spread(key.hashCode());
    if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp;
        (e = tabAt(tab, (n - 1) &amp; h)) != null) {//当前key寻址的桶位有值
        if ((eh = e.hash) == h) {//如果第一个元素就是要找的元素，则直接返回
            if ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))
                return e.val;
        }
        hash小于0 分2种情况，是树或者正在扩容,需要借助find方法寻找元素，find的寻找方式依据Node的不同子类有不同的实现方式:
        // 情况一：eh=-1 是fwd结点 -&gt; 说明当前table正在扩容，且当前查询的这个桶位的数据已经被迁移走了，需要借助fwd结点的内部方法find去查询
        // 情况二：eh=-2 是TreeBin节点 -&gt; 需要使用TreeBin 提供的find方法查询。
        else if (eh &lt; 0)
            return (p = e.find(h, key)) != null ? p.val : null;
        //说明是当前桶位已经形成链表的这种情况: 遍历整个链表寻找元素    
        while ((e = e.next) != null) {
            if (e.hash == h &amp;&amp;
                ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek))))
                return e.val;
        }
    }
    return null;
}
//TreeBin节点的find方法
final Node&lt;K,V&gt; find(int h, Object k) {
    if (k != null) {
        for (Node&lt;K,V&gt; e = first; e != null; ) {
            int s; K ek;
            if (((s = lockState) &amp; (WAITER|WRITER)) != 0) {
                if (e.hash == h &amp;&amp;
                    ((ek = e.key) == k || (ek != null &amp;&amp; k.equals(ek))))
                    return e;
                e = e.next;
            }
            else if (U.compareAndSetInt(this, LOCKSTATE, s,
                                            s + READER)) {
                TreeNode&lt;K,V&gt; r, p;
                try {
                    p = ((r = root) == null ? null :
                            r.findTreeNode(h, k, null));
                } finally {
                    Thread w;
                    if (U.getAndAddInt(this, LOCKSTATE, -READER) ==
                        (READER|WAITER) &amp;&amp; (w = waiter) != null)
                        LockSupport.unpark(w);
                }
                return p;
            }
        }
    }
    return null;
}
//ForwardingNode的find方法 
Node&lt;K,V&gt; find(int h, Object k) {
    // loop to avoid arbitrarily deep recursion on forwarding nodes
    outer: for (Node&lt;K,V&gt;[] tab = nextTable;;) {
        Node&lt;K,V&gt; e; int n;
        if (k == null || tab == null || (n = tab.length) == 0 ||
            (e = tabAt(tab, (n - 1) &amp; h)) == null)
            return null;
        for (;;) {
            int eh; K ek;
            if ((eh = e.hash) == h &amp;&amp;
                ((ek = e.key) == k || (ek != null &amp;&amp; k.equals(ek))))
                return e;
            if (eh &lt; 0) {
                if (e instanceof ForwardingNode) {
                    tab = ((ForwardingNode&lt;K,V&gt;)e).nextTable;
                    continue outer;
                }
                else
                    return e.find(h, k);
            }
            if ((e = e.next) == null)
                return null;
        }
    }
}

</code></pre></div>]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/1e11ee1378bca91c1d8d8.jpg" type="image/jpeg"/>
    </item>
    <item>
      <title>多线程</title>
      <link>https://javaguide.cn/backend/java/concurrentprogramming.html</link>
      <guid>https://javaguide.cn/backend/java/concurrentprogramming.html</guid>
      <source url="https://javaguide.cn/rss.xml">多线程</source>
      <description>多线程 1. cas底层 2. 原子操作类 3. Semaphore(信号量)-允许多个线程同时访问 1.8. 什么是线程饥饿？导致原因？ 1.7. Java中用到的线程调度算法是什么？ 1.5. 程序运行原理 1.6. 什么是多线程上下文切换？如何减少或者避免？ 1.11. 线程通信、线程同步、线程互斥三者关系？ 1.13. 如何在两个线程间共享数据...</description>
      <category>后端</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>多线程</p>
<!--more-->
<!-- TOC -->
<ul>
<li><a href="#1-cas%E5%BA%95%E5%B1%82">1. cas底层</a></li>
<li><a href="#2-%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C%E7%B1%BB">2. 原子操作类</a></li>
<li><a href="#3-semaphore%E4%BF%A1%E5%8F%B7%E9%87%8F-%E5%85%81%E8%AE%B8%E5%A4%9A%E4%B8%AA%E7%BA%BF%E7%A8%8B%E5%90%8C%E6%97%B6%E8%AE%BF%E9%97%AE">3. Semaphore(信号量)-允许多个线程同时访问</a>
<ul>
<li><a href="#18-%E4%BB%80%E4%B9%88%E6%98%AF%E7%BA%BF%E7%A8%8B%E9%A5%A5%E9%A5%BF%E5%AF%BC%E8%87%B4%E5%8E%9F%E5%9B%A0">1.8. 什么是线程饥饿？导致原因？</a></li>
<li><a href="#17-java%E4%B8%AD%E7%94%A8%E5%88%B0%E7%9A%84%E7%BA%BF%E7%A8%8B%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95%E6%98%AF%E4%BB%80%E4%B9%88">1.7. Java中用到的线程调度算法是什么？</a></li>
<li><a href="#15-%E7%A8%8B%E5%BA%8F%E8%BF%90%E8%A1%8C%E5%8E%9F%E7%90%86">1.5. 程序运行原理</a></li>
<li><a href="#16-%E4%BB%80%E4%B9%88%E6%98%AF%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2%E5%A6%82%E4%BD%95%E5%87%8F%E5%B0%91%E6%88%96%E8%80%85%E9%81%BF%E5%85%8D">1.6. 什么是多线程上下文切换？如何减少或者避免？</a></li>
<li><a href="#111-%E7%BA%BF%E7%A8%8B%E9%80%9A%E4%BF%A1%E7%BA%BF%E7%A8%8B%E5%90%8C%E6%AD%A5%E7%BA%BF%E7%A8%8B%E4%BA%92%E6%96%A5%E4%B8%89%E8%80%85%E5%85%B3%E7%B3%BB">1.11. 线程通信、线程同步、线程互斥三者关系？</a></li>
<li><a href="#113-%E5%A6%82%E4%BD%95%E5%9C%A8%E4%B8%A4%E4%B8%AA%E7%BA%BF%E7%A8%8B%E9%97%B4%E5%85%B1%E4%BA%AB%E6%95%B0%E6%8D%AE">1.13. 如何在两个线程间共享数据？</a></li>
<li><a href="#21-%E5%A4%9A%E6%A0%B8cpu%E7%BC%93%E5%AD%98%E6%9E%B6%E6%9E%84">2.1. 多核CPU缓存架构？</a></li>
<li><a href="#32-%E9%94%81%E7%9A%84%E5%86%85%E5%AD%98%E8%AF%AD%E4%B9%89">3.2. 锁的内存语义</a></li>
<li><a href="#34-%E9%94%81%E7%B2%97%E5%8C%96%E6%B6%88%E9%99%A4%E5%92%8C%E8%86%A8%E8%83%80">3.4. 锁粗化消除和膨胀</a></li>
<li><a href="#316-volatile%E5%86%85%E5%AD%98%E8%AF%AD%E4%B9%89">3.16. volatile内存语义</a></li>
</ul>
</li>
<li><a href="#6-forkjoin%E6%A1%86%E6%9E%B6">6. Fork/Join框架</a></li>
<li><a href="#10-java%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E8%87%AA%E6%97%8B">10. java如何实现自旋?</a></li>
<li><a href="#6-java%E5%B9%B6%E5%8F%91%E6%9C%BA%E5%88%B6%E7%9A%84%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86">6. Java并发机制的底层实现原理</a>
<ul>
<li><a href="#61-volatile%E7%9A%84%E5%BA%94%E7%94%A8">6.1. volatile的应用</a></li>
<li><a href="#62-%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86">6.2. 原子操作的实现原理</a></li>
<li><a href="#63-%E5%A4%84%E7%90%86%E5%99%A8%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C">6.3. 处理器如何实现原子操作：</a></li>
</ul>
</li>
<li><a href="#7-java%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80">7. java内存模型基础</a>
<ul>
<li><a href="#71-%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%B8%A4%E4%B8%AA%E5%85%B3%E9%94%AE%E9%97%AE%E9%A2%98">7.1. 并发编程模型的两个关键问题</a></li>
</ul>
</li>
<li><a href="#8-java%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%8A%BD%E8%B1%A1%E7%BB%93%E6%9E%84">8. Java内存模型的抽象结构</a></li>
<li><a href="#9-%E4%BB%8E%E6%BA%90%E4%BB%A3%E7%A0%81%E5%88%B0%E6%8C%87%E4%BB%A4%E5%BA%8F%E5%88%97%E7%9A%84%E9%87%8D%E6%8E%92%E5%BA%8F">9. 从源代码到指令序列的重排序</a></li>
<li><a href="#10-%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%88%86%E7%B1%BB">10. 并发编程模型的分类</a></li>
<li><a href="#11-happens-before%E7%AE%80%E4%BB%8B">11. happens-before简介</a></li>
<li><a href="#12-%E9%87%8D%E6%8E%92%E5%BA%8F">12. 重排序</a></li>
<li><a href="#13-as-if-serial%E8%AF%AD%E4%B9%89">13. as-if-serial语义</a></li>
<li><a href="#14-%E9%87%8D%E6%8E%92%E5%BA%8F%E5%AF%B9%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%BD%B1%E5%93%8D">14. 重排序对多线程的影响</a></li>
<li><a href="#15-%E9%A1%BA%E5%BA%8F%E4%B8%80%E8%87%B4%E6%80%A7">15. 顺序一致性</a></li>
<li><a href="#16-%E9%A1%BA%E5%BA%8F%E4%B8%80%E8%87%B4%E6%80%A7%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B">16. 顺序一致性内存模型</a></li>
<li><a href="#17-volatile%E7%9A%84%E5%86%85%E5%AD%98%E8%AF%AD%E4%B9%89">17. volatile的内存语义</a></li>
<li><a href="#18-volatile%E7%9A%84%E7%89%B9%E6%80%A7">18. volatile的特性</a></li>
<li><a href="#19-volatile%E5%86%99-%E8%AF%BB%E5%BB%BA%E7%AB%8B%E7%9A%84happens-before%E5%85%B3%E7%B3%BB">19. volatile写-读建立的happens-before关系</a></li>
<li><a href="#20-volatile%E5%86%99-%E8%AF%BB%E7%9A%84%E5%86%85%E5%AD%98%E8%AF%AD%E4%B9%89">20. volatile写-读的内存语义</a></li>
<li><a href="#21-volatile%E5%86%85%E5%AD%98%E8%AF%AD%E4%B9%89%E7%9A%84%E5%AE%9E%E7%8E%B0">21. volatile内存语义的实现</a></li>
<li><a href="#22-%E9%94%81%E7%9A%84%E5%86%85%E5%AD%98%E8%AF%AD%E4%B9%89">22. 锁的内存语义</a>
<ul>
<li><a href="#221-%E9%94%81%E7%9A%84%E9%87%8A%E6%94%BE-%E8%8E%B7%E5%8F%96%E5%BB%BA%E7%AB%8B%E7%9A%84happens-before%E5%85%B3%E7%B3%BB">22.1. 锁的释放-获取建立的happens-before关系</a></li>
<li><a href="#222-%E9%94%81%E7%9A%84%E9%87%8A%E6%94%BE%E5%92%8C%E8%8E%B7%E5%8F%96%E7%9A%84%E5%86%85%E5%AD%98%E8%AF%AD%E4%B9%89">22.2. 锁的释放和获取的内存语义</a></li>
<li><a href="#223-%E9%94%81%E5%86%85%E5%AD%98%E8%AF%AD%E4%B9%89%E7%9A%84%E5%AE%9E%E7%8E%B0">22.3. 锁内存语义的实现</a></li>
<li><a href="#224-concurrent%E5%8C%85%E7%9A%84%E5%AE%9E%E7%8E%B0">22.4. concurrent包的实现</a></li>
<li><a href="#225-final%E5%9F%9F%E7%9A%84%E5%86%85%E5%AD%98%E8%AF%AD%E4%B9%89">22.5. final域的内存语义</a>
<ul>
<li><a href="#2251-final%E5%9F%9F%E7%9A%84%E9%87%8D%E6%8E%92%E5%BA%8F%E8%A7%84%E5%88%99">22.5.1. final域的重排序规则</a></li>
<li><a href="#2252-%E5%86%99final%E5%9F%9F%E7%9A%84%E9%87%8D%E6%8E%92%E5%BA%8F%E8%A7%84%E5%88%99">22.5.2. 写final域的重排序规则</a></li>
<li><a href="#2253-%E8%AF%BBfinal%E5%9F%9F%E7%9A%84%E9%87%8D%E6%8E%92%E5%BA%8F%E8%A7%84%E5%88%99">22.5.3. 读final域的重排序规则</a></li>
<li><a href="#2254-final%E5%9F%9F%E4%B8%BA%E5%BC%95%E7%94%A8%E7%B1%BB%E5%9E%8B">22.5.4. final域为引用类型</a></li>
<li><a href="#2255-%E4%B8%BA%E4%BB%80%E4%B9%88final%E5%BC%95%E7%94%A8%E4%B8%8D%E8%83%BD%E4%BB%8E%E6%9E%84%E9%80%A0%E5%87%BD%E6%95%B0%E5%86%85%E6%BA%A2%E5%87%BA">22.5.5. 为什么final引用不能从构造函数内“溢出”</a></li>
<li><a href="#2256-final%E8%AF%AD%E4%B9%89%E5%9C%A8%E5%A4%84%E7%90%86%E5%99%A8%E4%B8%AD%E7%9A%84%E5%AE%9E%E7%8E%B0">22.5.6. final语义在处理器中的实现</a></li>
<li><a href="#2257-happens-before">22.5.7. happens-before</a></li>
<li><a href="#2258-happens-before%E7%9A%84%E5%AE%9A%E4%B9%89">22.5.8. happens-before的定义</a></li>
<li><a href="#2259-happens-before%E8%A7%84%E5%88%99">22.5.9. happens-before规则</a></li>
<li><a href="#22510-%E5%8F%8C%E9%87%8D%E6%A3%80%E6%9F%A5%E9%94%81%E5%AE%9A%E4%B8%8E%E5%BB%B6%E8%BF%9F%E5%88%9D%E5%A7%8B%E5%8C%96">22.5.10. 双重检查锁定与延迟初始化</a></li>
<li>[22.5.11. - 3.8.1 双重检查锁定的由来](#22511</li>
</ul>
</li>
</ul>
</li>
</ul>
]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/d1a3ad11e842eda9f71fa.png" type="image/png"/>
    </item>
    <item>
      <title>Exception</title>
      <link>https://javaguide.cn/backend/java/exception.html</link>
      <guid>https://javaguide.cn/backend/java/exception.html</guid>
      <source url="https://javaguide.cn/rss.xml">Exception</source>
      <description>exception 1. 异常 2. 异常处理：当产生异常时，必须有处理方式。要么捕获，要么声明抛出 3. 自定义异常 1. 异常 Java异常是Java提供的一种识别及响应错误的一致性机制。 Java异常机制可以使程序中异常处理代码和正常业务代码分离，保证程序代码更加优雅，并提高程序健壮性 Java把异常信息封装成一个类。异常时会创建异常类对象并抛出...</description>
      <category>后端</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>exception</p>
<!--more-->
<!-- TOC -->
<ul>
<li><a href="#1-%E5%BC%82%E5%B8%B8">1. 异常</a></li>
<li><a href="#2-%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86%E5%BD%93%E4%BA%A7%E7%94%9F%E5%BC%82%E5%B8%B8%E6%97%B6%E5%BF%85%E9%A1%BB%E6%9C%89%E5%A4%84%E7%90%86%E6%96%B9%E5%BC%8F%E8%A6%81%E4%B9%88%E6%8D%95%E8%8E%B7%E8%A6%81%E4%B9%88%E5%A3%B0%E6%98%8E%E6%8A%9B%E5%87%BA">2. 异常处理：当产生异常时，必须有处理方式。要么捕获，要么声明抛出</a></li>
<li><a href="#3-%E8%87%AA%E5%AE%9A%E4%B9%89%E5%BC%82%E5%B8%B8">3. 自定义异常</a></li>
</ul>
<!-- /TOC -->
<h1>1. 异常</h1>
<ul>
<li>Java异常是Java提供的一种识别及响应错误的一致性机制。</li>
<li>Java异常机制可以使程序中异常处理代码和正常业务代码分离，保证程序代码更加优雅，并提高程序健壮性</li>
<li>Java把异常信息封装成一个类。异常时会创建异常类对象并抛出异常信息(如异常位置、原因)</li>
<li>Exception 类及其子类是 Throwable 的一种形式，它用来表示java程序中可能会产生的异常，并要求对产生的异常进行合理的异常处理</li>
<li>异常处理的性能成本非常高；仅在异常情况下使用异常；在可恢复的异常情况下使用异常；</li>
</ul>
<h1>2. 异常处理：当产生异常时，必须有处理方式。要么捕获，要么声明抛出</h1>
<ul>
<li>在一个方法中如果发生异常，这个方法会创建一个异常对象，并转交给 JVM，该异常对象包含异常名称，异常描述以及异常发生时应用程序的状态。创建异常对象并转交给 JVM 的过程称为抛出异常。可能有一系列的方法调用，最终才进入抛出异常的方法，这一系列方法调用的有序列表叫做调用栈。JVM 会顺着调用栈去查找看是否有可以处理异常的代码，如果有，则调用异常处理代码。当 JVM 发现可以处理异常的代码时，会把发生的异常传递给它。如果 JVM 没有找到可以处理该异常的代码块，JVM 就会将该异常转交给默认的异常处理器（默认处理器为 JVM 的一部分），默认异常处理器打印出异常信息并终止应用程序。</li>
<li>抛出异常：throw new 异常类名(参数)：抛出异常告知调用者。可以抛出所有异常；throw抛出的异常，本身不捕获就要throws抛出</li>
<li>声明异常：方法 throws 异常类名1,异常类名2… {} 声明异常,交给调用者去处理。非检查异常（Error、RuntimeException 或它们的子类）不可使用 throws 关键字来声明要抛出的异常</li>
<li>捕获异常：Java中对异常有针对性的语句进行捕获，可以对出现的异常进行指定方式的处理
<ul>
<li>try catch finally：检测异常，并传递给catch处理，并在finally中进行资源释放</li>
<li>try catch：对代码进行异常检测，并对检测的异常传递给catch处理.对异常进行捕获处理</li>
<li>try 多个catch：对代码进行异常检测，并对检测的异常传递给catch处理，多个catch中的异常不能相同，子类异常要求在上面的catch处理,父类异常在下面的catch处理。有继承关系的异常会最先捕获</li>
<li>try finally：异常是没有捕获处理的，finally，只为关闭资源</li>
<li>finally：一定会执行的，即使在try{}catch{}中有return；finally的return决定该方法的结果</li>
</ul>
</li>
<li>异常的处理，指处理异常的一种可能性，即有了异常处理的代码，不一定会产生异常；如果没有产生异常,则代码正常执行,如果产生异常,则中断当前执行代码,执行异常处理代码
<ul>
<li>String getMessage()：返回此throwable的详细消息字符串</li>
<li>void printStackTrace()：将此throwable及其追踪输出至标准错误流</li>
<li>String toString()：返回此throwable的简短描述</li>
</ul>
</li>
</ul>
<br>
<table>
<thead>
<tr>
<th style="text-align:center">父类</th>
<th style="text-align:center">子类重写方法的细节（"不能比父类多"）</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">如果父类方法声明异常</td>
<td style="text-align:center">子类只能声明父类异常或者该异常的子类，或者不声明</td>
</tr>
<tr>
<td style="text-align:center">当父类方法声明多个异常时</td>
<td style="text-align:center">子类覆盖时只能声明多个异常的子集</td>
</tr>
<tr>
<td style="text-align:center">当被覆盖的方法没有异常声明时</td>
<td style="text-align:center">子类覆盖时无法声明异常的。此时子类产生该异常，只能捕获处理，不能声明抛出</td>
</tr>
<tr>
<td style="text-align:center">当多异常处理时，捕获处理</td>
<td style="text-align:center">前边的类不能是后边类的父类</td>
</tr>
<tr>
<td style="text-align:center">接口中没有声明异常，而实现类覆盖方法时发生了异常</td>
<td style="text-align:center">只能catch的捕获继续throw抛出，并将异常转换成RuntimeException子类抛出</td>
</tr>
</tbody>
</table>
<h1>3. 自定义异常</h1>
<ul>
<li>继承Exception,必须throws声明,一声明就告知调用者捕获,问题处理了调用者的程序会继续执行</li>
<li>继承RuntimeExcpetion,不需throws声明的，调用者不需要编写捕获代码的，因为调用根本就不知道有问题。一旦发生异常，调用者程序会停掉，并由jvm将信息显示到屏幕，让调用者修正代码</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>Class 异常名 extends Exception{ 
	//编译时异常继承Exception，运行时异常继承RuntimeException。
	public 异常名(){
		super();
	}
	public 异常名(String s){ 
		super(s); 
	}
}
</code></pre></div>]]></content:encoded>
    </item>
    <item>
      <title>io</title>
      <link>https://javaguide.cn/backend/java/io.html</link>
      <guid>https://javaguide.cn/backend/java/io.html</guid>
      <source url="https://javaguide.cn/rss.xml">io</source>
      <description>io 1. IO概述 2. IO的继承体系 3. java.io.File：Java中把文件或者目录（文件夹）都封装成File对象 4. java.io.OutputStream: 抽象类，表示输出字节流的所有类的超类 5. java.io.FlieOutputStream 6. java.io.ObjectOutputStream操作对象的流 7. ...</description>
      <category>后端</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>io</p>
<!--more-->
<!-- TOC -->
<ul>
<li><a href="#1-io%E6%A6%82%E8%BF%B0">1. IO概述</a></li>
<li><a href="#2-io%E7%9A%84%E7%BB%A7%E6%89%BF%E4%BD%93%E7%B3%BB">2. IO的继承体系</a></li>
<li><a href="#3-javaiofilejava%E4%B8%AD%E6%8A%8A%E6%96%87%E4%BB%B6%E6%88%96%E8%80%85%E7%9B%AE%E5%BD%95%E6%96%87%E4%BB%B6%E5%A4%B9%E9%83%BD%E5%B0%81%E8%A3%85%E6%88%90file%E5%AF%B9%E8%B1%A1">3. java.io.File：Java中把文件或者目录（文件夹）都封装成File对象</a></li>
<li><a href="#4-javaiooutputstream-%E6%8A%BD%E8%B1%A1%E7%B1%BB%E8%A1%A8%E7%A4%BA%E8%BE%93%E5%87%BA%E5%AD%97%E8%8A%82%E6%B5%81%E7%9A%84%E6%89%80%E6%9C%89%E7%B1%BB%E7%9A%84%E8%B6%85%E7%B1%BB">4. java.io.OutputStream: 抽象类，表示输出字节流的所有类的超类</a></li>
<li><a href="#5-javaioflieoutputstream">5. java.io.FlieOutputStream</a></li>
<li><a href="#6-javaioobjectoutputstream%E6%93%8D%E4%BD%9C%E5%AF%B9%E8%B1%A1%E7%9A%84%E6%B5%81">6. java.io.ObjectOutputStream操作对象的流</a></li>
<li><a href="#7-javaiofilteroutputstream">7. java.io.FilterOutputStream</a></li>
<li><a href="#8-javaioprintstream">8. java.io.PrintStream</a></li>
<li><a href="#9-javaiobufferedoutputstream">9. java.io.BufferedOutputStream</a></li>
<li><a href="#10-javaioinputstream">10. java.io.InputStream</a></li>
<li><a href="#11-javaiofileinputstream">11. java.io.FileInputStream</a></li>
<li><a href="#12-javaioobjectinputstream-%E5%AF%B9%E8%B1%A1%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%B5%81%E4%BB%8E%E6%B5%81%E4%B8%AD%E8%AF%BB%E5%8F%96%E5%AF%B9%E8%B1%A1%E7%9A%84%E6%93%8D%E4%BD%9C%E6%B5%81">12. java.io.ObjectInputStream 对象反序列化流，从流中读取对象的操作流</a></li>
<li><a href="#13-javaiofilterinputstream">13. java.io.FilterInputStream</a></li>
<li><a href="#14-javaiobufferedinputstream">14. java.io.BufferedInputStream</a></li>
<li><a href="#15-javaiowriter-%E5%86%99%E5%85%A5%E5%AD%97%E7%AC%A6%E6%B5%81%E7%9A%84%E6%8A%BD%E8%B1%A1%E7%B1%BB">15. java.io.Writer 写入字符流的抽象类</a></li>
<li><a href="#16-javaiobufferedwriter-%E5%AD%97%E7%AC%A6%E7%BC%93%E5%86%B2%E8%BE%93%E5%87%BA%E6%B5%81%E6%8F%90%E9%AB%98%E4%BA%86io%E8%AF%BB%E5%86%99%E9%80%9F%E5%BA%A6">16. java.io.BufferedWriter 字符缓冲输出流，提高了IO读写速度</a></li>
<li><a href="#17-javaioprintwriter">17. java.io.PrintWriter</a></li>
<li><a href="#18-javaiooutputstreamwriter">18. java.io.OutputStreamWriter</a></li>
<li><a href="#19-javaiofilewriter">19. java.io.FileWriter</a></li>
<li><a href="#20-javaioreader-%E8%AF%BB%E5%8F%96%E5%AD%97%E7%AC%A6%E6%B5%81%E7%9A%84%E6%8A%BD%E8%B1%A1%E8%B6%85%E7%B1%BB">20. java.io.Reader 读取字符流的抽象超类</a></li>
<li><a href="#21-javaiobufferedreader-%E5%AD%97%E7%AC%A6%E7%BC%93%E5%86%B2%E8%BE%93%E5%85%A5%E6%B5%81%E6%8F%90%E9%AB%98%E4%BA%86io%E8%AF%BB%E5%86%99%E9%80%9F%E5%BA%A6">21. java.io.BufferedReader 字符缓冲输入流，提高了IO读写速度</a></li>
<li><a href="#22-javaioinputstreamreader-%E5%AD%97%E8%8A%82%E6%B5%81%E9%80%9A%E5%90%91%E5%AD%97%E7%AC%A6%E6%B5%81%E7%9A%84%E6%A1%A5%E6%A2%81%E5%AE%83%E4%BD%BF%E7%94%A8%E6%8C%87%E5%AE%9A%E7%9A%84%E5%AD%97%E7%AC%A6%E7%BC%96%E7%A0%81%E8%A1%A8%E8%AF%BB%E5%8F%96%E5%AD%97%E8%8A%82%E5%B9%B6%E5%B0%86%E5%85%B6%E8%A7%A3%E7%A0%81%E4%B8%BA%E5%AD%97%E7%AC%A6">22. java.io.InputStreamReader 字节流通向字符流的桥梁：它使用指定的字符编码表读取字节并将其解码为字符</a></li>
<li><a href="#23-javaiofilereader">23. java.io.FileReader</a></li>
<li><a href="#24-flush%E5%92%8Cclose%E7%9A%84%E5%8C%BA%E5%88%AB">24. flush()和close()的区别？</a></li>
<li><a href="#25-%E6%96%87%E4%BB%B6%E5%A4%8D%E5%88%B6">25. 文件复制</a></li>
</ul>
<!-- /TOC -->
<!-- /TOC -->
<h1>1. IO概述</h1>
<ul>
<li>IO就是将内存中的数据持久化存储到持久化设备上，使用的时候从持久化设备上读入内存</li>
<li>IO操作:当需要把内存中的数据存储到持久化设备上这个动作称为输出（写）Output操作。
<ul>
<li>当把持久设备上的数据读取到内存中的这个动作称为输入（读）Input操作。</li>
</ul>
</li>
<li>IOExcption异常</li>
</ul>
<h1>2. IO的继承体系</h1>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/3e02a33c786b280333be7.png" alt="IO.jpg" tabindex="0"><figcaption>IO.jpg</figcaption></figure>
<h1>3. java.io.File：Java中把文件或者目录（文件夹）都封装成File对象</h1>
<ul>
<li>File("e:\a\hello.java");将给定路径名称字符串转换为抽象路径名创建File对象，(包括不存在文件或者文件夹)</li>
<li>boolean createNewFile()创建不存在的文件并返回true，存在false</li>
<li>boolean mkdir()创建不存在的单层文件夹并返回true，存在false</li>
<li>boolean mkdirs()创建多层文件夹</li>
<li>boolean delete()删除此抽象路径名表示的文件或空目录</li>
<li>boolean isFile()判断此抽象路径名表示的文件是否为标准文件</li>
<li>boolean isDirectory()判断此抽象路径名表示的文件是否是目录（文件夹）</li>
<li>String getAbsolutePath()获取当前File对象的绝对路径名字符串</li>
<li>String getPath()将此抽象路径名转换为一个路径名字符串</li>
<li>String getName()获取当前File对象的文件或目录的名称</li>
<li>long length()获取当前File对象的文件或文件夹的大小（字节）</li>
<li>boolean exists() 判断File对象对应的文件或目录是否存在</li>
<li>String[] list()获得抽象路径名目录的文件和目录的字符串数组，指定的目录必须是存在的目录。否则数组为null</li>
<li>File[] listFiles()获取抽象路径名目录中的File对象数组，指定的目录必须是存在的目录。否则数组为null</li>
<li>File[] listFiles(FilenameFilter filter)返回File的目录中满足过滤器的文件和目录抽象路径名数组</li>
<li>File[] listFiles(FileFilter filter)返回File的目录中满足过滤器的文件和目录抽象路径名数组</li>
<li>FilenameFilter接口:过滤文件名</li>
<li>boolean accept(FIle dir,String name)测试指定路径名是否包含在某个路径列表中中</li>
<li>FileFilter接口:过滤文件或者文件夹</li>
<li>boolean accept(File pathname)测试指定抽象路径名是否应该包含在某个路径名列表中</li>
</ul>
<h1>4. java.io.OutputStream: 抽象类，表示输出字节流的所有类的超类</h1>
<ul>
<li>void close()关闭输出流并释放与此流有关的所有系统资源</li>
<li>void flush()刷新此输出流并强制写出所有输出字节</li>
<li>void write(byte[] b)将b.length个字节从指定的byte数组写入此输出流</li>
<li>void write(byte[] b,int off,int len)将制定byte数组从偏移量off开始的len个字节写入此输出流</li>
</ul>
<h1>5. java.io.FlieOutputStream</h1>
<ul>
<li>FlieOutputStream(File file)创建Flie对象表示文件中写入数据的输出流（文件存在则覆盖）</li>
<li>FlieOutputStream(String name)创建指向指定名称文件中写入数据的输出流(文件存在则覆盖)</li>
<li>FileOutputStream(File file,boolean append)true在文件末尾继续添加，“\r\n”换行</li>
<li>FlieOutputStream(String name,boolean append)true就表示可以在文件末尾继续添加</li>
</ul>
<h1>6. java.io.ObjectOutputStream操作对象的流</h1>
<ul>
<li>ObjectOutputStream(OutputStream out)传入OutputStream的实现类如FileOutputStream即可</li>
<li>void writeObject(Object obj)将指定对象写入ObjectOutputStream</li>
<li>①被序列化的对象所属的类必须实现Serializable接口。否则会发生异常NotSerializableException异常。</li>
<li>②反序列化对象时，如果对象所属的class文件在序列化之后被修改了，那么会发生异常InvalidClassException。</li>
<li>Serializable标记接口，给需要序列化的类，提供了一个序列版本号serialVersionUID. private static final long serialVersionUID = 1L;该版本号的目的在于验证序列化的对象和对应类是否版本匹配</li>
<li>③transient修饰的属性不会琲序列化</li>
<li>④静态修饰也不会被序列化，因为序列化是把对象数据进行持久化存储，而静态的属于类加载时的数据，不会被序列化</li>
</ul>
<h1>7. java.io.FilterOutputStream</h1>
<ul>
<li>FilterOutputStream(OutputStream out)传入OutputStream的实现类如FileOutputStream即可</li>
</ul>
<h1>8. java.io.PrintStream</h1>
<ul>
<li>PrintStream(OutputStream out, boolean autoFlush)开启文件自动刷新</li>
<li>void print(String str)输出任意类型的数据</li>
<li>void println(String str)输出任意类型的数据，自动写入换行操作</li>
</ul>
<h1>9. java.io.BufferedOutputStream</h1>
<ul>
<li>BufferedOutputStream(OutputStream out)字节缓冲输出流提高了IO的读写速度</li>
</ul>
<h1>10. java.io.InputStream</h1>
<ul>
<li>InputStream此抽象类，是表示字节输入流的所有类的超类。</li>
<li>int read()读取一个字节并返回，没有字节返回-1.//速度慢</li>
<li>int read(byte[] b)读取一定量的字节数，并存储到字节(推荐1024整数倍字节)数组中</li>
</ul>
<h1>11. java.io.FileInputStream</h1>
<ul>
<li>FileInputStream(File file)通过File对象来创建一个FileInputStream</li>
<li>FileInputStream(String name)通过文件系统中的路径名name来创建一个FileInputStream</li>
</ul>
<h1>12. java.io.ObjectInputStream 对象反序列化流，从流中读取对象的操作流</h1>
<ul>
<li>ObjectInputStream(InputStream in)传入InputStream的实现类如FileInputStream即可</li>
<li>Object readObject()从ObjectInputStream读取对象</li>
<li>①被序列化的对象所属的类必须实现Serializable接口。否则会发生异常NotSerializableException异常。</li>
<li>②反序列化对象时，如果对象所属的class文件在序列化之后被修改了，那么会发生异常InvalidClassException。</li>
<li>Serializable标记接口给需要序列化的类提供了一个序列版本号serialVersionUID. private static final long serialVersionUID = 1L;该版本号的目的在于验证序列化的对象和对应类是否版本匹配</li>
<li>③transient修饰的属性不会琲序列化</li>
<li>④静态修饰也不会被序列化，因为序列化是把对象数据进行持久化存储，而静态的属于类加载时的数据，不会被序列化</li>
</ul>
<h1>13. java.io.FilterInputStream</h1>
<ul>
<li>FilterInputStream(OutputStream out)传入OutputStream的实现类如FileOutputStream即可</li>
</ul>
<h1>14. java.io.BufferedInputStream</h1>
<ul>
<li>BufferedInputStream(InputStream in)字节缓冲输入流，提高了IO的读写速度</li>
</ul>
<h1>15. java.io.Writer 写入字符流的抽象类</h1>
<ul>
<li>void write(String str)写入字符串</li>
<li>void write(String str,int off,int len)写入字符串的某一部分</li>
<li>void write(char[] cbuf)写入字符数组</li>
<li>abstract void write(char[] cbuf,int off,int len)写入字符数组的某一部分</li>
<li>void write(int c)写入单个字符字节流转成字符流，将字符串按照指定的编码表转成字节</li>
</ul>
<h1>16. java.io.BufferedWriter 字符缓冲输出流，提高了IO读写速度</h1>
<ul>
<li>BufferedWriter(Writer out)使用默认大小输出缓冲区,传入Writer实现类如FileWriter</li>
<li>void newLine()根据当前的系统，写入一个换行符</li>
</ul>
<h1>17. java.io.PrintWriter</h1>
<ul>
<li>public PrintWriter(OutputStream out, boolean autoFlush)//开启文件自动刷新</li>
<li>PrintWriter(Writer out, boolean autoFlush)//开启文件自动刷新</li>
<li>void println(String str): 输出任意类型的数据，自动写入换行操作</li>
<li>void print(String str)输出任意类型的数据</li>
</ul>
<h1>18. java.io.OutputStreamWriter</h1>
<ul>
<li>OutputStreamWriter类字符流转成字节流，将字符串按照指定的编码表转成字节</li>
<li>OutputStreamWriter(OutputStream out Charset cs)创建使用给定字符集的编码对象</li>
</ul>
<h1>19. java.io.FileWriter</h1>
<ul>
<li>FileWriter假定默认字符编码GBK和默认字节缓冲区大小都是可接受的。</li>
<li>FileWriter(File file)根据File对象构造一个FileWriter对象(覆盖)</li>
<li>FileWriter(String FileName)根据文件名创建FileWriter对象</li>
<li>FileWriter(File file,boolean append)File对象构造FileWriter对象(true继续写)</li>
<li>FileWriter(String FileName,boolean append)文件名创建FileWriter对象(true继续写)</li>
</ul>
<h1>20. java.io.Reader 读取字符流的抽象超类</h1>
<ul>
<li>int read()读取单个字符并返回，若没有则返回-1</li>
<li>int read(char[] cbuf)将字符读入数组，并返回读取的个数</li>
</ul>
<h1>21. java.io.BufferedReader 字符缓冲输入流，提高了IO读写速度</h1>
<ul>
<li>BufferedReader(Reader in)默认大小输入缓冲区</li>
<li>String readLine()返回文本行内容字符串，不包含任何行终止符，到达流的末尾返回null</li>
</ul>
<h1>22. java.io.InputStreamReader 字节流通向字符流的桥梁：它使用指定的字符编码表读取字节并将其解码为字符</h1>
<ul>
<li>InputStreamReader(InputStream&nbsp;in Charset&nbsp;cs)创建使用给定字符集的解码对象</li>
</ul>
<h1>23. java.io.FileReader</h1>
<ul>
<li>读取字符文件的便捷类，假定默认字符编码GBK和默认字节缓冲区大小都是适当的</li>
<li>FileReader(File file)从file对象创建一个新的FileReader</li>
<li>FileReader(String fileName)从读取数据的文件名创建一个新的FileReader</li>
</ul>
<h1>24. flush()和close()的区别？</h1>
<ul>
<li>flush():将流中的缓冲区缓冲的数据刷新到目的地中，刷新后，流还可以继续使用。</li>
<li>close():关闭资源，但在关闭前会将缓冲区中的数据先刷新到目的地，否则丢失数据，然后在关闭流。流不可以使用。如果写入数据多，一定要一边写一边刷新，<br>
最后一次可以不刷新，由close完成刷新并关闭</li>
</ul>
<h1>25. 文件复制</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>采用高效的流，一个多个字节的方式赋值
BufferedInputStream in = new BufferedInputStream(new FileInputStream(src));
BufferedOutputStream out = new BufferedOutputStream(new FileOutputStream(dest));
byte[] buffer = new byte[1024];
int len = -1;
while ( (len = in.read(buffer)) != -1) {
	out.write(buffer, 0, len);
}
in.close();
out.close();
采用高效的流，一次一个字节的方式复制
BufferedInputStream in = new BufferedInputStream(new FileInputStream(src));
BufferedOutputStream out = new BufferedOutputStream(new FileOutputStream(dest));
int ch = -1;
while ((ch=in.read()) != -1) {
	out.write(ch);	
}		
in.close();
out.close();
采用高效的流文件复制
BufferedReader in = new BufferedReader(new FileReader("file.txt"));
BufferedWriter out = new BufferedWriter(new FileWriter("copyFile.txt"));
String line = null;
while ( (line = in.readLine()) != null ) {
	out.write(line);
	out.newLine();
}
out.close();
in.close();
</code></pre></div>]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/3e02a33c786b280333be7.png" type="image/png"/>
    </item>
    <item>
      <title>java</title>
      <link>https://javaguide.cn/backend/java/java.html</link>
      <guid>https://javaguide.cn/backend/java/java.html</guid>
      <source url="https://javaguide.cn/rss.xml">java</source>
      <description>java java概述 java是用来编写互联网(电商、P2P)和企业级应用(ERP、CRM、BOS、OA)等软件的一门面向对象编程语言 java跨平台(操作系统:Windows\Linux\Mac)特性:一次编写后在任意操作系统上运行，依赖虚拟机JVM（java Virtual Machine）实现 Java语言采用Unicode编码标准，Unico...</description>
      <category>后端</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>java</p>
<!--more-->
<h1>java概述</h1>
<ul>
<li>java是用来编写互联网(电商、P2P)和企业级应用(ERP、CRM、BOS、OA)等软件的一门面向对象编程语言</li>
<li>java跨平台(操作系统:Windows\Linux\Mac)特性:一次编写后在任意操作系统上运行，依赖虚拟机JVM（java Virtual Machine）实现</li>
<li>Java语言采用Unicode编码标准，Unicode（标准码），它为每个字符制订了一个唯一的数值</li>
<li>jdk1.5之后的三大版本
<ul>
<li>Java SE（J2SE，Java 2 Platform Standard Edition，标准版）桌面、服务器、嵌入式环境</li>
<li>Java EE（J2EE，Java 2 Platform Enterprise Edition，企业版）提供 Web 服务、组件模型、管理和通信 API</li>
<li>Java ME（J2ME，Java 2 Platform Micro Edition，微型版）移动设备和嵌入式设备</li>
</ul>
</li>
</ul>
<h1>java开发环境的搭建</h1>
<ul>
<li>java开发环境概述（java程序运行需要的环境）
<ul>
<li>JDK：java Development Kit，程序员的电脑上安装JDK；JDK包含JRE</li>
<li>JRE：java Runtime Environment，java运行环境，用户在电脑上安装JRE即可</li>
</ul>
</li>
<li>java程序运行过程
<ul>
<li>java源代码-&gt;编译器-&gt;jvm可执行的java字节码(即虚拟指令)-&gt;jvm-&gt;jvm中解析器-&gt;机器可执行的二进制机器码-&gt;程序运行</li>
</ul>
</li>
<li>编写HelloWorld程序
<ul>
<li>编写java源代码文件:用记事本新建文件并命名为HelloWorld.java（类名必须与源文件名称完全相同）</li>
<li>编译：通过jvm编译器把源文件编译成字节码文件(扩展名为.class)
<ul>
<li>编译器：JDK目录下的bin目录javac.exe</li>
<li>编译命令为：D:\develop\java\jdk1.7.0_72\bin\javac.exe D:\java\HelloWorld.java</li>
<li>编译之后会在源文件同目录下生成字节码文件，字节码文件的扩展名为.class</li>
<li>编译时控制台上不会有输出，如果有输出说明源代码有错误</li>
</ul>
</li>
<li>运行：使用解释器来运行字节码文件
<ul>
<li>D:\develop\java\jdk1.7.0_72\bin\java.exe HelloWord 在运行HelloWorld.class文件时不能给出“.class”，切记！！！</li>
</ul>
</li>
<li>解释器运行过程：
<ul>
<li>查找classpath下面的所有的class文件，从根目录开始，解释器获取包的名称并将每个句点替换成反斜杠，以从classpath根中产生路径名称，得到的路径会与classpath中的各个不同的项相连接，解释器就在这些目录中查找与你所要创建的类名称相关的.class文件</li>
</ul>
</li>
<li>查看字节码文件
<ul>
<li>D:\develop\java\jdk1.7.0_72\bin\javap.exe –c HelloWord 在运行HelloWorld.class文件时不能给出“.class”，切记！！！</li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class HelloWorld {
    public static void main(String[] args) {
        System.out.println("HelloWorld");
    }
}
</code></pre></div><ul>
<li>配置java环境变量（减少输入JDK的bin目录的麻烦）
<ul>
<li>在DOS控制台中使用的程序只给出程序名称，而没有给出完整路径时，Windows系统会到Path变量保存的路径中查找程序
<ul>
<li>鼠标右键点击计算机→属性→高级系统设置→环境变量→系统变量中的Path→编辑，将JDK安装目录\bin路径配置到PATH变量中，用英文分号与其他变量隔开</li>
<li>编译：D:&gt;javac HelloWorld.java</li>
<li>运行：D:&gt;java HelloWorld</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1><code>注释、关键字与标识符</code></h1>
<ul>
<li>
<p>程序注释:对源码进行解释说明的文字, //单行注释、/*多行注释*/、/**文档注释**/</p>
</li>
<li>
<p>关键字:被赋予特殊含义，具有专门用途的均为小写的单词,public等|</p>
</li>
<li>
<p>标识符:类、方法、变量、包、接口名,组成元素 a-zA-Z、0-9、_与$</p>
<ul>
<li>规则:数字不能开头、不可以使用关键字、严格区分大小写，见名知意</li>
<li>命名规范
<ul>
<li>包名：多单词组成时所有字母均小写，使用.连接aaa.bbb.ccc</li>
<li>类名&amp;接口名：大驼峰式AaaBbbCcc</li>
<li>变量名&amp;方法名：小驼峰式aaaBbbCcc</li>
<li>常量名：多单词组成是所有字母均大写，使用_连接AAA_BBB_CCC</li>
<li>表名&amp;字段名&amp;视图名&amp;存储过程: 小写字母或者数字+下划线</li>
</ul>
</li>
</ul>
</li>
<li>
<p>查看注释文档 D:\java\jdk1.7.0_72\bin\javadoc.exe –c HelloWord.java</p>
</li>
</ul>
<h1><code>数据类型</code></h1>
<ul>
<li>数据类型数据范围从小到大：byte -&gt; short -&gt; int -&gt; long -&gt; float -&gt; double</li>
<li>范围小的数据类型值（如byte），可以直接转换为范围大的数据类型值（如int）</li>
<li>范围大的数据类型值（如int），不可以直接转换为范围小的数据类型值（如byte）</li>
<li>多种类型数据混合运算时，系统自动将所有数据转换成容量最大的那一种数据类型再计算</li>
<li>数据类型转换（布尔值除外）不同类型的变量可以在一起运算，但要先进行类型转换再运算
<ul>
<li>自动类型转换:范围小的数据类型转换成范围大的数据类型 格式:范围大的数据类型 变量 = 范围小的数据类型值</li>
<li>强制类型转换:范围大的数据类型转换成范围小的数据类型 格式:范围小的数据类型 变量 = (范围小的数据类型) 范围大的数据类型值，</li>
</ul>
</li>
<li>基本数据类型存储在堆栈中，对象存储在堆中</li>
<li>成员变量时上述数据类型才有默认值，局部变量没有</li>
</ul>
<h1>直接常量和变量</h1>
<table>
<thead>
<tr>
<th style="text-align:center">直接常量(不变的数据量)数据类型</th>
<th style="text-align:center">举例（字符均指汉字数字和字母）</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">整数类型</td>
<td style="text-align:center">二进制：以0零b(0B)开头 如0b1011 、0B1001</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">八进制：以0开头   如01、07、0721</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">十进制：正常数字   如 13、25等</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">十六进制：以0x(0X)开头,数字以0-9及A-F组成,如0x23A2、0xa、0x10</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">其他进制到十进制：把系数*基数的权次幂相加即可。</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">十进制到其他进制转换：除基取余，直到商为0，最后，余数反转就是结果</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">整数常量根据所在范围来确定类型、默认的整数类型是int类型</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">添加了“L”后缀的整数常量都是long类型</td>
</tr>
<tr>
<td style="text-align:center">浮点类型</td>
<td style="text-align:center">1.0、-3.15、3.168等</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">无后缀以及使用“D”后缀的小数都是double类型(默认的浮点类型)</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">float类型常量必须添加“F”后缀，默认的浮点类型是double类型</td>
</tr>
<tr>
<td style="text-align:center">字符类型</td>
<td style="text-align:center">字符必须使用’’ 包裹，并且其中只能且仅能包含一个字符</td>
</tr>
<tr>
<td style="text-align:center">布尔类型</td>
<td style="text-align:center">true、false</td>
</tr>
<tr>
<td style="text-align:center">字符串类型String(引用类型)</td>
<td style="text-align:center">字符串必须使用""包裹，可以包含0~N个字符</td>
</tr>
</tbody>
</table>
<ul>
<li>变量:内存中装载数据的小盒子，用来存数据和取数据</li>
<li>定义变量：数据类型  变量名  =  数据值；</li>
<li>变量定义后可以不赋值，使用时再赋值。不赋值不能使用</li>
<li>变量不可以重复定义</li>
<li>变量使用时有作用域的限制</li>
</ul>
<h1>原码、反码、补码（看计算机组成原理）</h1>
<ul>
<li>原码：二进制数的有符号表示法，即最高位为符号位，</li>
<li>反码：A：正数 与原码相同B：负数 符号位不变，数值位按位取反，0变1,1变0</li>
<li>补码：A：正数 与原码相同B：负数 反码加1。</li>
</ul>
<h1>运算符</h1>
<ul>
<li>运算符是用来计算数据的符号。数据为常量或变量。被运算符操作的数我们称为操作数。</li>
<li>String与其他基本数据类型相加，会将其他类型转换为String再拼接</li>
<li>如果对char、byte、short类型进行移位处理，那么在移位进行之前，会先转成int，结果也是int。</li>
<li>int只有数值右端的低5位有效，防止溢出，因为2的5次方为32，int类型只有32位，同理，long只有6位</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align:center">运算符</th>
<th style="text-align:center">举例</th>
<th style="text-align:center">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">算术运算符</td>
<td style="text-align:center">-(减、负号)、*、+(正、加号、连接字符串)</td>
<td style="text-align:center">加法运算符在连接字符串时只有直接与字符串相加才会转成字符串</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">%(取模)</td>
<td style="text-align:center">小数取余没有意义。结果符号与被取余符号相同</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">/</td>
<td style="text-align:center">均为整数则取整舍余，当其中一边为浮点型则按正常规则相除。除数不为0</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">++(自增)--(自减)</td>
<td style="text-align:center">单独使用，不参与运算操作时，运算符前后位置导致的运算结果一致</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">后置时运算后才自增/减1，前置则运算前自增/减1</td>
</tr>
<tr>
<td style="text-align:center">赋值运算符</td>
<td style="text-align:center">+=、-=、*=、/=、%=</td>
<td style="text-align:center">将结果自动强转成等号左边的数据类型,左边必须是变量</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">=</td>
<td style="text-align:center">将=符号右边的值，赋值给=符号左边的变量</td>
</tr>
<tr>
<td style="text-align:center">比较运算符</td>
<td style="text-align:center">!=、&lt;、&gt;、&lt;=、&gt;=</td>
<td style="text-align:center">返回布尔值，判断两个操作数的大小关系及是否相等关系</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">==</td>
<td style="text-align:center">比较左右基本数字类型的变量值或者引用数据类型的变量的内存地址是否相等</td>
</tr>
<tr>
<td style="text-align:center">逻辑运算符</td>
<td style="text-align:center">&amp;(与)、¦(或)、</td>
<td style="text-align:center">连接两个其他表达式计算后的布尔值结果，并求出布尔值结果</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">&amp;&amp;(短路与)、¦¦(短路或)</td>
<td style="text-align:center">只要能判断出结果则后边的部分就不再判断</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">逻辑非!</td>
<td style="text-align:center">将true变false，false变true</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">异或^：</td>
<td style="text-align:center">左右两边条件结果相同，结果就为false，否则true</td>
</tr>
<tr>
<td style="text-align:center">三元运算符</td>
<td style="text-align:center">(条件表达式)？表达式1：表达式2；</td>
<td style="text-align:center">条件表达式的值若为true，结果为表达式1；否则为表达式2</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">System.out.println( 3&gt;2 ? “正确” : “错误” );</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">int a = 3;int b = 4;String result = (a==b) ? “相等” : “不相等”;</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">int n = (3&gt;2 &amp;&amp; 4&gt;6) ? 100 : 200;</td>
</tr>
<tr>
<td style="text-align:center">按位操作符</td>
<td style="text-align:center">&amp;(按位与)</td>
<td style="text-align:center">仅当两个操作数都为1时。输出结果才为1。否则为0</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">¦(按位或)</td>
<td style="text-align:center">仅当两个操作数都为0时，输出的结果才为0。</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">~(取反)</td>
<td style="text-align:center">将各位数字取反：全部的0置为1，1置为0</td>
</tr>
<tr>
<td style="text-align:center">移位操作符</td>
<td style="text-align:center">^(异或)</td>
<td style="text-align:center">仅当两个操作数不同一时候。对应的输出结果才为1，否则为0</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">&lt;&lt;</td>
<td style="text-align:center">左移就是把一个数的全部位数都向左移动若干位，低位补0，乘以2的n次幂</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">&gt;&gt;</td>
<td style="text-align:center">右移就是把一个数的全部位数都向右移动若干位，若正数，高位插入0，否则插入1，除以2的n次幂</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">&gt;&gt;&gt;</td>
<td style="text-align:center">无符号右移一位。无论正负都在高位插入0</td>
</tr>
</tbody>
</table>
<br>
<table>
<thead>
<tr>
<th style="text-align:center">运算符优先级</th>
<th style="text-align:center">描述</th>
<th style="text-align:center">运算符</th>
<th style="text-align:center">优先级</th>
<th style="text-align:center">描述</th>
<th style="text-align:center">运算符</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">括号</td>
<td style="text-align:center">()、[]</td>
<td style="text-align:center">9</td>
<td style="text-align:center">按位与</td>
<td style="text-align:center">&amp;</td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">正负号</td>
<td style="text-align:center">+、-</td>
<td style="text-align:center">10</td>
<td style="text-align:center">按位异或</td>
<td style="text-align:center">^</td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center">自增自减，非</td>
<td style="text-align:center">++、--、!</td>
<td style="text-align:center">11</td>
<td style="text-align:center">按位或</td>
<td style="text-align:center">|</td>
</tr>
<tr>
<td style="text-align:center">4</td>
<td style="text-align:center">乘除，取余</td>
<td style="text-align:center">*、/、%</td>
<td style="text-align:center">12</td>
<td style="text-align:center">逻辑与</td>
<td style="text-align:center">&amp;&amp;</td>
</tr>
<tr>
<td style="text-align:center">5</td>
<td style="text-align:center">加减</td>
<td style="text-align:center">+、-</td>
<td style="text-align:center">13</td>
<td style="text-align:center">逻辑或</td>
<td style="text-align:center">||</td>
</tr>
<tr>
<td style="text-align:center">6</td>
<td style="text-align:center">移位运算</td>
<td style="text-align:center">&lt;&lt;、&gt;&gt;、&gt;&gt;&gt;</td>
<td style="text-align:center">14</td>
<td style="text-align:center">条件运算</td>
<td style="text-align:center">?:</td>
</tr>
<tr>
<td style="text-align:center">7</td>
<td style="text-align:center">大小关系</td>
<td style="text-align:center">&gt;、&gt;=、&lt;、&lt;=</td>
<td style="text-align:center">15</td>
<td style="text-align:center">赋值运算</td>
<td style="text-align:center">=、+=、-=、*=、/=、%=</td>
</tr>
<tr>
<td style="text-align:center">8</td>
<td style="text-align:center">相等关系</td>
<td style="text-align:center">==、!=</td>
<td style="text-align:center">16</td>
<td style="text-align:center">位赋值运算</td>
<td style="text-align:center">&amp;=、|=、&lt;&lt;=、&gt;&gt;=、&gt;&gt;&gt;=</td>
</tr>
</tbody>
</table>
<h1>流程控制</h1>
<h2>顺序结构</h2>
<h2>选择结构</h2>
<ul>
<li>选择结构if</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>	if语句判断条件是一个布尔值，当判断条件为true时，{}中的执行语句才会执行
		if (条件语句){ 
			执行语句;
			……
		}
	if…else语句指如果判断条件为true时，就进行某种处理，否则就进行另一种处理
		if (判断条件){
			执行语句1
			……
		}else{
			执行语句2
			……
		}//与三元运算符功能相似
	if…else if…else语句所有条件均未满足，else后面{}中的执行语句n+1会执行
		if (判断条件1) {
			执行语句1
		} else if (判断条件2) {
			执行语句2
		}
		...
		else if (判断条件n) {
			执行语句n
		} else {
			执行语句n+1
		}
</code></pre></div><ul>
<li>选择结构switch：if…else if…else语句来实现，但是由于判断条件比较多，实现起来代码过长，不便于阅读</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>	switch (表达式){//表达式的值为byte、short、int、char、enum枚举、String
	case 目标值1:
		执行语句1
		break;
	case 目标值2:
	case 目标值3:
		执行语句2//多个条件满足
		break;
	．．．．．．
	case 目标值n:
		执行语句n
		break;
	default:
		执行语句n+1
		break;
	}
</code></pre></div><h2>循环结构（迭代）</h2>
<ul>
<li>循环语句while：反复进行条件判断，条件成立，{}内的执行语句就会执行，直到条件不成立，while循环结束</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>	while(循环条件表达式){//循环体
		执行语句...
		控制条件表达式;
	}
</code></pre></div><ul>
<li>循环语句do…while：循环体会无条件执行一次，然后再根据循环条件来决定是否继续执行</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>	do {
		执行语句………
		控制条件表达式;
	} while(循环条件表达式);
</code></pre></div><ul>
<li>循环语句for：一般用在循环次数已知的情况下</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>	for（初始化表达式; 循环条件; 操作表达式）{//1,243,243
		执行语句
		………
	}
	for(数据类型 变量名 : 遍历的变量){
		执行语句
	}
</code></pre></div><ul>
<li>无限循环:while(true){} 或for(;😉{} ：无限循环存在的原因是并不知道循环多少次，而是根据某些条件，来控制循环</li>
<li>循环嵌套:在一个循环语句的循环体中再定义一个循环语句的语法结构</li>
</ul>
<h2>跳转语句</h2>
<ul>
<li>break语句
<ul>
<li>在switch条件语句中时，终止某个case并跳出switch结构</li>
<li>在循环语句中，作跳出本层循环语句，执行后面的代码</li>
<li>标记：当break语句出现在嵌套循环中的内层循环时，它只能跳出内层循环，</li>
<li>如果想使用break语句结束嵌套循环则需要对外层循环添加标签（后面跟有冒号的标识符） XXX：然后break XXX</li>
</ul>
</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public static void main(String[] args) {
    ok:
    for (int i = 0; i &lt; 10; i++) {
        for (int j = 0; j &lt; 10; j++) {
            System.out.println("i=" + i + ",j=" + j);
            if (j == 5) {
                break ok;
            }
        }
    }
}
</code></pre></div><ul>
<li>continue语句：终止本次循环，执行下一次循环；可以通过使用标记的方式结束本次嵌套循环，用法与break语句相似</li>
</ul>
<h1>数组</h1>
<ul>
<li>数组（长度固定，数组中存储的元素的数据类型要求一致）</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>|分类|说明|代码|
|:-:|:-:|:-:|
|一维数组|定义|动态初始化（定义数组时只指定数组长度，由系统自动为元素赋初值）|
|||数据类型[] 数组名 = new 数据类型[数组长度];|
|||静态初始化（定义数组时为元素赋值）|
|||类型[] 数组名 = new 类型[]{元素，元素，……};|
|||类型[] 数组名 = {元素，元素，元素，……};(建议)|
||访问|数组名[索引]、数组名[索引] =值、数组名.length|	
||遍历|for (int i = 0; i &lt; arr.length; i++) {System.out.println(arr[i]);}|
||最值|int max=arr[0];for(int x=1;x&lt;arr.length;x++){if(arr[x] &gt; max){max = arr[x];}}|
|二维数组|定义|int[][] arr = new int[m][n]|
|||m:二维数组中一维数组的个数,n:每个一维数组中元素的个数int[][] arr = new int[3][];|
|||每一个一维数组通过赋值来确定数组长度int[][] arr = &amp;#123;&amp;#123;1,2&amp;#125;,&amp;#123;3,4,5,6&amp;#125;,&amp;#123;7,8,9&amp;#125;&amp;#125;|
||访问|数组名[索引][索引]、数组名[索引][索引]=值、数组名.length|
||遍历|for(int i=0;i&lt;arr2.length;i++){for(int j=0;j&lt;arr2[i].length;j++){System.out.println(arr2[i][j]);}}|
|数组异常||NullPointerException变量引用数组时，变量的值必须是数组对象，不能为null
|||ArrayIndexOutOfBoundsException访问数组的元素时，索引不能超出0~length-1范围|
</code></pre></div><h1>可变参数：(Object... args)</h1>
<h1>类与对象</h1>
<ul>
<li>类是对某一类事物的抽象描述，类用于描述多个对象的共同特征，它是对象的模板。</li>
<li>对象用于表示现实中该类事物的个体，它是类的实例</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>[public] [abstract] class 类名{
    访问修饰符 [static] [final] 数据类型 变量名(s);//变量

    访问修饰符 [abstract|static]  [void/返回值] 方法名([参数类型 参数名])//参数列表//成员[静态]方法
    [{//局部代码块
        [执行语句………;]
        [return 返回值;]
    }](s);

    访问修饰符 类名{}(s);//构造方法

    {}(s);//构造代码块
    
    static{}(s);//静态代码块
    
    内部类(s);
}
</code></pre></div><ul>
<li>成员方法
<ul>
<li>形式参数：方法定义中参数列表的变量、实际参数：调用方法时，传入给方法的数值</li>
<li>当传入的数值为基本数据类型（包含String类型），传递的是变量的值</li>
<li>当传入的数值为引用数据类型（String类型除外），传递的是变量的地址</li>
<li>有返回值方法调用:①单独调用②输出调用③赋值调用、无返回值类型的方法调用方式：单独调用</li>
</ul>
</li>
<li>构造方法
<ul>
<li>构造方法名称必须和类型保持一致、想让其他程序无法创建该类的对象，则用private修饰</li>
<li>构造方法默认第一条语句为super();用来访问父类中的空参数构造方法，进行父类成员的初始化操作</li>
<li>super(参数) 与 this(参数) 不能同时在构造方法中存在</li>
<li>默认先执行父类的构造方法，再执行子类的构造方法</li>
</ul>
</li>
<li>局部代码块{}:定义在方法中的代码块,用来限制变量的作用范围</li>
<li>构造代码块{}:定义在类中方法外的代码块、创建对象时只执行一次，用于对象成员初始化、优先于构造方法执行</li>
<li>静态代码块static{}:定义在类中方法外使用static修饰的代码块、被加载时执行一次，用于给静态变量赋值、类静态成员初始化赋值。优于主方法、构造代码块执行</li>
<li>finalize()方法：一旦垃圾回收器准备好释放对象占用的存储空间，会先调用器finalize()方法，并且在下一次垃圾回收动作发生时，才会真正回收对象占用的内存
<ul>
<li>有时，若分配内存时采用类类似C语言中的做法，即调用本地方法时需要来释放内存，但不要滥用</li>
</ul>
</li>
</ul>
<h2>匿名对象</h2>
<ul>
<li>创建对象时，只有创建对象的语句，却没有把对象地址值赋值给某个变量 new 类名([参数]);</li>
<li>只能使用一次、可作为方法接收的参数、方法返回值使用</li>
</ul>
<h1>转型</h1>
<ul>
<li>向上转型:当有子类对象赋值给一个父类引用（多态）
<ul>
<li>方法传参可以定义为父类，实际参数可以传子类</li>
<li>父类类型 变量名 = (父类类型) 子类类型的变量</li>
<li>好处：隐藏了子类类型，提高了代码的扩展性</li>
<li>弊端：只能使用父类共性的内容，而无法使用子类特有功能</li>
</ul>
</li>
<li>向下转型：一个已经向上转型的子类对象可以使用强制类型转换,将父类引用转为子类引用
<ul>
<li>如果是直接创建父类对象，是无法向下转型的！</li>
<li>子类类型 变量名 = (子类类型) 父类类型的变量</li>
<li>好处：可以使用子类特有功能</li>
<li>弊端：需要面对具体的子类对象；容易发生ClassCastException类型转换异常。在转换之前必须做类型判断</li>
</ul>
</li>
<li>当不需要面对子类类型时，通过提高扩展性，或者使用父类的功能就能完成相应的操作 当要使用子类特有功能时，就需要使用向下转型</li>
</ul>
<h1>抽象类（基础功能）与接口（扩展功能）</h1>
<ul>
<li>抽象类：被abstract关键字修饰的类是抽象类，定义了抽象方法的类
<ul>
<li>抽象类可以不定义抽象方法。但抽象方法一定要定义在抽象类中，含有抽象方法的类一定是抽象类</li>
<li>抽象类不可以直接创建对象，原因：调用抽象方法没有意义</li>
<li>只有覆盖了抽象类中所有抽象方法后，其子类才可以创建对象。否则该子类还是一个抽象类</li>
<li>抽象类都是父类，因为不断抽取而来的。</li>
<li>抽象类的存在的意义是为了不让该类创建对象,方法可以直接让子类去使用</li>
<li>abstract不可以和private、final、static共存</li>
<li>子类：抽象方法的实现类、抽象类</li>
</ul>
</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>abstract class 类名 {
    [public abstract 返回值类型 方法名(参数);(s)]
}
</code></pre></div><ul>
<li>接口：功能的集合，是比抽象类更为抽象的”类”，只包含了功能声明的特殊类
<ul>
<li>优点：将功能的声明与实现分离，优化了程序设计，解耦</li>
<li>接口避免了单继承的局限性。父类中定义的事物的基本功能，接口中定义的事物的扩展功能</li>
<li>接口不可以创建对象，可通过多态的方式，由子类来创建对象，接口多态</li>
<li>子类必须覆盖掉接口中所有的抽象方法后，子类才可以实例化。否则子类是一个抽象类</li>
<li>解决了多继承时，当多个父类中有相同功能时，子类调用产生的不确定性。因为没有接口方法体</li>
<li>接口与类关系 class 类 implements 接口1,接口2 {}</li>
<li>接口与接口关系 interface Zi extends Fu1,Fu2,Fu3{}</li>
</ul>
</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public interface 接口名{
    [public static final] A_B=值;//常量，接口变量，不可被修改
    [public abstract] 返回值类型 方法名(数据类型 变量名(s));//抽象方法
}
</code></pre></div><h1>成员变量和局部变量区别</h1>
<table>
<thead>
<tr>
<th style="text-align:center">项目</th>
<th style="text-align:center">成员变量</th>
<th style="text-align:center">局部变量</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">定义的位置</td>
<td style="text-align:center">类中的变量</td>
<td style="text-align:center">方法中或者{}语句里面的变量</td>
</tr>
<tr>
<td style="text-align:center">内存中的位置</td>
<td style="text-align:center">堆内存的对象中</td>
<td style="text-align:center">栈内存的方法中</td>
</tr>
<tr>
<td style="text-align:center">生命周期</td>
<td style="text-align:center">随着对象的出现而出现在堆中，随着对象的消失而从堆中消失</td>
<td style="text-align:center">随着方法的运行而出现在栈中，随着方法的弹栈而消失</td>
</tr>
<tr>
<td style="text-align:center">初始化</td>
<td style="text-align:center">有默认的初始化值</td>
<td style="text-align:center">必须手动的给其赋值才可以使用。</td>
</tr>
<tr>
<td style="text-align:center">作用域</td>
<td style="text-align:center">针对整个类有效</td>
<td style="text-align:center">只在某个范围内有效。(方法,语句体内)</td>
</tr>
</tbody>
</table>
<h1>包的声明与访问</h1>
<ul>
<li>类中声明的包必须与实际class文件所在的文件夹情况相一致，否则，程序运行时会找不到类</li>
<li>类中包的声明：package 包名.包名.包名…; 必须在程序的第一行</li>
<li>包名采用全部小写字母，多层包之间用”.”连接</li>
<li>带有包的类创建对象：包名.类名 变量名 = new包名.类名();</li>
<li>导包：import 包名.类名;  import 包名.*;(导入包内所有类)在声明包package后，定义所有类class前</li>
<li>同一个包中的类（同一个文件夹中），或者java.lang包中类时可以省略包名，直接使用该类</li>
<li>类用public修饰，则类名必须与文件名相同。一个文件中只能有一个public修饰的类</li>
</ul>
<h1>常见关键字(小写)</h1>
<ul>
<li>this
<ul>
<li>指向当前对象指针，创建对象的时候就存在</li>
<li>调用本类对象构造方法：this([参数列表]);必须定义在构造方法的第一行，因为初始化动作要最先执行</li>
<li>调用本类对象一般方法：方法名([参数列表])或this.方法名([参数列表])</li>
<li>成员变量名前面加上this.区别成员变量和局部变量</li>
</ul>
</li>
<li>super
<ul>
<li>指向直接父类的指针</li>
<li>调用父类变量：super.变量名</li>
<li>调用父类构造方法：super([实参列表])</li>
<li>调用父类方法：super.方法名([实参列表])</li>
<li>如果我们没写任何的构造方法，编译器提供给我们一个空参数构造方法</li>
<li>如果我们手动给出了构造方法，编译器不会在给我们提供默认的空参数构造方法</li>
<li>子类继承父类中的内容,必须先调用父类的构造方法进行初始化，故子类中所有构造方法有默认的隐式super();故父类的构造方法会先执行</li>
<li>如果默认的隐式super()在父类中没有对应的构造方法，那么必须在构造方法中通过this或者super的形式明确要调用的构造方法</li>
</ul>
</li>
<li>final
<ul>
<li>类、变量或方法不想被继承、修改、重写，可以重载</li>
<li>但是可以继承其他类,可以覆盖其他方法时加上final</li>
<li>修饰的变量称为常量，只能赋值一次，必须在创建对象前赋值、没有显式赋值时，多个构造方法都要为其赋值</li>
<li>修饰引用类型的变量值为对象地址值，地址值不能更改、但是地址内的对象属性值可以修改</li>
<li>final成员变量
<ul>
<li>类变量static修饰的变量：直接赋值或者静态代码块中赋值</li>
<li>实例变量：声明变量直接赋初值，非静态初始化块、构造器中赋初值</li>
</ul>
</li>
<li>final局部变量
<ul>
<li>如果final局部变量已经进行了初始化则后面就不能再次进行更改，如果final变量未进行初始化，可以进行赋值，当且仅有一次赋值</li>
</ul>
</li>
<li>final方法参数</li>
<li>final方法：
<ul>
<li>确保继承中使方法行为保持不变，而且不会被覆盖</li>
<li>效率，编译器将针对该方法的所有调用转为内嵌调用，跳过插入程序代码的方式而执行方法调用机制（将参数压入栈，跳至方法代码处执行，然后跳回并清理栈中的参数，处理返回值），并且以方法体中的实际代码的副本替代方法调用，消除方法的开销</li>
</ul>
</li>
</ul>
</li>
<li>static
<ul>
<li>无需创建对象，独立于对象存在，多个对象共享</li>
<li>类的加载的时候只执行一次（性能优化），不能使用this/super</li>
<li>静态修饰的内容（方法、变量）存于静态区,同一个类中，静态成员只能访问静态成员，但非静态成员能访问静态成员</li>
<li>调用：类名.静态成员变量名\类名.静态成员方法名(参数)</li>
<li>静态常量public static final 数据类型 AA_BB = 值</li>
<li>main方法为静态方法仅为程序执行入口，不属于任何一个对象，可以定义在任意类中</li>
</ul>
</li>
<li>instanceof
<ul>
<li>判断某个对象是否属于某种数据类型,boolean b = 对象 instanceof 数据类型</li>
</ul>
</li>
</ul>
<h1>常用类api</h1>
<ul>
<li>api：Application(应用) Programming(程序) Interface(接口)
<ul>
<li>java API就是jdk中提供给我们使用的类，这些类将底层的代码实现封装了起来</li>
<li>源码：JDK安装目录的src.zip</li>
</ul>
</li>
</ul>
<h2>Scanner</h2>
<ul>
<li>Scanner(InputStream source)<a href="http://xn--System-9m7iy0fo4hxp2m.in" target="_blank" rel="noopener noreferrer">一般传入System.in</a></li>
<li>int nextInt(); 接收控制台录入的数字</li>
<li>String next(); 接收控制台录入的字符串</li>
</ul>
<h2>Random</h2>
<ul>
<li>Random()</li>
<li>int nextInt(int maxValue)产生[0,maxValue)范围的随机整数</li>
<li>double nextDouble()  产生[0,1)范围的随机小数</li>
</ul>
<h2>Object:所有类的父类</h2>
<ul>
<li>boolean equals(Object obj)比较两个对象是否相同（默认使用==比较地址）经常需要复写它根据对象属性判断对象是否相同</li>
<li>String toString()返回该对象的字符串(包名.类名+@+内存地址值) 经常重写得到相应的字符串表现形式</li>
<li>int hashCode()返回哈希码
<ul>
<li>为什么要有 hashCode？当你把对象加入 HashSet 时，HashSet 会先计算对象的 hashcode 值来判断对象加入的位置，同时也会与其他已经加入的对象的 hashcode 值作比较，如果没有相符的hashcode，HashSet会假设对象没有重复出现。但是如果发现有相同 hashcode 值的对象，这时会调用 equals()方法来检查 hashcode 相等的对象是否真的相同。如果两者相同，HashSet 就不会让其加入操作成功。如果不同的话，就会重新散列到其他位置。大大减少了 equals 的次数，相应就大大提高了执行速度。</li>
<li>如果两个对象相等，则hashcode一定也是相同的，两个对象有相同的hashcode值，它们也不一定是相等的</li>
<li>equals 方法被覆盖过，则 hashCode 方法也必须被覆盖。hashCode() 的默认行为是对堆上的对象产生独特值。如果没有重写 hashCode()，则该 class 的两个对象无论如何都不会相等（即使这两个对象指向相同的数据）</li>
<li>对象的相等 比的是内存中存放的内容是否相等而 引用相等 比较的是他们指向的内存地址是否相等</li>
</ul>
</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>//equals复写例子
class Person extends Object{
	int age ;
	//复写父类的equals方法，实现自己的比较方式
	public boolean equals(Object obj) {
		//判断当前调用equals方法的对象和传递进来的对象是否是同一个
		if(this == obj){
			return true;
		}
		//判断传递进来的对象是否是Person类型
		if(!(obj instanceof Person)){
			return false;
		}
		//将obj向下转型为Perosn引用，访问其属性
		Person p = (Person)obj;
		return this.age == p.age;
	}
}
</code></pre></div><h2>Date,DateFormat,SimpleDateFormat,Calendar</h2>
<ul>
<li>
<p>Date()系统当前日期时间，表示特定的瞬间，精确到毫秒</p>
</li>
<li>
<p>Date(long date)1970年1月1日0点，加上date毫秒值对应的日期时间</p>
</li>
<li>
<p>long getTime()返回自1970年1月1日00:00：GMT以来此Date对象表示的毫秒数</p>
</li>
<li>
<p>DateFormat与语言环境无关的方式格式化并解析日期或时间的抽象类</p>
</li>
<li>
<p>SimpleDateFormat</p>
<ul>
<li>SimpleDateFormat()默认的格式化操作，可以字符串与Date对象相互转换</li>
<li>SimpleDateFormat(String pattern)替换”yyyy-MM-dd-HH-mm-ss-SS”剩余内容原样输出</li>
<li>String format(Date date) 把日期格式化成字符串</li>
<li>Date parse(String source)将字符串转成日期</li>
</ul>
</li>
<li>
<p>Calendar</p>
<ul>
<li>static Calendar getInstance();使用默认时区和语言环境获得一个日历</li>
<li>abstract void add(int field,int amount)指定字段增加某值12345</li>
<li>int get(int field)返回给定日历字段的值 field是指Calendar.YEAR/MONTH/DATE/HOUR/MINUTE/SECOND</li>
<li>final void set(int field,int value)设置指定字段的值</li>
<li>final Date getTime()获取该日历对象转成的日期对象</li>
<li>西方星期的开始为周日，中国为周一</li>
<li>在Calendar类中，月份的表示是以0-11代表1-12月</li>
</ul>
</li>
</ul>
<h2>System</h2>
<ul>
<li>不能手动创建对象因为构造方法被private修饰，阻止外界创建对象</li>
<li>long currentTimeMillis()当前系统时间与1970年01月01日00:00点的毫秒差值</li>
<li>void exit(int status)用来结束正在运行的Java程序。0正常退出</li>
<li>void gc()用来运行JVM中的垃圾回收器，完成内存中垃圾的清除</li>
<li>String getProperty(String key)用来获取指系统属性信息（自己查表）</li>
<li>从指定源数组中复制一个数组复制从指定位置开始到目标数组指定位置结束</li>
<li>void arrarycopy(Object src,int srcPog,Object dest,int destPes,int length</li>
</ul>
<h2>Math</h2>
<ul>
<li>Static double abs(double a)绝对值</li>
<li>Static double ceil(double a)结果为比参数值大的最小整数的double值</li>
<li>Static double floor(double a)结果为比参数值小的最大整数的double值</li>
<li>Static double max(double a,double b)返回两个参数值中较大的值</li>
<li>Static double min(double a,double b)返回两个参数值中较小的值</li>
<li>Static double pow(double a,double b)返回第一个参数的第二个参数次幂的值</li>
<li>Static double random()产生一个大于等于0.0且小于1.0的double小数</li>
</ul>
<h2>Arrays</h2>
<ul>
<li>Static void sort(int[] a)对指定数组中的元素进行排序（元素值从小到大进行排序）</li>
<li>Static void binarySearch(int[] a,int key)在指定的有序数组中，返回元素的位置或-1</li>
<li>Static String toString(int[] a)返回指定数组元素内容的字符串形式</li>
</ul>
<h2>Properties</h2>
<ul>
<li>持久的属性集。可保存在流中或从流中加载</li>
<li>Hashtable的子类，键值都是字符串键值可以存储到集合或文件中,来源也可以是文件</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>- void load(InputStream in)把指定流所对应的文件中的数据读取并保存到Propertie集合中
- void load(Reader)按面向行的格式从输入字符流中读取属性列表（键和元素对）
- void store(OutputStream out,String commonts)commonts代表对描述信息，无实际意义
- void store(Writer writer,String comments);与load(Reader)方法对应
- Object setProperty(String key, String value)调用 Hashtable 的方法 put。
- String getProperty(String key)用指定的键在此属性列表中搜索属性
- Set&lt;String&gt; stringPropertyNames()返回此属性列表中的键集，
</code></pre></div><h2>ResourceBundle</h2>
<ul>
<li>static ResourceBundle getBundle(String fileNmae)获得ResourceBundle对象</li>
<li>getString(String key)获得properties文件中键对应的值</li>
</ul>
<h1>正则表达式：Regular Expression</h1>
<ul>
<li>用来定义匹配规则，匹配一系列符合某个句法规则的字符串。用于检索、替换那些符合某个规则的文本</li>
<li>Pattern类</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>class RegexExample1{
   public static void main(String[] args){
      String content = "I am noob " +
        "from runoob.com.";
 
      String pattern = ".*runoob.*";
 
      boolean isMatch = Pattern.matches(pattern, content);
      System.out.println("字符串中是否包含了 'runoob' 子字符串? " + isMatch);
   }
}
</code></pre></div><table>
<thead>
<tr>
<th style="text-align:center">正则表达式</th>
<th style="text-align:center">含义</th>
<th style="text-align:center">匹配规则</th>
<th style="text-align:center">匹配的字符串内容</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">x</td>
<td style="text-align:center">字符x</td>
<td style="text-align:center">a</td>
<td style="text-align:center">a</td>
</tr>
<tr>
<td style="text-align:center">\|反斜线字符|\||</td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">\t</td>
<td style="text-align:center">制表符</td>
<td style="text-align:center">\t</td>
<td style="text-align:center">产生一个制表符的空间</td>
</tr>
<tr>
<td style="text-align:center">\n</td>
<td style="text-align:center">换行符</td>
<td style="text-align:center">\n</td>
<td style="text-align:center">换行,光标在原有位置的下一行</td>
</tr>
<tr>
<td style="text-align:center">\r</td>
<td style="text-align:center">回车符</td>
<td style="text-align:center">\r</td>
<td style="text-align:center">产生回车后的效果,光标来到下一行行首</td>
</tr>
<tr>
<td style="text-align:center">[abc]</td>
<td style="text-align:center">字符a、b或c</td>
<td style="text-align:center">[abc]</td>
<td style="text-align:center">字符a，或者字符b，或字符c的一个</td>
</tr>
<tr>
<td style="text-align:center">[^abc]</td>
<td style="text-align:center">除了a、b、c以外的任何字符</td>
<td style="text-align:center">[^abc]</td>
<td style="text-align:center">不是字符a，或者不是字符b，或不是字符c的任意一个字符</td>
</tr>
<tr>
<td style="text-align:center">[a-zA-Z]</td>
<td style="text-align:center">a 到 z 或 A 到 Z，两头的字母包括在内</td>
<td style="text-align:center">[a-zA-Z]</td>
<td style="text-align:center">一个大写或者小写字母</td>
</tr>
<tr>
<td style="text-align:center">[0-9]或者\d</td>
<td style="text-align:center">0到9数字，两头的数字包括在内</td>
<td style="text-align:center">[0-9]</td>
<td style="text-align:center">一个数字</td>
</tr>
<tr>
<td style="text-align:center">[a-zA-Z_0-9]或者\w</td>
<td style="text-align:center">字母或者数字或者下划线(即单词字符)</td>
<td style="text-align:center">[a-zA-Z_0-9]</td>
<td style="text-align:center">一个字母或者是一个数字或一个下滑线</td>
</tr>
<tr>
<td style="text-align:center">.</td>
<td style="text-align:center">任何字符</td>
<td style="text-align:center">\\.</td>
<td style="text-align:center">一个任意字符</td>
</tr>
<tr>
<td style="text-align:center">^</td>
<td style="text-align:center">行的开头</td>
<td style="text-align:center"><sup class="footnote-ref"><a href="#footnote1">[1]</a><a class="footnote-anchor" id="footnote-ref1"></a></sup><a class="footnote-anchor" id="footnote-ref1">[0-9]$</a></td>
<td style="text-align:center">从[abc]这个位置开始, 相当于左双引号</td>
</tr>
<tr>
<td style="text-align:center">$</td>
<td style="text-align:center">行的结尾</td>
<td style="text-align:center"><sup class="footnote-ref"><a href="#footnote2">[2]</a><a class="footnote-anchor" id="footnote-ref2"></a></sup><a class="footnote-anchor" id="footnote-ref2">[0-9]$</a></td>
<td style="text-align:center">以[0-9]这个结束, 相当于右双引号</td>
</tr>
<tr>
<td style="text-align:center">\b</td>
<td style="text-align:center">单词边界</td>
<td style="text-align:center">\b[abc]\b</td>
<td style="text-align:center">字母a或b或c的左右两边需要的是非单词字符([a-zA-Z_0-9])</td>
</tr>
<tr>
<td style="text-align:center">X?</td>
<td style="text-align:center">X出现一次或一次也没有</td>
<td style="text-align:center">a?</td>
<td style="text-align:center">一个字符a，或者一个a都没有</td>
</tr>
<tr>
<td style="text-align:center">X*</td>
<td style="text-align:center">X出现零次或多次</td>
<td style="text-align:center">a*</td>
<td style="text-align:center">多个字符a，或者一个a都没有</td>
</tr>
<tr>
<td style="text-align:center">X+</td>
<td style="text-align:center">X出现一次或多次</td>
<td style="text-align:center">a+</td>
<td style="text-align:center">多个字符a，或者一个a</td>
</tr>
<tr>
<td style="text-align:center">X{n}</td>
<td style="text-align:center">X出现恰好 n 次</td>
<td style="text-align:center">a{5}</td>
<td style="text-align:center">5个字符a</td>
</tr>
<tr>
<td style="text-align:center">X{n,}</td>
<td style="text-align:center">X出现至少 n 次</td>
<td style="text-align:center">a{5, }</td>
<td style="text-align:center">最少有5个字符a</td>
</tr>
<tr>
<td style="text-align:center">X{n,m}</td>
<td style="text-align:center">X出现至少 n 次，但是不超过 m 次</td>
<td style="text-align:center">a{5,8}</td>
<td style="text-align:center">有5个字符a 到 8个字符a之间</td>
</tr>
</tbody>
</table>
<h1>动态代理</h1>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/9fed0d6aa26a8530ca255.png" alt="动态代理.png" tabindex="0"><figcaption>动态代理.png</figcaption></figure>
<ul>
<li>JDK动态代理（Proxy对象）使用（目标对象必须有接口）
<ul>
<li>Object o = Poxy.newProxyInstance(ClassLoader loader,Class&lt;?&gt;[] interfaces,InvocationHandler h));
<ul>
<li>Object:代理对象</li>
<li>loader:与目标对象相同的类加载器:接口实现类Class对象.getClassLoader()/Thread.currentThread().getContextClassLoader()</li>
<li>interfaces:与目标对象实现的所有的接口Class对象数组:new Class[]{接口Class对象}/实现类Class对象.getInterfaces()</li>
<li>h:InvocationHandler接口实现类
<ul>
<li>Object invoke(Object proxy,Method method,Object[] args)</li>
<li>proxy:代理对象(实现类对象)</li>
<li>method:代理对象(实现类对象)当前执行方法method.getName()\method.invoke(对象，实际参数)</li>
<li>args:方法实际参数</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1>注解</h1>
<ul>
<li>注解概述<br>
- 代码级别的说明，与类、接口、枚举同一层次
<ul>
<li>注释：在阅读程序时清楚</li>
</ul>
</li>
</ul>
<hr class="footnotes-sep">
<section class="footnotes">
<ol class="footnotes-list">
<li id="footnote1" class="footnote-item"><p>abc <a href="#footnote-ref1" class="footnote-backref">↩︎</a></p>
</li>
<li id="footnote2" class="footnote-item"><p>abc <a href="#footnote-ref2" class="footnote-backref">↩︎</a></p>
</li>
</ol>
</section>
]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/9fed0d6aa26a8530ca255.png" type="image/png"/>
    </item>
    <item>
      <title>jvm</title>
      <link>https://javaguide.cn/backend/java/jvm.html</link>
      <guid>https://javaguide.cn/backend/java/jvm.html</guid>
      <source url="https://javaguide.cn/rss.xml">jvm</source>
      <description>1. java虚拟机运行时数据区域 2.1. 程序计数器的功能？ 2.2. java虚拟机栈 2.3. java堆 2.4. 方法区 2.5. 直接内存 2. HotSpot虚拟机对象 2.1. 对象（普通Java对象，不包括数组和Class对象等）的创建 2.4. OutOfMemoryError异常 2.4.1. java堆溢出 2.4.2. 虚拟...</description>
      <category>后端</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<!-- TOC -->
<ul>
<li><a href="#1-java%E8%99%9A%E6%8B%9F%E6%9C%BA%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA%E5%9F%9F">1. java虚拟机运行时数据区域</a>
<ul>
<li><a href="#21-%E7%A8%8B%E5%BA%8F%E8%AE%A1%E6%95%B0%E5%99%A8%E7%9A%84%E5%8A%9F%E8%83%BD">2.1. 程序计数器的功能？</a></li>
<li><a href="#22-java%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88">2.2. java虚拟机栈</a></li>
<li><a href="#23-java%E5%A0%86">2.3. java堆</a></li>
<li><a href="#24-%E6%96%B9%E6%B3%95%E5%8C%BA">2.4. 方法区</a></li>
<li><a href="#25-%E7%9B%B4%E6%8E%A5%E5%86%85%E5%AD%98">2.5. 直接内存</a></li>
</ul>
</li>
<li><a href="#2-hotspot%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%AF%B9%E8%B1%A1">2. HotSpot虚拟机对象</a>
<ul>
<li><a href="#21-%E5%AF%B9%E8%B1%A1%E6%99%AE%E9%80%9Ajava%E5%AF%B9%E8%B1%A1%E4%B8%8D%E5%8C%85%E6%8B%AC%E6%95%B0%E7%BB%84%E5%92%8Cclass%E5%AF%B9%E8%B1%A1%E7%AD%89%E7%9A%84%E5%88%9B%E5%BB%BA">2.1. 对象（普通Java对象，不包括数组和Class对象等）的创建</a></li>
<li><a href="#24-outofmemoryerror%E5%BC%82%E5%B8%B8">2.4. OutOfMemoryError异常</a>
<ul>
<li><a href="#241-java%E5%A0%86%E6%BA%A2%E5%87%BA">2.4.1. java堆溢出</a></li>
<li><a href="#242-%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88%E5%92%8C%E6%9C%AC%E5%9C%B0%E6%96%B9%E6%B3%95%E6%A0%88%E6%BA%A2%E5%87%BA">2.4.2. 虚拟机栈和本地方法栈溢出</a></li>
<li><a href="#123-%E6%96%B9%E6%B3%95%E5%8C%BA%E5%92%8C%E8%BF%90%E8%A1%8C%E6%97%B6%E5%B8%B8%E9%87%8F%E6%B1%A0%E6%BA%A2%E5%87%BA">1.2.3. 方法区和运行时常量池溢出</a></li>
<li><a href="#124-%E6%96%B9%E6%B3%95%E5%8C%BA%E5%92%8C%E8%BF%90%E8%A1%8C%E6%97%B6%E5%B8%B8%E9%87%8F%E6%B1%A0%E6%BA%A2%E5%87%BA">1.2.4. 方法区和运行时常量池溢出</a></li>
<li><a href="#243-%E6%9C%AC%E6%9C%BA%E7%9B%B4%E6%8E%A5%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA">2.4.3. 本机直接内存溢出</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#3-%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%E5%92%8C%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5">3. 垃圾收集器和内存分配策略</a>
<ul>
<li><a href="#31-%E7%A1%AE%E5%AE%9A%E5%AF%B9%E8%B1%A1%E6%98%AF%E5%90%A6%E5%AD%98%E6%B4%BB%E7%9A%84%E7%AE%97%E6%B3%95">3.1. 确定对象是否存活的算法</a></li>
<li><a href="#32-%E5%BC%95%E7%94%A8%E5%88%86%E7%B1%BB">3.2. 引用分类</a></li>
<li><a href="#33-%E6%A0%87%E8%AE%B0%E5%AF%B9%E8%B1%A1%E6%AD%BB%E4%BA%A1">3.3. 标记对象死亡</a></li>
<li><a href="#34-%E5%9B%9E%E6%94%B6%E6%96%B9%E6%B3%95%E5%8C%BA">3.4. 回收方法区</a></li>
</ul>
</li>
<li><a href="#4-%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E7%AE%97%E6%B3%95">4. 垃圾收集算法</a></li>
<li><a href="#5-hotspot%E7%9A%84%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0">5. HotSpot的算法实现</a>
<ul>
<li><a href="#51-%E6%9E%9A%E4%B8%BE%E6%A0%B9%E8%8A%82%E7%82%B9">5.1. 枚举根节点</a></li>
<li><a href="#52-%E5%AE%89%E5%85%A8%E7%82%B9safepoint">5.2. 安全点(Safepoint)</a></li>
<li><a href="#53-%E5%AE%89%E5%85%A8%E5%8C%BA%E5%9F%9Fsafe-region">5.3. 安全区域(Safe Region)</a></li>
</ul>
</li>
<li><a href="#6-%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8">6. 垃圾收集器：</a>
<ul>
<li><a href="#61-serial%E6%94%B6%E9%9B%86%E5%99%A8">6.1. Serial收集器</a></li>
<li><a href="#62-parnew%E6%94%B6%E9%9B%86%E5%99%A8">6.2. ParNew收集器</a></li>
<li><a href="#63-parallel-scavenge%E6%94%B6%E9%9B%86%E5%99%A8">6.3. Parallel Scavenge收集器</a></li>
<li><a href="#64-serial-old%E6%94%B6%E9%9B%86%E5%99%A8">6.4. Serial Old收集器</a></li>
<li><a href="#65-parallel-old%E6%94%B6%E9%9B%86%E5%99%A8">6.5. Parallel Old收集器</a></li>
<li><a href="#66-cms%E6%94%B6%E9%9B%86%E5%99%A8concurrent-mark-sweep">6.6. CMS收集器（Concurrent Mark Sweep）</a></li>
<li><a href="#67-g1%E6%94%B6%E9%9B%86%E5%99%A8garbage-first">6.7. G1收集器(Garbage-First)</a></li>
</ul>
</li>
<li><a href="#7-gc%E6%97%A5%E5%BF%97">7. GC日志</a></li>
<li><a href="#8-%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E4%B8%8E%E5%9B%9E%E6%94%B6%E7%AD%96%E7%95%A5">8. 内存分配与回收策略</a>
<ul>
<li><a href="#81-%E5%AF%B9%E8%B1%A1%E4%BC%98%E5%85%88%E5%9C%A8eden%E5%88%86%E9%85%8D">8.1. 对象优先在Eden分配</a></li>
<li><a href="#82-%E5%A4%A7%E5%AF%B9%E8%B1%A1%E7%9B%B4%E6%8E%A5%E8%BF%9B%E5%85%A5%E8%80%81%E5%B9%B4%E4%BB%A3">8.2. 大对象直接进入老年代</a></li>
<li><a href="#83-%E9%95%BF%E6%9C%9F%E5%AD%98%E6%B4%BB%E7%9A%84%E5%AF%B9%E8%B1%A1%E5%B0%86%E8%BF%9B%E5%85%A5%E8%80%81%E5%B9%B4%E4%BB%A3">8.3. 长期存活的对象将进入老年代</a></li>
<li><a href="#84-%E5%8A%A8%E6%80%81%E5%AF%B9%E8%B1%A1%E5%B9%B4%E9%BE%84%E5%88%A4%E5%AE%9A">8.4. 动态对象年龄判定</a></li>
<li><a href="#85-%E7%A9%BA%E9%97%B4%E5%88%86%E9%85%8D%E6%8B%85%E4%BF%9D">8.5. 空间分配担保</a></li>
</ul>
</li>
<li><a href="#9-%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E5%B7%A5%E5%85%B7">9. 虚拟机性能监控与故障处理工具</a>
<ul>
<li><a href="#91-jdk%E7%9A%84%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7">9.1. JDK的命令行工具</a>
<ul>
<li><a href="#911-jps%E8%99%9A%E6%8B%9F%E6%9C%BA%E8%BF%9B%E7%A8%8B%E7%8A%B6%E5%86%B5%E5%B7%A5%E5%85%B7jvm-process-status-tool">9.1.1. jps：虚拟机进程状况工具（JVM Process Status Tool）</a></li>
<li><a href="#912-jstat%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%BB%9F%E8%AE%A1%E4%BF%A1%E6%81%AF%E7%9B%91%E8%A7%86%E5%B7%A5%E5%85%B7jvm-statistics-monitoring-tool">9.1.2. jstat：虚拟机统计信息监视工具（JVM Statistics Monitoring Tool）</a></li>
<li><a href="#913-jinfojava%E9%85%8D%E7%BD%AE%E4%BF%A1%E6%81%AF%E5%B7%A5%E5%85%B7configuration-info-for-java">9.1.3. jinfo：Java配置信息工具（Configuration Info for Java）</a></li>
<li><a href="#914-jmapjava%E5%86%85%E5%AD%98%E6%98%A0%E5%83%8F%E5%B7%A5%E5%85%B7memory-map-for-java">9.1.4. jmap：Java内存映像工具（Memory Map for Java）</a></li>
<li><a href="#915-jhat%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%A0%86%E8%BD%AC%E5%82%A8%E5%BF%AB%E7%85%A7%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7jvm-heap-analysis-tool">9.1.5. jhat：虚拟机堆转储快照分析工具（JVM Heap Analysis Tool）</a></li>
<li><a href="#916-jstackjava%E5%A0%86%E6%A0%88%E8%B7%9F%E8%B8%AA%E5%B7%A5%E5%85%B7stack-trace-for-java">9.1.6. jstack：Java堆栈跟踪工具（Stack Trace for Java）</a></li>
</ul>
</li>
<li><a href="#92-hsdisjit%E7%94%9F%E6%88%90%E4%BB%A3%E7%A0%81%E5%8F%8D%E6%B1%87%E7%BC%96">9.2. HSDIS：JIT生成代码反汇编</a></li>
</ul>
</li>
<li><a href="#10-jdk%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E5%B7%A5%E5%85%B7">10. JDK的可视化工具</a>
<ul>
<li><a href="#101-jconsolejava%E7%9B%91%E8%A7%86%E4%B8%8E%E7%AE%A1%E7%90%86%E6%8E%A7%E5%88%B6%E5%8F%B0">10.1. JConsole：Java监视与管理控制台</a></li>
<li><a href="#102-visualvm%E5%A4%9A%E5%90%88%E4%B8%80%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E5%B7%A5%E5%85%B7">10.2. VisualVM：多合一故障处理工具</a></li>
</ul>
</li>
<li><a href="#11-%E8%B0%83%E4%BC%98%E6%A1%88%E4%BE%8B%E5%88%86%E6%9E%90%E4%B8%8E%E5%AE%9E%E6%88%98">11. 调优案例分析与实战</a>
<ul>
<li><a href="#111-%E9%AB%98%E6%80%A7%E8%83%BD%E7%A1%AC%E4%BB%B6%E4%B8%8A%E7%9A%84%E7%A8%8B%E5%BA%8F%E9%83%A8%E7%BD%B2%E7%AD%96%E7%95%A5">11.1. 高性能硬件上的程序部署策略</a></li>
<li><a href="#112-%E9%9B%86%E7%BE%A4%E9%97%B4%E5%90%8C%E6%AD%A5%E5%AF%BC%E8%87%B4%E7%9A%84%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA">11.2. 集群间同步导致的内存溢出</a></li>
<li><a href="#113-%E5%A0%86%E5%A4%96%E5%86%85%E5%AD%98%E5%AF%BC%E8%87%B4%E7%9A%84%E6%BA%A2%E5%87%BA%E9%94%99%E8%AF%AF">11.3. 堆外内存导致的溢出错误</a></li>
<li><a href="#114-%E5%A4%96%E9%83%A8%E5%91%BD%E4%BB%A4%E5%AF%BC%E8%87%B4%E7%B3%BB%E7%BB%9F%E7%BC%93%E6%85%A2">11.4. 外部命令导致系统缓慢</a></li>
<li><a href="#115-%E6%9C%8D%E5%8A%A1%E5%99%A8jvm%E8%BF%9B%E7%A8%8B%E5%B4%A9%E6%BA%83">11.5. 服务器JVM进程崩溃</a></li>
<li><a href="#116-%E4%B8%8D%E6%81%B0%E5%BD%93%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AF%BC%E8%87%B4%E5%86%85%E5%AD%98%E5%8D%A0%E7%94%A8%E8%BF%87%E5%A4%A7">11.6. 不恰当数据结构导致内存占用过大</a></li>
<li><a href="#117-%E7%94%B1windows%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98%E5%AF%BC%E8%87%B4%E7%9A%84%E9%95%BF%E6%97%B6%E9%97%B4%E5%81%9C%E9%A1%BF">11.7. 由Windows虚拟内存导致的长时间停顿</a></li>
</ul>
</li>
<li><a href="#12-%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%89%A7%E8%A1%8C%E5%AD%90%E7%B3%BB%E7%BB%9F">12. 虚拟机执行子系统</a>
<ul>
<li><a href="#121-%E7%B1%BB%E6%96%87%E4%BB%B6%E7%BB%93%E6%9E%84">12.1. 类文件结构</a></li>
<li><a href="#122-class%E7%B1%BB%E6%96%87%E4%BB%B6%E7%9A%84%E7%BB%93%E6%9E%84">12.2. Class类文件的结构</a>
<ul>
<li><a href="#1221-magicminor_versionmajor_version">12.2.1. magic，minor_version，major_version</a></li>
<li><a href="#1222-%E5%B8%B8%E9%87%8F%E6%B1%A0">12.2.2. 常量池</a></li>
</ul>
</li>
<li><a href="#123-%E8%AE%BF%E9%97%AE%E6%A0%87%E5%BF%97access_flags">12.3. 访问标志（access_flags）</a></li>
<li><a href="#124-%E7%B1%BB%E7%B4%A2%E5%BC%95%E7%88%B6%E7%B1%BB%E7%B4%A2%E5%BC%95%E4%B8%8E%E6%8E%A5%E5%8F%A3%E7%B4%A2%E5%BC%95%E9%9B%86%E5%90%88">12.4. 类索引、父类索引与接口索引集合</a></li>
<li><a href="#125-%E5%AD%97%E6%AE%B5%E8%A1%A8%E9%9B%86%E5%90%88">12.5. 字段表集合</a></li>
<li><a href="#126-%E6%96%B9%E6%B3%95%E8%A1%A8%E9%9B%86%E5%90%88">12.6. 方法表集合</a></li>
<li><a href="#127-%E5%B1%9E%E6%80%A7%E8%A1%A8%E9%9B%86%E5%90%88attribute_info">12.7. 属性表集合（attribute_info）</a>
<ul>
<li><a href="#1271-code%E5%B1%9E%E6%80%A7">12.7.1. Code属性</a></li>
<li><a href="#1272-exceptions%E5%B1%9E%E6%80%A7">12.7.2. Exceptions属性</a></li>
<li><a href="#1273-linenumbertable%E5%B1%9E%E6%80%A7">12.7.3. LineNumberTable属性</a></li>
</ul>
</li>
<li><a href="#128-%E4%BB%A3%E7%A0%81%E9%87%8D%E6%8E%92%E5%BA%8F">12.8. 代码重排序</a></li>
<li><a href="#129-as-if-serial%E8%A7%84%E5%88%99%E5%92%8Chappens-before%E8%A7%84%E5%88%99">12.9. as-if-serial规则和happens-before规则</a></li>
</ul>
</li>
<li><a href="#13-gc%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E6%9C%BA%E5%88%B6">13. GC垃圾回收机制</a></li>
<li><a href="#24-%E5%AF%B9%E8%B1%A1%E6%98%AF%E5%A6%82%E4%BD%95%E5%AE%9A%E4%BD%8D%E8%AE%BF%E9%97%AE%E7%9A%84">24. 对象是如何定位访问的？</a></li>
<li><a href="#25-monitor">25. Monitor</a>
<ul>
<li><a href="#%E4%BB%A3%E7%A0%81%E4%BC%98%E5%8C%96">代码优化</a></li>
</ul>
</li>
</ul>
<!-- /TOC -->
<h1>1. java虚拟机运行时数据区域</h1>
<ul>
<li>直接内存(Direct Memory)(虚拟机规范中定义的内存区域)</li>
</ul>
<h2>2.1. 程序计数器的功能？</h2>
<ul>
<li>字节码解释器工作时就是通过改变这个计数器的值来选取下一条要执行的字节码指令，分支，循环，跳转，异常处理，线程恢复等基础功能都要依赖这个计数器完成</li>
<li>java虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的，在任何一个确定的时刻，一个处理器（对于多核处理器来说是一个内核）都只会执行一条线程中的指令。因此，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各条线程之间计数器互不影响，独立存储。</li>
<li>如果线程正在执行Java方法，这个计数器记录的是正在执行的虚拟机字节码指令地址；如果正在执行的native方法，这个计数器则为空（undefined）</li>
<li>在java虚拟机规范中没有规定任何OutOfMemoryError情况的区域</li>
</ul>
<h2>2.2. java虚拟机栈</h2>
<ul>
<li>每个方法在执行的同时都会创建一个栈帧(Stack Frame)用于存储局部变量表，操作数栈，动态链接，方法出口等信息，每个方法从调用至执行完成的过程，就对应着一个栈帧在虚拟机中入栈到出栈的过程</li>
<li>java内存区的栈就是虚拟机栈，或者说虚拟机栈中局部变量表部分。该表存放了编译期可知的各种基本数据类型，对象引用（reference类型，非对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或其他与此对象相关的位置）和returnAddress类型（指向了一条字节码指令的地址）。其中64位长度的long和double类型的数据会占用两个局部变量空间(Slot),其余的数据类型只占一个。局部变量表所需的内存空间在编译期间完成分配，当进入一个方法时，这个方法只需要帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小空间</li>
<li>如果线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError异常；如果虚拟机栈可以动态扩展，如果扩展无法申请到足够内存，就会抛出OutOfMemory异常</li>
</ul>
<h2>2.3. java堆</h2>
<ul>
<li>虚拟机所管理的内存中最大的一块。在虚拟机启动时创建。</li>
<li>从内存回收的角度看,垃圾收集管理的主要区域(GC堆（Garbage Collected Heap）)，由于现在收集器基本采用分代收集算法。所以java堆可以细分为新生代和老年代；再细致点有Eden空间 From Survivor空间 To Survivor空间等。</li>
<li>从内存分配的角度看，线程共享的java堆中可能划分出多个线程私有的分配缓冲区(Thread Local Allocation Buffer,TLAB)。不论过无论如何划分，都与存放内容无关，无论哪个区域，存储的都仍然是对象实例，进一步划分的目的是为了更好地回收内存，或者更快地分配内存。</li>
<li>根据java虚拟机规范，java堆可以处于物理上不连续的内存空间中，只要逻辑上是连续的即可，就像磁盘空间一样，在实现时既可以实现成固定大小的，也可以是可扩展的，不过当前主流虚拟机都是按照可扩展来实现的（通过-Xmx和-Xms控制），</li>
<li>如果在堆中没有内存完成实例分配，并且堆也无法再扩展时，将会抛出OutOfMemoryError异常</li>
<li>该内存区域存放了对象实例及数组(所有new的对象)。其大小通过-Xms(最小值)和-Xmx(最大值)参数设置，
<ul>
<li>-Xms为JVM启动时申请的最小内存，默认为操作系统物理内存的1/64但小于1G，</li>
<li>-Xmx为JVM可申请的最大内存，默认为物理内存的1/4但小于1G，</li>
<li>默认当空余堆内存小于40%时，JVM会增大Heap到-Xmx指定的大小，可通过-XX:MinHeapFreeRation=来指定这个比列</li>
<li>当空余堆内存大于70%时，JVM会减小heap的大小到-Xms指定的大小，可通过XX:MaxHeapFreeRation=来指定这个比列</li>
<li>对于运行系统，为避免在运行时频繁调整Heap的大小，通常-Xms与-Xmx的值设成一样</li>
</ul>
</li>
</ul>
<h2>2.4. 方法区</h2>
<ul>
<li>
<p>java虚拟机规范对方法去的限制非常宽松，除了和java堆一样不需要连续的内存和可以选择固定大小或者可扩展外，还可以选择不实现垃圾收集。垃圾收集在这个区域时比较少出现的，但并非数据进入方法区就永久存在了，这个区域的内存回收目标主要是针对常量池的回收和对类型的卸载。</p>
</li>
<li>
<p>根据java虚拟机规范，当方法切无法满足内存分配需求时，将抛出OutOfMemoryError异常</p>
</li>
<li>
<p>运行时常量池(Runtime Constant Pool)是方法区一部分。Class文件中除了有类的版本，字段，方法，接口等描述信息外，还有一项信息的常量池(Constant Pool Table),用于存放编译期生成的各种字面量和符号引用，这部分内容将在类加载后进入方法区的运行时常量池中存放</p>
</li>
<li>
<p>java虚拟机对Class文件每一部分（包括常量池）的格式都有严格规定，每一个字节用于存储那种数据都必须符合规范上要求的才会被虚拟机认可，装载和执行，但对于运行时常量池，java虚拟机规范没有做任何细节的要求。一般来说，除了保存Class文件中描述的符号引用外，还会把翻译出来的直接引用也存储在运行时常量池中。</p>
</li>
<li>
<p>运行时常量池相对于Class文件常量池的另外一个重要特征是具备动态性，java语言并不要求常量一定只有编译期才能产生，也就是并非预置入Class文件中常量池的内容才能进入方法区运行时常量池，运行期间也可能将新的常量放入池中，这种特性被开发人员用得多的特性便是String类的intern()方法</p>
</li>
<li>
<p>当常量池无法再申请到内存时会抛出OutOfMemoryError异常，这个区域的内存回收目标主要是针对常量池的回收和对类型的卸载。</p>
</li>
<li>
<p>默认最小值为16MB，最大值为64MB，可以通过-XX:PermSize 和 -XX:MaxPermSize 参数限制方法区的大小。</p>
</li>
</ul>
<h2>2.5. 直接内存</h2>
<ul>
<li>不是虚拟机运行时数据区的一部分</li>
<li>jdk1.4引入的NIO类，引入了一种基于通道（Channel）与缓冲区Buffer的I/O方式，可以使用Native函数库直接分配堆外内存，然后通过一个存储在Java堆中的DirectByteBuffer对象作为这块内存的引用进行操作，这样能在一些场景中显著提高性能，因为避免了Java堆和Native堆中来回复制数据</li>
<li>本机直接内存的分配不会受到java堆大小的限制，但受到本机总内存（包括RAM以及SWAP区或者分页文件）大小以及处理器寻址空间的限制。在根据实际内存设置-Xmx等参数信息，不要忽略直接内存，使得各个内存区域总和小于物理内存限制（包括物理的和操作系统级的限制），避免扩展时出现OutOfMemoryError异常</li>
</ul>
<h1>2. HotSpot虚拟机对象</h1>
<h2>2.1. 对象（普通Java对象，不包括数组和Class对象等）的创建</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>HotSpot解释器的代码片段
//确保常量池中存放的是已解释的类
if（！constants-＞tag_at（index）.is_unresolved_klass（））{
//断言确保是klassOop和instanceKlassOop（这部分下一节介绍）
oop entry=（klassOop）*constants-＞obj_at_addr（index）；
assert（entry-＞is_klass（），"Should be resolved klass"）；
klassOop k_entry=（klassOop）entry；
assert（k_entry-＞klass_part（）-＞oop_is_instance（），"Should be instanceKlass"）；
instanceKlass * ik=（instanceKlass*）k_entry-＞klass_part（）；
//确保对象所属类型已经经过初始化阶段
if（ik-＞is_initialized（）＆＆ik-＞can_be_fastpath_allocated（））
{
//取对象长度
size_t obj_size=ik-＞size_helper（）；
oop result=NULL；
//记录是否需要将对象所有字段置零值
bool need_zero=！ZeroTLAB；
//是否在TLAB中分配对象
if（UseTLAB）{
result=（oop）THREAD-＞tlab（）.allocate（obj_size）；
}
if（result==NULL）{
need_zero=true；
//直接在eden中分配对象
retry：
HeapWord * compare_to=*Universe：heap（）-＞top_addr（）；
HeapWord * new_top=compare_to+obj_size；
/*cmpxchg是x86中的CAS指令，这里是一个C++方法，通过CAS方式分配空间，如果并发失败，
转到retry中重试，直至成功分配为止*/
if（new_top＜=*Universe：heap（）-＞end_addr（））{
if（Atomic：cmpxchg_ptr（new_top,Universe：heap（）-＞top_addr（），compare_to）！=compare_to）{
goto retry；
}
result=（oop）compare_to；
}
}
if（result！=NULL）{
//如果需要，则为对象初始化零值
if（need_zero）{
HeapWord * to_zero=（HeapWord*）result+sizeof（oopDesc）/oopSize；
obj_size-=sizeof（oopDesc）/oopSize；
if（obj_size＞0）{
memset（to_zero，0，obj_size * HeapWordSize）；
}
}
//根据是否启用偏向锁来设置对象头信息
if（UseBiasedLocking）{
result-＞set_mark（ik-＞prototype_header（））；
}else{
result-＞set_mark（markOopDesc：prototype（））；
}
result-＞set_klass_gap（0）；
result-＞set_klass（k_entry）；
//将对象引用入栈，继续执行下一条指令
SET_STACK_OBJECT（result，0）；
UPDATE_PC_AND_TOS_AND_CONTINUE（3，1）；
}
}
}
</code></pre></div><h2>2.4. OutOfMemoryError异常</h2>
<p>-verbose:gc -Xms20M -Xmx20M -Xmn10M -XX:+PrintGCDetails -XX:SurvivorRatio=8</p>
<h3>2.4.1. java堆溢出</h3>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>/**
*VM Args：-Xms20m-Xmx20m-XX：+HeapDumpOnOutOfMemoryError
*将堆最小值-Xms参数与最大值-Xmx参数设置为一样即可避免自动扩展
*XX:+HeapDunpOnOutOfMemoryError可以让虚拟机在内存溢出异常时Dump出当前的内存堆存储快照以便时候分析
*@author zzm
*/
public class HeapOOM{
static class OOMObject{
}
public static void main（String[]args）{
List＜OOMObject＞list=new ArrayList＜OOMObject＞（）；
while（true）{
list.add（new OOMObject（））；
}
}
}
</code></pre></div><ul>
<li>java堆用于存储对象实例，只要不断地创建对象，并保障GC Roots到对象之间有可达路径来避免垃圾回收机制清除这些对象，那么在对象数量达到最大堆的容量限制后就会产生内存溢出异常</li>
<li>要解决这个区域的异常，一般的手段是通过内存映像分析工具（如Eclipse Memory Analyzer）对Dump出来的堆转储快照进行分析，重点确认内存中的对象是否必要，也要分清楚到底是出现内存泄漏（Memory Leak）还是内存溢出（Memory Overflow）</li>
<li>如果是内存泄漏，可进一步通过工具查看泄漏对象到GC Roots的引用链，于是就能找到泄漏对象是通过怎样的路径与GC Roots相关联并导致垃圾回收器无法自动回收它们的。掌握了泄漏对象的类型信息以及GC Roots引用链的信息，就可以比较准确定位出泄漏代码的位置</li>
<li>如果不存在泄漏，就是内存中的对象确实还必须存活着，那就应当检查虚拟机参数（-Xmx和Xms）与机器物理内存对比看是否还可以调大，从代码上检查是否存在某些对象生命周期过长，持有状态时间过长的情况，尝试减少程序运行期的内存消耗</li>
</ul>
<h3>2.4.2. 虚拟机栈和本地方法栈溢出</h3>
<ul>
<li>在HotSpot虚拟机并不区分虚拟机栈和本地方法栈，栈容量由-Xss参数设定</li>
<li>如果线程请求的栈深度大于虚拟机所允许的最大深度，将抛出StatckOverflowError异常</li>
<li>如果虚拟机在扩展栈是无法申请到足够的内存空间，则抛出OutOfMemoryError异常</li>
<li>在单个线程下，无论是由于栈帧太大还是虚拟机栈容量太小，当内存琺分配的时候，虚拟机抛出的都是StackOverflow异常</li>
<li>在多线程情况下，通过不断建立线程的方式可以产生内存溢出异常，但与栈空间是否足够大不存在任何联系，在这种情况下，为每个线程的栈分配的内存越大，反而越容易产生内存溢出异常，因为操作系统分配给每个进程的内存是有限制的，虚拟机提供了参数控制java堆和方法区两部分内存的最大值，剩余内存为总内存减去Xmx(最大堆容量)再减去MaxPermSize(最大方法区容量)，程序计数器消耗内存很小，可以忽略，那么剩下的内存就由虚拟机栈和本地方法栈了，每个线程分配到的栈容量越大，可以建立的线程数量自然就越少，建立线程时就越容易把剩下的内存耗尽</li>
<li>多线程应用出现StackOverflowError异常时有错误堆栈可以阅读，而且如果使用虚拟机默认参数，栈深度在大多数情况下（因为每个方法压入栈的帧大小并不是一样的，所以说大多数情况下）达到1000-2000完全没有问题，对于正常的方法调用（包括递归），这个深度完全够用。但是如果是建立过多线程导致的内存溢出，在不能减少线程数或者更换64位虚拟机的情况下，就只能通过减少最大堆和减少栈容量换取更多线程。</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>/**
*VM Args：-Xss2M（这时候不妨设置大些）
*@author zzm
*/
public class JavaVMStackOOM{
private void dontStop（）{
while（true）{
}
}
public void stackLeakByThread（）{
while（true）{
Thread thread=new Thread（new Runnable（）{
@Override
public void run（）{
dontStop（）；
}
}）；
thread.start（）；
}
}
public static void main（String[]args）throws Throwable{
JavaVMStackOOM oom=new JavaVMStackOOM（）；
oom.stackLeakByThread（）；
}
}

Exception in thread"main"java.lang.OutOfMemoryError：unable to create new native thread
</code></pre></div><h3>1.2.3. 方法区和运行时常量池溢出</h3>
<h3>1.2.4. 方法区和运行时常量池溢出</h3>
<ul>
<li>String.intern()是一个native方法，作用是：如果字符串常量池中已经包含一个等于次String对象的字符串，则返回代表池中这个字符串的String对象；否则将此String对象包含的字符串添加到常量池中，并且返回次String对象的引用。在jdk1.6以及以前的版本中，由于常量池分配在永久代内，可以通过-XX：PermSize和-XX：MaxPermSize限制方法区的大小，从而简介限制其中常量池的容量</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>/**
*VM Args：-XX：PermSize=10M-XX：MaxPermSize=10M
*@author zzm
*/
public class RuntimeConstantPoolOOM{
  public static void main（String[]args）{
  //使用List保持着常量池引用，避免Full GC回收常量池行为
  List＜String＞list=new ArrayList＜String＞（）；
  //10MB的PermSize在integer范围内足够产生OOM了
  int i=0；
  while（true）{
    list.add（String.valueOf（i++）.intern（））；
    }
  }
}

Exception in thread"main"java.lang.OutOfMemoryError：PermGen space
at java.lang.String.intern（Native Method）
at org.fenixsoft.oom.RuntimeConstantPoolOOM.main（RuntimeConstantPoolOOM.java：18）
PermGen space说明运行时常量池属于方法区（HotSpot虚拟机中的永久代）的一部分
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class RuntimeConstantPoolOOM{
  public static void main（String[]args）{
    String str1=new StringBuilder（"计算机"）.append（"软件"）.toString（）；
    System.out.println（str1.intern（）==str1）；
    String str2=new StringBuilder（"ja"）.append（"va"）.toString（）；
    System.out.println（str2.intern（）==str2）；
  }
}

</code></pre></div><ul>
<li>jdk1.6中的到2个false，jdk1.7一个true一个false、jdk1.6中intern（）方法会把首次遇到的字符串实例复制到永久代中，返回的也是永久代中的这个字符串实例的引用，而由StringBuilder创建的字符串实例在java堆上，所以必然不是同一引用，将返回false。而jdk1.7的intern()实现不会复制实例，只是在常量池中记录首次出现的实例引用，因此intern()返回的引用和由StringBuilfer创建的那个字符串实例是同一个。对str2比较返回false是因为java这个字符串在执行StringBuilder.toString()之前出现过，字符串常量池中已经有她的引用了，不符合“首次出现”的原则</li>
<li>方法区用于存放Class相关信息，如类名，修饰访问符，常量池，字段描述，方法描述等，测试思路是运行时产生大量的类去填满方法区，直到溢出。可以直接使用java SE API可以动态产生类（如反射时的GeneratedConstructorAccessor和动态代理等），也可以借助CGLIB直接操作字节码运行时产生大量动态类</li>
<li>在经常动态生成大量Class的应用中，需要特别注意类的回收情况，包括使用CGLIB字节码增强和动态语言外，大量JSP或动态生成JSP文件的应用（JSP第一次运行时需要编译为Java类），基于OSGi的应用（即使是同一个类文件，被不同加载器加载也会视为不同的类）等</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>/**
*VM Args：-XX：PermSize=10M-XX：MaxPermSize=10M
*@author zzm
*/
public class JavaMethodAreaOOM{
public static void main（String[]args）{
while（true）{
Enhancer enhancer=new Enhancer（）；
enhancer.setSuperclass（OOMObject.class）；
enhancer.setUseCache（false）；
enhancer.setCallback（new MethodInterceptor（）{
public Object intercept（Object obj,Method method,Object[]args,MethodProxy proxy）throws Throwable{
return proxy.invokeSuper（obj,args）；
}
}）；
enhancer.create（）；
}
}
static class OOMObject{
}
}
Caused by：java.lang.OutOfMemoryError：PermGen space
at java.lang.ClassLoader.defineClass1（Native Method）
at java.lang.ClassLoader.defineClassCond（ClassLoader.java：632）
at java.lang.ClassLoader.defineClass（ClassLoader.java：616）
……8 more
</code></pre></div><h3>2.4.3. 本机直接内存溢出</h3>
<ul>
<li>DirectMemory容量可以通过-XX:MaxDirectMemorySize指定，默认与Java堆最大值（-Xmx）一样</li>
<li>越过DirectByteBuffer类，直接通过反射获取Unsafe实例进行内存分配（Unsafe类的getUnsafe()方法限制了只有引导类加载器才会返回实例，设计者希望只有rt.jar中的类才能使用Unsafe的功能。）因为虽然使用DirectByteBuffer分配内存也会抛出内存溢出异常，但它排除异常时并没有真正向操作系统申请分配内存，而是通过计算得知内存无法分配，于是手动抛出异常，真正申请分配内存的方法是unsafe.allocateMemory();</li>
<li>由DirectMemory导致的内存溢出，在Heap Dump文件中不会看见明显的异常，而且文件很小，可能是程序中直接或者间接使用了NIO</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>/**
*VM Args：-Xmx20M-XX：MaxDirectMemorySize=10M
*@author zzm
*/
public class DirectMemoryOOM{
private static final int_1MB=1024*1024；
public static void main（String[]args）throws Exception{
Field unsafeField=Unsafe.class.getDeclaredFields（）[0]；
unsafeField.setAccessible（true）；
Unsafe unsafe=（Unsafe）unsafeField.get（null）；
while（true）{
unsafe.allocateMemory（_1MB）；
}
}
}
Exception in thread"main"java.lang.OutOfMemoryError
at sun.misc.Unsafe.allocateMemory（Native Method）
at org.fenixsoft.oom.DMOOM.main（DMOOM.java：20）
</code></pre></div><h1>3. 垃圾收集器和内存分配策略</h1>
<ul>
<li>程序计数器，虚拟机栈，本地方法栈3个区域随线程而生，随线程而灭，栈中的栈帧随着方法进入和退出进行出栈和入栈操作，每一个栈帧中分配多少内存基本上是在类结果定下来时就已知（尽管运行期jit编译器进行一些优化），因此这几个区域的内存分配和回收具备确定性，在这几个区域内就不需要过多考虑回收问题，因为方法结束或者线程结束时，内存自然就回收了</li>
<li>java堆和方法区不一样，一个接口多个实现类需要的内存可能不一样，一个方法中的多个分支需要的内存可能不一样，只有程序处于运行期间才能知道会创建那些对象，这部分的分配和回收都是动态的，垃圾收集器关注的是这部分内存</li>
</ul>
<h2>3.1. 确定对象是否存活的算法</h2>
<h2>3.2. 引用分类</h2>
<h2>3.3. 标记对象死亡</h2>
<ul>
<li>标记对象死亡至少经过两次标记过程：如果对象在进行可达性分析后发现没有与GC Roots相连接的引用链，那它将会被第一次标记并且进行一次筛选，筛选条件是次对象是否有必要执行finalize()方法，当对象没有覆盖finalize()方法，或者finalize（）方法已经被虚拟机调用用过，虚拟机量这两种情况视为没有必要执行</li>
<li>如果对象被判定为有必要执行finalize()方法， 那么这个对象将会放置在一个F-Queue队列中，并稍后由一个虚拟机自动建立的，低优先级的Finalizer线程去执行它，但并不承诺会等待他执行运行结束，这样做的原因是，如果一个对象在finalize()方法中执行缓慢，或者发生死循环，将很可能到时F-Queue队列中其它对象永久处于等待，甚至导致整个内存回收系统崩溃。</li>
<li>finalize()方法是对象逃脱死亡命运的最后一次机会。稍后GC将对F-Queue中的对象进行第二次小规模标记，如果对象要在finalize()方法中避免被回收，只要重新与引用连上的任何一个对象建立关联即可，比如吧自己（this）复制给某个类变量或者对象的成员变量。那再第二次标记时将被移除即将回收集合，如果对象还没有逃脱，那就真的被回收了</li>
<li>finalize()方法尽量少使用，不是C/C++中的析构函数，运行代价高昂，不确定性大，无法保证各个对象的调用顺序，可以使用try-finally或者其它方式做的更好</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>/**
*此代码演示了两点：
*1.对象可以在被GC时自我拯救。
*2.这种自救的机会只有一次，因为一个对象的finalize（）方法最多只会被系统自动调用一次
*@author zzm
*/
public class FinalizeEscapeGC{
public static FinalizeEscapeGC SAVE_HOOK=null；
public void isAlive（）{
System.out.println（"yes,i am still alive：）"）；
}
@Override
protected void finalize（）throws Throwable{
super.finalize（）；
System.out.println（"finalize mehtod executed！"）；
FinalizeEscapeGC.SAVE_HOOK=this；
}
public static void main（String[]args）throws Throwable{
SAVE_HOOK=new FinalizeEscapeGC（）；
//对象第一次成功拯救自己
SAVE_HOOK=null；
System.gc（）；
//因为finalize方法优先级很低，所以暂停0.5秒以等待它
Thread.sleep（500）；
if（SAVE_HOOK！=null）{
SAVE_HOOK.isAlive（）；
}else{
System.out.println（"no,i am dead：（"）；
}
//下面这段代码与上面的完全相同，但是这次自救却失败了
SAVE_HOOK=null；
System.gc（）；
//因为finalize方法优先级很低，所以暂停0.5秒以等待它
Thread.sleep（500）；
if（SAVE_HOOK！=null）{
SAVE_HOOK.isAlive（）；
}else{
System.out.println（"no,i am dead：（"）；
}
}
}
运行结果：
finalize mehtod executed！
yes,i am still alive：）
no,i am dead：（
有两段完全一样的代码片段，执行结果却是一次逃
脱成功，一次失败，这是因为任何一个对象的finalize（）方法都只会被系统自动调用一次，
如果对象面临下一次回收，它的finalize（）方法不会被再次执行，因此第二段代码的自救行
动失败了。
</code></pre></div><h2>3.4. 回收方法区</h2>
<ul>
<li>方法区（HotSpot虚拟机中的永久代）没有垃圾收集，虚拟机规范中确实说过不要求在方法区实现垃圾收集，性价比比较低</li>
<li>永久代的垃圾回收包括两部分：废弃常量和无用类。回收废弃常量与回收Java堆中的对象非常相似，以常量池中字面量的回收为例，假如一个字符串abc进入常量池中，但是当前系统中没有任何一个String对象叫做abc的，没有任何对象引用常量池中的abc常量，也没有其它地方使用了这个字面量，如果此时发生内存回收，而且必要的话，这个abc常量会被清理出常量池，常量池中的其它类（接口），方法，字段的符号也与此类似</li>
<li>判定无用的类的同时满足3个条件：该类所有的实例都已经被回收，java堆中不存在该类的任何实例。加载该类的ClassLoader已经被回收。该类对应的java.lang.Class对象没有任何地方被引用，无法在任何地方通过反射访问该类的方法</li>
<li>是否对类进行回收，HotSpot提供-Xnoclassgc参数进行控制，还可以使用-verbose:class以及-XX:+TranceClassLoading（Product版）-XX:+TraceClassUnLoading查看类加载和卸载信息（FastDebug版）</li>
<li>在大量使用反射，动态代理，CGLIb等ByteCode框架，动态生成JSP以及OSGi这列频繁自定义ClassLoader的场景<br>
都需要虚拟机具备类卸载功能，以保证永久代不会溢出</li>
</ul>
<h1>4. 垃圾收集算法</h1>
<h1>5. HotSpot的算法实现</h1>
<h2>5.1. 枚举根节点</h2>
<ul>
<li>从可达性分析中从GC Roots节点找引用链这个操作为例，可作为GC Roots的节点主要在全局性的引用（例如常量或类静态属性）与执行上下文（例如栈帧中的本地变量表）中，现在很多应用仅仅方法区就有数百兆，如果要逐个检查这里面的引用，那么必然会消耗很多时间。</li>
<li>另外，可达性分析对执行时间的敏感还体现在GC停顿上，因为这项分析工作必须在一个能确保一致性的快照中进行——这里“一致性”的意思是指在整个分析期间整个执行系统看起来就像被冻结在某个时间点上，不可以出现分析过程中对象引用关系还在不断变化的情况，该点不满足的话分析结果准确性就无法得到保证。这点是导致GC进行时必须停顿所有Java执行线程（Sun将这件事情称为“Stop The World”）的其中一个重要原因，即使是在号称（几乎）不会发生停顿的CMS收集器中，枚举根节点时也是必须要停顿的。</li>
<li>由于目前的主流Java虚拟机使用的都是准确式GC，所以当执行系统停顿下来后，并不需要一个不漏地检查完所有<br>
执行上下文和全局的引用位置，虚拟机应当是有办法直接得知哪些地方存放着对象引用。在HotSpot的实现中，是使用一组称为OopMap的数据结构来达到这个目的的，在类加载完成的时候，HotSpot就把对象内什么偏移量上是什么类型的数据计算出来，在JIT编译过程中，也会在特定的位置记录下栈和寄存器中哪些位置是引用。这样，GC在扫描时就可以直接得知<br>
这些信息了。</li>
</ul>
<h2>5.2. 安全点(Safepoint)</h2>
<ul>
<li>在OopMap的协助下，HotSpot可以快速且准确地完成GC Roots枚举，但一个很现实的问题随之而来：可能导致引用关系变化，或者说OopMap内容变化的指令非常多，如果为每一条指令都生成对应的OopMap，那将会需要大量的额外空间，这样GC的空间成本将会变得很高。</li>
<li>实际上，HotSpot也的确没有为每条指令都生成OopMap，前面已经提到，只是在“特定的位置”记录了这些信息，这些位置称为安全点（Safepoint），即程序执行时并非在所有地方都能停顿下来开始GC，只有在到达安全点时才能暂停。Safepoint的选定既不能太少以致于让GC等待时间太长，也不能过于频繁以致于过分增大运行时的负荷。所以，安全点的选定基本上是以程序“是否具有让程序长时间执行的特征”为标准进行选定的——因为每条指令执行的时间都非常短暂，程序不太可能因为指令流长度太长这个原因而过长时间运行，“长时间执行”的最明显特征就是指令序列复用，例如方法调用、循环跳转、异常跳转等，所以具有这些功能的指令才会产生Safepoint。</li>
<li>对于Sefepoint，另一个需要考虑的问题是如何在GC发生时让所有线程（这里不包括执行JNI调用的线程）都“跑”到最近的安全点上再停顿下来。这里有两种方案可供选择：抢先式中断（Preemptive Suspension）和主动式中断（Voluntary Suspension），其中抢先式中断不需要线程的执行代码主动去配合，在GC发生时，首先把所有线程全部中断，如果发现有线程中断的地方不在安全点上，就恢复线程，让它“跑”到安全点上。现在几乎没有虚拟机实现采用抢先式中断来暂停线程从而响应GC事件。而主动式中断的思想是当GC需要中断线程的时候，不直接对线程操作，仅仅简单地设置一个标志，各个线程执行时主动去轮询这个标志，发现中断标志为真时就自己中断挂起。轮询标志的地方和安全点是重合的，另外再加上创建对象需要分配内存的地方。</li>
</ul>
<h2>5.3. 安全区域(Safe Region)</h2>
<ul>
<li>使用Safepoint似乎已经完美地解决了如何进入GC的问题，但实际情况却并不一定。<br>
Safepoint机制保证了程序执行时，在不太长的时间内就会遇到可进入GC的Safepoint。但是，程序“不执行”的时候呢？所谓的程序不执行就是没有分配CPU时间，典型的例子就是线程处于Sleep状态或者Blocked状态，这时候线程无法响应JVM的中断请求，“走”到安全的地方去中断挂起，JVM也显然不太可能等待线程重新被分配CPU时间。对于这种情况，就需要安全区域（Safe Region）来解决。</li>
<li>安全区域是指在一段代码片段之中，引用关系不会发生变化。在这个区域中的任意地方开始GC都是安全的。我们也可以把Safe Region看做是被扩展了的Safepoint。</li>
<li>在线程执行到Safe Region中的代码时，首先标识自己已经进入了Safe Region，那样，当在这段时间里JVM要发起GC时，就不用管标识自己为Safe Region状态的线程了。在线程要离开Safe Region时，它要检查系统是否已经完成了根节点枚举（或者是整个GC过程），如果完成了，那线程就继续执行，否则它就必须等待直到收到可以安全离开Safe Region的信号为止。</li>
<li>内存回收如何进行是由虚拟机所采用的GC收集器决定的，而通常虚拟机中往往不止有一种GC收集器。</li>
</ul>
<h1>6. 垃圾收集器：</h1>
<ul>
<li>如果说收集算法是内存回收的方法论，那么垃圾收集器就是内存回收的具体实现。这里讨论的收集器基于JDK 1.7 Update 14之后的HotSpot虚拟机（在这个版本中正式提供了商用的G1收集器，之前G1仍处于实验状态），Hotspot虚拟机包含的所有收集器.如果两个收集器之间存在连线，就说明它们可以搭配使用。虚拟机所处的区域，则表示它是属于新生代收集器还是老年代收集器。</li>
</ul>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/b4dfad59e848dff058479.png" alt="垃圾收集器.png" tabindex="0"><figcaption>垃圾收集器.png</figcaption></figure>
<h2>6.1. Serial收集器</h2>
<ul>
<li>一个单线程的收集器，它只会使用一个CPU或一条收集线程去完成垃圾收集工作，在进行垃圾收集时，必须暂停其他所有的工作线程，直到它收集结束。“StopThe World”是由虚拟机在后台自动发起和自动完成的，在用户不可见的情况下把用户正常工作的线程全部停掉，这对很多应用来说都是难以接受的。</li>
<li>虚拟机运行在Client模式下的默认新生代收集器。它也有着优于其他收集器的地方：简单而高效（与其他收集器的单线程比），对于限定单个CPU的环境来说，Serial收集器由于没有线程交互的开销，专心做垃圾收集自然可以获得最高的单线程收集效率。在用户的桌面应用场景中，分配给虚拟机管理的内存一般来说不会很大，收集几十兆甚至一两百兆的新生代（仅仅是新生代使用的内存，桌面应用基本上不会再大了），停顿时间完全可以控制在几十毫秒最多一百多毫秒以内，只要不是频繁发生，这点停顿是可以接受的。所以，Serial收集器对于运行在Client模式下的虚拟机来说是一个很好的选择。<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/137d353bad1f4276dbcd0.png" alt="Serial收集器.png"></li>
</ul>
<h2>6.2. ParNew收集器</h2>
<ul>
<li>Serial收集器的多线程版本，包括Serial收集器可用的所有控制参数（例如：-XX：SurvivorRatio、-XX：PretenureSizeThreshold、-XX：HandlePromotionFailure等）、收集算法、Stop The World、对象分配规则、回收策略等都与Serial收集器完全一样，</li>
<li>运行在Server模式下的虚拟机中首选的新生代收集器，其中有一个与性能无关但很重要的原因是，除了Serial收集器外，目前只有它能与CMS收集器配合工作。在JDK 1.5时期，HotSpot推出了一款在强交互应用中几乎可认为有划时代意义的垃圾收集器——CMS收集器（Concurrent Mark Sweep），这款收集器是HotSpot虚拟机中第一款真正意义上的并发（Concurrent）收集器，它第一次实现了让垃圾收集线程与用户线程（基本上）同时工作</li>
<li>CMS作为老年代的收集器，却无法与JDK 1.4.0中已经存在的新生代收集器Parallel Scavenge配合工作[1]，所以在JDK 1.5中使用CMS来收集老年代的时候，新生代只能选择ParNew或者Serial收集器中的一个。ParNew收集器也是使用-XX：+UseConcMarkSweepGC选项后的默认新生代收集器，也可以使用-XX：+UseParNewGC选项来强制指定它。</li>
<li>ParNew收集器在单CPU的环境中绝对不会有比Serial收集器更好的效果，甚至由于存在线程交互的开销，该收集器在通过超线程技术实现的两个CPU的环境中都不能百分之百地保证可以超越Serial收集器。当然，随着可以使用的CPU的数量的增加，它对于GC时系统资源的有效利用还是很有好处的。它默认开启的收集线程数与CPU的数量相同，在CPU非常多<br>
（譬如32个，现在CPU动辄就4核加超线程，服务器超过32个逻辑CPU的情况越来越多了）的环境下，可以使用-XX：ParallelGCThreads参数来限制垃圾收集的线程数。</li>
<li>并行（Parallel）：指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态</li>
<li>并发（Concurrent）：指用户线程与垃圾收集线程同时执行（但不一定是并行的，可能会交替执行），用户程序在继续运行，而垃圾收集程序运行于另一个CPU上。<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/3f1b9ba4c2a19e239081a.png" alt="ParNew收集器.png"></li>
</ul>
<h2>6.3. Parallel Scavenge收集器</h2>
<ul>
<li>使用复制算法的新生代收集器，又是并行的多线程收集器。CMS等收集器的关注点是尽可能地缩短垃圾收集时用户线程的停顿时间，而Parallel Scavenge收集器的目标则是达到一个可控制的吞吐量（Throughput）。所谓吞吐量就是CPU用于运行用户代码的时间与CPU总消耗时间的比值，即吞吐量=运行用户代码时间/（运行用户代码时间+垃圾收集时间），虚拟机总共运行了100分钟，其中垃圾收集花掉1分钟，那吞吐量就是99%。</li>
<li>停顿时间越短就越适合需要与用户交互的程序，良好的响应速度能提升用户体验，而高吞吐量则可以高效率地利用CPU时间，尽快完成程序的运算任务，主要适合在后台运算而不需要太多交互的任务。</li>
<li>Parallel Scavenge收集器提供了两个参数用于精确控制吞吐量
<ul>
<li>控制最大垃圾收集停顿时间的-XX：MaxGCPauseMillis参数，MaxGCPauseMillis参数允许的值是一个大于0的毫秒数，收集器将尽可能地保证内存回收花费的时间不超过设定值。不过不要认为如果把这个参数的值设置得稍小一点就能使得系统的垃圾收集速度变得更快，GC停顿时间缩短是以牺牲吞吐量和新生代空间来换取的：系统把新生代调小一些，收集300MB新生代肯定比收集500MB快吧，这也直接导致垃圾收集发生得更频繁一些，原来10秒收集一次、每次停顿100毫秒，现在变成5秒收集一次、每次停顿70毫秒。停顿时间的确在下降，但吞吐量也降下来了。</li>
<li>直接设置吞吐量大小的-XX：GCTimeRatio参数。GCTimeRatio参数的值应当是一个大于0且小于100的整数，也就是垃圾收集时间占总时间的比率，相当于是吞吐量的倒数。如果把此参数设置为19，那允许的最大GC时间就占总时间的5%（即1/（1+19）），默认值为99，就是允许最大1%（即1/（1+99））的垃圾收集时间。</li>
</ul>
</li>
<li>自适应调节策略开关参数-XX：+UseAdaptiveSizePolicy值得关注。当这个参数打开之后，就不需要手工指定新生代的大小（-Xmn）、Eden与Survivor区的比例（-XX：SurvivorRatio）、晋升老年代对象年龄（-XX：PretenureSizeThreshold）等细节参数了，虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或者最大的吞吐量，这种调节方式称为GC自适应的调节策略（GC Ergonomics）。如果对于收集器运作原理不太了解，使用Parallel Scavenge收集器配合自适应调节策略，把内存管理的调优任务交给虚拟机去完成将是一个不错的选择。只需要把基本的内存数据设置好（如-Xmx设置最大堆），然后使用MaxGCPauseMillis参数（更关注最大停顿时间）或GCTimeRatio（更关注吞吐量）参数给虚拟机设立一个优化目标，那具体细节参数的调节工作就由虚拟机完成了。</li>
</ul>
<h2>6.4. Serial Old收集器</h2>
<ul>
<li>Serial收集器的老年代版本，是一个单线程收集器，使用“标记-整理”算法。在于给Client模式下的虚拟机使用。如果在Server模式下，那么它主要还有两大用途：一种用途是在JDK 1.5以及之前的版本中与Parallel Scavenge收集器搭配使用[1]，另一种用途就是作为CMS收集器的后备预案，在并发收集发生Concurrent Mode Failure时使用<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/a0cd5e368bf9e098b64f4.png" alt="SerialOld收集器.png"></li>
</ul>
<h2>6.5. Parallel Old收集器</h2>
<ul>
<li>Parallel Scavenge收集器的老年代版本，使用多线程和“标记-整理”算法。这在JDK 1.6中才开始提供的，在此之前，新生代的Parallel Scavenge收集器一直处于比较尴尬的状态。原因是，如果新生代选择了Parallel Scavenge收集器，老年代除了Serial Old（PS MarkSweep）收集器外别无选择（还记得上面说过Parallel Scavenge收集器无法与CMS收集器配合工作吗？）。由于老年代Serial Old收集器在服务端应用性能上的“拖累”，使用了Parallel Scavenge收集器也未必能在整体应用上获得吞吐量最大化的效果，由于单线程的老年代收集中无法充分利用服务器多CPU的处理能力，在老年代很大而且硬件比较高级的环境中，这种组合的吞吐量甚至还不一定有ParNew加CMS的组合“给力”。直到Parallel Old收集器出现后，“吞吐量优先”收集器终于有了比较名副其实的应用组合，在注重吞吐量以及CPU资源敏感的场合，都可以优先考虑Parallel Scavenge加Parallel Old收集器。<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/f1f82ee058e4fbc578472.png" alt="ParallelOld收集器.png"></li>
</ul>
<h2>6.6. CMS收集器（Concurrent Mark Sweep）</h2>
<ul>
<li>一种以获取最短回收停顿时间为目标的收集器。目前很大一部分的Java应用集中在互联网站或者B/S系统的服务端上，这类应用尤其重视服务的响应速度，希望系统停顿时间最短，以给用户带来较好的体验。CMS收集器就非常符合这类应用的需求。</li>
<li>基于“标记—清除”算法实现,整个运作过程分为4个步骤
<ul>
<li>初始标记（CMS initial mark）初始标记、重新标记这两个步骤仍然需要“Stop The World”。初始标记仅仅只是标记一下GC Roots能直接关联到的对象，速度很快，</li>
<li>并发标记（CMS concurrent mark）并发标记阶段就是进行GC RootsTracing的过程</li>
<li>重新标记（CMS remark）为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长一些，但远比并发标记的时间短。</li>
<li>并发清除（CMS concurrent sweep）</li>
</ul>
</li>
<li>由于整个过程中耗时最长的并发标记和并发清除过程收集器线程都可以与用户线程一起。从总体上来说，CMS收集器的内存回收过程是与用户线程一起并发执行的。<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/05c6873a683a76ad9ce46.png" alt="CMS收集器.png"></li>
<li>优点：并发收集、低停顿</li>
<li>CMS收集器对CPU资源非常敏感。在并发阶段，它虽然不会导致用户线程停顿，但是会因为占用了一部分线程（或者说CPU资<br>
源）而导致应用程序变慢，总吞吐量会降低。CMS默认启动的回收线程数是（CPU数量+3）/4，也就是当CPU在4个以上时，并发回收时垃圾收集线程不少于25%的CPU资源，并且随着CPU数量的增加而下降。但是当CPU不足4个（譬如2个）时，CMS对用户程序的影响就可能变得很大，如果本来CPU负载就比较大，还分出一半的运算能力去执行收集器线程，就<br>
可能导致用户程序的执行速度忽然降低了50%，其实也让人无法接受。为了应付这种情况，虚拟机提供了一种称为“增量式并发收集器”（Incremental Concurrent Mark Sweep/i-CMS）的CMS收集器变种，所做的事情和单CPU年代PC机操作系统使用抢占式来模拟多任务机制的思想一样，就是在并发标记、清理的时候让GC线程、用户线程交替运行，尽量减少GC线程的独占资源的时间，这样整个垃圾收集的过程会更长，但对用户程序的影响就会显得少一些，也就是速度下降没有那么明显。实践证明，增量时的CMS收集器效果很一般，在目前版本中，i-CMS已经被声明为“deprecated”，即不再提倡用户使用。</li>
<li>CMS收集器无法处理浮动垃圾（Floating Garbage），可能出现“Concurrent Mode Failure”失败而导致另一次Full GC的产生。由于CMS并发清理阶段用户线程还在运行着，伴随程序运行自然就还会有新的垃圾不断产生，这一部分垃圾出现在标记过程之后，CMS无法在当次收集中处理掉它们，只好留待下一次GC时再清理掉。这一部分垃圾就称为“浮动垃<br>
圾”。也是由于在垃圾收集阶段用户线程还需要运行，那也就还需要预留有足够的内存空间给用户线程使用，因此CMS收集器不能像其他收集器那样等到老年代几乎完全被填满了再进行收集，需要预留一部分空间提供并发收集时的程序运作使用。在JDK 1.5的默认设置下，CMS收集器当老年代使用了68%的空间后就会被激活，这是一个偏保守的设置，如果在应用中老年代增长不是太快，可以适当调高参数-XX：CMSInitiatingOccupancyFraction的值来提高触发百分比，以便降低内存回收次数从而获取更好的性能，在JDK 1.6中，CMS收集器的启动阈值已经提升至92%。要是CMS运行期间预留的内存无法满足程序需要，就会出现一次“Concurrent Mode Failure”失败，这时虚拟机将启动后备预案：临时启用Serial Old收集器来重新进行老年代的垃圾收集，这样停顿时间就很长了。所以说参数-XX：CMSInitiatingOccupancyFraction设置得太高很容易导致大量“Concurrent Mode Failure”失败，性能反而降低。</li>
<li>CMS是一款基于“标记—清除”算法实现的收集器。CMS收集结束时会有大量空间碎片产生。空间碎片过多时，将会给大对象分配带来很大麻烦，往往会出现老年代还有很大空间剩余，但是无法找到足够大的连续空间来分配当前对象，不得不提前触发一次FullGC。为了解决这个问题，CMS收集器提供了一个-XX：+UseCMSCompactAtFullCollection开关参数（默认就是开启的），用于在CMS收集器顶不住要进行FullGC时开启内存碎片的合并整理过程，内存整理的过程是无法并发的，空间碎片问题没有了，但停顿时间不得不变长。虚拟机设计者还提供了另外一个参数-XX：CMSFullGCsBeforeCompaction，这个参数是用于设置执行多少次不压缩的Full GC后，跟着来一次带压缩的（默认值为0，表示每次进入FullGC时都进行碎片整理）</li>
</ul>
<h2>6.7. G1收集器(Garbage-First)</h2>
<ul>
<li>G1是一款面向服务端应用的垃圾收集器。可以替换掉JDK 1.5中发布的CMS收集器</li>
<li>并行与并发：G1能充分利用多CPU、多核环境下的硬件优势，使用多个CPU（CPU或者CPU核心）来缩短Stop-The-World停顿的时间，部分其他收集器原本需要停顿Java线程执行的GC动作，G1收集器仍然可以通过并发的方式让Java程序继续执行。</li>
<li>分代收集：与其他收集器一样，分代概念在G1中依然得以保留。虽然G1可以不需要其他收集器配合就能独立管理整个GC堆，但它能够采用不同的方式去处理新创建的对象和已经存活了一段时间、熬过多次GC的旧对象以获取更好的收集效果。</li>
<li>空间整合：与CMS的“标记—清理”算法不同，G1从整体来看是基于“标记—整理”算法实现的收集器，从局部（两个Region之间）上来看是基于“复制”算法实现的，但无论如何，这两种算法都意味着G1运作期间不会产生内存空间碎片，收集后能提供规整的可用内存。这种特性有利于程序长时间运行，分配大对象时不会因为无法找到连续内存空间而提前触发下一次GC。</li>
<li>G1收集器将整个Java堆划分为多个大小相等的独立区域（Region），虽然还保留有新生代和老年代的概念，但新生代和老年代不再是物理隔离的了，它们都是一部分Region（不需要连续）的集合</li>
<li>可预测的停顿：这是G1相对于CMS的另一大优势，降低停顿时间是G1和CMS共同的关注点，但G1除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为M毫秒的时间片段内，消耗在垃圾收集上的时间不得超过N毫秒，这几乎已经是实时Java（RTSJ）的垃圾收集器的特征了。G1收集器之所以能建立可预测的停顿时间模型，是因为它可以有计划地避免在整个Java堆中进行全区域的垃圾收集。G1跟踪各个Region里面的垃圾堆积的价值大小（回收所获得的空间大小以及回收所需时间的经验值），在后台维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的Region（这也就是Garbage-First名称的来由）。这种使用Region划分内存空间以及有优先级的区域回收方式，保证了G1收集器在有限的时间内可以获取尽可能高的收集效率。</li>
<li>把Java堆分为多个Region后，垃圾收集是否就真的能以Region为单位进行了？听起来顺理成章，再仔细想想就很容易发现问题所在：Region不可能是孤立的。一个对象分配在某个Region中，它并非只能被本Region中的其他对象引用，而是可以与整个Java堆任意的对象发生引用关系。那在做可达性判定确定对象是否存活的时候，岂不是还得扫描整个Java堆才能保证准确性？这个问题其实并非在G1中才有，只是在G1中更加突出而已。在以前的分代收集中，新生代的规模一般都比老年代要小许多，新生代的收集也比老年代要频繁许多，那回收新生代中的对象时也面临相同的问题，如果回收新生代时也不得不同时扫描老年代的话，那么Minor GC的效率可能下降不少。</li>
<li>在G1收集器中，Region之间的对象引用以及其他收集器中的新生代与老年代之间的对象引用，虚拟机都是使Remembered Set来避免全堆扫描的。G1中每个Region都有一个与之对应的Remembered Set，虚拟机发现程序在对Reference类型的数据进行写操作时，会产生一个Write Barrier暂时中断写操作，检查Reference引用的对象是否处于不同的Region之中（在分代的例子中就是检查是否老年代中的对象引用了新生代中的对象），如果是，便通过CardTable把相关引用信息记录到被引用对象所属的Region的Remembered Set之中。当进行内存回收时，在GC根节点的枚举范围中加Remembered Set即可保证不对全堆扫描也不会有遗漏。</li>
<li>如果不计算维护Remembered Set的操作，G1收集器的运作大致可划分为以下几个步骤：
<ul>
<li>初始标记（Initial Marking）：仅仅只是标记一下GC Roots能直接关联到的对象，并且修改TAMS（Next Top at Mark Start）的值，让下一阶段用户程序并发运行时，能在正确可用的Region中创建新对象，这阶段需要停顿线程，但耗时很短。</li>
<li>并发标记（Concurrent Marking）从GC Root开始对堆中对象进行可达性分析，找出存活的对象，这阶段耗时较长，但可与用户程序并发执行。</li>
<li>最终标记（Final Marking）为了修正在并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录，虚拟机将这段时间对象变化记录在线程Remembered Set Logs里面，最终标记阶段需要把Remembered Set Logs的数据合并到Remembered Set中，这阶段需要停顿线程，但是可并行执行。</li>
<li>筛选回收（Live Data Counting and Evacuation）首先对各个Region的回收价值和成本进行排序，根据用户所期望的GC停顿时间来制定回收计划，从Sun公司透露出来的信息来看，这个阶段其实也可以做到与用户程序一起并发执行，但是因为只回收一部分Region，时间是用户可控制的，而且停顿用户线程将大幅提高收集效率。<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/ed654609b4c9209ada12b.png" alt="G1收集器.png"></li>
</ul>
</li>
</ul>
<h1>7. GC日志</h1>
<ul>
<li>每个收集器的日志格式都可以不一样，但收集器的日志都维持一定的共性</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>33.125：[GC[DefNew：3324K-＞152K（3712K），0.0025925 secs]3324K-＞152K（11904K），0.0031680 secs]
100.667：[Ful l G C[Tenured：0K-＞210K(10240K)，0.0149142secs]4603K-＞210K（19456K），[Perm：2999K-＞2999K（21248K）]，0.0150007 secs][Times：user=0.01 sys=0.00，real=0.02 secs]
</code></pre></div><ul>
<li>
<p>最前面的数字“33.125：”和“100.667：”代表了GC发生的时间(从Java虚拟机启动以来经过的秒数)</p>
</li>
<li>
<p>GC日志开头的“[GC”和“[Full GC”说明了这次垃圾收集的停顿类型，如果有“Full”，说明这次GC是发生了Stop-The-World的，如果是调用System.gc（）方法所触发的收集，那么在这里将显示“[Full GC（System）”。</p>
</li>
<li>
<p>“[DefNew”、“[Tenured”、“[Perm”表示GC发生的区域，这里显示的区域名称与使用的GC收集器是密切相关的，例如上面样例所使用的Serial收集器中的新生代名为“DefaultNew Generation”，所以显示的是“[DefNew”。如果是ParNew收集器，新生代名称就会变为“[ParNew”，意为“Parallel New Generation”。如果采用Parallel Scavenge收集器，那它配套的新生代称为“PSYoungGen”，老年代和永久代同理，名称也是由收集器决定的。</p>
</li>
<li>
<p>方括号内部的“3324K-＞152K（3712K）”含义是“GC前该内存区域已使用容量-＞GC后该内存区域已使用容量（该内存区域总容量）”。而在方括号之外的“3324K-＞152K（11904K）”表示“GC前Java堆已使用容量-＞GC后Java堆已使用容量（Java堆总容量）”</p>
</li>
<li>
<p>“0.0025925 secs”表示该内存区域GC所占用的时间，单位是秒。有的收集器会给出更具体的时间数据，如“[Times：user=0.01 sys=0.00，real=0.02 secs]”，这里面的user、sys和real与Linux的time命令所输出的时间含义一致，分别代表用户态消耗的CPU时间、内核态消耗的CPU事件和操作从开始到结束所经过的墙钟时间（Wall Clock Time）。CPU时间与墙钟时间的区别是，墙钟时间包括各种非运算的等待耗时，例如等待磁盘I/O、等待线程阻塞，而CPU时间不包括这些耗时，但当系统有多CPU或者多核的话，多线程操作会叠加这些CPU时间，所以user或sys时间超过real时间是完全正常的</p>
</li>
<li>
<p>垃圾收集器参数总结（JDK 1.7）</p>
</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align:left">参数</th>
<th style="text-align:left">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">UseSerialGC</td>
<td style="text-align:left">虚拟机运行在Client模式下的默认值，打开此开关后，使用Serial + Serial Old的收集器组合进行内存回收</td>
</tr>
<tr>
<td style="text-align:left">UseParNewGC</td>
<td style="text-align:left">打开此开关后，使用ParNew + Serial Old的收集器组合进行内存回收</td>
</tr>
<tr>
<td style="text-align:left">UseConcMarkSweepGC</td>
<td style="text-align:left">打开此开关后，使用ParNew + CMS + Serial Old的收集器组合进行内存回收。</td>
</tr>
<tr>
<td style="text-align:left">UseParallelGC</td>
<td style="text-align:left">虚拟机运行在Server模式下的默认值，打开此开关后，使用Parallel Scavenge + Serial Old（PS MarkSweep）的收集器组合进行内存回收</td>
</tr>
<tr>
<td style="text-align:left">UseParallelOldGC</td>
<td style="text-align:left">打开此开关后，使用Parallel Scavenge + Parallel Old 的收集器组合进行内存回收</td>
</tr>
<tr>
<td style="text-align:left">SurvivorRatio</td>
<td style="text-align:left">新生代中Eden区域与Survivor区域的容量比值，默认为8，代表Eden : Survivor=8:1</td>
</tr>
<tr>
<td style="text-align:left">PretenureSizeThreshold</td>
<td style="text-align:left">直接晋升到老年代的对象大小，设置这个参数后，大于这个参数的对象将直接在老年代分配</td>
</tr>
<tr>
<td style="text-align:left">MaxTenuringThreshold</td>
<td style="text-align:left">晋升到老年代的对象年龄。每个对象在坚持过一次Minor GC之后，年龄就增加1，当超过这个参数值时就进入老年代</td>
</tr>
<tr>
<td style="text-align:left">UseAdaptiveSizePolicy</td>
<td style="text-align:left">动态调整Java堆中各个区域的大小以及进入老年代的年龄</td>
</tr>
<tr>
<td style="text-align:left">HandlePromotionFailure</td>
<td style="text-align:left">是否允许分配担保失败，即老年代的剩余空间不足以应付新生代的整个Eden和Survivor区的所有对象都存活的极端情况</td>
</tr>
<tr>
<td style="text-align:left">ParallelGCThreads</td>
<td style="text-align:left">设置并行GC时进行内存回收的线程数</td>
</tr>
<tr>
<td style="text-align:left">GCTimeRatio</td>
<td style="text-align:left">GC时间占总时间的比率，默认值为99，即允许1%的GC时间。仅使用Parallel Scavenge收集器时生效</td>
</tr>
<tr>
<td style="text-align:left">MaxGCPauseMillis</td>
<td style="text-align:left">设置GC的最大停顿时间。仅在使用Parallel Scavenge收集器生效</td>
</tr>
<tr>
<td style="text-align:left">CMSInitiatingOccupancyFraction</td>
<td style="text-align:left">设置CMS收集器在老年代空间被使用多少后触发垃圾收集，默认值为68%，仅使用CMS收集器时生效</td>
</tr>
<tr>
<td style="text-align:left">UseCMSCompactAtFullCollection</td>
<td style="text-align:left">设置CMS收集器在完成垃圾收集后是否要进行一次内存碎片整理。仅在使用CMS收集器时生效</td>
</tr>
<tr>
<td style="text-align:left">CMSFullGCsBeforeCompaction</td>
<td style="text-align:left">设置CMS收集器在进行若干次垃圾收集后再启动一次内存碎片整理。仅在使用CMS收集器时生效</td>
</tr>
</tbody>
</table>
<h1>8. 内存分配与回收策略</h1>
<ul>
<li>对象的内存分配，往大方向讲，就是在堆上分配（但也可能经过JIT编译后被拆散为标量类型并间接地栈上分配），对象主要分配在新生代的Eden区上，如果启动了本地线程分配缓冲，将按线程优先在TLAB上分配。少数情况下也可能会直接分配在老年代中，分配的规则取决于当前使用的是哪一种垃圾收集器组合，还有虚拟机中与内存相关的参数的设置。</li>
</ul>
<h2>8.1. 对象优先在Eden分配</h2>
<ul>
<li>大多数情况下，对象在新生代Eden区中分配。当Eden区没有足够空间进行分配时，虚拟机将发起一次Minor GC。</li>
<li>虚拟机提供了-XX：+PrintGCDetails这个收集器日志参数，告诉虚拟机在发生垃圾收集行为时打印内存回收日志，并且在进程退出的时候输出当前的内存各区域分配情况。在实际应用中，内存回收日志一般是打印到文件后通过日志工具进行分析</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>private static final int_1MB=1024*1024；
/**
*VM参数：-verbose：gc-Xms20M-Xmx20M-Xmn10M-XX：+PrintGCDetails
-XX：SurvivorRatio=8
*/
public static void testAllocation（）{
  byte[]allocation1，allocation2，allocation3，allocation4；
  allocation1=new byte[2*_1MB]；
  allocation2=new byte[2*_1MB]；
  allocation3=new byte[2*_1MB]；
  allocation4=new byte[4*_1MB]；//出现一次Minor GC
}
[GC[DefNew：6651K-＞148K（9216K），0.0070106 secs]6651K-＞6292K（19456K），
0.0070426 secs][Times：user=0.00 sys=0.00，real=0.00 secs]
Heap
def new generation total 9216K,used 4326K[0x029d0000，0x033d0000，0x033d0000）
eden space 8192K，51%used[0x029d0000，0x02de4828，0x031d0000）
from space 1024K，14%used[0x032d0000，0x032f5370，0x033d0000）
to space 1024K，0%used[0x031d0000，0x031d0000，0x032d0000）
tenured generation total 10240K,used 6144K[0x033d0000，0x03dd0000，0x03dd0000）
the space 10240K，60%used[0x033d0000，0x039d0030，0x039d0200，0x03dd0000）
compacting perm gen total 12288K,used 2114K[0x03dd0000，0x049d0000，0x07dd0000）
the space 12288K，17%used[0x03dd0000，0x03fe0998，0x03fe0a00，0x049d0000）
No shared spaces configured.

testAllocation（）方法中，尝试分配3个2MB大小和1个4MB大小的对象，在运行时通过-Xms20M、-Xmx20M、-Xmn10M这3个参数限制了Java堆大小为20MB，不可扩展，其中10MB分配给新生代，剩下的10MB分配给老年代。-XX：SurvivorRatio=8决定了新生代中Eden区与一个Survivor区的空间比例是8:1，从输出的结果也可以清晰地看到“eden
space 8192K、from space 1024K、to space 1024K”的信息，新生代总可用空间为9216KB（Eden区+1个Survivor区的总容量）。

执行testAllocation（）中分配allocation4对象的语句时会发生一次Minor GC，这次GC的结果是新生代6651KB变为148KB，而总内存占用量则几乎没有减少（因为allocation1、allocation2、allocation3三个对象都是存活的，虚拟机几乎没有找到可回收的对象）。这次GC发生的原因是给allocation4分配内存的时候，发现Eden已经被占用了6MB，剩余空间已不足以分配allocation4所需的4MB内存，因此发生Minor GC。GC期间虚拟机又发现已有的3个2MB大小的对象全部无法放入Survivor空间（Survivor空间只有1MB大小），所以只好通过分配担保机制提前转移到老年代去。
这次GC结束后，4MB的allocation4对象顺利分配在Eden中，因此程序执行完的结果是Eden占用4MB（被allocation4占用），Survivor空闲，老年代被占用6MB（被allocation1、allocation2、allocation3占用）。
</code></pre></div><ul>
<li>Minor GC和Full GC有什么不一样吗？
<ul>
<li>新生代GC（Minor GC）：指发生在新生代的垃圾收集动作，因为Java对象大多都具备朝生夕灭的特性，所以Minor GC非常频繁，一般回收速度也比较快。</li>
<li>老年代GC（Major GC/Full GC）：指发生在老年代的GC，经常会伴随至少一次的Minor GC（但非绝对的，在Parallel Scavenge收集器的收集策略里就有直接进行Major GC的策略选择过程）。Major GC的速度一般会比Minor GC慢10倍以上</li>
</ul>
</li>
</ul>
<h2>8.2. 大对象直接进入老年代</h2>
<ul>
<li>大对象是指需要大量连续内存空间的Java对象，最典型的大对象就是那种很长的字符串以及数组。经常出现大对象容易导致内存还有不少空间时就提前触发垃圾收集以获取足够的连续空间来“安置”它们。写程序应该避免产生大对象</li>
<li>虚拟机提供了一个-XX：PretenureSizeThreshold参数，令大于这个设置值的对象直接在老年代分配。目的是避免在Eden区及两个Survivor区之间发生大量的内存复制（新生代采用复制算法收集内存）。</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>private static final int_1MB=1024*1024；
/**
*VM参数：-verbose：gc-Xms20M-Xmx20M-Xmn10M-XX：+PrintGCDetails-XX：SurvivorRatio=8
*-XX：PretenureSizeThreshold=3145728
*/
public static void testPretenureSizeThreshold（）{
  byte[]allocation；
  allocation=new byte[4*_1MB]；//直接分配在老年代中
}
Heap
def new generation total 9216K,used 671K[0x029d0000，0x033d0000，0x033d0000）
eden space 8192K，8%used[0x029d0000，0x02a77e98，0x031d0000）
from space 1024K，0%used[0x031d0000，0x031d0000，0x032d0000）
to space 1024K，0%used[0x032d0000，0x032d0000，0x033d0000）
tenured generation total 10240K,used 4096K[0x033d0000，0x03dd0000，0x03dd0000）
the space 10240K，40%used[0x033d0000，0x037d0010，0x037d0200，0x03dd0000）
compacting perm gen total 12288K,used 2107K[0x03dd0000，0x049d0000，0x07dd0000）
the space 12288K，17%used[0x03dd0000，0x03fdefd0，0x03fdf000，0x049d0000）
No shared spaces configured

testPretenureSizeThreshold（）方法后，我们看到Eden空间几乎没有被使用，而老年代的10MB空间被使用了40%，也就是4MB的allocation对象直接就分配在老年代中，这是因为PretenureSizeThreshold被设置为3MB（就是3145728，这个参数不能像-Xmx之类的参数一样直接写3MB），因此超过3MB的对象都会直接在老年代进行分配。注意
PretenureSizeThreshold参数只对Serial和ParNew两款收集器有效，Parallel Scavenge收集器不认识这个参数，Parallel Scavenge收集器一般并不需要设置。如果遇到必须使用此参数的场合，可以考虑ParNew加CMS的收集器组合
</code></pre></div><h2>8.3. 长期存活的对象将进入老年代</h2>
<ul>
<li>虚拟机采用了分代收集的思想来管理内存，虚拟机给每个对象定义了一个对象年龄（Age）计数器。如果对象在Eden出生并经过第一次Minor GC后仍然存活，并且能被Survivor容纳的话，将被移动到Survivor空间中，并且对象年龄设为1。对象在Survivor区中每“熬过”一次Minor GC，年龄就增加1岁，当它的年龄增加到一定程度（默认为15岁），就将会被晋升到老年代中。对象晋升老年代的年龄阈值，可以通过参数-XX：MaxTenuringThreshold设置。</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>private static final int_1MB=1024*1024；
/**
*VM参数：-verbose：gc-Xms20M-Xmx20M-Xmn10M-XX：+PrintGCDetails-XX：SurvivorRatio=8-XX：MaxTenuringThreshold=1
*-XX：+PrintTenuringDistribution
*/
@SuppressWarnings（"unused"）
public static void testTenuringThreshold（）{
  byte[]allocation1，allocation2，allocation3；
  allocation1=new byte[_1MB/4]；
  //什么时候进入老年代取决于XX：MaxTenuringThreshold设置
  allocation2=new byte[4*_1MB]；
  allocation3=new byte[4*_1MB]；
  allocation3=null；
  allocation3=new byte[4*_1MB]；
}
以MaxTenuringThreshold=1参数来运行的结果：

[GC[DefNew
Desired Survivor size 524288 bytes,new threshold 1（max 1）
-age 1：414664 bytes，414664 total ：4859K-＞404K（9216K），0.0065012 secs]4859K-＞4500K（19456K），0.0065283 secs][Times：user=0.02 sys=0.00，real=0.02 secs]
[GC[DefNew
Desired Survivor size 524288 bytes,new threshold 1（max 1）
：4500K-＞0K（9216K），0.0009253 secs]8596K-＞4500K（19456K），0.0009458 secs][Times：user=0.00 sys=0.00，real=0.00 secs]
Heap
def new generation total 9216K,used 4178K[0x029d0000，0x033d0000，0x033d0000）
eden space 8192K，51%used[0x029d0000，0x02de4828，0x031d0000）
from space 1024K，0%used[0x031d0000，0x031d0000，0x032d0000）
to space 1024K，0%used[0x032d0000，0x032d0000，0x033d0000）
tenured generation total 10240K,used 4500K[0x033d0000，0x03dd0000，0x03dd0000）
the space 10240K，43%used[0x033d0000，0x03835348，0x03835400，0x03dd0000）
compacting perm gen total 12288K,used 2114K[0x03dd0000，0x049d0000，0x07dd0000）
the space 12288K，17%used[0x03dd0000，0x03fe0998，0x03fe0a00，0x049d0000）
No shared spaces configured. 

以MaxTenuringThreshold=15参数来运行的结果：
[GC[DefNew
Desired Survivor size 524288 bytes,new threshold 15（max 15）
-age 1：414664 bytes，414664 total ：4859K-＞404K（9216K），0.0049637 secs]4859K-＞4500K（19456K），0.0049932 secs][Times：user=0.00 sys=0.00，real=0.00 secs]
[GC[DefNew
Desired Survivor size 524288 bytes,new threshold 15（max 15）
-age 2：414520 bytes，414520 total ：4500K-＞404K（9216K），0.0008091 secs]8596K-＞4500K（19456K），0.0008305 secs][Times：user=0.00 sys=0.00，real=0.00 secs]
Heap
def new generation total 9216K,used 4582K[0x029d0000，0x033d0000，0x033d0000）
eden space 8192K，51%used[0x029d0000，0x02de4828，0x031d0000）
from space 1024K，39%used[0x031d0000，0x03235338，0x032d0000）
to space 1024K，0%used[0x032d0000，0x032d0000，0x033d0000）
tenured generation total 10240K,used 4096K[0x033d0000，0x03dd0000，0x03dd0000）
the space 10240K，40%used[0x033d0000，0x037d0010，0x037d0200，0x03dd0000）
compacting perm gen total 12288K,used 2114K[0x03dd0000，0x049d0000，0x07dd0000）
the space 12288K，17%used[0x03dd0000，0x03fe0998，0x03fe0a00，0x049d0000）
No shared spaces configured

分别以-XX：MaxTenuringThreshold=1和-XX：MaxTenuringThreshold=15两种设置来执行代码清单3-7中的testTenuringThreshold（）方法，此方法中的allocation1对象需要256KB内存，Survivor空间可以容纳。当MaxTenuringThreshold=1时，allocation1对象在第二次GC发生时进入老年代，新生代已使用的内存GC后非常干净地变成0KB。而MaxTenuringThreshold=15时，第二次GC发生后，allocation1对象则还留在新生代Survivor空间，这时新生代仍然有404KB被占用
</code></pre></div><h2>8.4. 动态对象年龄判定</h2>
<ul>
<li>为了能更好地适应不同程序的内存状况，虚拟机并不是永远地要求对象的年龄必须达到了MaxTenuringThreshold才能晋升老年代，如果在Survivor空间中相同年龄所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代，无须等到MaxTenuringThreshold中要求的年龄。</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>private static final int_1MB=1024*1024；
/**
*VM参数：-verbose：gc-Xms20M-Xmx20M-Xmn10M-XX：+PrintGCDetails-XX：SurvivorRatio=8-XX：MaxTenuringThreshold=15
*-XX：+PrintTenuringDistribution
*/
@SuppressWarnings（"unused"）
public static void testTenuringThreshold2（）{
  byte[]allocation1，allocation2，allocation3，allocation4；
  allocation1=new byte[_1MB/4]；
  //allocation1+allocation2大于survivo空间一半
  allocation2=new byte[_1MB/4]；
  allocation3=new byte[4*_1MB]；
  allocation4=new byte[4*_1MB]；
  allocation4=null；
  allocation4=new byte[4*_1MB]；
}
[GC[DefNew
Desired Survivor size 524288 bytes,new threshold 1（max 15）
-age 1：676824 bytes，676824 total ：5115K-＞660K（9216K），0.0050136 secs]5115K-＞4756K（19456K），0.0050443 secs][Times：user=0.00 sys=0.01，real=0.01 secs]
[GC[DefNew
Desired Survivor size 524288 bytes,new threshold 15（max 15）
：4756K-＞0K（9216K），0.0010571 secs]8852K-＞4756K（19456K），0.0011009 secs][Times：user=0.00 sys=0.00，real=0.00 secs]
Heap
def new generation total 9216K,used 4178K[0x029d0000，0x033d0000，0x033d0000）
eden space 8192K，51%used[0x029d0000，0x02de4828，0x031d0000）
from space 1024K，0%used[0x031d0000，0x031d0000，0x032d0000）
to space 1024K，0%used[0x032d0000，0x032d0000，0x033d0000）
tenured generation total 10240K,used 4756K[0x033d0000，0x03dd0000，0x03dd0000）
the space 10240K，46%used[0x033d0000，0x038753e8，0x03875400，0x03dd0000）
compacting perm gen total 12288K,used 2114K[0x03dd0000，0x049d0000，0x07dd0000）
the space 12288K，17%used[0x03dd0000，0x03fe09a0，0x03fe0a00，0x049d0000）
No shared spaces configured

testTenuringThreshold2（）方法，并设置-XX：MaxTenuringThreshold=15，会发现运行结果中Survivor的空间占用仍然为0%，而老年代比预期增加了6%，也就是说，allocation1、allocation2对象都直接进入了老年代，而没有等到15岁的临界年龄。因为这两个对象加起来已经到达了512KB，并且它们是同年的，满足同年对象达到Survivor空间的一半规则。我们只要注释掉其中一个对象new操作，就会发现另外一个就不会晋升到老年代中去了。
</code></pre></div><h2>8.5. 空间分配担保</h2>
<ul>
<li>在发生Minor GC之前，虚拟机会先检查老年代最大可用的连续空间是否大于新生代所有对象总空间，如果这个条件成立，那么Minor GC可以确保是安全的。如果不成立，则虚拟机会查看HandlePromotionFailure设置值是否允许担保失败。如果允许，那么会继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小，如果大于，将尝试着进行<br>
一次Minor GC，尽管这次Minor GC是有风险的；如果小于，或者HandlePromotionFailure设置不允许冒险，那这时也要改为进行一次Full GC。</li>
</ul>
<p>下面解释一下“冒险”是冒了什么风险，前面提到过，新生代使用复制收集算法，但为了内存利用率，只使用其中一个Survivor空间来作为轮换备份，因此当出现大量对象在Minor GC后仍然存活的情况（最极端的情况就是内存回收后新生代中所有对象都存活），就需要老年代进行分配担保，把Survivor无法容纳的对象直接进入老年代。老年代要进行这样的担保，前提是老年代本身还有容纳这些对象的剩余空间，一共有多少对象会活下来在实际完成内存回收之前是无法明确知道的，所以只好取之前每一次回收晋升到老年代对象容量的平均大小值作为经验值，与老年代的剩余空间进行比较，决定是否进<br>
行Full GC来让老年代腾出更多空间。取平均值进行比较其实仍然是一种动态概率的手段，也就是说，如果某次Minor GC存活后的对象突增，远远高于平均值的话，依然会导致担保失败（Handle Promotion Failure）。如果出现了HandlePromotionFailure失败，那就只好在失败后重新发起一次Full GC。虽然担保失败时绕的圈子是最大的，但大部分情况下都还是会将HandlePromotionFailure开关打开，避免Full GC过于频繁</p>
<ul>
<li>参见代码清单3-9，请读者在JDK 6 Update 24之前的版本中运行测试。</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>private static final int_1MB=1024*1024；
/**
*VM参数：-Xms20M-Xmx20M-Xmn10M-XX：+PrintGCDetails-XX：SurvivorRatio=8-XX：-HandlePromotionFailure
*/
@SuppressWarnings（"unused"）
public static void testHandlePromotion（）{
  byte[]allocation1，allocation2，allocation3，allocation4，allocation5，allocation6，allocation7；
  allocation1=new byte[2*_1MB]；
  allocation2=new byte[2*_1MB]；
  allocation3=new byte[2*_1MB]；
  allocation1=null；
  allocation4=new byte[2*_1MB]；
  allocation5=new byte[2*_1MB]；
  allocation6=new byte[2*_1MB]；
  allocation4=null；
  allocation5=null；
  allocation6=null；
  allocation7=new byte[2*_1MB]；
}
以HandlePromotionFailure=false参数来运行的结果：
[GC[DefNew：6651K-＞148K（9216K），0.0078936 secs]6651K-＞4244K（19456K），0.0079192 secs][Times：user=0.00 sys=0.02，real=0.02 secs]
[G C[D e f N e w：6 3 7 8 K-＞6 3 7 8 K（9 2 1 6 K），0.0 0 0 0 2 0 6 s e c s][T e n u r e d：4096K-＞4244K（10240K），0.0042901 secs]10474K-＞
4244K（19456K），[Perm：2104K-＞2104K（12288K）]，0.0043613 secs][Times：user=0.00 sys=0.00，real=0.00 secs]

以HandlePromotionFailure=true参数来运行的结果：
[GC[DefNew：6651K-＞148K（9216K），0.0054913 secs]6651K-＞4244K（19456K），0.0055327 secs][Times：user=0.00 sys=0.00，real=0.00 secs]
[GC[DefNew：6378K-＞148K（9216K），0.0006584 secs]10474K-＞4244K（19456K），0.0006857 secs][Times：user=0.00 sys=0.00，real=0.00 secs]
在JDK 6 Update 24之后，这个测试结果会有差异，HandlePromotionFailure参数不会再影响到虚拟机的空间分配担保策略，观察OpenJDK中的源码变化（见代码清单3-10），虽然源码中还定义了HandlePromotionFailure参数，但是在代码中已经不会再使用它。JDK 6 Update 24之后的规则变为只要老年代的连续空间大于新生代对象总大小或者历次晋升的平均大小就会进行Minor GC，否则将进行Full GC。
</code></pre></div><p>代码清单3-10 HotSpot中空间分配检查的代码片段</p>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>bool TenuredGeneration：promotion_attempt_is_safe（size_t
max_promotion_in_bytes）const{
//老年代最大可用的连续空间
size_t available=max_contiguous_available（）；
//每次晋升到老年代的平均大小
size_t av_promo=（size_t）gc_stats（）-＞avg_promoted（）-＞padded_average（）；
//老年代可用空间是否大于平均晋升大小，或者老年代可用空间是否大于当此GC时新生代所有对象容量
bool res=（available＞=av_promo）||（available＞=
max_promotion_in_bytes）；
return res；
}
</code></pre></div><h1>9. 虚拟机性能监控与故障处理工具</h1>
<ul>
<li>给一个系统定位问题的时候，知识、经验是关键基础，数据是依据，工具是运用知识处理数据的手段。这里说的数据包括：运行日志、异常堆栈、GC日志、线程快照（threaddump/javacore文件）、堆转储快照（heapdump/hprof文件）等。经常使用适当的虚拟机监控和分析的工具可以加快我们分析数据、定位解决问题的速度</li>
</ul>
<h2>9.1. JDK的命令行工具</h2>
<ul>
<li>如果在工作中需要监控运行于JDK 1.5的虚拟机之上的程序，在程序启动时请添加参数“-Dcom.sun.management.jmxremote”开启JMX管理功能，否则由于部分工具都是基于JMX（包括4.3节介绍的可视化工具），它们都将会无法使用，如果被监控程序运行于JDK1.6的虚拟机之上，那JMX管理默认是开启的，虚拟机启动时无须再添加任何参数。</li>
</ul>
<h3>9.1.1. jps：虚拟机进程状况工具（JVM Process Status Tool）</h3>
<ul>
<li>列出正在运行的虚拟机进程，并显示虚拟机执行主类（Main Class,main()函数所在的类）名称以及这些进程的本地虚拟机唯一ID（Local Virtual Machine Identifier,LVMID）。虽然功能比较单一，但它是使用频率最高的JDK命令行工具，因为其他的JDK工具大多需要输入它查询到的LVMID来确定要监控的是哪一个虚拟机进程。对于本地虚拟机进程来说，LVMID与操作系统的进程ID（Process Identifier,PID）是一致的，使用Windows的任务管理器或者UNIX的ps命令也可以查询到虚拟机进程的LVMID，但如果同时启动了多个虚拟机进程，无法根据进程名称定位时，那就只能依赖jps命令显示主类的功能才能区分了</li>
<li>jps可以通过RMI协议查询开启了RMI服务的远程虚拟机进程状态，hostid为RMI注册表中注册的主机名。</li>
<li>jps命令格式：jps[options][hostid]</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align:left">选项</th>
<th style="text-align:left">作用</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">-q</td>
<td style="text-align:left">只输出LVMID,省略主类的名称</td>
</tr>
<tr>
<td style="text-align:left">-m</td>
<td style="text-align:left">输出虚拟机进程启动时传递给主类main()函数的参数</td>
</tr>
<tr>
<td style="text-align:left">-l</td>
<td style="text-align:left">输出主类的全名，如果进程执行的是Jar包，输出jar路径</td>
</tr>
<tr>
<td style="text-align:left">-v</td>
<td style="text-align:left">输出虚拟机进程启动时JVM参数</td>
</tr>
</tbody>
</table>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>D：\Develop\Java\jdk1.6.0_21\bin＞jps -l
2388 D：\Develop\glassfish\bin\..\modules\admin-cli.jar
2764 com.sun.enterprise.glassfish.bootstrap.ASMain
3788 sun.tools.jps.Jps
</code></pre></div><h3>9.1.2. jstat：虚拟机统计信息监视工具（JVM Statistics Monitoring Tool）</h3>
<ul>
<li>jstat是用于监视虚拟机各种运行状态信息的命令行工具。它可以显示本地或者远程[1]虚拟机进程中的类装载、内存、垃圾收集、JIT编译等运行数据，在没有GUI图形界面，只提供了纯文本控制台环境</li>
<li>jstat命令格式为：jstat[option vmid[interval[s|ms][count]]]。如果是本地虚拟机进程，VMID与LVMID是一致的，如果是远程虚拟机进程，那VMID的格式应当是：[protocol：][//]lvmid[@hostname[：port]/servername]参数interval和count代表查询间隔和次数，如果省略这两个参数，说明只查询一次。假设需要每250毫秒查询一次进程2764垃圾收集状况，一共查询20次，那命令应当是：jstat-gc 2764 250 20选项option代表着用户希望查询的虚拟机信息，主要分为3类：类装载、垃圾收集、运行期编译状况，具体选项及作用请参考下面的描述</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align:left">选项</th>
<th style="text-align:left">作用</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">-class</td>
<td style="text-align:left">监视类装载、卸载数量、总空间以及类装载所耗费的时间</td>
</tr>
<tr>
<td style="text-align:left">-gc</td>
<td style="text-align:left">监视Java堆状况，包括Eden区、两个survivor区、老年代、元空间的容量、已用空间、GC时间合计等信息</td>
</tr>
<tr>
<td style="text-align:left"></td>
<td style="text-align:left">-gccapacity</td>
</tr>
<tr>
<td style="text-align:left">-gcutil</td>
<td style="text-align:left">监视内容与-gc基本相同，但输出主要关注已使用空间占总空间的百分比</td>
</tr>
<tr>
<td style="text-align:left">-gccause</td>
<td style="text-align:left">与-gcutil功能一样，但是会额外输出导致上一次GC产生的原因</td>
</tr>
<tr>
<td style="text-align:left">-gcnew</td>
<td style="text-align:left">监视新生代GC状况</td>
</tr>
<tr>
<td style="text-align:left">-gcnewcapacity</td>
<td style="text-align:left">监视内容与-gcnew基本相同，输出主要关注使用到的最大、最小空间</td>
</tr>
<tr>
<td style="text-align:left">-gcold</td>
<td style="text-align:left">监视老年代状况</td>
</tr>
<tr>
<td style="text-align:left">-gcoldcapacity</td>
<td style="text-align:left">监视内容与-gcold基本相同，输出主要关注用到的最大、最小空间</td>
</tr>
<tr>
<td style="text-align:left">-gcmetacapacity</td>
<td style="text-align:left">输出元数据用到的最大、最小空间</td>
</tr>
<tr>
<td style="text-align:left">-compiler</td>
<td style="text-align:left">输出JIT编译器编译过的方法、耗时等信息</td>
</tr>
<tr>
<td style="text-align:left">-printcompilation</td>
<td style="text-align:left">输出已经被JIT编译的方法</td>
</tr>
</tbody>
</table>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>jstat执行样例
D：\Develop\Java\jdk1.6.0_21\bin＞jstat-gcutil 2764
S0 S1 E O P YGC YGCT FGC FGCT GCT
0.00 0.00 6.20 41.42 47.20 16 0.105 3 0.472 0.577
查询结果表明：这台服务器的新生代Eden区（E，表示Eden）使用了6.2%的空间，两个Survivor区（S0、S1，表示Survivor0、Survivor1）里面都是空的，老年代（O，表示Old）和永久代（P，表示Permanent）则分别使用了41.42%和47.20%的空间。程序运行以来共发生Minor GC（YGC，表示Young GC）16次，总耗时0.105秒，发生Full GC（FGC，表示Full GC）3次，Full GC总耗时（FGCT，表示Full GC Time）为0.472秒，所有GC总耗时（GCT，表示GC Time）为0.577秒。
</code></pre></div><h3>9.1.3. jinfo：Java配置信息工具（Configuration Info for Java）</h3>
<ul>
<li>实时地查看和调整虚拟机各项参数。包括未被显式指定的参数的系统默认值，就只能使用jinfo的-flag选项进行查询了（如果只限于JDK 1.6或以上版本的话，使用java-XX：+PrintFlagsFinal查看参数默认值也是一个很好的选择），jinfo还可以使用-sysprops选项把虚拟机进程的System.getProperties（）的内容打印出来。这个命令在JDK 1.5时期已经随着Linux版的JDK发布，当时只提供了信息查询的功能，JDK 1.6之后，jinfo在Windows和Linux平台都有提供，并且加入了运行期修改参数的能力，可以使用-flag[+|-]name或者-flag name=value修改一部分运行期可写的虚拟机参数值。JDK 1.6中，jinfo对于Windows平台功能仍然有较大限制，只提供了最基本的-flag选项。</li>
<li>jinfo命令格式：jinfo[option]pid</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>执行样例：查询CMSInitiatingOccupancyFraction参数值。
C：\＞jinfo-flag CMSInitiatingOccupancyFraction 1444
-XX：CMSInitiatingOccupancyFraction=85
</code></pre></div><h3>9.1.4. jmap：Java内存映像工具（Memory Map for Java）</h3>
<ul>
<li>用于生成堆转储快照（一般称为heapdump或dump文件）。也可以添加参数-XX：+HeapDumpOnOutOfMemoryError，可以让虚拟机在OOM异常出现之后自动生成dump文件，通过-XX：+HeapDumpOnCtrlBreak参数则可以使用[Ctrl]+[Break]<br>
键让虚拟机生成dump文件，又或者在Linux系统下通过Kill-3命令发送进程退出信号给虚拟机，也能拿到dump文件。</li>
<li>查询finalize执行队列、Java堆和永久代的详细信息，如空间使用率、当前用的是哪种收集器等。</li>
<li>jmap有不少功能在Windows平台下都是受限的，除了生成dump文件的dump选项和用于查看每个类的实例、空间占用统计的-histo选项在所有操作系统都提供之外，其余选项都只能在Linux/Solaris下使用。</li>
<li>jmap命令格式：jmap[option]vmid</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>|选项|作用|
|:-|:-|
|-dump|	生成java堆快照,格式为:-dump[live,]format=b,file=&lt;filename&gt;,其中live子参数说明是否只dump出存活的对象|
|-finalizerinfo|显示在F-Queue中等待Finalizer线程执行finalize方法的对象,只能在Linux/Solaris下有效|
|-heap|显示java堆详细信息，如使用哪种回收器、参数配置、分代情况等,只能在Linux/Solaris下有效|
|-histo|显示堆中对象统计信息，包括类、实例数量、合计容量|
|permstat|以ClassLoader为统计口径显示永久代内存状态,只能在Linux/Solaris下有效|
|-F|强制生成快照,只能在Linux/Solaris下有效|
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>C：\Users\IcyFenix＞jmap-dump：format=b,file=eclipse.bin 3500
Dumping heap to C：\Users\IcyFenix\eclipse.bin……
Heap dump file created
</code></pre></div><h3>9.1.5. jhat：虚拟机堆转储快照分析工具（JVM Heap Analysis Tool）</h3>
<ul>
<li>与jmap搭配使用，来分析jmap生成的堆转储快照。jhat内置了一个微型的HTTP/HTML服务器，生成dump文件的分析结果后，可以在浏览器中查看。但一般都不会去直接使用jhat命令来分析dump文件，主要原因有二：一是一般不会在部署应用程序的服务器上直接分析dump文件，即使可以这样做，也会尽量将dump文件复制到其他机器上进行分析，因为分析工作是一个耗时而且消耗硬件资源的过程，既然都要在其他机器进行，就没有必要受到命令行工具的限制了；另一个原因是jhat的分析功能相对来说比较简陋。</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>使用jhat分析dump文件
C：\Users\IcyFenix＞jhat eclipse.bin
Reading from eclipse.bin……
Dump file created Fri Nov 19 22：07：21 CST 2010
Snapshot read,resolving……
Resolving 1225951 objects……
Chasing references,expect 245 dots……
Eliminating duplicate references……
Snapshot resolved.
Started HTTP server on port 7000
Server is ready.
屏幕显示“Server is ready.”的提示后，用户在浏览器中键入http://localhost：7000/就可以看到分析结果
分析结果默认是以包为单位进行分组显示，分析内存泄漏问题主要会使用到其中的“Heap Histogram”（与jmap-histo功能一样）与OQL页签的功能，前者可以找到内存中总容量最大的对象，后者是标准的对象查询语言，使用类似SQL的语法对内存中的对象进行查询统计
</code></pre></div><h3>9.1.6. jstack：Java堆栈跟踪工具（Stack Trace for Java）</h3>
<ul>
<li>用于生成虚拟机当前时刻的线程快照（一般称为threaddump或者javacore文件）。线程快照就是当前虚拟机内每一条线程正在执行的方法堆栈的集合，生成线程快照的主要目的是定位线程出现长时间停顿的原因，如线程间死锁、死循环、请求外部资源导致的长时间等待等都是导致线程长时间停顿的常见原因。线程出现停顿的时候通过jstack来查看各个线程的调用堆栈，就可以知道没有响应的线程到底在后台做些什么事情，或者等待着什么资源。</li>
<li>jstack命令格式：jstack[option]vmid</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align:left">选项</th>
<th style="text-align:left">作用</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">-F</td>
<td style="text-align:left">当正常输出请求不被响应时，强制输出线程堆栈</td>
</tr>
<tr>
<td style="text-align:left">-l</td>
<td style="text-align:left">除堆栈外，显示关于锁的附加信息</td>
</tr>
<tr>
<td style="text-align:left">-m</td>
<td style="text-align:left">如果调用到本地方法的话，可以显示C/C++的堆栈</td>
</tr>
</tbody>
</table>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>C：\Users\IcyFenix＞jstack-l 3500
2010-11-19 23：11：26
Full thread dump Java HotSpot（TM）64-Bit Server VM（17.1-b03 mixed mode）：
"[ThreadPool Manager]-Idle Thread"daemon prio=6 tid=0x0000000039dd4000 nid=0xf50 in Object.wait（）[0x000000003c96f000]
java.lang.Thread.State：WAITING（on object monitor）
at java.lang.Object.wait（Native Method）
-waiting on＜0x0000000016bdcc60＞（a org.eclipse.equinox.internal.util.impl.tpt.threadpool.Executor）
at java.lang.Object.wait（Object.java：485）
at org.eclipse.equinox.internal.util.impl.tpt.threadpool.Executor.run（Executor.java：106）
-locked＜0x0000000016bdcc60＞（a org.eclipse.equinox.internal.util.impl.tpt.threadpool.Executor）
Locked ownable synchronizers：
-None
</code></pre></div><ul>
<li>在JDK 1.5中，java.lang.Thread类新增了一个getAllStackTraces（）方法用于获取虚拟机中所有线程的StackTraceElement对象。使用这个方法可以通过简单的几行代码就完成jstack的大部分功能，在实际项目中不妨调用这个方法做个管理员页面，可以随时使用浏览器来查看线程堆栈</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>查看线程状况的JSP页面
＜%@page import="java.util.Map"%＞
＜html＞
＜head＞
＜title＞服务器线程信息＜/title＞
＜/head＞
＜body＞
＜pre＞
＜%
for（Map.Entry＜Thread,StackTraceElement[]＞stackTrace：Thread.
getAllStackTraces（）.entrySet（））{
Thread thread=（Thread）stackTrace.getKey（）；
StackTraceElement[]stack=（StackTraceElement[]）stackTrace.getValue（）；
if（thread.equals（Thread.currentThread（）））{
continue；
}
out.print（"\n线程："+thread.getName（）+"\n"）；
for（StackTraceElement element：stack）{
out.print（"\t"+element+"\n"）；
}
}
%＞
＜/pre＞
＜/body＞
＜/html＞

</code></pre></div><h2>9.2. HSDIS：JIT生成代码反汇编</h2>
<ul>
<li>HSDIS是一个Sun官方推荐的HotSpot虚拟机JIT编译代码的反汇编插件，它包含在HotSpot虚拟机的源码之中，但没有提供编译后的程序。在Project Kenai的网站[1]也可以下载到单独的源码。它的作用是让HotSpot的-XX：+PrintAssembly指令调用它来把动态生成的本地代码还原为汇编代码输出，同时还生成了大量非常有价值的注释，这样我们就可以通过输出的代码来分析问题。可以根据自己的操作系统和CPU类型从Project Kenai的网站上下载编译好的插件，直接放到JDK_HOME/jre/bin/client和JDK_HOME/jre/bin/server目录中即可。如果没有找到所需操作系统（譬如Windows的就没有）的成品，那就得自己使用源码编译一下[2]。还需要注意的是，如果读者使用的是Debug或者FastDebug版的HotSpot，那可以直接通过-XX：+PrintAssembly指令使用插件；如果使用的是Product版的HotSpot，那还要额外加入<br>
一个-XX：+UnlockDiagnosticVMOptions参数。笔者以代码清单4-6中的简单测试代码为例演示一下这个插件的使用。</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class Bar{
  int a=1；
  static int b=2；
  public int sum（int c）{
    return a+b+c；
  }
  public static void main（String[]args）{
    new Bar（）.sum（3）；
  }
}
编译这段代码，并使用以下命令执行。
java-XX：+PrintAssembly-Xcomp-XX：CompileCommand=dontinline，*Bar.sum-XX：Compi leCommand=compileonly，*Bar.sum test.Bar

参数-Xcomp是让虚拟机以编译模式执行代码，不需要执行足够次数来预热就能触发JIT编译。两个-XX：CompileCommand意思是让编译器不要内联sum（）并且只编译sum（），-XX：+PrintAssembly就是输出反汇编内容。
[Disassembling for mach='i386']
[Entry Point]
[Constants]
#{method}'sum''（I）I'in'test/Bar'
#this：ecx='test/Bar'
#parm0：edx=int
#[sp+0x20]（sp of caller）
……
0x01cac407：cmp 0x4（%ecx），%eax
0x01cac40a：jne 0x01c6b050；{runtime_call}
[Verified Entry Point]
0x01cac410：mov%eax，-0x8000（%esp） //检查栈溢。
0x01cac417：push%ebp //保存上一栈帧基址。
0x01cac418：sub$0x18，%esp；*aload_0 ；-test.Bar：sum@0（line 8）//sub$0x18，%esp：给新帧分配空间
；block B0[0，10]
0x01cac41b：mov 0x8（%ecx），%eax；*getfield a ；-test.Bar：sum@1（line 8）//mov 0x8（%ecx），%eax：取实例变量a，这里0x8（%ecx）就是ecx+0x8的意思，前面“[Constants]”节中提示了“this：ecx='test/Bar'”，即ecx寄存器中放的就是this对象的地址。偏移0x8是越过this对象的对象头，之后就是实例变量a的内存位置。这次是访问“Java堆”中的数据
0x01cac41e：mov$0x3d2fad8，%esi；{oop（a
'java/lang/Class'='test/Bar'）}//mov$0x3d2fad8，%esi：取test.Bar在方法区的指针。
0x01cac423：mov 0x68（%esi），%esi；*getstatic b ；-test.Bar：sum@4（line 8）//mov 0x68（%esi），%esi：取类变量b，这次是访问“方法区”中的数据。
0x01cac426：add%esi，%eax //add%esi，%eax和add%edx，%eax：做两次加法，求a+b+c的值，前面的代码把a放在
eax中，把b放在esi中，而c在[Constants]中提示了，“parm0：edx=int”，说明c在edx中。
0x01cac428：add%edx，%eax //add$0x18，%esp：撤销栈帧。
0x01cac42a：add$0x18，%esp //pop%ebp：恢复上一栈帧。
0x01cac42d：pop%ebp
0x01cac42e：test%eax，0x2b0100；{poll_return} //test%eax，0x2b0100：轮询方法返回处的SafePoint。
0x01cac434：ret //ret：方法返回。

</code></pre></div><h1>10. JDK的可视化工具</h1>
<h2>10.1. JConsole：Java监视与管理控制台</h2>
<ul>
<li>JConsole（Java Monitoring and Management Console）是一种基于JMX的可视化监视、管理工具。它管理部分的功能是针对JMX MBean进行管理，由于MBean可以使用代码、中间件服务器的管理控制台或者所有符合JMX规范的软件进行访问.</li>
<li>启动JConsole:通过JDK/bin目录下的“jconsole.exe”启动JConsole后，将自动搜索出本机运行的所有虚拟<br>
机进程，不需要用户自己再使用jps来查询了，如图4-4所示。双击选择其中一个进程即可开<br>
始监控，也可以使用下面的“远程进程”功能来连接远程服务器，对远程虚拟机进行监控。</li>
<li>“概述”页签显示的是整个虚拟机主要运行数据的概览，其中包括“堆内存使用情况”、“线程”、“类”、“CPU使用情况”4种信息的曲线图，这些曲线图是后面“内存”、“线程”、“类”页签的信息汇总</li>
<li>“内存”页签相当于可视化的jstat命令，用于监视受收集器管理的虚拟机内存（Java堆和永久代）的变化趋势。</li>
<li>运行时设置的虚拟机参数为：-Xms100m-Xmx100m-XX：+UseSerialGC，这段代码的作用是以64KB/50毫秒的速度往Java堆中填充数据，一共填充1000次，使用JConsole的“内存”页签进行监视，观察曲线和柱状指示图的变化。程序运行后，在“内存”页签中可以看到内存池Eden区的运行趋势呈现折线状，而监视范围扩大至整个堆后，会发现曲线是一条向上增长的平滑曲线。并且从柱状图可以看出，在1000次循环执行结束，运行了System.gc（）后，虽然整个新生代Eden和Survivor区都基本被清空了，但是代表老年代的柱状图仍然保持峰值状态，说明被填充进堆中的数据在System.gc（）方法执行之后仍然存活。</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>    /**
     *内存占位符对象，一个OOMObject大约占64KB
     */
    static class OOMObject{
        public byte[]placeholder=new byte[64*1024];
    }
    public static void fillHeap(int num)throws InterruptedException{
        List&lt;OOMObject&gt; list = new ArrayList&lt;OOMObject&gt;();
        for(int i=0;i&lt;num;i++){
            //稍作延时，令监视曲线的变化更加明显
            Thread.sleep(50);
            list.add(new OOMObject());
        }
        System.gc();
    }
    public static void main(String[]args)throws Exception{
        fillHeap(1000);
    }
</code></pre></div><ul>
<li>
<p>虚拟机启动参数只限制了Java堆为100MB，没有指定-Xmn参数，能否从监控图中估<br>
计出新生代有多大？显示Eden空间为27 328KB，因为没有设置-XX：SurvivorRadio参数，所以Eden与Survivor空间比例为默认值8:1，整个新生代空间大约为27 328KB×125%=34160KB。</p>
</li>
<li>
<p>为何执行了System.gc（）之后，图4-6中代表老年代的柱状图仍然显示峰值状态，代<br>
码需要如何调整才能让System.gc（）回收掉填充到堆中的对象？执行完System.gc（）之后，空间未能回收是因为List＜OOMObject＞list对象仍然存活，fillHeap（）方法仍然没有退出，因此list对象在System.gc（）执行时仍然处于作用域之内。如果把System.gc（）移动到fillHeap（）方法外调用就可以回收掉全部内存。</p>
</li>
<li>
<p>“线程”页签的功能相当于可视化的jstack命令，遇到线程停顿时可以使用这个页签进行监控分析。线程长时间停顿的主要原因主要有：等待外部资源（数据库连接、网络资源、设备资源等）、死循环、锁等待（活锁和死锁）。</p>
</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>/**
     *线程死循环演示
     */
    public static void createBusyThread(){
        Thread thread=new Thread(new Runnable(){
            @Override
            public void run(){
                while(true)//第41行
  ;
            }
        },"testBusyThread");
        thread.start();
    }
    /**
     *线程锁等待演示
     */
    public static void createLockThread(final Object lock){
        Thread thread=new Thread(new Runnable(){
            @Override
            public void run(){
                synchronized(lock){
                    try{
                        lock.wait();
                    }catch(InterruptedException e){
                        e.printStackTrace();
                    }
                }
            }
        },"testLockThread");
        thread.start();
    }
    public static void main(String[]args)throws Exception{
        BufferedReader br=new BufferedReader(new InputStreamReader(System.in));
        br.readLine();
        createBusyThread();
        br.readLine();
        Object obj=new Object();
        createLockThread(obj);
    }

</code></pre></div><ul>
<li>
<p>“线程”页签中选择main线程，如图4-7所示。堆栈追踪显示BufferedReader在readBytes方法中等待System.in的键盘输入，这时线程为Runnable状态，Runnable状态的线程会被分配运行时间，但readBytes方法检查到流没有更新时会立刻归还执行令牌，这种等待只消耗很小的CPU资源。</p>
</li>
<li>
<p>接着监控testBusyThread线程，如图4-8所示，testBusyThread线程一直在执行空循环，从堆栈追踪中看到一直在MonitoringTest.java代码的41行停留，41行为：while（true）。这时候线程为Runnable状态，而且没有归还线程执行令牌的动作，会在空循环上用尽全部执行时间直到线程切换，这种等待会消耗较多的CPU资源。</p>
</li>
<li>
<p>testLockThread线程在等待着lock对象的notify或notifyAll方法的出现，线程这时候处于WAITING状态，在被唤醒前不会被分配执行时间。testLockThread线程正在处于正常的活锁等待，只要lock对象的notify（）或notifyAll（）<br>
方法被调用，这个线程便能激活以继续执行。</p>
</li>
<li>
<p>死锁代码样例</p>
</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>/**
*线程死锁等待演示
*/
static class SynAddRunalbe implements Runnable{
  int a,b；
  public SynAddRunalbe（int a,int b）{
    this.a=a；
    this.b=b；
  }
  @Override
  public void run（）{
    synchronized（Integer.valueOf（a））{
      synchronized（Integer.valueOf（b））{
      System.out.println（a+b）；
      }
    }
  }
  }
  public static void main（String[]args）{
    for（int i=0；i＜100；i++）{
    new Thread（new SynAddRunalbe（1，2））.start（）；
    new Thread（new SynAddRunalbe（2，1））.start（）；
  }
}
</code></pre></div><ul>
<li>开了200个线程去分别计算1+2以及2+1的值，其实for循环是可省略的，两个线程也可能会导致死锁，不过那样概率太小，需要尝试运行很多次才能看到效果。一般的话，带for循环的版本最多运行2～3次就会遇到线程死锁，程序无法结束。造成死锁的原因是Integer.valueOf（）方法基于减少对象创建次数和节省内存的考虑，[-128，127]之间的数字会被缓存[3]，当valueOf（）方法传入参数在这个范围之内，将直接返回缓存中的对象。也就是说，代码中调用了200次Integer.valueOf（）方法一共就只返回了两个不同的对象。假如在某个线程的两个synchronized块之间发生了一次线程切换，那就会出现线程A等着被线程B持有的Integer.valueOf（1），线程B又等着被线程A持有的Integer.valueOf（2），结果出现大家都跑不下去的情景。出现线程死锁之后，点击JConsole线程面板的“检测到死锁”按钮，将出现一个新的“死锁”页签，线程Thread-43在等待一个被线程Thread-12持有Integer对象，而点击线程Thread-12则显示它也在等待一个Integer对象，被线程Thread-43持有，这样两个线程就互相卡住，都不存在等到锁释放的希望了。<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/ce75d2edba93bb5f498a6.png" alt="线程死锁.png"></li>
</ul>
<h2>10.2. VisualVM：多合一故障处理工具</h2>
<ul>
<li>VisualVM（All-in-One Java Troubleshooting Tool）是随JDK发布的功能最强大的运行监视和故障处理程序，官方在VisualVM的软件说明中写上了“All-in-One”的描述字样，预示着它除了运行监视、故障处理外，还提供了很多其他方面的功能。如性能分析（Profiling），VisualVM的不需要被监视的程序基于特殊Agent运行，因此它对应用程序的实际性能的影响很小，使得它可以直接应用在生产环境中。</li>
<li>插件安装：通过插件扩展支持，VisualVM可以做到：
<ul>
<li>显示虚拟机进程以及进程的配置、环境信息（jps、jinfo）。</li>
<li>监视应用程序的CPU、GC、堆、方法区以及线程的信息（jstat、jstack）。</li>
<li>dump以及分析堆转储快照（jmap、jhat）。</li>
<li>方法级的程序运行性能分析，找出被调用最多、运行时间最长的方法。</li>
<li>离线程序快照：收集程序的运行时配置、线程dump、内存dump等信息建立一个快照，可以将快照发送开发者处进行Bug反馈</li>
<li>其他plugins的无限的可能性……</li>
</ul>
</li>
<li>使用VisualVM的自动安装功能已经可以找到大多数所需的插件，在有网络连接的环境下，点击“工具”→“插件菜单”，在页签的“可用插件”中列举了当前版本VisualVM可以使用的插件，选中插件后在右边窗口将显示这个插件的基本信息，如开发者、版本、功能描述等。</li>
<li>生成、浏览堆转储快照.在VisualVM中生成dump文件有两种方式，可以执行下列任一操作：
<ul>
<li>在“应用程序”窗口中右键单击应用程序节点，然后选择“堆Dump”。</li>
<li>在“应用程序”窗口中双击应用程序节点以打开应用程序标签，然后在“监视”标签中单击“堆Dump”。生成了dump文件之后，应用程序页签将在该堆的应用程序下增加一个以[heapdump]开头的子节点，并且在主页签中打开了该转储快照，如图4-14所示。如果需要把dump文件保存或发送出去，要在heapdump节点上右键选择“另存为”菜单，否则当VisualVM关闭时，生成的dump文件会被当做临时文件删除掉。要打开一个已经存在的dump文件，通过文件菜单中的“装入”功能，选择硬盘上的dump文件即可。</li>
</ul>
</li>
<li>从堆页签中的“摘要”面板可以看到应用程序dump时的运行时参数、System.getProperties（）的内容、线程堆栈等信息，“类”面板则是以类为统计口径统计类的实例数量、容量信息，“实例”面板不能直接使用，因为不能确定用户想查看哪个类的实例，所以需要通过“类”面板进入，在“类”中选择一个关心的类后双击鼠标，即可在“实例”里面看见此类中500个实例的具体属性信息。“OQL控制台”面板中就是运行OQL查询语句的，同jhat中介绍的OQL功能一样。</li>
<li>分析程序性能,在Profiler页签中，VisualVM提供了程序运行期间方法级的CPU执行时间分析以及内存分析，做Profiling分析肯定会对程序运行性能有比较大的影响，所以一般不在生产环境中使用这项功能。要开始分析，先选择“CPU”和“内存”按钮中的一个，然后切换到应用程序中对程序进行操作，VisualVM会记录到这段时间中应用程序执行过的方法。如果是CPU分析，将会统计每个方法的执行次数、执行耗时；如果是内存分析，则会统计每个方法关联的对象数以及这些对象所占的空间。分析结束后，点击“停止”按钮结束监控过程，</li>
<li>在JDK 1.5之后，在Client模式下的虚拟机加入并且自动开启了类共享——这是一个在多虚拟机进程中共享rt.jar中类数据以提高加载速度和节省内存的优化，而根据相关Bug报告的反映，VisualVM的Profiler功能可能会因为类共享而导致被监视的应用程序崩溃，所以读者进行Profiling前，最好在被监视程序中使用-Xshare：off参数来关闭类共享优化。</li>
<li>BTrace动态日志跟踪,是一个VisualVM插件，本身也是可以独立运行的程序。它的作用是在不停止目标程序运行的前提下，通过HotSpot虚拟机的HotSwap技术动态加入原本并不存在的调试代码。这项功能对实际生产中的程序很有意义：经常遇到程序出现问题，但排查错误的一些必要信息，譬如方法参数、返回值等，在开发时并没有打印到日志之中，以至于不得不停掉服务，通过调试增量来加入日志代码以解决问题。当遇到生产环境服务无法随便停止时，缺一两句日志导致排错进行不下去是一件非常郁闷的事情。在VisualVM中安装了BTrace插件后，在应用程序面板中右键点击要调试的程序，会出现“Trace Application……”菜单，点击将进入BTrace面板。这个面板里面看起来就像一个简单的Java程序开发环境，里面还有一小段Java代码.BTrace的用法还有许多，打印调用堆栈、参数、返回值只是最基本的应用，在它的网站上有使用BTrace进行性能监视、定位连接泄漏和内存泄漏、解决多线程竞争问题</li>
</ul>
<h1>11. 调优案例分析与实战</h1>
<h2>11.1. 高性能硬件上的程序部署策略</h2>
<ul>
<li>管理员为了尽量利用硬件资源选用了64位的JDK 1.5，并通过-Xmx和-Xms参数将Java堆固定在12GB。使用一段时间后发现使用效果并不理想，网站经常不定期出现长时间失去响应的情况。监控服务器运行状况后发现网站失去响应是由GC停顿导致的，虚拟机运行在Server模式，默认使用吞吐量优先收集器，回收12GB的堆，一次Full GC的停顿时间高达14秒。并且由于程序设计的关系，访问文档时要把文档从磁盘提取到内存中，导致内存中出现很多由文档序列化产生的大对象，这些大对象很多都进入了老年代，没有在Minor GC中清理掉。这种情况下即使有12GB的堆，内存也很快被消耗殆尽，由此导致每隔十几分钟出现十几秒的停顿</li>
<li>程序部署上的主要问题显然是过大的堆内存进行回收时带来的长时间的停顿。硬件升级前使用32位系统1.5GB的堆，用户只感觉到使用网站比较缓慢，但不会发生十分明显的停顿，因此才考虑升级硬件以提升程序效能，如果重新缩小给Java堆分配的内存，那么硬件上的投资就显得很浪费</li>
<li>在高性能硬件上部署程序，目前主要有两种方式：
<ul>
<li>通过64位JDK来使用大内存。</li>
<li>使用若干个32位虚拟机建立逻辑集群来利用硬件资源。</li>
</ul>
</li>
<li>此案例中的管理员采用了第一种部署方式。对于用户交互性强、对停顿时间敏感的系统，可以给Java虚拟机分配超大堆的前提是有把握把应用程序的Full GC频率控制得足够低，至少要低到不会影响用户使用，譬如十几个小时乃至一天才出现一次Full GC，这样可以通过在深夜执行定时任务的方式触发Full GC甚至自动重启应用服务器来保持内存可用空间在一个稳定的水平。<br>
控制Full GC频率的关键是看应用中绝大多数对象能否符合“朝生夕灭”的原则，即大多数对象的生存时间不应太长，尤其是不能有成批量的、长生存时间的大对象产生，这样才能保障老年代空间的稳定。</li>
<li>在大多数网站形式的应用里，主要对象的生存周期都应该是请求级或者页面级的，会话级和全局级的长生命对象相对很少。只要代码写得合理，应当都能实现在超大堆中正常使用而没有Full GC，这样的话，使用超大堆内存时，网站响应速度才会比较有保证。除此之外，如果计划使用64位JDK来管理大内存，还需要考虑下面可能面临的问题：
<ul>
<li>内存回收导致的长时间停顿。</li>
<li>64位JDK的性能测试结果普遍低于32位JDK。</li>
</ul>
</li>
<li>需要保证程序足够稳定，因为这种应用要是产生堆溢出几乎就无法产生堆转储快照（因为要产生十几GB乃至更大的Dump文件），哪怕产生了快照也几乎无法进行分析。相同程序在64位JDK消耗的内存一般比32位JDK大，这是由于指针膨胀，以及数据类型<br>
对齐补白等因素导致的。</li>
<li>所以现阶段不少管理员还是选择第二种方式：使用若干个32位虚拟机建立逻辑集群来利用硬件资源。具体做法是在一台物理机器上启动多个应用服务器进程，每个服务器进程分配不同端口，然后在前端搭建一个负载均衡器，以反向代理的方式来分配访问请求。不需要太过在意均衡器转发所消耗的性能，即使使用64位JDK，许多应用也不止有一台服务器，因此在许多应用中前端的均衡器总是要存在的。</li>
<li>考虑到在一台物理机器上建立逻辑集群的目的仅仅是为了尽可能利用硬件资源，并不需要关心状态保留、热转移之类的高可用性需求，也不需要保证每个虚拟机进程有绝对准确的均衡负载，因此使用无Session复制的亲合式集群是一个相当不错的选择。我们仅仅需要保障集群具备亲合性，也就是均衡器按一定的规则算法（一般根据SessionID分配）将一个固定的用户请求永远分配到固定的一个集群节点进行处理即可，这样程序开发阶段就基本不用为集群环境做什么特别的考虑了。</li>
<li>如果读者计划使用逻辑集群的方式来部署程序，可能会遇到下面一些问题：
<ul>
<li>尽量避免节点竞争全局的资源，最典型的就是磁盘竞争，各个节点如果同时访问某个磁盘文件的话（尤其是并发写操作容易出现问题），很容易导致IO异常。</li>
<li>很难最高效率地利用某些资源池，譬如连接池，一般都是在各个节点建立自己独立的连接池，这样有可能导致一些节点池满了而另外一些节点仍有较多空余。尽管可以使用集中式的JNDI，但这个有一定复杂性并且可能带来额外的性能开销。</li>
<li>各个节点仍然不可避免地受到32位的内存限制，在32位Windows平台中每个进程只能使用2GB的内存，考虑到堆以外的内存开销，堆一般最多只能开到1.5GB。在某些Linux或UNIX系统（如Solaris）中，可以提升到3GB乃至接近4GB的内存，但32位中仍然受最高4GB（2^32）内存的限制。</li>
<li>大量使用本地缓存（如大量使用HashMap作为K/V缓存）的应用，在逻辑集群中会造成较大的内存浪费，因为每个逻辑节点上都有一份缓存，这时候可以考虑把本地缓存改为集中式缓存。</li>
</ul>
</li>
<li>这个案例之中，最后的部署方案调整为建立5个32位JDK的逻辑集群，每个进程按2GB内存计算（其中堆固定为1.5GB），占用了10GB内存。另外建立一个Apache服务作为前端均衡代理访问门户。考虑到用户对响应速度比较关心，并且文档服务的主要压力集中在磁盘和内存访问，CPU资源敏感度较低，因此改为CMS收集器进行垃圾回收。部署方式调整后，服务再没有出现长时间停顿，速度比硬件升级前有较大提升。</li>
</ul>
<h2>11.2. 集群间同步导致的内存溢出</h2>
<ul>
<li>有一个基于B/S的MIS系统，硬件为两台2个CPU、8GB内存的HP小型机，服务器是WebLogic 9.2，每台机器启动了3个WebLogic实例，构成一个6个节点的亲合式集群。由于是亲合式集群，节点之间没有进行Session同步，但是有一些需求要实现部分数据在各个节点间共享。开始这些数据存放在数据库中，但由于读写频繁竞争很激烈，性能影响较大，后面使用JBossCache构建了一个全局缓存。全局缓存启用后，服务正常使用了一段较长的时间，但最近却不定期地出现了多次的内存溢出问题。</li>
<li>在内存溢出异常不出现的时候，服务内存回收状况一直正常，每次内存回收后都能恢复到一个稳定的可用空间，开始怀疑是程序某些不常用的代码路径中存在内存泄漏，但管理员反映最近程序并未更新、升级过，也没有进行什么特别操作。只好让服务带着-XX：+HeapDumpOnOutOfMemoryError参数运行了一段时间。在最近一次溢出之后，管理员发回了heapdump文件，发现里面存在着大量的org.jgroups.protocols.pbcast.NAKACK对象。</li>
<li>JBossCache是基于自家的JGroups进行集群间的数据通信，JGroups使用协议栈的方式来实现收发数据包的各种所需特性自由组合，数据包接收和发送时要经过每层协议栈的up（）和down（）方法，其中的NAKACK栈用于保障各个包的有效顺序及重发。</li>
<li>由于信息有传输失败需要重发的可能性，在确认所有注册在GMS（Group Membership Service）的节点都收到正确的信息前，发送的信息必须在内存中保留。而此MIS的服务端中有一个负责安全校验的全局Filter，每当接收到请求时，均会更新一次最后操作时间，并且将这个时间同步到所有的节点去，使得一个用户在一段时间内不能在多台机器上登录。在服务使用过程中，往往一个页面会产生数次乃至数十次的请求，因此这个过滤器导致集群各个节点之间网络交互非常频繁。当网络情况不能满足传输要求时，重发数据在内存中不断堆积，很快就产生了内存溢出。</li>
<li>这个案例中的问题，既有JBossCache的缺陷，也有MIS系统实现方式上缺陷。JBossCache官方的maillist中讨论过很多次类似的内存溢出异常问题，据说后续版本也有了改进。而更重要的缺陷是这一类被集群共享的数据要使用类似JBossCache这种集群缓存来同步的话，可以允许读操作频繁，因为数据在本地内存有一份副本，读取的动作不会耗费多少资源，但不应当有过于频繁的写操作，那样会带来很大的网络同步的开销。</li>
</ul>
<h2>11.3. 堆外内存导致的溢出错误</h2>
<ul>
<li>一个学校的小型项目：基于B/S的电子考试系统，为了实现客户端能实时地从服务器端接收考试数据，系统使用了逆向AJAX技术（也称为Comet或者Server Side Push），选用CometD 1.1.1作为服务端推送框架，服务器是Jetty 7.1.4，硬件为一台普通PC机，Core i5 CPU，4GB内存，运行32位Windows操作系统。</li>
<li>测试期间发现服务端不定时抛出内存溢出异常，服务器不一定每次都会出现异常，但假如正式考试时崩溃一次，那估计整场电子考试都会乱套，网站管理员尝试过把堆开到最大，而32位系统最多到1.6GB就基本无法再加大了，而且开大了基本没效果，抛出内存溢出异常好像还更加频繁了。加入-XX：+HeapDumpOnOutOfMemoryError，居然也没有任何反应，抛出内存溢出异常时什么文件都没有产生。无奈之下只好挂着jstat并一直紧盯屏幕，发现GC并不频繁，Eden区、Survivor区、老年代以及永久代内存全部都表示“情绪稳定，压力不大”，但就是照样不停地抛出内存溢出异常，最后，在内存溢出后从系统日志中找到异常堆栈</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>[org.eclipse.jetty.util.log]handle failed java.lang.OutOfMemoryError：null
at sun.misc.Unsafe.allocateMemory（Native Method）
at java.nio.DirectByteBuffer.＜init＞（DirectByteBuffer.java：99）
at java.nio.ByteBuffer.allocateDirect（ByteBuffer.java：288）
at org.eclipse.jetty.io.nio.DirectNIOBuffer.＜init＞
</code></pre></div><ul>
<li>操作系统对每个进程能管理的内存是有限制的，这台服务器使用的32位Windows平台的限制是2GB，其中划了1.6GB给Java堆，而Direct Memory内存并不算入1.6GB的堆之内，因此它最大也只能在剩余的0.4GB空间中分出一部分。在此应用中导致溢出的关键是：垃圾收集进行时，虚拟机虽然会对Direct Memory进行回收，但是Direct Memory却不能像新生代、老年代那样，发现空间不足了就通知收集器进行垃圾回收，它只能等待老年代满了后Full GC，然后“顺便地”帮它清理掉内存的废弃对象。否则它只能一直等到抛出内存溢出异常时，先catch掉，再在catch块里面“大喊”一声：“System.gc（）！”。要是虚拟机还是不听（譬如打开了-XX：+DisableExplicitGC开关），那就只能眼睁睁地看着堆中还有许多空闲内存，自己却不得不抛出内存溢出异常了。而本案例中使用的CometD 1.1.1框架，正好有大量的NIO操作需要使用到Direct Memory内存。</li>
<li>从实践经验的角度出发，除了Java堆和永久代之外，我们注意到下面这些区域还会占用较多的内存，这里所有的内存总和受到操作系统进程最大内存的限制。
<ul>
<li>Direct Memory：可通过-XX：MaxDirectMemorySize调整大小，内存不足时抛出OutOfMemoryError或者OutOfMemoryError：Direct buffer memory。</li>
<li>线程堆栈：可通过-Xss调整大小，内存不足时抛出StackOverflowError（纵向无法分配，即无法分配新的栈帧）或者OutOfMemoryError：unable to create new native thread（横向无法分配，即无法建立新的线程）。</li>
<li>Socket缓存区：每个Socket连接都Receive和Send两个缓存区，分别占大约37KB和25KB内存，连接多的话这块内存占用也比较可观。如果无法分配，则可能会抛出IOException：Too many open files异常。</li>
<li>JNI代码：如果代码中使用JNI调用本地库，那本地库使用的内存也不在堆中。</li>
<li>虚拟机和GC：虚拟机、GC的代码执行也要消耗一定的内存。</li>
</ul>
</li>
</ul>
<h2>11.4. 外部命令导致系统缓慢</h2>
<ul>
<li>一个数字校园应用系统，运行在一台4个CPU的Solaris 10操作系统上，中间件为GlassFish服务器。系统在做大并发压力测试的时候，发现请求响应时间比较慢，通过操作系统的mpstat工具发现CPU使用率很高，并且系统占用绝大多数的CPU资<br>
源的程序并不是应用系统本身。这是个不正常的现象，通常情况下用户应用的CPU占用率应该占主要地位，才能说明系统是正常工作的。</li>
<li>通过Solaris 10的Dtrace脚本可以查看当前情况下哪些系统调用花费了最多的CPU资源，Dtrace运行后发现最消耗CPU资源的竟然是“fork”系统调用。众所周知，“fork”系统调用是Linux用来产生新进程的，在Java虚拟机中，用户编写的Java代码最多只有线程的概念，不应当有进程的产生。</li>
<li>通过本系统的开发人员，最终找到了答案：每个用户请求的处理都需要执行一个外部shell脚本来获得系统的一些信息。执行这个shell脚本是通过Java的Runtime.getRuntime（）.exec（）方法来调用的。这种调用方式可以达到目的，但是它在Java虚拟机中是非常消耗资源的操作，即使外部命令本身能很快执行完毕，频繁调用时创建进程的开销也非常可观。Java虚拟机执行这个命令的过程是：首先克隆一个和当前虚拟机拥有一样环境变量的进程，再用这个新的进程去执行外部命令，最后再退出这个进程。如果频繁执行这个操作，系统的消耗会很大，不仅是CPU，内存负担也很重。</li>
<li>用户根据建议去掉这个Shell脚本执行的语句，改为使用Java的API去获取这些信息后，系统很快恢复了正常</li>
</ul>
<h2>11.5. 服务器JVM进程崩溃</h2>
<ul>
<li>一个基于B/S的MIS系统，硬件为两台2个CPU、8GB内存的HP系统，服务器是WebLogic 9.2（就是5.2.2节中的那套系统）。正常运行一段时间后，最近发现在运行期间频繁出现集群节点的虚拟机进程自动关闭的现象，留下了一个hs_err_pid###.log文件后，进程就消失了，两台物理机器里的每个节点都出现过进程崩溃的现象。从系统日志中可以看出，每个节点的虚拟机进程在崩溃前不久，都发生过大量相同的异常</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>java.net.SocketException：Connection reset
at java.net.SocketInputStream.read（SocketInputStream.java：168）
at java.io.BufferedInputStream.fill（BufferedInputStream.java：218）
at java.io.BufferedInputStream.read（BufferedInputStream.java：235）
at org.apache.axis.transport.http.HTTPSender.readHeadersFromSocket（HTTPSender.java：583）
at org.apache.axis.transport.http.HTTPSender.invoke（HTTPSender.java：143）……99 more
</code></pre></div><ul>
<li>这是一个远端断开连接的异常，通过系统管理员了解到系统最近与一个OA门户做了集成，在MIS系统工作流的待办事项变化时，要通过Web服务通知OA门户系统，把待办事项的变化同步到OA门户之中。通过SoapUI测试了一下同步待办事项的几个Web服务，发现调用后竟然需要长达3分钟才能返回，并且返回结果都是连接中断。</li>
<li>由于MIS系统的用户多，待办事项变化很快，为了不被OA系统速度拖累，使用了异步的方式调用Web服务，但由于两边服务速度的完全不对等，时间越长就累积了越多Web服务没有调用完成，导致在等待的线程和Socket连接越来越多，最终在超过虚拟机的承受能力后使得虚拟机进程崩溃。解决方法：通知OA门户方修复无法使用的集成接口，并将异步调用改为生产者/消费者模式的消息队列实现后，系统恢复正常。</li>
</ul>
<h2>11.6. 不恰当数据结构导致内存占用过大</h2>
<ul>
<li>有一个后台RPC服务器，使用64位虚拟机，内存配置为-Xms4g-Xmx8g-Xmn1g，使用ParNew+CMS的收集器组合。平时对外服务的Minor GC时间约在30毫秒以内，完全可以接受。但业务上需要每10分钟加载一个约80MB的数据文件到内存进行数据分析，这些数据会在内存中形成超过100万个HashMap＜Long,Long＞Entry，在这段时间里面Minor GC就会造成超过500毫秒的停顿，对于这个停顿时间就接受不了了，具体情况如下面GC日志所示。</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>{Heap before GC invocations=95（full 4）：
par new generation total 903168K,used 803142K[0x00002aaaae770000，0x00002aaaebb70000，0x00002aaaebb70000）
eden space 802816K，100%used[0x00002aaaae770000，0x00002aaadf770000，0x00002aaadf770000）
from space 100352K，0%used[0x00002aaae5970000，0x00002aaae59c1910，0x00002aaaebb70000）
to space 100352K，0%used[0x00002aaadf770000，0x00002aaadf770000，0x00002aaae5970000）
concurrent mark-sweep generation total 5845540K,used 3898978K[0x00002aaaebb70000，0x00002aac507f9000，0x00002aacae770000）
concurrent-mark-sweep perm gen total 65536K,used 40333K[0x00002aacae770000，0x00002aacb2770000，0x00002aacb2770000）
2 0 1 1-1 0-2 8 T 1 1：4 0：4 5.1 6 2+0 8 0 0：2 2 6.5 0 4：[G C 2 2 6.5 0 4：[P a r N e w：803142K-＞100352K（903168K），0.5995670 secs]4702120K-＞
4056332K（6748708K），0.5997560
secs][Times：user=1.46 sys=0.04，real=0.60 secs]
Heap after GC invocations=96（full 4）：
par new generation total 903168K,used 100352K[0x00002aaaae770000，0x00002aaaebb70000，0x00002aaaebb70000）
eden space 802816K，0%used[0x00002aaaae770000，0x00002aaaae770000，0x00002aaadf770000）
from space 100352K，100%used[0x00002aaadf770000，0x00002aaae5970000，
0x00002aaae5970000）
to space 100352K，0x00002aaaebb70000）0%used[0x00002aaae5970000，0x00002aaae5970000，
concurrent mark-sweep generation total 5845540K,used 3955980K[0x00002aaaebb70000，0x00002aac507f9000，0x00002aacae770000）
concurrent-mark-sweep perm gen total 65536K,used 40333K[0x00002aacae770000，0x00002aacb2770000，0x00002aacb2770000）
}
Total time for which application threads were stopped：0.6070570 seconds
</code></pre></div><ul>
<li>平时的Minor GC时间很短，原因是新生代的绝大部分对象都是可清除的，在Minor GC之后Eden和Survivor基本上处于完全空闲的状态。而在分析数据文件期间，800MB的Eden空间很快被填满从而引发GC，但Minor GC之后，新生代中绝大部分对象依然是存活的。ParNew收集器使用的是复制算法，这个算法的高效是建立在大部分对象都“朝生夕灭”的特性上的，如果存活对象过多，把这些对象复制到Survivor并维持这些对象引用的正确就成为一个沉重的负担，因此导致GC暂停时间明显变长。</li>
<li>如果不修改程序，仅从GC调优的角度去解决这个问题，可以考虑将Survivor空间去掉（加入参数-XX：SurvivorRatio=65536、-XX：MaxTenuringThreshold=0或者-XX：+AlwaysTenure），让新生代中存活的对象在第一次Minor GC后立即进入老年代，等到Major GC的时候再清理它们。这种措施可以治标，但也有很大副作用，治本的方案需要修改程序，因为这里的问题产生的根本原因是用HashMap＜Long,Long＞结构来存储数据文件空间效率太低。</li>
<li>具体分析一下空间效率。在HashMap＜Long,Long＞结构中，只有Key和Value所存放的两个长整型数据是有效数据，共16B（2×8B）。这两个长整型数据包装成java.lang.Long对象之后，就分别具有8B的MarkWord、8B的Klass指针，在加8B存储数据的long值。在这两个Long对象组成Map.Entry之后，又多了16B的对象头，然后一个8B的next字段和4B的int型的hash字段，为了对齐，还必须添加4B的空白填充，最后还有HashMap中对这个Entry的8B的引用，这样增加两个长整型数字，实际耗费的内存为（Long（24B）×2）+Entry（32B）+HashMap Ref（8B）=88B，空间效率为16B/88B=18%，实在太低了。</li>
</ul>
<h2>11.7. 由Windows虚拟内存导致的长时间停顿</h2>
<ul>
<li>有一个带心跳检测功能的GUI桌面程序，每15秒会发送一次心跳检测信号，如果对方30秒以内都没有信号返回，那就认为和对方程序的连接已经断开。程序上线后发现心跳检测有误报的概率，查询日志发现误报的原因是程序会偶尔出现间隔约一分钟左右的时间完全无日志输出，处于停顿状态。</li>
<li>因为是桌面程序，所需的内存并不大（-Xmx256m），所以开始并没有想到是GC导致的程序停顿，但是加入参数-XX：+PrintGCApplicationStoppedTime-XX：+PrintGCDateStampsXloggc：gclog.log后，从GC日志文件中确认了停顿确实是由GC导致的，大部分GC时间都控制在100毫秒以内，但偶尔就会出现一次接近1分钟的GC。</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>Total time for which application threads were stopped：0.0112389 seconds
Total time for which application threads were stopped：0.0001335 seconds
Total time for which application threads were stopped：0.0003246 seconds
Total time for which application threads were stopped：41.4731411 seconds
Total time for which application threads were stopped：0.0489481 seconds
Total time for which application threads were stopped：0.1110761 seconds
Total time for which application threads were stopped：0.0007286 seconds
Total time for which application threads were stopped：0.0001268 seconds
</code></pre></div><ul>
<li>从GC日志中找到长时间停顿的具体日志信息（添加了-XX：+PrintReferenceGC参数），找到的日志片段如下所示。从日志中可以看出，真正执行GC动作的时间不是很长，但从准备开始GC，到真正开始GC之间所消耗的时间却占了绝大部分。</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>2012-08-29T19：14：30.968+0800：10069.800：[GC10099.225：[SoftReference，0 refs，0.0000109 secs]10099.226：[WeakReference，4072 refs，0.0012099
secs]10099.227：[FinalReference，984 refs，1.5822450 secs]10100.809：[PhantomReference，251 refs，0.0001394 secs]10100.809：[JNI Weak Reference，0.0994015 secs]
[PSYoungGen：175672K-＞8528K（167360K）]251523K-＞100182K（353152K），31.1580402 secs][Times：user=0.61 sys=0.52，real=31.16 secs]
</code></pre></div><ul>
<li>除GC日志之外，还观察到这个GUI程序内存变化的一个特点，当它最小化的时候，资源管理中显示的占用内存大幅度减小，但是虚拟内存则没有变化，因此怀疑程序在最小化时它的工作内存被自动交换到磁盘的页面文件之中了，这样发生GC时就有可能因为恢复页面文件的操作而导致不正常的GC停顿。在Java的GUI程序中要避免这种现象，可以加入参数“-Dsun.awt.keepWorkingSetOnMinimize=true”来解决。这个参数在许多AWT的程序上都有应用，例如JDK自带的Visual VM，用于保证程序在恢复最小化时能够立即响应。在这个案例中加入该参数后，问题得到解决。</li>
</ul>
<h1>12. 虚拟机执行子系统</h1>
<h2>12.1. 类文件结构</h2>
<ul>
<li>代码编译的结果从本地机器码转变为字节码，实现语言，平台无关性的基础是虚拟机和字节码存储格式。Java虚拟机不和包括Java在内的任何语言绑定，它只与“Class文件”这种特定的二进制文件格式所关联，Class文件中包含了Java虚拟机指令集和符号表以及若干其他辅助信息。基于安全方面的考虑，Java虚拟机规范要求在Class文件中使用许多强制性的语法和结构化约束，但任一门功能性语言都可以表示为一个能被Java虚拟机所接受的有效的Class文件。作为一个通用的、机器无关的执行平台，任何其他语言的实现者都可以将Java虚拟机作为语言的产品交付媒介。虚拟机并不关心Class的来源是何种语言</li>
<li>Java语言中的各种变量、关键字和运算符号的语义最终都是由多条字节码命令组合而成的，因此字节码命令所能提供的语义描述能力肯定会比Java语言本身更加强大。因此，有一些Java语言本身无法有效支持的语言特性不代表字节码本身无法有效支持，这也为其他语言实现一些有别于Java的语言特性提供了基础。</li>
</ul>
<h2>12.2. Class类文件的结构</h2>
<ul>
<li>任何一个Class文件都对应着唯一一个类或接口的定义信息，但反过来说，类或接口并不一定都得定义在文件里（譬如类或接口也可以通过类加载器直接生成）。</li>
<li>Class文件是一组以8位字节为基础单位的二进制流，各个数据项目严格按照顺序紧凑地排列在Class文件之中，中间没有添加任何分隔符，这使得整个Class文件中存储的内容几乎全部是程序运行的必要数据，没有空隙存在。当遇到需要占用8位字节以上空间的数据项时，则会按照高位在前的方式分割成若干个8位字节进行存储。</li>
<li>根据Java虚拟机规范的规定，Class文件格式采用一种类似于C语言结构体的伪结构来存储数据，这种伪结构中只有两种数据类型：无符号数和表
<ul>
<li>无符号数属于基本的数据类型，以u1、u2、u4、u8来分别代表1个字节、2个字节、4个字节和8个字节的无符号数，无符号数可以用来描述数字、索引引用、数量值或者按照UTF-8编码构成字符串值。</li>
<li>表是由多个无符号数或者其他表作为数据项构成的复合数据类型，所有表都习惯性地以“_info”结尾。表用于描述有层次关系的复合结构的数据，整个Class文件本质上就是一张表，它由表所示的数据项构成</li>
</ul>
</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align:center">类型</th>
<th style="text-align:center">名称</th>
<th style="text-align:center">数量</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">u4</td>
<td style="text-align:center">magic</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">u2</td>
<td style="text-align:center">minor_version</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">u2</td>
<td style="text-align:center">major_version</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">u2</td>
<td style="text-align:center">constant_pool_count</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">cp_info</td>
<td style="text-align:center">constatnt_pool</td>
<td style="text-align:center">constant_pool_count-1</td>
</tr>
<tr>
<td style="text-align:center">u2</td>
<td style="text-align:center">access_flags</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">u2</td>
<td style="text-align:center">this_class</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">u2</td>
<td style="text-align:center">super_class</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">u2</td>
<td style="text-align:center">interfaces_count</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">u2</td>
<td style="text-align:center">interfaces</td>
<td style="text-align:center">interfaces_count</td>
</tr>
<tr>
<td style="text-align:center">u2</td>
<td style="text-align:center">fields_count</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">field_info</td>
<td style="text-align:center">fields</td>
<td style="text-align:center">fields_count</td>
</tr>
<tr>
<td style="text-align:center">u2</td>
<td style="text-align:center">method_count</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">methods_info</td>
<td style="text-align:center">methods</td>
<td style="text-align:center">methods_count</td>
</tr>
<tr>
<td style="text-align:center">u2</td>
<td style="text-align:center">attributes_count</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">attributes</td>
<td style="text-align:center">attributes</td>
<td style="text-align:center">attributes_count</td>
</tr>
</tbody>
</table>
<ul>
<li>
<p>无论是无符号数还是表，当需要描述同一类型但数量不定的多个数据时，经常会使用一个前置的容量计数器加若干个连续的数据项的形式，这时称这一系列连续的某一类型的数据为某一类型的集合</p>
</li>
<li>
<p>demo代码与使用WinHex打开class文件的结果</p>
</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>package org.fenixsoft.clazz；
  public class TestClass{
  private int m；
  public int inc（）{
  return m+1；
  }
}
</code></pre></div><p><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/4d17e9d2e21e9846c612c.png" alt=""><br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/955dbf691fa6ce075bdc5.png" alt="javapTestClass.png"></p>
<h3>12.2.1. magic，minor_version，major_version</h3>
<ul>
<li>每个Class文件的头4个字节称为魔数（Magic Number），它的唯一作用是确定这个文件是否为一个能被虚拟机接受的Class文件。使用魔数而不是扩展名来进行识别主要是基于安全方面的考虑，因为文件扩展名可以随意地改动。文件格式的制定者可以自由地选择魔数值，只要这个魔数值还没有被广泛采用过同时又不会引起混淆即可。Class文件的魔数值为：0xCAFEBABE（咖啡宝贝？）</li>
<li>紧接着魔数的4个字节存储的是Class文件的版本号：第5和第6个字节是次版本号（Minor Version），第7和第8个字节是主版本号（Major Version）。高版本的JDK能向下兼容以前版本的Class文件，但不能运行以后版本的Class文件，即使文件格式并未发生任何变化，虚拟机也必须拒绝执行超过其版本号的Class文件。</li>
</ul>
<h3>12.2.2. 常量池</h3>
<ul>
<li>紧接着主次版本号之后的是常量池入口，它是Class文件结构中与其他项目关联最多的数据类型，也是占用Class文件空间最大的数据项目之一，同时它还是在Class文件中第一个出现的表类型数据项目。由于常量池中常量的数量是不固定的，所以在常量池的入口需要放置一项u2类型的数据，代表常量池容量计数值（constant_pool_count）。这个容量计数是从1而不是0开始的，</li>
<li>在Class文件格式规范制定之时，设计者将第0项常量空出来是有特殊考虑的，这样做的目的在于满足后面某些指向常量池的索引值的数据在特定情况下需要表达“不引用任何一个常量池项目”的含义，这种情况就可以把索引值置为0来表示。Class文件结构中只有常量池的容量计数是从1开始，对于其他集合类型，包括接口索引集合、字段表集合、方法表集合等的容量计数都是从0开始的。</li>
<li>常量池中主要存放两大类常量：字面量（Literal）和符号引用（Symbolic References）。
<ul>
<li>字面量比较接近于Java语言层面的常量概念，如文本字符串、声明为final的常量值等。</li>
<li>符号引用则属于编译原理方面的概念，包括了下面三类常量：
<ul>
<li>类和接口的全限定名（Fully Qualified Name）</li>
<li>字段的名称和描述符（Descriptor）</li>
<li>方法的名称和描述符</li>
</ul>
</li>
</ul>
</li>
<li>Java代码在进行Javac编译的时候，在虚拟机加载Class文件的时候进行动态连接。也就是说，在Class文件中不会保存各个方法、字段的最终内存布局信息，因此这些字段、方法的符号引用不经过运行期转换的话无法得到真正的内存入口地址，也就无法直接被虚拟机使用。当虚拟机运行时，需要从常量池获得对应的符号引用，再在类创建时或运行时解析、翻译到具体的内存地址之中。</li>
<li>常量池中每一项常量都是一个表，共有14种表，这14种表都有一个共同的特点，就是表开始的第一位是一个u1类型的标志位（tag，取值见表6-3中标志列），代表当前这个常量属于哪种常量类型。</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align:center">类型</th>
<th style="text-align:center">标志</th>
<th style="text-align:center">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">CONSTANT_Utf8_info</td>
<td style="text-align:center">1</td>
<td style="text-align:center">UTF-8编码的字符串</td>
</tr>
<tr>
<td style="text-align:center">CONSTANT_Integer_info</td>
<td style="text-align:center">3</td>
<td style="text-align:center">整型字面量</td>
</tr>
<tr>
<td style="text-align:center">CONSTANT_Float_info</td>
<td style="text-align:center">4</td>
<td style="text-align:center">浮点型字面量</td>
</tr>
<tr>
<td style="text-align:center">CONSTANT_Long_info</td>
<td style="text-align:center">5</td>
<td style="text-align:center">长整型字面量</td>
</tr>
<tr>
<td style="text-align:center">CONSTANT_Double_info</td>
<td style="text-align:center">6</td>
<td style="text-align:center">双精度浮点型面量</td>
</tr>
<tr>
<td style="text-align:center">CONSTANT_Class_info</td>
<td style="text-align:center">7</td>
<td style="text-align:center">类或接口的符号引用</td>
</tr>
<tr>
<td style="text-align:center">CONSTANT_String_info</td>
<td style="text-align:center">8</td>
<td style="text-align:center">字符串类型字面量</td>
</tr>
<tr>
<td style="text-align:center">CONSTANT_Fieldref_info</td>
<td style="text-align:center">9</td>
<td style="text-align:center">字段的符号引用</td>
</tr>
<tr>
<td style="text-align:center">CONSTANT_Methodred_info</td>
<td style="text-align:center">10</td>
<td style="text-align:center">类中方法的符号引用</td>
</tr>
<tr>
<td style="text-align:center">CONSTANT_InterfaceMethodref_info</td>
<td style="text-align:center">11</td>
<td style="text-align:center">接口中方法符号引用</td>
</tr>
<tr>
<td style="text-align:center">CONSTANT_NameAndType_info</td>
<td style="text-align:center">12</td>
<td style="text-align:center">字段或方法的部分符号引用</td>
</tr>
<tr>
<td style="text-align:center">CONSTANT_MethodHandle_info</td>
<td style="text-align:center">15</td>
<td style="text-align:center">表示方法句柄</td>
</tr>
<tr>
<td style="text-align:center">CONSTANT_MethodType_info</td>
<td style="text-align:center">16</td>
<td style="text-align:center">表示方法类型</td>
</tr>
<tr>
<td style="text-align:center">CONSTANT_InvokeDynamic_info</td>
<td style="text-align:center">18</td>
<td style="text-align:center">表示一个动态方法调用点</td>
</tr>
</tbody>
</table>
<ul>
<li>
<p>14种常量类型各自均有自己的结构。<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/c478680fbe6480ddca3d4.png" alt="常量池.png"></p>
</li>
<li>
<p>tag是标志位，它用于区分常量类型；name_index是一个索引值，它指向常量池中一个CONSTANT_Utf8_info类型常量，此常量代表了这个类（或者接口）的全限定名</p>
</li>
<li>
<p>length值说明了这个UTF-8编码的字符串长度是多少字节，它后面紧跟着的长度为length字节的连续数据是一个使用UTF-8缩略编码表示的字符串。UTF-8缩略编码与普通UTF-8编码的区别是：从'\u0001'到'\u007f'之间的字符（相当于1～127的ASCII码）的缩略编码使用一个字节表示，从'\u0080'到'\u07ff'之间的所有字符的缩略编码用两个字节表示，从'\u0800'到'\uffff'之间的所有字符的缩略编码就按照普通UTF-8编码规则使用三个字节表示。</p>
</li>
<li>
<p>本例中这个字符串的length值（偏移地址：0x0000000E）为0x001D，也就是长29字节，<br>
往后29字节正好都在1～127的ASCII码范围以内</p>
</li>
<li>
<p>由于Class文件中方法、字段等都需要引用CONSTANT_Utf8_info型常量来描述名称，所以CONSTANT_Utf8_info型常量的最大长度也就是Java中方法、字段名的最大长度。而这里的最大长度就是length的最大值，既u2类型能表达的最大值65535。所以Java程序中如果定义了超过64KB英文字符的变量或方法名，将会无法编译。</p>
</li>
<li>
<p>在JDK的bin目录中，一个专门用于分析Class文件字节码的工具：javap，代码清单6-2中列出了使用javap工具的-verbose参数输出的TestClass.class文件字节码内容（此清单中省略了常量池以外的信息）.Class文件中还有很多数据项都要引用常量池中的常量</p>
</li>
</ul>
<h2>12.3. 访问标志（access_flags）</h2>
<ul>
<li>标志用于识别一些类或者接口层次的访问信息，包括：这个Class是类还是接口；是否定义为public类型；是否定义为abstract类型；如果是类的话，是否被声明为final等。access_flags中一共有16个标志位可以使用，当前只定义了其中8个，没有使用到的标志位要求一律为0。将匹配的标志位全部进行或操作，即可获得访问标志的值</li>
</ul>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/08eaede8df6a15e54b94d.png" alt="访问标志.png" tabindex="0"><figcaption>访问标志.png</figcaption></figure>
<h2>12.4. 类索引、父类索引与接口索引集合</h2>
<ul>
<li>类索引（this_class）和父类索引（super_class）都是一个u2类型的数据，而接口索引集合（interfaces）是一组u2类型的数据的集合，Class文件中由这三项数据来确定这个类的继承关系。</li>
<li>类索引用于确定这个类的全限定名</li>
<li>父类索引用于确定这个类的父类的全限定名。除了java.lang.Object之外，所有的Java类都有父类，因此除了java.lang.Object外，所有Java类的父类索引都不为0。</li>
<li>接口索引集合就用来描述这个类实现了哪些接口，这些被实现的接口将按implements语句（如果这个类本身是一个接口，则应当是extends语句）后的接口顺序从左到右排列在接口索引集合中。</li>
<li>类索引和父类索引用两个u2类型的索引值表示，它们各自指向一个类型为CONSTANT_Class_info的类描述符常量，通过CONSTANT_Class_info类型的常量中的索引值可以找到定义在CONSTANT_Utf8_info类型的常量中的全限定名字符串。</li>
<li>对于接口索引集合，第一项u2类型的数据为接口计数器（interfaces_count），表示索引表的容量。如果该类没有实现任何接口，则该计数器值为0，后面接口的索引表不再占用任何字节</li>
</ul>
<h2>12.5. 字段表集合</h2>
<ul>
<li>字段表（field_info）用于描述接口或者类中声明的变量。字段（field）包括类级变量以及实例级变量，但不包括在方法内部声明的局部变量。Java中描述一个字段可以包括的信息有：字段的作用域（public、private、protected修饰符）、是实例变量还是类变量（static修饰符）、可变性（final）、并发可见性（volatile修饰符，是否强制从主内存读写）、可否被序列化（transient修饰符）、字段数据类型（基本类型、对象、数组）、字段名称。上述这些信息中，各个修饰符都是布尔值，要么有某个修饰符，要么没有，很适合使用标志位来表示。而字段叫什么名字、字段被定义为什么数据类型，这些都是无法固定的，只能引用常量池中的常量来描述。字段表的最终格式。</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align:center">类型</th>
<th style="text-align:center">名称</th>
<th style="text-align:center">数量</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">u2</td>
<td style="text-align:center">access_flags</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">u2</td>
<td style="text-align:center">name_index</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">u2</td>
<td style="text-align:center">descriptor_index</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">u2</td>
<td style="text-align:center">attributes_count</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">attributes_info</td>
<td style="text-align:center">attributes</td>
<td style="text-align:center">attributes_count</td>
</tr>
</tbody>
</table>
<ul>
<li>字段修饰符放在access_flags项目中，其中可以设置的标志位和含义见表6-9。</li>
</ul>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/ec0f8f95bac2a15e549ca.png" alt="字段访问标志.png" tabindex="0"><figcaption>字段访问标志.png</figcaption></figure>
<ul>
<li>
<p>在实际情况中，ACC_PUBLIC、ACC_PRIVATE、ACC_PROTECTED三个标志最多只能选择其一，ACC_FINAL、ACC_VOLATILE不能同时选择。接口之中的字段必须有ACC_PUBLIC、ACC_STATIC、ACC_FINAL标志，这些都是由Java本身的语言规则所决定的。</p>
</li>
<li>
<p>跟随access_flags标志的是两项索引值：name_index和descriptor_index。它们都是对常量池的引用，分别代表着字段的简单名称以及字段和方法的描述符。</p>
</li>
<li>
<p>“org/fenixsoft/clazz/TestClass”是这个类的全限定名，仅仅是把类全名中的“.”替换成了“/”而已，为了使连续的多个全限定名之间不产生混淆，在使用时最后一般会加入一个“；”表示全限定名结束。简单名称是指没有类型和参数修饰的方法或者字段名称，这个类中的inc（）方法和m字段的简单名称分别是“inc”和“m”。</p>
</li>
<li>
<p>描述符的作用是用来描述字段的数据类型、方法的参数列表（包括数量、类型以及顺序）和返回值。根据描述符规则，基本数据类型（byte、char、double、float、int、long、short、boolean）以及代表无返回值的void类型都用一个大写字符来表示，而对象类型则用字符L加对象的全限定名来表示。</p>
</li>
</ul>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/f968abcf911a29d7d5459.png" alt="描述符标识字符含义.png" tabindex="0"><figcaption>描述符标识字符含义.png</figcaption></figure>
<ul>
<li>
<p>对于数组类型，每一维度将使用一个前置的“[”字符来描述，如一个定义为“java.lang.String[][]”类型的二维数组，将被记录为：“[[Ljava/lang/String；”，一个整型数组“int[]”将被记录为“[I”。</p>
</li>
<li>
<p>用描述符来描述方法时，按照先参数列表，后返回值的顺序描述，参数列表按照参数的严格顺序放在一组小括号“（）”之内。如方法void inc（）的描述符为“（）V”，方法java.lang.String toString（）的描述符为“（）Ljava/lang/String；”，方法int indexOf（char[]source,int sourceOffset,int sourceCount,char[]target,int targetOffset,int targetCount,int fromIndex）的描述符为“（[CII[CIII）I”。</p>
</li>
<li>
<p>字段表都包含的固定数据项目到descriptor_index为止就结束了，不过在descriptor_index之后跟随着一个属性表集合用于存储一些额外的信息，字段都可以在属性表中描述零至多项的额外信息。</p>
</li>
<li>
<p>字段表集合中不会列出从超类或者父接口中继承而来的字段，但有可能列出原本Java代码之中不存在的字段，譬如在内部类中为了保持对外部类的访问性，会自动添加指向外部类实例的字段。另外，在Java语言中字段是无法重载的，两个字段的数据类型、修饰符不管是否相同，都必须使用不一样的名称，但是对于字节码来讲，如果两个字段的描述符不一致，那字段重名就是合法的。</p>
</li>
</ul>
<h2>12.6. 方法表集合</h2>
<ul>
<li>Class文件存储格式中对方法的描述与对字段的描述几乎采用了完全一致的方式，方法表的结构如同字段表一样，依次包括了访问标志（access_flags）、名称索引（name_index）、描述符索引（descriptor_index）、属性表集合（attributes）几项，这些数据项目的含义也非常类似，仅在访问标志和属性表集合的可选项中有所区别。</li>
</ul>
<p><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/975a04fa962a595d6cb88.png" alt="方法表结构.png"><br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/1efeb44773efc042205b6.png" alt="方法访问标志.png"></p>
<ul>
<li>
<p>方法的定义可以通过访问标志、名称索引、描述符索引表达清楚，但方法里面的代码去哪里了？方法里的Java代码，经过编译器编译成字节码指令后，存放在方法属性表集合中一个名为“Code”的属性里面，属性表作为Class文件格式中最具扩展性的一种数据项目，将在6.3.7节中详细讲解。</p>
</li>
<li>
<p>与字段表集合相对应的，如果父类方法在子类中没有被重写（Override），方法表集合中就不会出现来自父类的方法信息。但同样的，有可能会出现由编译器自动添加的方法，最典型的便是类构造器“＜clinit＞”方法和实例构造器“＜init＞”[1]方法。在Java语言中，要重载（Overload）一个方法，除了要与原方法具有相同的简单名称之外，还要求必须拥有一个与原方法不同的特征签名[2]，特征签名就是一个方法中各个参数在常量池中的字段符号引用的集合，也就是因为返回值不会包含在特征签名中，因此Java语言里面是无法仅仅依靠返回值的不同来对一个已有方法进行重载的。但是在Class文件格式中，特征签名的范围更大一些，只要描述符不是完全一致的两个方法也可以共存。也就是说，如果两个方法有相同的名称和特征签名，但返回值不同，那么也是可以合法共存于同一个Class文件中的。</p>
</li>
</ul>
<h2>12.7. 属性表集合（attribute_info）</h2>
<ul>
<li>在Class文件、字段表、方法表都可以携带自己的属性表（attribute_info）集合，以用于描述某些场景专有的信息。不要求各个属性表具有严格顺序，并且只要不与已有属性名重复，任何人实现的编译器都可以向属性表中写入自己定义的属性信息，Java虚拟机运行时会忽略掉它不认识的属性。为了能正确解析Class文件。预定义属性具体内容见表6-13。</li>
</ul>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/c59b86bae6cf785d75b94.png" alt="虚拟机规范预定义的属性.png" tabindex="0"><figcaption>虚拟机规范预定义的属性.png</figcaption></figure>
<ul>
<li>对于每个属性，它的名称需要从常量池中引用一个CONSTANT_Utf8_info类型的常量来表示，而属性值的结构则是完全自定义的，只需要通过一个u4的长度属性去说明属性值所占用的位数即可。一个符合规则的属性表应该满足表6-14中所定义的结构。</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align:center">类型</th>
<th style="text-align:center">名称</th>
<th style="text-align:center">数量</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">u2</td>
<td style="text-align:center">attribute_name_index</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">u4</td>
<td style="text-align:center">attribute_length</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">u1</td>
<td style="text-align:center">info</td>
<td style="text-align:center">attribute_length</td>
</tr>
</tbody>
</table>
<h3>12.7.1. Code属性</h3>
<ul>
<li>Java程序方法体中的代码经过Javac编译器处理后，最终变为字节码指令存储在Code属性内。Code属性出现在方法表的属性集合之中，但并非所有的方法表都必须存在这个属性，譬如接口或者抽象类中的方法就不存在Code属性，如果方法表有Code属性存在，那么它的结构将如表6-15所示。</li>
</ul>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/2598b64531c9556e47c1a.png" alt="Code属性表的结构.png" tabindex="0"><figcaption>Code属性表的结构.png</figcaption></figure>
<ul>
<li>
<p>attribute_name_index是一项指向CONSTANT_Utf8_info型常量的索引，常量值固定为“Code”，它代表了该属性的属性名称，attribute_length指示了属性值的长度，由于属性名称索引与属性长度一共为6字节，所以属性值的长度固定为整个属性表长度减去6个字节。</p>
</li>
<li>
<p>max_stack代表了操作数栈（Operand Stacks）深度的最大值。在方法执行的任意时刻，操作数栈都不会超过这个深度。虚拟机运行的时候需要根据这个值来分配栈帧（Stack Frame）中的操作栈深度。</p>
</li>
<li>
<p>max_locals代表了局部变量表所需的存储空间。单位是Slot,Slot是虚拟机为局部变量分配内存所使用的最小单位。对于byte、char、float、int、short、boolean和returnAddress等长度不超过32位的数据类型，每个局部变量占用1个Slot，而double和long这两种64位的数据类型则需要两个Slot来存放。方法参数（包括实例方法中的隐藏参数“this”）、显式异常处理器的参数（Exception Handler Parameter，就是try-catch语句中catch块所定义的异常）、方法体中定义的局部变量都需要使用局部变量表来存放。另外，并不是在方法中用到了多少个局部变量，就把这些局部变量所占Slot之和作为max_locals的值，原因是局部变量表中的Slot可以重用，当代码执行超出一个局部变量的作用域时，这个局部变量所占的Slot可以被其他局部变量所使用，Javac编译器会根据变量的作用域来分配Slot给各个变量使用，然后计算出max_locals的大小。</p>
</li>
<li>
<p>code_length和code用来存储Java源程序编译后生成的字节码指令。code_length代表字节码长度，code是用于存储字节码指令的一系列字节流。既然叫字节码指令，那么每个指令就是一个u1类型的单字节，当虚拟机读取到code中的一个字节码时，就可以对应找出这个字节码代表的是什么指令，并且可以知道这条指令后面是否需要跟随参数，以及参数应当如何理解。一个u1数据类型的取值范围为0x00～0xFF，对应十进制的0～255，也就是一共可以表达256条指令，编码与指令之间的对应关系可查阅本书的附录B“虚拟机字节码指令表”。</p>
</li>
<li>
<p>code_length，虽然它是一个u4类型的长度值，理论上最大值可以达到2^32-1，但是虚拟机规范中明确限制了一个方法不允许超过65535条字节码指令，即它实际只使用了u2的长度，如果超过这个限制，Javac编译器也会拒绝编译，例如在编译一个很复杂的JSP文件时，某些JSP编译器会把JSP内容和页面输出的信息归并于一个方法之中，就可能因为方法生成字节码超长的原因而导致编译失败。</p>
</li>
<li>
<p>Code属性是Class文件中最重要的一个属性，如果把一个Java程序中的信息分为代码（Code，方法体里面的Java代码）和元数据（Metadata，包括类、字段、方法定义及其他信息）两部分，那么在整个Class文件中，Code属性用于描述代码，所有的其他数据项目都用于描述元数据。</p>
</li>
<li>
<p>在字节码指令之后的是这个方法的显式异常处理表（下文简称异常表）集合，异常表对于Code属性来说并不是必须存在的，如代码清单6-4中就没有异常表生成。异常表的格式如表6-16所示，它包含4个字段，这些字段的含义为：如果当字节码在第start_pc行[1]到第end_pc行之间（不含第end_pc行）出现了类型为catch_type或者其子类的异常（catch_type为指向一个CONSTANT_Class_info型常量的索引），则转到第handler_pc行继续处理。当catch_type的值为0时，代表任意异常情况都需要转向到handler_pc处进行处理。</p>
</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align:center">类型</th>
<th style="text-align:center">名称</th>
<th style="text-align:center">数量</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">u2</td>
<td style="text-align:center">start_pc</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">u2</td>
<td style="text-align:center">end_pc</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">u2</td>
<td style="text-align:center">handler_pc</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">u2</td>
<td style="text-align:center">catch_pc</td>
<td style="text-align:center">1</td>
</tr>
</tbody>
</table>
<ul>
<li>异常表实际上是Java代码的一部分，编译器使用异常表而不是简单的跳转命令来实现Java异常及finally处理机制[2]。<br>
代码清单6-5是一段演示异常表如何运作的例子，这段代码主要演示了在字节码层面中try-catch-finally是如何实现的。在阅读字节码之前，大家不妨先看看下面的Java源码，想一下这段代码的返回值在出现异常和不出现异常的情况下分别应该是多少？</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>//Java源码
public int inc（）{
int x；
try{
x=1；
return x；
}catch（Exception e）{
x=2；
return x；
}finally{
x=3；
}
}
//编译后的ByteCode字节码及异常表
public int inc（）；
Code：
Stack=1，Locals=5，Args_size=1
0：iconst_1//try块中的x=1
1：istore_1
2：iload_1//保存x到returnValue中，此时x=1
3：istore 4
5：iconst_3//finaly块中的x=3
6：istore_1
7：iload 4//将returnValue中的值放到栈顶，准备给ireturn返回
9：ireturn
10：astore_2//给catch中定义的Exception e赋值，存储在Slot 2中
11：iconst_2//catch块中的x=2
12：istore_1
13：iload_1//保存x到returnValue中，此时x=2
14：istore 4
16：iconst_3//finaly块中的x=3
17：istore_1
18：iload 4//将returnValue中的值放到栈顶，准备给ireturn返回
20：ireturn
21：astore_3//如果出现了不属于java.lang.Exception及其子类的异常才会走到这里
22：iconst_3//finaly块中的x=3
23：istore_1
24：aload_3//将异常放置到栈顶，并抛出
25：athrow
Exception table：
from to target type
0 5 10 Class java/lang/Exception
0 5 21 any
10 16 21 any

</code></pre></div><ul>
<li>编译器为这段Java源码生成了3条异常表记录，对应3条可能出现的代码执行路径。从Java代码的语义上讲，这3条执行路径分别为：如果try语句块中出现属于Exception或其子类的异常，则转到catch语句块处理。如果try语句块中出现不属于Exception或其子类的异常，则转到finally语句块处理。如果catch语句块中出现任何异常，则转到finally语句块处理。</li>
</ul>
<h3>12.7.2. Exceptions属性</h3>
<ul>
<li>Exceptions属性是在方法表中与Code属性平级的一项属性，Exceptions属性的作用是列举出方法中可能抛出的受查异常<br>
（Checked Excepitons），也就是方法描述时在throws关键字后面列举的异常。它的结构见表6-17。</li>
<li>Exceptions属性中的number_of_exceptions项表示方法可能抛出number_of_exceptions种受查异常，每一种受查异常使用一个exception_index_table项表示，exception_index_table是一个指向常量池中CONSTANT_Class_info型常量的索引，代表了该受查异常的类型</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align:center">类型</th>
<th style="text-align:center">名称</th>
<th style="text-align:center">数量</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">u2</td>
<td style="text-align:center">attribute_name_index</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">u4</td>
<td style="text-align:center">attribute_length</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">u2</td>
<td style="text-align:center">number_of_exceptions</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">u2</td>
<td style="text-align:center">exception_index_table</td>
<td style="text-align:center">number_of_exceptions</td>
</tr>
</tbody>
</table>
<h3>12.7.3. LineNumberTable属性</h3>
<ul>
<li>LineNumberTable属性用于描述Java源码行号与字节码行号（字节码的偏移量）之间的对应关系。它并不是运行时必需的属性，但默认会生成到Class文件之中，可以在Javac中分别使用-g：none或-g：lines选项来取消或要求生成这项信息。如果选择不生成LineNumberTable属性，对程序运行产生的最主要的影响就是当抛出异常时，堆栈中将不会显示出错的行号，并且在调试程序的时候，也无法按照源码行来设置断点。LineNumberTable属性的结构见表6-18。</li>
<li>line_number_table是一个数量为line_number_table_length、类型为line_number_info的集合，line_number_info表包括了start_pc和line_number两个u2类型的数据项，前者是字节码行号，后者是Java源码行号。</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align:center">类型</th>
<th style="text-align:center">名称</th>
<th style="text-align:center">数量</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">u2</td>
<td style="text-align:center">attribute_name_index</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">u4</td>
<td style="text-align:center">attribute_length</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">u2</td>
<td style="text-align:center">line_number_table_length</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">line_number_info</td>
<td style="text-align:center">line_number_table</td>
<td style="text-align:center">line_number_table_length</td>
</tr>
</tbody>
</table>
<h2>12.8. 代码重排序</h2>
<ul>
<li>在执行程序时，为了提供性能，处理器和编译器常常会对指令进行重排序，重排序不会影响单线程环境的执行结果，但是会破坏多线程的执行语义，需满足以下两个条件
<ul>
<li>在单线程环境下不能改变程序运行的结果；</li>
<li>存在数据依赖关系的不允许重排序</li>
</ul>
</li>
<li>uniqueInstance = new Singleton(); 这段代码其实是分为三步执行：
<ul>
<li>uniqueInstance 分配内存空间</li>
<li>初始化 uniqueInstance</li>
<li>将 uniqueInstance 指向分配的内存地址</li>
<li>由于 JVM 具有指令重排的特性，执行顺序有可能变成 1-&gt;3-&gt;2。指令重排在单线程环境下不会出现问题，但是在多线程环境下会导致一个线程获得还没有初始化的实例。例如，线程 T1 执行了 1 和 3，此时 T2 调用 getUniqueInstance() 后发现 uniqueInstance 不为空，因此返回 uniqueInstance，但此时 uniqueInstance 还未被初始化。</li>
<li>使用 volatile 关键字修饰可以防止指令重排</li>
<li>volatile 提供多线程共享变量可见性和禁止指令重排序优化</li>
</ul>
</li>
</ul>
<h2>12.9. as-if-serial规则和happens-before规则</h2>
<ul>
<li>as-if-serial语义保证单线程内程序的执行结果不被改变，单线程程序是按程序的顺序来执行的。</li>
<li>happens-before关系保证正确同步的多线程程序的执行结果不被改变。正确同步的多线程程序是按happens-before指定的顺序来执行的</li>
<li>两者都是为了在不改变程序执行结果的前提下，尽可能地提高程序执行的并行度。</li>
</ul>
<h1>13. GC垃圾回收机制</h1>
<ul>
<li>
<p>垃圾回收是在内存中存在没有引用的对象或超过作用域的对象时进行的。</p>
</li>
<li>
<p>垃圾回收的目的是识别并且丢弃应用不再使用的对象来释放和重用资源。</p>
</li>
<li>
<p>如果对象的引用被置为null，在下一次垃圾回收时才会释放其占用的内存。</p>
</li>
<li>
<p>垃圾回收器（garbage colector）决定回收某对象时，就会运行该对象的finalize()方法；可以覆盖此方法来实现对其资源的回收。一旦垃圾回收器准备释放对象占用的内存，将首先调用该对象的finalize()方法，并且下一次垃圾回收动作发生时，才真正回收对象占用的内存空间</p>
</li>
<li>
<p>finalization构析函数在大部分时候，什么都不用做(也就是不需要重载)。只有在某些很特殊的情况下，比如调用了一些native的方法(一般是C写的)，可以要在finaliztion里去调用C的释放函数。</p>
</li>
<li>
<p>monitorGC</p>
<ul>
<li>由于现在收集器都是采用分代收集算法，堆被划分为新生代和老年代。新生代主要存储新创建的对象和尚未进入老年代的对象。老年代存储经过多次新生代GC(Minor GC)任然存活的对象。
<ul>
<li>新生代：程序新创建的对象都是从新生代分配内存，新生代由Eden Space和两块相同大小的Survivor Space(通常又称S0和S1或From和To)构成，
<ul>
<li>可通过-Xmn参数来指定新生代的大小，也可以通过-XX:SurvivorRation来调整Eden Space及Survivor Space的大小。</li>
</ul>
</li>
<li>老年代：用于存放经过多次新生代GC任然存活的对象，例如缓存对象，新建的对象也有可能直接进入老年代，
<ul>
<li>①.大对象，可通过启动参数设置-XX:PretenureSizeThreshold=1024(单位为字节，默认为0)来代表超过多大时就不在新生代分配，而是直接在老年代分配。</li>
<li>②.大的数组对象，切数组中无引用外部对象。 老年代所占的内存大小为-Xmx对应的值减去-Xmn对应的值</li>
</ul>
</li>
<li>在新生代中，超过Survivor Space的区域60%的对象会被直接放入到老生代中，特别注意</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Full GC</p>
<ul>
<li>全部GC：jvm调优就是减少jvm的full GC ，因为fullGC会导致CPU停止运作，此时用户觉得无响应，直到处理FUll GC处理完</li>
</ul>
</li>
</ul>
<p>jdk8的openjdk的源码包/openjdk/hotspot/src/share/vm/oops，Mark Word对应markOop.hpp</p>
<ul>
<li>openjdk工具包org.openjdk.jol.jol-core-0.8.jar可以用来获取对象的信息和虚拟机的信息,jol-core 常用的三个方法
<ul>
<li>ClassLayout.parseInstance(object).toPrintable()：查看对象内部信息.</li>
<li>GraphLayout.parseInstance(object).toPrintable()：查看对象外部信息，包括引用的对象.</li>
<li>GraphLayout.parseInstance(object).totalSize()：查看对象总大小.</li>
<li>结果
<ul>
<li>OFFSET：偏移地址，单位字节；</li>
<li>SIZE：占用的内存大小，单位为字节；</li>
<li>TYPE DESCRIPTION：类型描述，其中object header为对象头；</li>
<li>VALUE：对应内存中当前存储的值，二进制32位；</li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class D {
  public static void main(String[] args) {
      //普通对象
      D d = new D();
      System.out.println(ClassLayout.parseInstance(d).toPrintable());
  }
}

jdk8由于默认开启了指针压缩，d对象实例共占据16byte，对象头（object header）占据12byte（96bit），其中 mark word占8byte（64bit），klass pointe 占4byte，另外剩余4byte是填充对齐的。
如果关闭指针压缩-XX:-UseCompressedOops,对象头所占用的内存大小变为16byte（128bit），其中mark word占8byte，klass pointe 占8byte，无对齐填充。开启指针压缩可以减少对象的内存使用。从两次打印的D对象布局信息来看，关闭指针压缩时，对象头的SIZE增加了4byte，这里由于D对象是无属性的，读者可以试试增加几个属性字段来看下，这样会明显的发现SIZE增长。因此开启指针压缩，理论上来讲，大约能节省百分之五十的内存。
</code></pre></div><p><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/042e522f1cccbc2521f93.png" alt="普通对象内存布局.png"><br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/449c32a362dfab7763f0c.png" alt="无指针压缩的对象内存布局.png"></p>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public static void main(String[] args) {
    int[] a = {1};//数组对象
    System.out.println(ClassLayout.parseInstance(a).toPrintable());
}
总SIZE为共24byte，对象头占16byte，其中Mark Work占8byte，Klass Point 占4byte，array length 占4byte，因为里面只有一个int 类型的1，所以数组对象的实例数据占据4byte，剩余对齐填充占据4byte。
</code></pre></div><figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/762320af20cac0d89facc.png" alt="数组对象内存布局.png" tabindex="0"><figcaption>数组对象内存布局.png</figcaption></figure>
<h1>24. 对象是如何定位访问的？</h1>
<ul>
<li>
<p>java程序需要通过栈上的reference类型数据来访问堆上的具体对象。但具体访问方式由虚拟机而定的。主流的访问方式有使用句柄和直接指针两种。</p>
</li>
<li>
<p>句柄访问方式</p>
<ul>
<li>在java堆中将会划分出一块内存作为句柄池，reference中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与类型数据各自的具体地址信息。</li>
<li>好处：refercence中存储的是稳定的句柄地址，在对象被移动（垃圾收集时移动对象）时只会改变句柄中的实例数据指针，而reference本身不用修改<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/adfba4af312ef43d8a748.png" alt="通过句柄访问对象.png"></li>
</ul>
</li>
<li>
<p>直接指针访问方式(HotSpot)</p>
<ul>
<li>在reference中存储的直接就是对象地址。</li>
<li>好处：速度更快，节省了一次指针定位的时间开销，由于对象的访问在java中非常频繁，因此这类开销积少成多后也是一项非常可观的执行成本。<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/c55db80c102b0c360d692.png" alt="通过直接指针访问对象.png"></li>
</ul>
</li>
</ul>
<h1>25. Monitor</h1>
<ul>
<li>一个同步工具/机制，它通常被描述为一个对象。
<ul>
<li>互斥：一个Monitor在同一时刻只能被一个线程占用</li>
<li>信号机制(signal)：占用Monitor锁失败的线程会暂时放弃竞争并等待释放锁通知，而占用Monitor锁的线程执行完成后会通知正在等待这个条件变量的其他线程，让其可以重新竞争锁。所有对象都可成为Monitor</li>
</ul>
</li>
<li>每一个线程都有私有可用Monitor Record列表，同时还有一个全局的可用列表。 每一个被锁住的对象都会和一个Monitor Record关联（对象头的 MarkWord中的LockWord指向Monitor起始地址），Monitor Record中有一个Owner字段，存放拥有该锁的线程的唯一标识，表示该锁被这个线程占用。包含
<ul>
<li>Owner：1）初始时为 NULL 表示当前没有任何线程拥有该 Monitor Record；2）当线程成功拥有该锁后保存线程唯一标识；3）当锁被释放时又设置为 NULL 。</li>
<li>EntryQ：关联一个系统互斥锁（ semaphore ），阻塞所有试图锁住 Monitor Record失败的线程 。</li>
<li>RcThis：表示 blocked 或 waiting 在该 Monitor Record 上的所有线程的个数。</li>
<li>Nest：用来实现重入锁的计数。</li>
<li>HashCode：保存从对象头拷贝过来的 HashCode 值（可能还包含 GC age ）。</li>
<li>Candidate：用来避免不必要的阻塞或等待线程唤醒。因为每一次只有一个线程能够成功拥有锁，如果每次前一个释放锁的线程唤醒所有正在阻塞或等待的线程，会引起不必要的上下文切换（从阻塞到就绪然后因为竞争锁失败又被阻塞）从而导致性能严重下降。Candidate 只有两种可能的值 ：1）0 表示没有需要唤醒的线程；2）1 表示要唤醒一个继任线程来竞争锁。</li>
</ul>
</li>
</ul>
<h2>代码优化</h2>
<ul>
<li>尽可能使用局部变量</li>
<li>尽量减少对变量的重复计算 如遍历时i小于list.size()可以改为i小于length</li>
<li>异常不应该用来控制程序流程.异常对性能不利。抛出异常首先要创建一个新的对象，Throwable接口的构造函数调用名为fillInStackTrace()的本地同步方法，fillInStackTrace()方法检查堆栈，收集调用跟踪信息。只要有异常被抛出，Java虚拟机就必须调整调用堆栈，因为在处理过程中创建一个新的对象。异常只能用于错误处理，不应该用来控制程序流程。</li>
<li>尽量采用懒加载的策略，即在需要的时候才创建</li>
<li>不要将数组声明为public static final 因为这毫无意义，数组的内容还是可以随意改变的，</li>
<li>不要创建一些不使用的对象，不要导入一些不使用的类</li>
<li>程序运行过程中避免使用反射</li>
<li>使用数据库连接池和线程池.重用对象，前者可以避免频繁地打开和关闭连接，后者可以避免频繁地创建和销毁线程。</li>
<li>容器初始化时尽可能指定长度。避免容器长度不足时，扩容带来的性能损耗。</li>
<li>ArrayList随机遍历快，LinkedList添加删除快</li>
<li>使用Entry遍历Map</li>
<li>不要手动调用System.gc();</li>
<li>String尽量少用正则表达式。其效率较低，replace() 不支持正则。replaceAll() 支持正则。如果仅仅是字符的替换建议使用replace()。</li>
<li>日志的输出要注意级别</li>
<li>对资源的close()建议分开操作</li>
</ul>
]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/b4dfad59e848dff058479.png" type="image/png"/>
    </item>
    <item>
      <title>ReentrantLock</title>
      <link>https://javaguide.cn/backend/java/reentrantLock.html</link>
      <guid>https://javaguide.cn/backend/java/reentrantLock.html</guid>
      <source url="https://javaguide.cn/rss.xml">ReentrantLock</source>
      <description>ReentrantLock ReentrantLock 特点：公平、非公平、可重入、互斥锁、需手动开启和释放锁,异常不自动释放锁，要在finally里面声明。底层使用Unsafe的park方法加锁， 所有方法实现实际上都是调用了其静态内存类Sync中的方法，而Sync类继承了同步器AbstractQueuedSynchronizer（AQS）是关键 !...</description>
      <category>源码</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>ReentrantLock</p>
<!--more-->
<!-- TOC -->
<!-- /TOC -->
<h1>ReentrantLock</h1>
<ul>
<li>特点：公平、非公平、可重入、互斥锁、需手动开启和释放锁,异常不自动释放锁，要在finally里面声明。底层使用Unsafe的park方法加锁，</li>
<li>所有方法实现实际上都是调用了其静态内存类Sync中的方法，而Sync类继承了同步器AbstractQueuedSynchronizer（AQS）是关键<br>
<code>![](源码-AbstractQueuedSynchronizer.md)</code></li>
<li>volatile保证有序和可见性，cas保证原子性，保证线程同步</li>
</ul>
<h2>1. 构造函数</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class ReentrantLock implements Lock, java.io.Serializable {
    private final Sync sync;
    public ReentrantLock() {
        sync = new NonfairSync();
    }
    public ReentrantLock(boolean fair) {
        sync = fair ? new FairSync() : new NonfairSync();
    }
    public void lock() {
        sync.lock();
    }
    public void lockInterruptibly() throws InterruptedException {
        sync.acquireInterruptibly(1);
    }
    public boolean tryLock() {
        return sync.nonfairTryAcquire(1);
    }
    public boolean tryLock(long timeout, TimeUnit unit)
            throws InterruptedException {
        return sync.tryAcquireNanos(1, unit.toNanos(timeout));
    }
    public void unlock() {
        sync.release(1);
    }
}
</code></pre></div><h2>2. 非公平锁的获取nonfairTryAcquire(int acquires)与释放tryRelease(int releases)</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>abstract static class Sync extends AbstractQueuedSynchronizer {
    abstract void lock();
    /*
    * 非公平锁获取锁-同步状态volatile变量state表示锁被一个线程重复获取的次数
    * 1 如果state为0，表明该锁未被任何线程占有，通过CAS操作将state改为1并设置独占锁线程为当前线程
    * 2 如果独占锁线程为当前线程，将state设置为state+1 重入锁原理
    * 非公平性锁可能使线程“饥饿”，为什么它又被设定成默认的实现呢？因为非公平性锁的开销更小。公平性锁
    * 保证了锁的获取按照FIFO原则，而代价是进行大量的线程切换。非公平性锁虽然可能造成线程“饥饿”，但极
    * 少的线程切换，保证了其更大的吞吐量。
    */
    final boolean nonfairTryAcquire(int acquires) {
        final Thread current = Thread.currentThread();
        int c = getState();
        if (c == 0) {
            if (compareAndSetState(0, acquires)) {
                setExclusiveOwnerThread(current);
                return true;
            }
        }
        else if (current == getExclusiveOwnerThread()) {
            int nextc = c + acquires;
            if (nextc &lt; 0) // overflow
                throw new Error("Maximum lock count exceeded");
            setState(nextc);
            return true;
        }
        return false;
    }
    /*
    * 释放锁
    * 1 state-1后判断是否为0，如果是设置当前独占锁线程为null
    * 2 设置state为state状态-1
    */
    protected final boolean tryRelease(int releases) {
        int c = getState() - releases;
        if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException();
        boolean free = false;
        if (c == 0) {//将同步状态是否为0作为最终释放的条件
            free = true;
            setExclusiveOwnerThread(null);
        }
        setState(c);
        return free;
    }

    final ConditionObject newCondition() {
        return new ConditionObject();
    }

}

static final class NonfairSync extends Sync {
            
    final void lock() {
        if (compareAndSetState(0, 1))
            setExclusiveOwnerThread(Thread.currentThread());
        else
            acquire(1);
    }

    protected final boolean tryAcquire(int acquires) {
        return nonfairTryAcquire(acquires);
    }
}
</code></pre></div><h2>3. 公平锁的获取tryAcquire(int acquires)与释放tryRelease(int releases)</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>static final class FairSync extends Sync {
    final void lock() {
        acquire(1);
    }
    /*
    * 公平锁每次都是从同步队列中的第一个节点获取到锁，而非公平性锁则不一定，有可能刚释放锁的线程能再次获取到锁.锁的获取顺序就应该符合请求的绝对时间顺序FIFO。
    * 比非公平锁的获取多hasQueuedPredecessors()
    */
    protected final boolean tryAcquire(int acquires) {
        final Thread current = Thread.currentThread();
        int c = getState();
        if (c == 0) {
            if (!hasQueuedPredecessors() &amp;&amp;
                compareAndSetState(0, acquires)) {
                setExclusiveOwnerThread(current);
                return true;
            }
        }
        else if (current == getExclusiveOwnerThread()) {
            int nextc = c + acquires;
            if (nextc &lt; 0)
                throw new Error("Maximum lock count exceeded");
            setState(nextc);
            return true;
        }
        return false;
    }
}
    
public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer{
    /*
    * 判断同步队列中当前节点是否有前驱节点，如果有则需要等待前驱节点释放锁才能继续获取锁
    * 返回true条件:且不止有一个结点，头结点的后继节点不是当前节点时
    *   1 h != t返回true表示队列中至少有两个不同节点存在
    *   2 (s = h.next) == null返回true，说明头节点之后是没有后继节点的
    *        有另一个线程已经执行到初始化队列的操作了，介于compareAndSetHead(new Node())与tail = head之间
    *   3 s.thread != Thread.currentThread()返回true 表示后继节点的相关线程不是当前线程
    *
    */
    public final boolean hasQueuedPredecessors() {
        Node t = tail; 
        Node h = head;
        Node s;
        return h != t &amp;&amp;
            ((s = h.next) == null || s.thread != Thread.currentThread());
    }
}
</code></pre></div><h1>4. Condition类的await()</h1>
<ul>
<li>1.等待队列：FIFO的队列，在队列中的每个节点都包含了一个在Condition对象上等待线程的引用，同步队列和等待队列中节点类型都是同步器的静态内部类AbstractQueuedSynchronizer.Node。<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/5c6c3548b7452d9f5df2c.jpg" alt="等待队列的基本结构.png">
<ul>
<li>Condition拥有首尾节点的引用，而新增节点只需要将原有的尾节点nextWaiter指向它，并且更新尾节点即可。节点引用更新的过程并没有使用CAS保证，原因在于调用await()方法的线程必定是获取了锁的线程，由锁来保证线程安全的。</li>
<li>在Object的监视器模型上，一个对象拥有一个同步队列和等待队列，而并发包中的Lock（同步器）拥有一个同步队列和多个等待队列</li>
</ul>
</li>
<li>2.等待
<ul>
<li>调用Condition的await()方法，会使当前线程变为等待状态构造成节点从尾部加入等待队列并释放锁.当从await()方法返回时，当前线程一定获取了Condition相关联的锁。</li>
<li>如果从队列（同步队列和等待队列）的角度看await()方法，当调用await()方法时，相当于同步队列的首节点（获取了锁的节点）移动到Condition的等待队列中。</li>
</ul>
</li>
<li>如果从队列的角度去看，当前线程加入Condition的等待队列，同步队列的首节点并不会直接加入等待队列，而是通过addConditionWaiter()方法把当前线程构造成一个新的节点并将其加入等待队列中。</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>    private transient Node firstWaiter;
    private transient Node lastWaiter;
    Node nextWaiter
    /*
    * 调用该方法的线程成功获取了锁的线程，也就是同步队列中的首节点
    * 1 调用addConditionWaiter()将当前线程包装成Node，尾插入到等待队列中
    * 2 调用fullyRelease(node)释放当前线程所占用的lock，在释放的过程中会唤醒同步队列中的下一个节点
    * 3 while循环，退出条件如下
    *   调用checkInterruptWhileWaiting()通过Thread.interrupted()判断当前线程被中断，如果被中断了，
    *       则通过CAS操作判断是否已经被修改为Cancel。如果是则表明中断类型是THROW_IE(signal之前)，否则REINTERRUPT(没有中断过)
    *   调用isOnSyncQueue(node)判断当前节点在同步队列中(condition.signal/condition.signalAll方法当前节点移动到了同步队列)
    * 4 在同步队列中尝试获取锁。唤醒同步队列中的后继节点 当等待队列中的节点被唤醒，则唤醒节点的线程开始尝试获取同步状态。如果不是通过其他线程调用Condition.signal()方法唤醒，而是对等待线程进行中断，则会抛出InterruptedException。
    * 5 获取锁成功后如果有后继节点则调用unlinkCancelledWaiters()清除Condition队列中状态不是Node.CONDITION的节点
    * 6 如果中断了则调用reportInterruptAfterWait()响应中断，THROW_IE抛出异常，REINTERRUPT中断当前线程
    */
    public final void await() throws InterruptedException {
        if (Thread.interrupted()) throw new InterruptedException();
        Node node = addConditionWaiter();//1
        int savedState = fullyRelease(node);//2
        int interruptMode = 0;
        while (!isOnSyncQueue(node)) { //3
            LockSupport.park(this);
            if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)
                break;
        }
        if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE)//4
            interruptMode = REINTERRUPT;
        if (node.nextWaiter != null) //5
            unlinkCancelledWaiters();
        if (interruptMode != 0) //6
            reportInterruptAfterWait(interruptMode);
    }
    /*
    * 将当前线程包装成Node，尾插入到等待队列中
    *   1 如果尾结点被取消了则调用unlinkCancelledWaiters()清除Condition队列中状态不是Node.CONDITION的节点
    *   2 将当前线程和Condition等待状态包装成Node放入Condition队列的尾节点中
    */
    private Node addConditionWaiter() {
        Node t = lastWaiter;
        if (t != null &amp;&amp; t.waitStatus != Node.CONDITION) {//1
            unlinkCancelledWaiters();
            t = lastWaiter;
        }
        Node node = new Node(Thread.currentThread(), Node.CONDITION);//2
        if (t == null)
            firstWaiter = node;
        else
            t.nextWaiter = node;
        lastWaiter = node;
        return node;
    }
    
    private void unlinkCancelledWaiters() {
        Node t = firstWaiter;
        Node trail = null;//记录从头结点到尾结点的最后一个有效结点
        while (t != null) {
            Node next = t.nextWaiter;
            if (t.waitStatus != Node.CONDITION) {
                t.nextWaiter = null;
                if (trail == null)// 如果trail为null，表示原先的condition队列头节点实效，需要设置新的condition队列头
                    firstWaiter = next;
                else
                    trail.nextWaiter = next;// 如果next为null，表示原先的condition队列尾节点也实效，重新设置队列尾节点
                if (next == null)
                    lastWaiter = trail;
            }
            else
                trail = t;
            t = next;
        }
    }
    
    final int fullyRelease(Node node) {
        boolean failed = true;
        try {
            int savedState = getState();
            if (release(savedState)) {
                //成功释放同步状态
                failed = false;
                return savedState;
            } else {
                //不成功释放同步状态抛出异常
                throw new IllegalMonitorStateException();
            }
        } finally {
            if (failed)
                node.waitStatus = Node.CANCELLED;
        }
    }

    public final boolean release(int arg) {
        if (tryRelease(arg)) {
            Node h = head;
            if (h != null &amp;&amp; h.waitStatus != 0)
                unparkSuccessor(h);
            return true;
        }
        return false;
    }

    final boolean isOnSyncQueue(Node node) {
        if (node.waitStatus == Node.CONDITION || node.prev == null)
            return false;
        if (node.next != null) // If has successor, it must be on queue
            return true;
        return findNodeFromTail(node);
    }
    
    private boolean findNodeFromTail(Node node) {
        Node t = tail;
        for (;;) {
            if (t == node)
                return true;
            if (t == null)
                return false;
            t = t.prev;
        }
    }
    
    private static final int REINTERRUPT =  1;//表示在线程中断发生时还没有调用过signal方法
    private static final int THROW_IE    = -1;//表示在线程中断发生时已经调用过signal方法了
    private int checkInterruptWhileWaiting(Node node) {
        return Thread.interrupted() ?
            (transferAfterCancelledWait(node) ? THROW_IE : REINTERRUPT) :
            0;
    }
    
    final boolean transferAfterCancelledWait(Node node) {
        //如果这步CAS操作成功的话就表明CONDITION被修改成Cancel了，中断发生在signal方法之前
        if (compareAndSetWaitStatus(node, Node.CONDITION, 0)) {
            enq(node);
            return true;
        }
        //说明中断发生在signal方法之后 如果sinal方法还没有将结点转移到同步队列, 就通过自旋等待一下
        while (!isOnSyncQueue(node))
            Thread.yield();
        return false;
    }
    
    private void reportInterruptAfterWait(int interruptMode) throws InterruptedException {
        if (interruptMode == THROW_IE) throw new InterruptedException();
        else if (interruptMode == REINTERRUPT) selfInterrupt();
    }
</code></pre></div><h1>5. Condition类的不响应中断awaitUninterruptibly()</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>    //reportInterruptAfterWait
    public final void awaitUninterruptibly() {
        Node node = addConditionWaiter();
        int savedState = fullyRelease(node);
        boolean interrupted = false;
        while (!isOnSyncQueue(node)) {
            LockSupport.park(this);
            if (Thread.interrupted())
                interrupted = true;
        }
        if (acquireQueued(node, savedState) || interrupted)
            selfInterrupt();
    }
</code></pre></div><h1>6. Condition类的将等待时间最长的线程放入同步队列signal()</h1>
<ul>
<li>通过调用同步器的enq(Node node)方法，等待队列中的头节点线程安全地移动到同步队列。当节点移动到同步队列后，当前线程再使用LockSupport唤醒该节点的线程。</li>
<li>被唤醒后的线程，将从await()方法中的while循环中退出（isOnSyncQueue(Node node)方法返回true，节点已经在同步队列中），进而调用同步器的acquireQueued()方法加入到获取同步状态的竞争中。</li>
<li>成功获取同步状态（或者说锁）之后，被唤醒的线程将从先前调用的await()方法返回，此时该线程已经成功地获取了锁。</li>
<li>Condition的signalAll()方法，相当于对等待队列中的每个节点均执行一次signal()方法，效果就是将等待队列中所有节点全部移动到同步队列中，并唤醒每个节点的线程。</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>    /*
    * 将节点移到同步队列中。然后唤醒在等待队列中等待时间最长的节点（首节点）
    * 将等待队列的头结点
    * 1 调用isHeldExclusively()检测当前线程是否已经获取lock，没有则抛出异常（保证当前线程必须获取了锁）
    * 2 获取等待队列中第一个节点，将其移动到同步队列并使用LockSupport唤醒节点中的线程。之后的操作都是针对这个节点
    * 3 调用transferForSignal(node)配合循环将当前节点设置为0并加入同步队列，入队成功后尝试设置为SIGNAL，若失败则唤醒线程
    */
    public final void signal() {
        if (!isHeldExclusively()) throw new IllegalMonitorStateException();//1
        Node first = firstWaiter;//2
        if (first != null)
            doSignal(first);
    }
    protected final boolean isHeldExclusively() {
        return getExclusiveOwnerThread() == Thread.currentThread();
    }
    private void doSignal(Node first) {
        do {
            if ( (firstWaiter = first.nextWaiter) == null)
                lastWaiter = null;
            first.nextWaiter = null;
        } while (!transferForSignal(first) &amp;&amp;
                (first = firstWaiter) != null);
    }

    final boolean transferForSignal(Node node) {
        if (!compareAndSetWaitStatus(node, Node.CONDITION, 0))
            return false;
        Node p = enq(node);
        int ws = p.waitStatus;
        if (ws &gt; 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL))
            LockSupport.unpark(node.thread);
        return true;
    }

</code></pre></div><h1>7. Condition类的唤醒所有等待线程signalAll()</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>    //从头到尾轮询节点唤醒，并释放所有节点的资源
    private void doSignalAll(Node first) {
        lastWaiter = firstWaiter = null;
        do {
            Node next = first.nextWaiter;
            first.nextWaiter = null;
            transferForSignal(first);
            first = next;
        } while (first != null);
    }
</code></pre></div><h1>14. ReentrantLock</h1>
<ul>
<li>API
<ul>
<li>void lock(); //获取锁</li>
<li>void lockInterruptibly() throws InterruptedException；//获取锁的过程能够响应中断</li>
<li>boolean tryLock();//非阻塞式响应中断能立即返回，获取锁放回true反之返回fasle</li>
<li>boolean tryLock(long time, TimeUnit unit) throws InterruptedException;//超时获取锁，在超时内或者未中断的情况下能够获取锁</li>
<li>Condition newCondition();//获取与lock绑定的等待通知组件，当前线程必须获得了锁才能进行等待，进行等待时会先释放锁，当再次获取锁时才能从等待中返回</li>
<li>void unlock();//释放锁</li>
<li>Condition newCondition();//返回条件锁对象 可以多次调用lock.newCondition()方法创建多个condition对象</li>
</ul>
</li>
<li>Lock使用</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>    lock.lock(); // 相当于 synchronized
    //lock.tryLock()优先考虑获取锁，待获取锁成功后，才响应中断
    //lock.lockInterruptibly()优先考虑响应中断Tread.interrupt可以中断等待，而不是响应锁的普通获取或重入获取
    try {
        System.out.println("m2...");
    } finally {
        lock.unlock();//必须在finally块中释放锁
    }
</code></pre></div><ul>
<li>Condition类API
<ul>
<li>void await():当前线程释放锁并进入等待队列，如果其他线程调用condition的signal或者signalAll方法并且当前线程获取Lock从await方法返回，如果在等待状态中被中断会抛出被中断异常；</li>
<li>long awaitNanos(long nanosTimeout)：当前线程进入等待状态直到被通知，中断或者超时；</li>
<li>boolean await(long time, TimeUnit unit)throws InterruptedException：同第二种，支持自定义时间单位</li>
<li>boolean awaitUntil(Date deadline) throws InterruptedException：当前线程进入等待状态直到被通知，中断或者到了某个时间</li>
<li>void signal()：唤醒一个等待在condition上的线程，将该线程从等待队列中转移到同步队列中，如果在同步队列中能够竞争到Lock则可以从等待方法中返回。</li>
<li>void signalAll()：与1的区别在于能够唤醒所有等待在condition上的线程</li>
</ul>
</li>
<li>Condition与Object的wait/notify/notifyAll
<ul>
<li>Object的wait和notify/notify是与对象监视器配合完成线程间的等待/通知机制，而Condition与Lock配合完成等待通知机制</li>
<li>Condition能够支持不响应中断，而通过使用Object方式不支持；</li>
<li>Condition能够支持一个同步队列和多个等待队列，而Object方式只能支持一个同步队列和一个等待队列</li>
<li>Condition能够支持超时时间的设置，而Object不支持</li>
</ul>
</li>
<li>生产者和消费者的应用</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class ConditionTest {
    private LinkedList&lt;String&gt; buffer;    //容器
    private int maxSize ;           //容器最大
    private Lock lock;
    private Condition fullCondition;
    private Condition notFullCondition;

    ConditionTest(int maxSize){
        this.maxSize = maxSize;
        buffer = new LinkedList&lt;String&gt;();
        lock = new ReentrantLock();
        fullCondition = lock.newCondition();
        notFullCondition = lock.newCondition();
    }

    public void set(String string) throws InterruptedException {
        lock.lock();    //获取锁
        try {
            while (maxSize == buffer.size()){
                notFullCondition.await();       //满了，添加的线程进入等待状态
            }

            buffer.add(string);
            fullCondition.signal();
        } finally {
            lock.unlock();      //记得释放锁
        }
    }

    public String get() throws InterruptedException {
        String string;
        lock.lock();
        try {
            while (buffer.size() == 0){
                fullCondition.await();
            }
            string = buffer.poll();
            notFullCondition.signal();
        } finally {
            lock.unlock();
        }
        return string;
    }
}
</code></pre></div><h1>6. LockSupport</h1>
<ul>
<li>LockSupprot是线程的阻塞原语，用来阻塞线程和唤醒线程</li>
<li>void park()：阻塞当前线程，如果调用unpark方法或者当前线程被中断，从能从park()方法中返回</li>
<li>void park(Object blocker)：功能同方法1，入参增加一个Object对象，用来记录导致线程阻塞的阻塞对象，方便进行问题排查；</li>
<li>void parkNanos(long nanos)：阻塞当前线程，最长不超过nanos纳秒，增加了超时返回的特性；</li>
<li>void parkNanos(Object blocker, long nanos)：功能同方法3，入参增加一个Object对象，用来记录导致线程阻塞的阻塞对象，方便进行问题排查；</li>
<li>void parkUntil(long deadline)：阻塞当前线程，知道deadline；</li>
<li>void parkUntil(Object blocker, long deadline)：功能同方法5，入参增加一个Object对象，用来记录导致线程阻塞的阻塞对象，方便进行问题排查</li>
<li>void unpark(Thread thread):唤醒处于阻塞状态的指定线程</li>
</ul>
]]></content:encoded>
    </item>
    <item>
      <title>ReentrantReadWriteLock</title>
      <link>https://javaguide.cn/backend/java/reentrantReadWriteLock.html</link>
      <guid>https://javaguide.cn/backend/java/reentrantReadWriteLock.html</guid>
      <source url="https://javaguide.cn/rss.xml">ReentrantReadWriteLock</source>
      <description>ReentrantReadWriteLock 15. ReentrantReadWriteLock 特点：公平、非公平锁、读写锁、重入锁、锁降级 1. 构造方法 2. 写锁的获取tryAcquire(int acquires)与释放tryRelease(int releases) 写锁是一个支持重进入的排它锁。如果当前线程已经获取了写锁，则增加写状态。...</description>
      <category>源码</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>ReentrantReadWriteLock</p>
<!--more-->
<!-- TOC -->
<!-- /TOC -->
<h1>15. ReentrantReadWriteLock</h1>
<ul>
<li>特点：公平、非公平锁、读写锁、重入锁、锁降级</li>
</ul>
<h1>1. 构造方法</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class ReentrantReadWriteLock implements ReadWriteLock, java.io.Serializable {
    public ReentrantReadWriteLock() {
        this(false);
    }
    public ReentrantReadWriteLock(boolean fair) {
        sync = fair ? new FairSync() : new NonfairSync();
        readerLock = new ReadLock(this);
        writerLock = new WriteLock(this);
    }
    public static class ReadLock implements Lock, java.io.Serializable{
        private final Sync sync;
        protected ReadLock(ReentrantReadWriteLock lock) {
            sync = lock.sync;
        }
    }
    public static class WriteLock implements Lock, java.io.Serializable{
        private final Sync sync;
        protected WriteLock(ReentrantReadWriteLock lock) {
            sync = lock.sync;
        }
    }
    static final class FairSync extends Sync {
        final boolean writerShouldBlock() {
            return hasQueuedPredecessors();
        }
        final boolean readerShouldBlock() {
            return hasQueuedPredecessors();
        }
    }
    static final class NonfairSync extends Sync {
        final boolean writerShouldBlock() {
            return false; // writers can always barge
        }
        final boolean readerShouldBlock() {
            return apparentlyFirstQueuedIsExclusive();
        }
    }
}
</code></pre></div><h1>2. 写锁的获取tryAcquire(int acquires)与释放tryRelease(int releases)</h1>
<ul>
<li>写锁是一个支持重进入的排它锁。如果当前线程已经获取了写锁，则增加写状态。如果当前线程在获取写锁时，读锁已经被获取（读状态不为0）或者该线程不是已经获取写锁的线程，则当前线程进入等待状态，原因在于：读写锁要确保写锁的操作对读锁可见，如果允许读锁在已被获取的情况下对写锁的获取，那么正在运行的其他读线程就无法感知到当前写线程的操作。因此，只有等待其他读线程都释放了读锁，写锁才能被当前线程获取，而写锁一旦被获取，则其他读写线程的后续访问均被阻塞。</li>
<li>写锁的释放与ReentrantLock的释放过程基本类似，每次释放均减少写状态，当写状态为0时表示写锁已被释放，从而等待的读写线程能够继续访问读写锁，同时前次写线程的修改对后续读写线程可见。</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>    static final int SHARED_SHIFT   = 16;
    static final int EXCLUSIVE_MASK = (1 &lt;&lt; SHARED_SHIFT) - 1 //1左移16位然后减1 0x0000FFFF
    static int exclusiveCount(int c) { return c &amp; EXCLUSIVE_MASK; } //取同步状态的低16位 表示写锁的获取次数
    /*
    * 在同步状态state上维护多个读线程和一个写线程的状态。读写锁将变量切分成了两个部分，高16位表示读，低16位表示写
    * 同步状态state不等于0时，当写状态（state&amp;0x0000FFFF(抹去高16位与运算得到低16位的值)）等于0时，则读状态（state&gt;&gt;&gt;16）大于0，即读锁已被获取。
    * 如果在一个整型变量上维护多种状态，就一定需要“按位切割使用”这个变量
    *  功能：写锁的获取：持有锁的线程state+1，非持有锁的线程CAS操作成功后获得锁
    * 1 判断state是否有线程已经获取锁，若不等于0执行2，等于0则执行3
    * 2 若持有锁的是当前线程时设置state+1并返回true（重入锁）
    * 3 writerShouldBlock(非公平锁false（默认），公平锁hasQueuedPredecessors())或者CAS设置state失败，获取锁失败
    * 4 将持有线程的设置为当前线程并返回true
    */
    protected final boolean tryAcquire(int acquires) {
        Thread current = Thread.currentThread();
        int c = getState();//1
        int w = exclusiveCount(c);
        if (c != 0) {//2
            // 存在读锁或者当前获取线程不是已经获取写锁的线程
            if (w == 0 || current != getExclusiveOwnerThread())
                return false;
            if (w + exclusiveCount(acquires) &gt; MAX_COUNT)
                throw new Error("Maximum lock count exceeded");
            setState(c + acquires);
            return true;
        }
        if (writerShouldBlock() ||
            !compareAndSetState(c, c + acquires))
            return false;
        setExclusiveOwnerThread(current);
        return true;
    }

    final boolean writerShouldBlock() {//非公平锁（默认）
        return false; // writers can always barge
    }
    final boolean writerShouldBlock() {//公平锁
        return hasQueuedPredecessors();
    }
    /*
    *  写锁的释放：设置state=state-1如果state=0则独占锁线程为null
    *  1 state-1
    *  2 写状态为0则占有锁的线程为null
    *  3 设置state
    */
    protected final boolean tryRelease(int releases) {
        if (!isHeldExclusively())
            throw new IllegalMonitorStateException();
        int nextc = getState() - releases;//1
        boolean free = exclusiveCount(nextc) == 0;//2
        if (free)
            setExclusiveOwnerThread(null);
        setState(nextc);//3
        return free;
    }
</code></pre></div><h1>3. 读锁的获取与释放</h1>
<ul>
<li>读锁是一个支持重进入的共享锁，它能够被多个线程同时获取，在没有其他写线程访问（或者写状态为0）时，读锁总会被成功地获取，而所做的也只是（线程安全的）增加读状态。如果当前线程已经获取了读锁，则增加读状态。如果当前线程在获取读锁时，写锁已被其他线程获取，则进入等待状态。</li>
<li>getReadHoldCount()方法，作用是返回当前线程获取读锁的次数。读状态是所有线程获取读锁次数的总和，而每个线程各自获取读锁的次数只能选择保存在ThreadLocal中，由线程自身维护，这使获取读锁的实现变得复杂。因此，这里将获取读锁的代码做了删减，保留必要的部分</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>    static final int SHARED_UNIT    = (1 &lt;&lt; SHARED_SHIFT);
    static int sharedCount(int c)    { return c &gt;&gt;&gt; SHARED_SHIFT; } //同步状态的高16位用来表示读锁被获取的次数
    /*
    *  读锁的获取
    *  1 若持有锁的线程不为当前线程时，锁获取失败 
    *  2 获取同步状态state的高16位的读锁获取次数
    *  3 如果头结点的下一个节点不是共享节点且CAS操作state设置高位成功则成功获取锁，如果不成功则执行4
    *  4 调用fullTryAcquireShared()重复CAS操作直至获取共享锁（待看）
    */
    protected final int tryAcquireShared(int unused) {
        Thread current = Thread.currentThread();
        int c = getState();
        if (exclusiveCount(c) != 0 &amp;&amp;//1
            getExclusiveOwnerThread() != current)
            return -1;
        int r = sharedCount(c);//2
        if (!readerShouldBlock() &amp;&amp; //3
            r &lt; MAX_COUNT &amp;&amp;
            compareAndSetState(c, c + SHARED_UNIT)) {//同步状态的高16位用来表示读锁被获取的次数
            //省略无关代码
            return 1;
        }
        return fullTryAcquireShared(current);
    }

    final boolean readerShouldBlock() {//非公平锁（默认）
        return apparentlyFirstQueuedIsExclusive();
    }

    final boolean apparentlyFirstQueuedIsExclusive() {
        Node h, s;
        return (h = head) != null &amp;&amp; (s = h.next)  != null &amp;&amp;
        !s.isShared() &amp;&amp; s.thread != null;
    }

    final boolean readerShouldBlock() {//公平锁
        return hasQueuedPredecessors();
    }
    //待看
    final int fullTryAcquireShared(Thread current) {
        HoldCounter rh = null;
        for (;;) {
            int c = getState();
            if (exclusiveCount(c) != 0) {
                if (getExclusiveOwnerThread() != current)
                    return -1;
                // else we hold the exclusive lock; blocking here
                // would cause deadlock.
            } else if (readerShouldBlock()) {
                // Make sure we're not acquiring read lock reentrantly
                if (firstReader == current) {
                    // assert firstReaderHoldCount &gt; 0;
                } else {
                    if (rh == null) {
                        rh = cachedHoldCounter;
                        if (rh == null || rh.tid != getThreadId(current)) {
                            rh = readHolds.get();
                            if (rh.count == 0)
                                readHolds.remove();
                        }
                    }
                    if (rh.count == 0)
                        return -1;
                }
            }
            if (sharedCount(c) == MAX_COUNT)
                throw new Error("Maximum lock count exceeded");
            if (compareAndSetState(c, c + SHARED_UNIT)) {
                if (sharedCount(c) == 0) {
                    firstReader = current;
                    firstReaderHoldCount = 1;
                } else if (firstReader == current) {
                    firstReaderHoldCount++;
                } else {
                    if (rh == null)
                        rh = cachedHoldCounter;
                    if (rh == null || rh.tid != getThreadId(current))
                        rh = readHolds.get();
                    else if (rh.count == 0)
                        readHolds.set(rh);
                    rh.count++;
                    cachedHoldCounter = rh; // cache for release
                }
                return 1;
            }
        }
    }
    //读锁的释放：将设置成state-SHARED_UNIT
    //读锁的每次释放（线程安全的，可能有多个读线程同时释放读锁）均减少读状态，减少的值是（1&lt;&lt;16）。
    protected final boolean tryReleaseShared(int unused) {
        //省略无关代码...
        for (;;) {
            int c = getState();
            int nextc = c - SHARED_UNIT;
            if (compareAndSetState(c, nextc))
                return nextc == 0;
        }
    }
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code># 读锁简化版
protected final int tryAcquireShared(int unused) {
    for (;;) {
        int c = getState();
        int nextc = c + (1 &lt;&lt; 16);
        if (nextc &lt; c)
            throw new Error("Maximum lock count exceeded");
        if (exclusiveCount(c) != 0 &amp;&amp; owner != Thread.currentThread())
            return -1;
        if (compareAndSetState(c, nextc))
            return 1;
    }
}
</code></pre></div><h1>4. 锁降级</h1>
<ul>
<li>读写锁支持锁降级，遵循按照获取写锁，获取读锁再释放写锁的次序，写锁能够降级成为读锁，不支持锁升级</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>  class CachedData {
    Object data;
    volatile boolean cacheValid;
    final ReentrantReadWriteLock rwl = new ReentrantReadWriteLock();
    void processCachedData() {
            rwl.readLock().lock();
            if (!cacheValid) {
                // Must release read lock before acquiring write lock
                rwl.readLock().unlock();
                rwl.writeLock().lock();
                try {
                    // Recheck state because another thread might have
                    // acquired write lock and changed state before we did.
                    if (!cacheValid) {
                        data = ...
                cacheValid = true;
            }
            // Downgrade by acquiring read lock before releasing write lock
            rwl.readLock().lock();
            } finally {
            rwl.writeLock().unlock(); // Unlock write, still hold read
            }
        }
    
        try {
            use(data);
        } finally {
            rwl.readLock().unlock();
        }
        }
    }
</code></pre></div>]]></content:encoded>
    </item>
    <item>
      <title>socket</title>
      <link>https://javaguide.cn/backend/java/socket.html</link>
      <guid>https://javaguide.cn/backend/java/socket.html</guid>
      <source url="https://javaguide.cn/rss.xml">socket</source>
      <description>socket 1. TCP/IP协议结构(Transmission Control Protocal/Internet Protoal 传输控制协议) 2. IP地址及其使用 3. 端口号及其使用 4. InetAddress类（封装了IP地址等信息） 5. UDP协议(User Datagram Protocol用户数据报协议/无连接通信协议) 6....</description>
      <category>后端</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>socket</p>
<!--more-->
<!-- TOC -->
<ul>
<li><a href="#1-tcpip%E5%8D%8F%E8%AE%AE%E7%BB%93%E6%9E%84transmission-control-protocalinternet-protoal-%E4%BC%A0%E8%BE%93%E6%8E%A7%E5%88%B6%E5%8D%8F%E8%AE%AE">1. TCP/IP协议结构(Transmission Control Protocal/Internet Protoal 传输控制协议)</a></li>
<li><a href="#2-ip%E5%9C%B0%E5%9D%80%E5%8F%8A%E5%85%B6%E4%BD%BF%E7%94%A8">2. IP地址及其使用</a></li>
<li><a href="#3-%E7%AB%AF%E5%8F%A3%E5%8F%B7%E5%8F%8A%E5%85%B6%E4%BD%BF%E7%94%A8">3. 端口号及其使用</a></li>
<li><a href="#4-inetaddress%E7%B1%BB%E5%B0%81%E8%A3%85%E4%BA%86ip%E5%9C%B0%E5%9D%80%E7%AD%89%E4%BF%A1%E6%81%AF">4. InetAddress类（封装了IP地址等信息）</a></li>
<li><a href="#5-udp%E5%8D%8F%E8%AE%AEuser-datagram-protocol%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E6%8A%A5%E5%8D%8F%E8%AE%AE%E6%97%A0%E8%BF%9E%E6%8E%A5%E9%80%9A%E4%BF%A1%E5%8D%8F%E8%AE%AE">5. UDP协议(User Datagram Protocol用户数据报协议/无连接通信协议)</a></li>
<li><a href="#6-tcptransmission-control-protocol%E4%BC%A0%E8%BE%93%E6%8E%A7%E5%88%B6%E5%8D%8F%E8%AE%AE%E9%9D%A2%E5%90%91%E8%BF%9E%E6%8E%A5%E7%9A%84%E9%80%9A%E4%BF%A1%E5%8D%8F%E8%AE%AE">6. TCP(Transmission Control Protocol传输控制协议/面向连接的通信协议)</a></li>
<li><a href="#7-tcp%E5%8D%8F%E8%AE%AE%E5%92%8Cudp%E5%8D%8F%E8%AE%AE%E7%9A%84%E5%BC%82%E5%90%8C">7. TCP协议和UDP协议的异同</a></li>
</ul>
<!-- /TOC -->
<h1>1. TCP/IP协议结构(Transmission Control Protocal/Internet Protoal 传输控制协议)</h1>
<ul>
<li>应用层：主要负责应用程序的协议，例如HTTP协议、FTP协议、DNS协议等。</li>
<li>传输层：主要使网络程序进行通信，在进行网络通信时，采用TCP协议/UDP协议</li>
<li>网络层：整个TCP/IP协议核心，将传输的数据进行分组并将分组数据发送到目标计算机或者网络IP、ICMP、IOMP协议</li>
<li>链路层：定义物理传输通道，通常是对某些网络连接设备的驱动协议，例如针对光纤、网线提供的驱动程序和接口</li>
</ul>
<h1>2. IP地址及其使用</h1>
<ul>
<li>唯一标识网络中的计算机标示号，可指定接受或连接计算机或者发送数据的计算机</li>
<li>广泛使用的是IPv4版本，由4个字节的二进制数表示，为了方便写成十进制，</li>
<li>每个字节用一个十进制数字（0-255）表示，数字间用“.”表示</li>
<li>IPv4地址枯竭，诞生了IPv6，用16个字节表示IP地址</li>
</ul>
<h1>3. 端口号及其使用</h1>
<ul>
<li>访问计算机的应用程序的标识号</li>
<li>用两个字节表示（16位的二进制数2的16次方表示：0-65535）</li>
<li>0-1023的端口用于知名网络服务，普通程序使用1024以上的端口号</li>
<li>一个端口只能访问一个应用程序，被占用就不行</li>
</ul>
<h1>4. InetAddress类（封装了IP地址等信息）</h1>
<ul>
<li>static InetAddress getByName(String host)在给定主机名的情况下确定主机的IP地址，主机名如"<a href="http://www.baidu.com" target="_blank" rel="noopener noreferrer">www.baidu.com</a>"</li>
<li>static InetAddress getLocalHost()返回本地主机</li>
<li>String getHostName()获取此IP地址的主机名</li>
<li>String getHostAddress()返回IP地址字符串(以文本表现形式)182.61.34.226</li>
</ul>
<h1>5. UDP协议(User Datagram Protocol用户数据报协议/无连接通信协议)</h1>
<ul>
<li>
<p>数据传输时，数据的发送端和接收端不建立逻辑连接。</p>
</li>
<li>
<p>当一台计算机向另外一台计算机发送数据时，发送端不会确认接收端是否存在，就会发出数据，</p>
</li>
<li>
<p>同样接收端在收到数据时，也不会向发送端反馈是否收到数据</p>
</li>
<li>
<p>UDP协议消耗资源小，通信效率高，传输速度快，通常用于音频、视频和普通数据的传输例如视频会议都使用UDP协议，</p>
</li>
<li>
<p>因为这种情况即使偶尔丢失一两个数据包，也不会对接收结果产生太大影响</p>
</li>
<li>
<p>在使用UDP协议传送数据时，由于UDP的面向无连接性，不能保证数据的完整性，因此在传输重要数据时不建议使用UDP协议</p>
</li>
<li>
<p>DatagramPacket类 数据报包：封装UDP通信中发送或者接收的数据</p>
<ul>
<li>DatagramPacket(byte[] buf,int length)//用于接收端，不需要明确来源，只需接受数据即可</li>
<li>DatagramPacket(byte[] buf,int length，inetAddress address，int port)//用于发送端，发送端必须指定接收端的ip地址和 端口号，该端口号必须与接收端DatagramSocket创建对象时的端口号相同才能通信</li>
<li>byte[] getData()返回数据缓冲区(对应构造)</li>
<li>int getLength()返回将要发送或接收到的数据的长度</li>
<li>InetAddress getAddress()返回数据来源机器或者将要发给的机器的IP地址</li>
<li>int getPort()返回数据来源机器或者将要发给的机器的端口号，对应发送端的构造方法参数</li>
</ul>
</li>
<li>
<p>DatagramSocket类数据报套接字类：发送和接收DatagramPacket数据包</p>
<ul>
<li>DatagramSocket()创建发送端的DatagramSocket对象,并绑定到任何可用端口</li>
<li>DatagramSocket(int port)一般用于接受端以指定接收端的监听端口号，但也可用于发送端绑定到指定的端口</li>
<li>void receive(DatagramPacket p)从此套接字接收数据报包</li>
<li>void send(DataramPacket p)从此套接字发送数据报包</li>
</ul>
</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>	UDP发送端
	public class UDPSend {
	public static void main(String[] args) throws IOException {
		DatagramSocket sendSocket = new DatagramSocket();
		byte[] buffer = "hello,UDP".getBytes();
		DatagramPacket dp = new DatagramPacket(buffer, buffer.length, 
		InetAddress.getByName("192.168.75.58"), 12306);
		sendSocket.send(dp);
		sendSocket.close();
	}
	}
	UDP接收端
	public class UDPReceive {
		public static void main(String[] args) throws IOException {
			DatagramSocket receiveSocket = new DatagramSocket(12306);
			byte[] buffer = new byte[1024];
			DatagramPacket dp = new DatagramPacket(buffer, 1024);
			receiveSocket.receive(dp);
			InetAddress ipAddress = dp.getAddress();
			String ip = ipAddress.getHostAddress();//获取到了IP地址
			byte[] data = dp.getData();	//发来了什么数据  getData()
			int length = dp.getLength();	//发来了多少数据 getLenth()
			String dataStr = new String(data,0,length);	//显示收到的数据
			System.out.println("IP地址："+ip+ "数据是"+ dataStr);
			receiveSocket.close();		//5,释放流资源
		}
	}
</code></pre></div><h1>6. TCP(Transmission Control Protocol传输控制协议/面向连接的通信协议)</h1>
<ul>
<li>
<p>传输数据前发送端和接收端建立逻辑连接再传输数据(可靠无差错的数据传输)</p>
</li>
<li>
<p>TCP连接由客户端向服务端发出连接请求，每次创建连接都经过“三次握手”</p>
</li>
<li>
<p>第一次握手，客户端向服务器端发出连接请求，等待服务器确认，</p>
</li>
<li>
<p>第二次握手，服务器端向客户端回送一个响应，通知客户端收到了连接请求，</p>
</li>
<li>
<p>第三次握手，客户端再次向服务器端发送确认信息，确认连接。</p>
</li>
<li>
<p>通信时，首先创建代表服务器端ServerSocket对象，相当于开启一个服务，并等待客户端的连接</p>
</li>
<li>
<p>然后创建代表客户端Socket对象向服务器端发出连接请求，服务器端响应请求</p>
</li>
<li>
<p>两者建立连接开始通信，客户端和服务器端是通过IO流进行交互的</p>
</li>
<li>
<p>由于TCP协议的面向连接特性，它可以保证传输数据的安全性和稳定性，被广泛采用</p>
</li>
<li>
<p>例如在下载或上传文件时，如果数据接收不完整，将会导致文件数据丢失而不能被打开，因此，下载或上传文件时必须采用TCP协议。</p>
</li>
<li>
<p>ServerSocket服务器端</p>
<ul>
<li>ServerSocket(int port)创建绑定到特定端口的服务器套接字</li>
<li>Socket accept()监听并接收到此套接字的连接、通过不同socket辨别不同计算机</li>
<li>InetAddress getInetAddress()返回此服务器套接字的本地地址</li>
<li>ServerSocket对象负责监听某台计算机的某个端口号，在创建ServerSocket对象后，</li>
<li>需要继续调用该对象的accept()方法，接收来自客户端的请求。当执行了accept()方法之后，</li>
<li>服务器端程序会发生阻塞，直到客户端发出连接请求，accept()方法才会返回一个Scoket对象用于和客户端实现通信，程序才能继续向下执行</li>
</ul>
</li>
<li>
<p>Socket客户端</p>
<ul>
<li>Socket(String host,int port)将Socket连接到指定主机上的指定端口号（常用）</li>
<li>Socket(InetAddress address,int port)将Socket连接到指定IP上的指定端口号。一旦创建马上连接，连接不到就报错</li>
<li>int getPort()返回一个int类型对象，该对象是Socket对象与服务器端连接的端口号</li>
<li>InetAddress getLocalAddress()获取Socket对象绑定的本地IP地址，并封装成InetAddress</li>
<li>void close()关闭Socket连接，关闭socket前，应将与socket相关的所有输入/输出流关闭</li>
<li>InputStream getInputStream()返回调用者的InputStream 对象并执行相应操作</li>
<li>OutputStream getOutputStream()返回调用者的InputStream 对象并执行相应操作</li>
</ul>
</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>	TCP 服务器端
	public class TCPServer {
		public static void main(String[] args) throws IOException {
			ServerSocket ss = new ServerSocket(8888);
			Socket s = ss.accept();
			//要读取s中传递的数据，s.getInputstream是取得s输入的字符
			InputStreamReader isr=new InputStreamReader(s.getInputStream());
			BufferedReader br=new BufferedReader(isr);
			//读取br中的字符，读取一个文本行
			String info=br.readLine();
			System.out.println("服务器接收到:\t"+info);
			//true是及时更新数据的意思	s.getOutputstream是取得s输出的字
			PrintWriter pw=new PrintWriter(s.getOutputStream(),true);
			pw.println("我是服务器，已收到你发送的信息!");	
		}
	}
	TCP 客户端
	public class TCPClient {
		public static void main(String[] args) throws IOException {
			//Socket()就是去连接某个服务器端 127.0.0.1表示服务器的ip 9999是服务器的端口号
			Socket s=new Socket("127.0.0.1",9999);

			//如果s连接成功，就可以发送数据到服务器端
			//我们通过pw向s写数据,true表示即时刷新
			PrintWriter pw=new PrintWriter(s.getOutputStream(),true);
			pw.println("你好吗？我是客户端");
			//要读取s中传递的数据
			InputStreamReader isr=new InputStreamReader(s.getInputStream());
			BufferedReader br=new BufferedReader(isr);
			String info=br.readLine();
			System.out.println("接收到服务器：\t"+info);
		}
	}
</code></pre></div><h1>7. TCP协议和UDP协议的异同</h1>
<ul>
<li>TCP通信同UDP通信一样，都能实现两台计算机之间的通信，通信的两端都需要创建socket对象</li>
<li>UDP中只有发送端和接收端，不区分客户端与服务器端，计算机之间可以任意地发送数据
<ul>
<li>TCP中是严格区分客户端与服务器端的，在通信时，必须先由客户端去连接服务器端才能实现通信</li>
<li>服务器端不可以主动连接客户端，并且服务器端程序需要事先启动，等待客户端的连接</li>
</ul>
</li>
<li>UDP协议传输速度快,效率高,资源消耗少,但会丢失数据;TCP协议传输安全稳定,不丢失数据</li>
</ul>
]]></content:encoded>
    </item>
    <item>
      <title>Spring</title>
      <link>https://javaguide.cn/backend/java/spring.html</link>
      <guid>https://javaguide.cn/backend/java/spring.html</guid>
      <source url="https://javaguide.cn/rss.xml">Spring</source>
      <description>spring源码 1. AnnotationConfigApplicationContext extends GenericApplicationContext,AbstractApplicationContext,DefaultResourceLoader implements AnnotationConfigRegistry,BeanDefinit...</description>
      <category>源码</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>spring源码</p>
<!--more-->
<!-- TOC -->
<!-- /TOC -->
<h1>1. AnnotationConfigApplicationContext extends GenericApplicationContext,AbstractApplicationContext,DefaultResourceLoader</h1>
<p>implements AnnotationConfigRegistry,BeanDefinitionRegistry,ConfigurableApplicationContext,AliasRegistry,ApplicationContext,Lifecycle,Closeable<br>
EnvironmentCapable, ListableBeanFactory, HierarchicalBeanFactory,MessageSource, ApplicationEventPublisher, ResourcePatternResolver,BeanFactory,ResourceLoader,AutoCloseable<br>
public class AnnotationConfigApplicationContext extends GenericApplicationContext implements AnnotationConfigRegistry{<br>
private final AnnotatedBeanDefinitionReader reader;</p>
<pre><code>private final ClassPathBeanDefinitionScanner scanner;

public AnnotationConfigApplicationContext() {
	this.reader = new AnnotatedBeanDefinitionReader(this);
	this.scanner = new ClassPathBeanDefinitionScanner(this);
}
public AnnotationConfigApplicationContext(Class&lt;?&gt;... annotatedClasses) {
	this();//创建AnnotatedBeanDefinitionReader和ClassPathBeanDefinitionScanner
	register(annotatedClasses);
	refresh();
}
//GenericApplicationContext 父类构造
private final DefaultListableBeanFactory beanFactory;
public GenericApplicationContext() {
	this.beanFactory = new DefaultListableBeanFactory();//默认创建了BeanFactory
}
//AbstractApplicationContext 父父类构造
private ResourcePatternResolver resourcePatternResolver;
public AbstractApplicationContext() {
	this.resourcePatternResolver = getResourcePatternResolver();
}

protected ResourcePatternResolver getResourcePatternResolver() {
	return new PathMatchingResourcePatternResolver(this);
}

public void register(Class&lt;?&gt;... annotatedClasses) {
	Assert.notEmpty(annotatedClasses, "At least one annotated class must be specified");
	this.reader.register(annotatedClasses);
}
public void register(Class&lt;?&gt;... annotatedClasses) {
	for (Class&lt;?&gt; annotatedClass : annotatedClasses) {
		registerBean(annotatedClass);
	}
}
public void registerBean(Class&lt;?&gt; annotatedClass) {
	doRegisterBean(annotatedClass, null, null, null);
}
//1.初始化AnnotatedGenericBeanDefinition
//		属性class = 传入的class
// 		属性metadata=StandardAnnotationMetadata 对象 里面的annotations=传入class的所有注解 nestedAnnotationsAsMap = true introspectedClass = 传入的class
//2.shouldSkip判断是否应该跳过，即是否有conditional注解(内部通过Processor接口实现类alwaysTrueAnnotationProcessor的调用searchWithGetSemantics判断返回null确定不跳过)
//3.解析@Scope注解，获取bean的作用域配置信息
//4.解析公共注解Lazy DependsOn Role Description
//5.将启动类注册到beanDefinitionMap中
&lt;T&gt; void doRegisterBean(Class&lt;T&gt; annotatedClass, @Nullable Supplier&lt;T&gt; instanceSupplier, @Nullable String name,
		@Nullable Class&lt;? extends Annotation&gt;[] qualifiers, BeanDefinitionCustomizer... definitionCustomizers) {
	AnnotatedGenericBeanDefinition abd = new AnnotatedGenericBeanDefinition(annotatedClass);
	if (this.conditionEvaluator.shouldSkip(abd.getMetadata())) {
		return;
	}

	abd.setInstanceSupplier(instanceSupplier);
	//解析@Scope注解，获取bean的作用域配置信息
	ScopeMetadata scopeMetadata = this.scopeMetadataResolver.resolveScopeMetadata(abd);
	abd.setScope(scopeMetadata.getScopeName());
	String beanName = (name != null ? name : this.beanNameGenerator.generateBeanName(abd, this.registry));//产生BeanName
	//解析公共注解Lazy DependsOn Role Description
	AnnotationConfigUtils.processCommonDefinitionAnnotations(abd);
	if (qualifiers != null) {
		for (Class&lt;? extends Annotation&gt; qualifier : qualifiers) {
			if (Primary.class == qualifier) {
				abd.setPrimary(true);
			}
			else if (Lazy.class == qualifier) {
				abd.setLazyInit(true);
			}
			else {
				abd.addQualifier(new AutowireCandidateQualifier(qualifier));
			}
		}
	}
	for (BeanDefinitionCustomizer customizer : definitionCustomizers) {
		customizer.customize(abd);
	}

	BeanDefinitionHolder definitionHolder = new BeanDefinitionHolder(abd, beanName);
	definitionHolder = AnnotationConfigUtils.applyScopedProxyMode(scopeMetadata, definitionHolder, this.registry);
	BeanDefinitionReaderUtils.registerBeanDefinition(definitionHolder, this.registry);
}
</code></pre>
<p>}</p>
<h1>2. BeanDefinitionReaderUtils</h1>
<p>public class BeanDefinitionReaderUtils {<br>
public static void registerBeanDefinition(<br>
BeanDefinitionHolder definitionHolder, BeanDefinitionRegistry registry)<br>
throws BeanDefinitionStoreException {</p>
<pre><code>	// Register bean definition under primary name.
	String beanName = definitionHolder.getBeanName();
	registry.registerBeanDefinition(beanName, definitionHolder.getBeanDefinition());

	// Register aliases for bean name, if any.
	String[] aliases = definitionHolder.getAliases();
	if (aliases != null) {
		for (String alias : aliases) {
			registry.registerAlias(beanName, alias);
		}
	}
}
</code></pre>
<p>}</p>
<h1>3. PathMatchingResourcePatternResolver</h1>
<p>public class PathMatchingResourcePatternResolver implements ResourcePatternResolver {<br>
private final ResourceLoader resourceLoader;<br>
public PathMatchingResourcePatternResolver(ResourceLoader resourceLoader) {<br>
Assert.notNull(resourceLoader, "ResourceLoader must not be null");<br>
this.resourceLoader = resourceLoader;<br>
}<br>
}</p>
<h1>4. DefaultListableBeanFactory extends AbstractAutowireCapableBeanFactory,AbstractBeanFactory,FactoryBeanRegistrySupport,DefaultSingletonBeanRegistry,SimpleAliasRegistry</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>implements ConfigurableListableBeanFactory,ListableBeanFactory, AutowireCapableBeanFactory, ConfigurableBeanFactory,BeanFactory,HierarchicalBeanFactory, SingletonBeanRegistry,AliasRegistry

public class DefaultListableBeanFactory extends AbstractAutowireCapableBeanFactory implements ConfigurableListableBeanFactory, BeanDefinitionRegistry, Serializable {
			private final Map&lt;String, BeanDefinition&gt; beanDefinitionMap = new ConcurrentHashMap&lt;&gt;(256);
			private volatile List&lt;String&gt; beanDefinitionNames = new ArrayList&lt;&gt;(256);
			private AutowireCandidateResolver autowireCandidateResolver = new SimpleAutowireCandidateResolver();
			private Comparator&lt;Object&gt; dependencyComparator;
			private final Map&lt;String, String&gt; aliasMap = new ConcurrentHashMap&lt;&gt;(16);
			private final Set&lt;String&gt; alreadyCreated = Collections.newSetFromMap(new ConcurrentHashMap&lt;&gt;(256));
			private volatile Set&lt;String&gt; manualSingletonNames = new LinkedHashSet&lt;&gt;(16);
			/** Cached array of bean definition names in case of frozen configuration */
			private volatile String[] frozenBeanDefinitionNames;

			DefaultListableBeanFactory{}
			//父类DefaultSingletonBeanRegistry
			/** Cache of singleton objects: bean name --&gt; bean instance */
			private final Map&lt;String, Object&gt; singletonObjects = new ConcurrentHashMap&lt;&gt;(256);

			/** Cache of singleton factories: bean name --&gt; ObjectFactory */
			private final Map&lt;String, ObjectFactory&lt;?&gt;&gt; singletonFactories = new HashMap&lt;&gt;(16);

			/** Cache of early singleton objects: bean name --&gt; bean instance */
			private final Map&lt;String, Object&gt; earlySingletonObjects = new HashMap&lt;&gt;(16);
			//父类AbstractBeanFactory
			@Nullable
			private ClassLoader beanClassLoader = ClassUtils.getDefaultClassLoader();
		}

		protected boolean hasBeanCreationStarted() {
			return !this.alreadyCreated.isEmpty();
		}

		public void registerBeanDefinition(String beanName, BeanDefinition beanDefinition) throws BeanDefinitionStoreException {
			if (beanDefinition instanceof AbstractBeanDefinition) {
				try {
					((AbstractBeanDefinition) beanDefinition).validate();
				}
				catch (BeanDefinitionValidationException ex) {
					throw new BeanDefinitionStoreException(beanDefinition.getResourceDescription(), beanName,
							"Validation of bean definition failed", ex);
				}
			}

			BeanDefinition existingDefinition = this.beanDefinitionMap.get(beanName);
			if (existingDefinition != null) {
				this.beanDefinitionMap.put(beanName, beanDefinition);
			}
			else {
				if (hasBeanCreationStarted()) {
					// Cannot modify startup-time collection elements anymore (for stable iteration)
					synchronized (this.beanDefinitionMap) {
						this.beanDefinitionMap.put(beanName, beanDefinition);
						List&lt;String&gt; updatedDefinitions = new ArrayList&lt;&gt;(this.beanDefinitionNames.size() + 1);
						updatedDefinitions.addAll(this.beanDefinitionNames);
						updatedDefinitions.add(beanName);
						this.beanDefinitionNames = updatedDefinitions;
						if (this.manualSingletonNames.contains(beanName)) {
							Set&lt;String&gt; updatedSingletons = new LinkedHashSet&lt;&gt;(this.manualSingletonNames);
							updatedSingletons.remove(beanName);
							this.manualSingletonNames = updatedSingletons;
						}
					}
				}
				else {
					this.beanDefinitionMap.put(beanName, beanDefinition);
					this.beanDefinitionNames.add(beanName);
					this.manualSingletonNames.remove(beanName);
				}
				this.frozenBeanDefinitionNames = null;
			}

			if (existingDefinition != null || containsSingleton(beanName)) {
				resetBeanDefinition(beanName);
			}
			else if (isConfigurationFrozen()) {
				clearByTypeCache();
			}
		}
		public void registerAlias(String name, String alias) {
			synchronized (this.aliasMap) {
				if (alias.equals(name)) {
					this.aliasMap.remove(alias);
				}
				else {
					String registeredName = this.aliasMap.get(alias);
					if (registeredName != null) {
						if (registeredName.equals(name)) {
							return;
						}
						if (!allowAliasOverriding()) {
							throw new IllegalStateException("Cannot define alias '" + alias + "' for name '" +
									name + "': It is already registered for name '" + registeredName + "'.");
						}
					}
					checkForAliasCircle(name, alias);
					this.aliasMap.put(alias, name);
				}
			}
	}
}
</code></pre></div><h1>5. AnnotatedBeanDefinitionReader</h1>
<p>public class AnnotatedBeanDefinitionReader{<br>
// 1.getOrCreateEnvironment判断registry是否实现了ConfigurableEnvironment接口，没有实现环境的接口的话返回默认实现的环境StandardEnvironment<br>
// 2.(1)将registry赋值给当前对象<br>
//(2)给当前对象创建conditionEvaluator（<br>
// 	conditionEvaluator对象初始化属性 ConditionContextImpl<br>
//registry 直接赋值<br>
// resourceLoader : 取出传递的resourceLoader(null)的ClassLoader或者是beanFactory的BeanClassLoader,最后才返回getDefaultClassLoader<br>
// 	beanfactory属性：取出ConfigurableListableBeanFactory接口或ConfigurableApplicationContext接口的BeanFactory）<br>
// 取出实现EnvironmentCapable接口的environment，否则使用StandardEnvironment<br>
//取出ResourceLoader接口的资源配置类,否则使用DefaultResourceLoader<br>
//(3)给当前对象registry注册AnnotationConfigProcessors<br>
//将registry强转为DefaultListableBeanFactory并设置AnnotationAwareOrderComparator和ContextAnnotationAutowireCandidateResolver属性<br>
<a href="//xn--org-zr0f.springframework.context.annotation.internalConfigurationAnnotationProcessor//%E6%B3%A8%E8%A7%A3%E5%90%8E%E7%BD%AE%E5%A4%84%E7%90%86%E5%99%A8" target="_blank" rel="noopener noreferrer">//将org.springframework.context.annotation.internalConfigurationAnnotationProcessor//注解后置处理器</a><br>
<a href="//org.springframework.context.annotation.internalAutowiredAnnotationProcessor" target="_blank" rel="noopener noreferrer">//org.springframework.context.annotation.internalAutowiredAnnotationProcessor</a>"<br>
<a href="//org.springframework.context.annotation.internalRequiredAnnotationProcessor" target="_blank" rel="noopener noreferrer">//org.springframework.context.annotation.internalRequiredAnnotationProcessor</a><br>
<a href="//org.springframework.context.annotation.internalCommonAnnotationProcessor" target="_blank" rel="noopener noreferrer">//org.springframework.context.annotation.internalCommonAnnotationProcessor</a><br>
<a href="//org.springframework.context.event.internalEventListenerProcessor" target="_blank" rel="noopener noreferrer">//org.springframework.context.event.internalEventListenerProcessor</a><br>
<a href="//org.springframework.context.event.internalEventListenerFactory" target="_blank" rel="noopener noreferrer">//org.springframework.context.event.internalEventListenerFactory</a><br>
// 放入到registry中<br>
private final BeanDefinitionRegistry registry;<br>
private ConditionEvaluator conditionEvaluator;<br>
private ScopeMetadataResolver scopeMetadataResolver = new AnnotationScopeMetadataResolver();<br>
private BeanNameGenerator beanNameGenerator = new AnnotationBeanNameGenerator();<br>
public AnnotatedBeanDefinitionReader(BeanDefinitionRegistry registry) {<br>
this(registry, getOrCreateEnvironment(registry));<br>
}</p>
<pre><code>public AnnotatedBeanDefinitionReader(BeanDefinitionRegistry registry, Environment environment) {
	Assert.notNull(registry, "BeanDefinitionRegistry must not be null");
	Assert.notNull(environment, "Environment must not be null");
	this.registry = registry;
	this.conditionEvaluator = new ConditionEvaluator(registry, environment, null);
	AnnotationConfigUtils.registerAnnotationConfigProcessors(this.registry);//将AnnotationConfigProcessors封装成RootBeanDefinition放入BeanFactory
}

//判断registry是否实现了ConfigurableEnvironment接口，没有实现环境的接口的话返回默认实现的环境StandardEnvironment
private static Environment getOrCreateEnvironment(BeanDefinitionRegistry registry) {
	Assert.notNull(registry, "BeanDefinitionRegistry must not be null");
	if (registry instanceof EnvironmentCapable) {
		//由于AnnotationConfigApplicationContext实现了EnvironmentCapable从这里返回
		//默认使用StandardEnvironment
		return ((EnvironmentCapable) registry).getEnvironment();
	}
	return new StandardEnvironment();
}
</code></pre>
<p>}</p>
<h1>6. ConditionEvaluator</h1>
<p>class ConditionEvaluator{<br>
private final ConditionContextImpl context;<br>
public ConditionEvaluator(@Nullable BeanDefinitionRegistry registry,@Nullable Environment environment, @Nullable ResourceLoader resourceLoader) {<br>
this.context = new ConditionContextImpl(registry, environment, resourceLoader);//resourceLoader=null<br>
}<br>
private static class ConditionContextImpl implements ConditionContext {<br>
private final BeanDefinitionRegistry registry;<br>
private final ConfigurableListableBeanFactory beanFactory;<br>
private final Environment environment;<br>
private final ResourceLoader resourceLoader;<br>
private final ClassLoader classLoader;<br>
public ConditionContextImpl(@Nullable BeanDefinitionRegistry registry,@Nullable Environment environment, @Nullable ResourceLoader resourceLoader) {<br>
this.registry = registry;<br>
this.beanFactory = deduceBeanFactory(registry);<br>
this.environment = (environment != null ? environment : deduceEnvironment(registry));<br>
this.resourceLoader = (resourceLoader != null ? resourceLoader : deduceResourceLoader(registry));<br>
this.classLoader = deduceClassLoader(resourceLoader, this.beanFactory);<br>
}<br>
}<br>
//取出ConfigurableListableBeanFactory接口或ConfigurableApplicationContext接口的BeanFactory，否则为null<br>
private ConfigurableListableBeanFactory deduceBeanFactory(@Nullable BeanDefinitionRegistry source) {<br>
if (source instanceof ConfigurableListableBeanFactory) {<br>
return (ConfigurableListableBeanFactory) source;<br>
}<br>
if (source instanceof ConfigurableApplicationContext) {<br>
return (((ConfigurableApplicationContext) source).getBeanFactory());由于AnnotationConfigApplicationContext实现了ConfigurableApplicationContext从这里返回<br>
}<br>
return null;<br>
}<br>
//取出EnvironmentCapable接口的environment，否则使用StandardEnvironment<br>
private Environment deduceEnvironment(@Nullable BeanDefinitionRegistry source) {<br>
if (source instanceof EnvironmentCapable) {<br>
return ((EnvironmentCapable) source).getEnvironment();由于AnnotationConfigApplicationContext实现了EnvironmentCapable从这里返回<br>
}<br>
return new StandardEnvironment();<br>
}<br>
//取出ResourceLoader接口的资源配置类，否则使用DefaultResourceLoader<br>
private ResourceLoader deduceResourceLoader(@Nullable BeanDefinitionRegistry source) {<br>
if (source instanceof ResourceLoader) {<br>
return (ResourceLoader) source;//由于AnnotationConfigApplicationContext实现了ResourceLoader从这里返回<br>
}<br>
return new DefaultResourceLoader();<br>
}</p>
<pre><code>//取出BeanFactory的classLoader，否则使用DefaultClassLoader
private ClassLoader deduceClassLoader(@Nullable ResourceLoader resourceLoader,@Nullable ConfigurableListableBeanFactory beanFactory) {
	if (resourceLoader != null) {
		ClassLoader classLoader = resourceLoader.getClassLoader();
		if (classLoader != null) {
			return classLoader;
		}
	}
	if (beanFactory != null) {
		return beanFactory.getBeanClassLoader();//resourceLoader为null从这里返回
	}
	return ClassUtils.getDefaultClassLoader();
}
public boolean shouldSkip(AnnotatedTypeMetadata metadata) {
	return shouldSkip(metadata, null);
}
public boolean shouldSkip(@Nullable AnnotatedTypeMetadata metadata, @Nullable ConfigurationPhase phase) {
	if (metadata == null || !metadata.isAnnotated(Conditional.class.getName())) {
		return false;
	}

	if (phase == null) {
		if (metadata instanceof AnnotationMetadata &amp;&amp;
				ConfigurationClassUtils.isConfigurationCandidate((AnnotationMetadata) metadata)) {
			return shouldSkip(metadata, ConfigurationPhase.PARSE_CONFIGURATION);
		}
		return shouldSkip(metadata, ConfigurationPhase.REGISTER_BEAN);
	}

	List&lt;Condition&gt; conditions = new ArrayList&lt;&gt;();
	for (String[] conditionClasses : getConditionClasses(metadata)) {
		for (String conditionClass : conditionClasses) {
			Condition condition = getCondition(conditionClass, this.context.getClassLoader());
			conditions.add(condition);
		}
	}

	AnnotationAwareOrderComparator.sort(conditions);

	for (Condition condition : conditions) {
		ConfigurationPhase requiredPhase = null;
		if (condition instanceof ConfigurationCondition) {
			requiredPhase = ((ConfigurationCondition) condition).getConfigurationPhase();
		}
		if ((requiredPhase == null || requiredPhase == phase) &amp;&amp; !condition.matches(this.context, metadata)) {
			return true;
		}
	}

	return false;
}
</code></pre>
<p>}</p>
<h1>7. AnnotationConfigUtils</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class AnnotationConfigUtils{
	public static void registerAnnotationConfigProcessors(BeanDefinitionRegistry registry) {
		registerAnnotationConfigProcessors(registry, null);
	}
	public static Set&lt;BeanDefinitionHolder&gt; registerAnnotationConfigProcessors(BeanDefinitionRegistry registry, @Nullable Object source) {
		//取出DefaultListableBeanFactory
		DefaultListableBeanFactory beanFactory = unwrapDefaultListableBeanFactory(registry);
		//设置类的加载顺序和自动加载解决者
		if (beanFactory != null) {
			if (!(beanFactory.getDependencyComparator() instanceof AnnotationAwareOrderComparator)) {
				beanFactory.setDependencyComparator(AnnotationAwareOrderComparator.INSTANCE);//为null自动写入
			}
			if (!(beanFactory.getAutowireCandidateResolver() instanceof ContextAnnotationAutowireCandidateResolver)) {
				beanFactory.setAutowireCandidateResolver(new ContextAnnotationAutowireCandidateResolver());//
			}
		}

		Set&lt;BeanDefinitionHolder&gt; beanDefs = new LinkedHashSet&lt;&gt;(8);
		//添加一堆BeanPostProcessors（RootBeanDefinition）
		if (!registry.containsBeanDefinition(CONFIGURATION_ANNOTATION_PROCESSOR_BEAN_NAME)) {
			RootBeanDefinition def = new RootBeanDefinition(ConfigurationClassPostProcessor.class);
			def.setSource(source);
			beanDefs.add(registerPostProcessor(registry, def, CONFIGURATION_ANNOTATION_PROCESSOR_BEAN_NAME));
		}

		if (!registry.containsBeanDefinition(AUTOWIRED_ANNOTATION_PROCESSOR_BEAN_NAME)) {
			RootBeanDefinition def = new RootBeanDefinition(AutowiredAnnotationBeanPostProcessor.class);
			def.setSource(source);
			beanDefs.add(registerPostProcessor(registry, def, AUTOWIRED_ANNOTATION_PROCESSOR_BEAN_NAME));
		}

		if (!registry.containsBeanDefinition(REQUIRED_ANNOTATION_PROCESSOR_BEAN_NAME)) {
			RootBeanDefinition def = new RootBeanDefinition(RequiredAnnotationBeanPostProcessor.class);
			def.setSource(source);
			beanDefs.add(registerPostProcessor(registry, def, REQUIRED_ANNOTATION_PROCESSOR_BEAN_NAME));
		}

		// Check for JSR-250 support, and if present add the CommonAnnotationBeanPostProcessor.
		if (jsr250Present &amp;&amp; !registry.containsBeanDefinition(COMMON_ANNOTATION_PROCESSOR_BEAN_NAME)) {
			RootBeanDefinition def = new RootBeanDefinition(CommonAnnotationBeanPostProcessor.class);
			def.setSource(source);
			beanDefs.add(registerPostProcessor(registry, def, COMMON_ANNOTATION_PROCESSOR_BEAN_NAME));
		}

		// Check for JPA support, and if present add the PersistenceAnnotationBeanPostProcessor.
		if (jpaPresent &amp;&amp; !registry.containsBeanDefinition(PERSISTENCE_ANNOTATION_PROCESSOR_BEAN_NAME)) {
			RootBeanDefinition def = new RootBeanDefinition();
			try {
				def.setBeanClass(ClassUtils.forName(PERSISTENCE_ANNOTATION_PROCESSOR_CLASS_NAME,
						AnnotationConfigUtils.class.getClassLoader()));
			}
			catch (ClassNotFoundException ex) {
				throw new IllegalStateException(
						"Cannot load optional framework class: " + PERSISTENCE_ANNOTATION_PROCESSOR_CLASS_NAME, ex);
			}
			def.setSource(source);
			beanDefs.add(registerPostProcessor(registry, def, PERSISTENCE_ANNOTATION_PROCESSOR_BEAN_NAME));
		}

		if (!registry.containsBeanDefinition(EVENT_LISTENER_PROCESSOR_BEAN_NAME)) {
			RootBeanDefinition def = new RootBeanDefinition(EventListenerMethodProcessor.class);
			def.setSource(source);
			beanDefs.add(registerPostProcessor(registry, def, EVENT_LISTENER_PROCESSOR_BEAN_NAME));
		}

		if (!registry.containsBeanDefinition(EVENT_LISTENER_FACTORY_BEAN_NAME)) {
			RootBeanDefinition def = new RootBeanDefinition(DefaultEventListenerFactory.class);
			def.setSource(source);
			beanDefs.add(registerPostProcessor(registry, def, EVENT_LISTENER_FACTORY_BEAN_NAME));
		}

		return beanDefs;
	}

	private static DefaultListableBeanFactory unwrapDefaultListableBeanFactory(BeanDefinitionRegistry registry) {
		if (registry instanceof DefaultListableBeanFactory) {
			return (DefaultListableBeanFactory) registry;
		}
		else if (registry instanceof GenericApplicationContext) {
			return ((GenericApplicationContext) registry).getDefaultListableBeanFactory();//由于AnnotationConfigApplicationContext实现了GenericApplicationContext
		}
		else {
			return null;
		}
	}

	//注册基础的registry并返回BeanDefinitionHolder
	private static BeanDefinitionHolder registerPostProcessor(BeanDefinitionRegistry registry, RootBeanDefinition definition, String beanName) {
		definition.setRole(BeanDefinition.ROLE_INFRASTRUCTURE);
		registry.registerBeanDefinition(beanName, definition);
		return new BeanDefinitionHolder(definition, beanName);
	}
	
	//将注解里面的method封装为AnnotationAttributes对象然后key为method的Name，Value为ValueHolder
	static AnnotationAttributes attributesFor(AnnotatedTypeMetadata metadata, Class&lt;?&gt; annotationClass) {
		return attributesFor(metadata, annotationClass.getName());
	}
	static AnnotationAttributes attributesFor(AnnotatedTypeMetadata metadata, String annotationClassName) {
		return AnnotationAttributes.fromMap(metadata.getAnnotationAttributes(annotationClassName, false));
	}

	public static void processCommonDefinitionAnnotations(AnnotatedBeanDefinition abd) {
		processCommonDefinitionAnnotations(abd, abd.getMetadata());
	}

	static void processCommonDefinitionAnnotations(AnnotatedBeanDefinition abd, AnnotatedTypeMetadata metadata) {
		AnnotationAttributes lazy = attributesFor(metadata, Lazy.class);
		if (lazy != null) {
			abd.setLazyInit(lazy.getBoolean("value"));
		}
		else if (abd.getMetadata() != metadata) {
			lazy = attributesFor(abd.getMetadata(), Lazy.class);
			if (lazy != null) {
				abd.setLazyInit(lazy.getBoolean("value"));
			}
		}

		if (metadata.isAnnotated(Primary.class.getName())) {
			abd.setPrimary(true);
		}
		AnnotationAttributes dependsOn = attributesFor(metadata, DependsOn.class);
		if (dependsOn != null) {
			abd.setDependsOn(dependsOn.getStringArray("value"));
		}

		if (abd instanceof AbstractBeanDefinition) {
			AbstractBeanDefinition absBd = (AbstractBeanDefinition) abd;
			AnnotationAttributes role = attributesFor(metadata, Role.class);
			if (role != null) {
				absBd.setRole(role.getNumber("value").intValue());
			}
			AnnotationAttributes description = attributesFor(metadata, Description.class);
			if (description != null) {
				absBd.setDescription(description.getString("value"));
			}
		}
	}

	static BeanDefinitionHolder applyScopedProxyMode(ScopeMetadata metadata, BeanDefinitionHolder definition, BeanDefinitionRegistry registry) {

		ScopedProxyMode scopedProxyMode = metadata.getScopedProxyMode();
		if (scopedProxyMode.equals(ScopedProxyMode.NO)) {
			return definition;
		}
		boolean proxyTargetClass = scopedProxyMode.equals(ScopedProxyMode.TARGET_CLASS);
		return ScopedProxyCreator.createScopedProxy(definition, registry, proxyTargetClass);
	}
}
</code></pre></div><h1>8. ScopedProxyCreator</h1>
<p>class ScopedProxyCreator {</p>
<pre><code>public static BeanDefinitionHolder createScopedProxy(
		BeanDefinitionHolder definitionHolder, BeanDefinitionRegistry registry, boolean proxyTargetClass) {

	return ScopedProxyUtils.createScopedProxy(definitionHolder, registry, proxyTargetClass);
}

public static String getTargetBeanName(String originalBeanName) {
	return ScopedProxyUtils.getTargetBeanName(originalBeanName);
}
</code></pre>
<p>}</p>
<h1>9. ScopedProxyUtils</h1>
<p>public abstract class ScopedProxyUtils {<br>
public static BeanDefinitionHolder createScopedProxy(BeanDefinitionHolder definition,<br>
BeanDefinitionRegistry registry, boolean proxyTargetClass) {</p>
<pre><code>	String originalBeanName = definition.getBeanName();
	BeanDefinition targetDefinition = definition.getBeanDefinition();
	String targetBeanName = getTargetBeanName(originalBeanName);

	// Create a scoped proxy definition for the original bean name,
	// "hiding" the target bean in an internal target definition.
	RootBeanDefinition proxyDefinition = new RootBeanDefinition(ScopedProxyFactoryBean.class);
	proxyDefinition.setDecoratedDefinition(new BeanDefinitionHolder(targetDefinition, targetBeanName));
	proxyDefinition.setOriginatingBeanDefinition(targetDefinition);
	proxyDefinition.setSource(definition.getSource());
	proxyDefinition.setRole(targetDefinition.getRole());

	proxyDefinition.getPropertyValues().add("targetBeanName", targetBeanName);
	if (proxyTargetClass) {
		targetDefinition.setAttribute(AutoProxyUtils.PRESERVE_TARGET_CLASS_ATTRIBUTE, Boolean.TRUE);
		// ScopedProxyFactoryBean's "proxyTargetClass" default is TRUE, so we don't need to set it explicitly here.
	}
	else {
		proxyDefinition.getPropertyValues().add("proxyTargetClass", Boolean.FALSE);
	}

	// Copy autowire settings from original bean definition.
	proxyDefinition.setAutowireCandidate(targetDefinition.isAutowireCandidate());
	proxyDefinition.setPrimary(targetDefinition.isPrimary());
	if (targetDefinition instanceof AbstractBeanDefinition) {
		proxyDefinition.copyQualifiersFrom((AbstractBeanDefinition) targetDefinition);
	}

	// The target bean should be ignored in favor of the scoped proxy.
	targetDefinition.setAutowireCandidate(false);
	targetDefinition.setPrimary(false);

	// Register the target bean as separate bean in the factory.
	registry.registerBeanDefinition(targetBeanName, targetDefinition);

	// Return the scoped proxy definition as primary bean definition
	// (potentially an inner bean).
	return new BeanDefinitionHolder(proxyDefinition, originalBeanName, definition.getAliases());
}
</code></pre>
<p>}</p>
<h1>10. ClassPathBeanDefinitionScanner extends ClassPathScanningCandidateComponentProvider implements EnvironmentCapable, ResourceLoaderAware，Aware</h1>
<p>public class ClassPathBeanDefinitionScanner extends ClassPathScanningCandidateComponentProvider{</p>
<pre><code>private final BeanDefinitionRegistry registry;
private final List&lt;TypeFilter&gt; includeFilters = new LinkedList&lt;&gt;();
//初始化对象当前属性
//1. useDefaultFilters = true 同时注册给当前includeFilters注册两个 javax.annotation.ManagedBean 和javax.inject.Named 两个 AnnotationTypeFilter
//2. environment = getOrCreateEnvironment判断registry是否实现了ConfigurableEnvironment接口，没有实现环境的接口的话返回默认实现的环境StandardEnvironment
//3. ResourceLoader =   registry是否实现ResourceLoader，否则为null
//4. registry = 传过来的registry
//5.this.includeFilter注册两个filter javax.annotation.ManagedBean和javax.inject.Named
public ClassPathBeanDefinitionScanner(BeanDefinitionRegistry registry) {
	this(registry, true);
}
public ClassPathBeanDefinitionScanner(BeanDefinitionRegistry registry, boolean useDefaultFilters) {
	this(registry, useDefaultFilters, getOrCreateEnvironment(registry));
}
public ClassPathBeanDefinitionScanner(BeanDefinitionRegistry registry, boolean useDefaultFilters,Environment environment) {
	this(registry, useDefaultFilters, environment,(registry instanceof ResourceLoader ? (ResourceLoader) registry : null));
}
public ClassPathBeanDefinitionScanner(BeanDefinitionRegistry registry, boolean useDefaultFilters,Environment environment, @Nullable ResourceLoader resourceLoader) {
	this.registry = registry;
	if (useDefaultFilters) {
		registerDefaultFilters();
	}
	setEnvironment(environment);
	setResourceLoader(resourceLoader);
}
protected void registerDefaultFilters() {
	this.includeFilters.add(new AnnotationTypeFilter(Component.class));
	ClassLoader cl = ClassPathScanningCandidateComponentProvider.class.getClassLoader();
	try {
		this.includeFilters.add(new AnnotationTypeFilter(((Class&lt;? extends Annotation&gt;) ClassUtils.forName("javax.annotation.ManagedBean", cl)), false));
	}
	catch (ClassNotFoundException ex) {}
	try {
		this.includeFilters.add(new AnnotationTypeFilter(((Class&lt;? extends Annotation&gt;) ClassUtils.forName("javax.inject.Named", cl)), false));
	}
	catch (ClassNotFoundException ex) {}
}
private static Environment getOrCreateEnvironment(BeanDefinitionRegistry registry) {
	Assert.notNull(registry, "BeanDefinitionRegistry must not be null");
	if (registry instanceof EnvironmentCapable) {
		return ((EnvironmentCapable) registry).getEnvironment();
	}
	return new StandardEnvironment();
}
</code></pre>
<p>}</p>
<h1>11. AnnotatedGenericBeanDefinition extends GenericBeanDefinition,AbstractBeanDefinition,BeanMetadataAttributeAccessor,AttributeAccessorSupport implements AnnotatedBeanDefinition ,BeanMetadataElement,BeanDefinition, Cloneable,AttributeAccessor, BeanMetadataElement,Serializable</h1>
<p>public class AnnotatedGenericBeanDefinition extends GenericBeanDefinition implements AnnotatedBeanDefinition {<br>
@Nullable<br>
private volatile Object beanClass;<br>
public AnnotatedGenericBeanDefinition(Class&lt;?&gt; beanClass) {<br>
setBeanClass(beanClass);<br>
this.metadata = new StandardAnnotationMetadata(beanClass, true);<br>
}<br>
}</p>
<h1>12. StandardAnnotationMetadata extends StandardClassMetadata implements AnnotationMetadata,ClassMetadata,AnnotatedTypeMetadata</h1>
<p>public class StandardAnnotationMetadata extends StandardClassMetadata implements AnnotationMetadata{<br>
private final Annotation[] annotations;</p>
<pre><code>private final boolean nestedAnnotationsAsMap;
public StandardAnnotationMetadata(Class&lt;?&gt; introspectedClass, boolean nestedAnnotationsAsMap) {

	super(introspectedClass);
	this.annotations = introspectedClass.getAnnotations();
	this.nestedAnnotationsAsMap = nestedAnnotationsAsMap;
}
public boolean isAnnotated(String annotationName) {
	return (this.annotations.length &gt; 0 &amp;&amp;
			AnnotatedElementUtils.isAnnotated(getIntrospectedClass(), annotationName));
}
//父类
private final Class&lt;?&gt; introspectedClass;
public StandardClassMetadata(Class&lt;?&gt; introspectedClass) {
	Assert.notNull(introspectedClass, "Class must not be null");
	this.introspectedClass = introspectedClass;
}

public Map&lt;String, Object&gt; getAnnotationAttributes(String annotationName, boolean classValuesAsString) {
	return (this.annotations.length &gt; 0 ? AnnotatedElementUtils.getMergedAnnotationAttributes(
			getIntrospectedClass(), annotationName, classValuesAsString, this.nestedAnnotationsAsMap) : null);
}
</code></pre>
<p>}</p>
<h1>13. AnnotatedElementUtils</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class AnnotatedElementUtils {
	public static boolean isAnnotated(AnnotatedElement element, String annotationName) {
		return Boolean.TRUE.equals(searchWithGetSemantics(element, null, annotationName, alwaysTrueAnnotationProcessor));
	}
	private interface Processor&lt;T&gt; {

		/**
		 * Process the supplied annotation.
		 * &lt;p&gt;The supplied annotation will be an actual target annotation
		 * that has been found by the search algorithm, unless this processor
		 * is configured to {@linkplain #alwaysProcesses always process}
		 * annotations in which case it may be some other annotation within an
		 * annotation hierarchy. In the latter case, the {@code metaDepth}
		 * will have a value greater than {@code 0}. In any case, it is
		 * up to concrete implementations of this method to decide what to
		 * do with the supplied annotation.
		 * &lt;p&gt;The {@code metaDepth} parameter represents the depth of the
		 * annotation relative to the first annotated element in the
		 * annotation hierarchy. For example, an annotation that is
		 * &lt;em&gt;present&lt;/em&gt; on a non-annotation element will have a depth
		 * of 0; a meta-annotation will have a depth of 1; and a
		 * meta-meta-annotation will have a depth of 2; etc.
		 * @param annotatedElement the element that is annotated with the
		 * supplied annotation, used for contextual logging; may be
		 * {@code null} if unknown
		 * @param annotation the annotation to process
		 * @param metaDepth the meta-depth of the annotation
		 * @return the result of the processing, or {@code null} to continue
		 * searching for additional annotations
		 */
		@Nullable
		T process(@Nullable AnnotatedElement annotatedElement, Annotation annotation, int metaDepth);

		/**
		 * Post-process the result returned by the {@link #process} method.
		 * &lt;p&gt;The {@code annotation} supplied to this method is an annotation
		 * that is present in the annotation hierarchy, between the initial
		 * {@link AnnotatedElement} and an invocation of {@link #process}
		 * that returned a non-null value.
		 * @param annotatedElement the element that is annotated with the
		 * supplied annotation, used for contextual logging; may be
		 * {@code null} if unknown
		 * @param annotation the annotation to post-process
		 * @param result the result to post-process
		 */
		void postProcess(@Nullable AnnotatedElement annotatedElement, Annotation annotation, T result);

		/**
		 * Determine if this processor always processes annotations regardless of
		 * whether or not the target annotation has been found.
		 * @return {@code true} if this processor always processes annotations
		 * @since 4.3
		 */
		boolean alwaysProcesses();

		/**
		 * Determine if this processor aggregates the results returned by {@link #process}.
		 * &lt;p&gt;If this method returns {@code true}, then {@link #getAggregatedResults()}
		 * must return a non-null value.
		 * @return {@code true} if this processor supports aggregated results
		 * @since 4.3
		 * @see #getAggregatedResults
		 */
		boolean aggregates();

		/**
		 * Get the list of results aggregated by this processor.
		 * &lt;p&gt;NOTE: the processor does &lt;strong&gt;not&lt;/strong&gt; aggregate the results
		 * itself. Rather, the search algorithm that uses this processor is
		 * responsible for asking this processor if it {@link #aggregates} results
		 * and then adding the post-processed results to the list returned by this
		 * method.
		 * @return the list of results aggregated by this processor (never {@code null})
		 * @since 4.3
		 * @see #aggregates
		 */
		List&lt;T&gt; getAggregatedResults();
	}
	static class AlwaysTrueBooleanAnnotationProcessor extends SimpleAnnotationProcessor&lt;Boolean&gt; {

		@Override
		public final Boolean process(@Nullable AnnotatedElement annotatedElement, Annotation annotation, int metaDepth) {
			return Boolean.TRUE;
		}
	}

	private static class MergedAnnotationAttributesProcessor implements Processor&lt;AnnotationAttributes&gt; {

		private final boolean classValuesAsString;

		private final boolean nestedAnnotationsAsMap;

		private final boolean aggregates;

		private final List&lt;AnnotationAttributes&gt; aggregatedResults;

		MergedAnnotationAttributesProcessor() {
			this(false, false, false);
		}

		MergedAnnotationAttributesProcessor(boolean classValuesAsString, boolean nestedAnnotationsAsMap) {
			this(classValuesAsString, nestedAnnotationsAsMap, false);
		}

		MergedAnnotationAttributesProcessor(boolean classValuesAsString, boolean nestedAnnotationsAsMap,
				boolean aggregates) {

			this.classValuesAsString = classValuesAsString;
			this.nestedAnnotationsAsMap = nestedAnnotationsAsMap;
			this.aggregates = aggregates;
			this.aggregatedResults = (aggregates ? new ArrayList&lt;&gt;() : Collections.emptyList());
		}

		@Override
		public boolean alwaysProcesses() {
			return false;
		}

		@Override
		public boolean aggregates() {
			return this.aggregates;
		}

		@Override
		public List&lt;AnnotationAttributes&gt; getAggregatedResults() {
			return this.aggregatedResults;
		}

		@Override
		@Nullable
		public AnnotationAttributes process(@Nullable AnnotatedElement annotatedElement, Annotation annotation, int metaDepth) {
			return AnnotationUtils.retrieveAnnotationAttributes(annotatedElement, annotation,
					this.classValuesAsString, this.nestedAnnotationsAsMap);
		}

		@Override
		public void postProcess(@Nullable AnnotatedElement element, Annotation annotation, AnnotationAttributes attributes) {
			annotation = AnnotationUtils.synthesizeAnnotation(annotation, element);
			Class&lt;? extends Annotation&gt; targetAnnotationType = attributes.annotationType();

			// Track which attribute values have already been replaced so that we can short
			// circuit the search algorithms.
			Set&lt;String&gt; valuesAlreadyReplaced = new HashSet&lt;&gt;();

			for (Method attributeMethod : AnnotationUtils.getAttributeMethods(annotation.annotationType())) {
				String attributeName = attributeMethod.getName();
				String attributeOverrideName = AnnotationUtils.getAttributeOverrideName(attributeMethod, targetAnnotationType);

				// Explicit annotation attribute override declared via @AliasFor
				if (attributeOverrideName != null) {
					if (valuesAlreadyReplaced.contains(attributeOverrideName)) {
						continue;
					}

					List&lt;String&gt; targetAttributeNames = new ArrayList&lt;&gt;();
					targetAttributeNames.add(attributeOverrideName);
					valuesAlreadyReplaced.add(attributeOverrideName);

					// Ensure all aliased attributes in the target annotation are overridden. (SPR-14069)
					List&lt;String&gt; aliases = AnnotationUtils.getAttributeAliasMap(targetAnnotationType).get(attributeOverrideName);
					if (aliases != null) {
						for (String alias : aliases) {
							if (!valuesAlreadyReplaced.contains(alias)) {
								targetAttributeNames.add(alias);
								valuesAlreadyReplaced.add(alias);
							}
						}
					}

					overrideAttributes(element, annotation, attributes, attributeName, targetAttributeNames);
				}
				// Implicit annotation attribute override based on convention
				else if (!AnnotationUtils.VALUE.equals(attributeName) &amp;&amp; attributes.containsKey(attributeName)) {
					overrideAttribute(element, annotation, attributes, attributeName, attributeName);
				}
			}
		}

		private void overrideAttributes(@Nullable AnnotatedElement element, Annotation annotation,
				AnnotationAttributes attributes, String sourceAttributeName, List&lt;String&gt; targetAttributeNames) {

			Object adaptedValue = getAdaptedValue(element, annotation, sourceAttributeName);

			for (String targetAttributeName : targetAttributeNames) {
				attributes.put(targetAttributeName, adaptedValue);
			}
		}

		private void overrideAttribute(@Nullable AnnotatedElement element, Annotation annotation,
				AnnotationAttributes attributes, String sourceAttributeName, String targetAttributeName) {

			attributes.put(targetAttributeName, getAdaptedValue(element, annotation, sourceAttributeName));
		}

		@Nullable
		private Object getAdaptedValue(
				@Nullable AnnotatedElement element, Annotation annotation, String sourceAttributeName) {

			Object value = AnnotationUtils.getValue(annotation, sourceAttributeName);
			return AnnotationUtils.adaptValue(element, value, this.classValuesAsString, this.nestedAnnotationsAsMap);
		}
	}

	private static &lt;T&gt; T searchWithGetSemantics(AnnotatedElement element,
			@Nullable Class&lt;? extends Annotation&gt; annotationType,
			@Nullable String annotationName, Processor&lt;T&gt; processor) {

		return searchWithGetSemantics(element, annotationType, annotationName, null, processor);
	}
	private static &lt;T&gt; T searchWithGetSemantics(AnnotatedElement element,
			@Nullable Class&lt;? extends Annotation&gt; annotationType, @Nullable String annotationName,
			@Nullable Class&lt;? extends Annotation&gt; containerType, Processor&lt;T&gt; processor) {

		try {
			return searchWithGetSemantics(element, annotationType, annotationName, containerType, processor,
					new HashSet&lt;&gt;(), 0);
		}
		catch (Throwable ex) {
			AnnotationUtils.rethrowAnnotationConfigurationException(ex);
			throw new IllegalStateException("Failed to introspect annotations on " + element, ex);
		}
	}
	// 在提供的注释列表中进行实际搜索。应该先用本地声明的注释调用该方法，然后再用继承的注释调用，从而允许本地注释优先于继承的注释。
	// ①记录已经访问的注解（用set防止重复）重复则不执行
	// ②调用searchWithGetSemanticsInAnnotations返回结果
	// ③没有结果就找当前类的父类的所有注解，调用searchWithGetSemanticsInAnnotations返回结果，再没有结果就返回null
	//总结：调用searchWithGetSemanticsInAnnotations解析当前注解返回结果（true或者是AnnotationAttributes暂时发现），结果为null，则继续找父注解，直到无结果返回
	private static &lt;T&gt; T searchWithGetSemantics(AnnotatedElement element,
			@Nullable Class&lt;? extends Annotation&gt; annotationType, @Nullable String annotationName,
			@Nullable Class&lt;? extends Annotation&gt; containerType, Processor&lt;T&gt; processor,
			Set&lt;AnnotatedElement&gt; visited, int metaDepth) {

		if (visited.add(element)) {
			try {
				// Start searching within locally declared annotations
				List&lt;Annotation&gt; declaredAnnotations = Arrays.asList(element.getDeclaredAnnotations());
				T result = searchWithGetSemanticsInAnnotations(element, declaredAnnotations,
						annotationType, annotationName, containerType, processor, visited, metaDepth);
				if (result != null) {
					return result;
				}

				if (element instanceof Class) {  // otherwise getAnnotations doesn't return anything new
					Class&lt;?&gt; superclass = ((Class) element).getSuperclass();
					if (superclass != null &amp;&amp; superclass != Object.class) {
						List&lt;Annotation&gt; inheritedAnnotations = new LinkedList&lt;&gt;();
						for (Annotation annotation : element.getAnnotations()) {
							if (!declaredAnnotations.contains(annotation)) {
								inheritedAnnotations.add(annotation);
							}
						}
						// Continue searching within inherited annotations
						result = searchWithGetSemanticsInAnnotations(element, inheritedAnnotations,
								annotationType, annotationName, containerType, processor, visited, metaDepth);
						if (result != null) {
							return result;
						}
					}
				}
			}
			catch (Throwable ex) {
				AnnotationUtils.handleIntrospectionFailure(element, ex);
			}
		}

		return null;
	}
	@Nullable
	// 在提供的注释列表中进行实际搜索。应该先用本地声明的注释调用该方法，然后再用继承的注释调用，从而允许本地注释优先于继承的注释。
	// ①遍历提供的注解，如果是spring的注解就调用processor接口的实现返回结果并记录总结果
	// ②再次遍历提供的注解，如果是spring的注解，那么调用searchWithGetSemantics解析结果并记录总结果
		//searchWithGetSemantics实现
		// ①记录已经访问的注解（用set防止重复）重复则不执行
		// ②调用searchWithGetSemanticsInAnnotations返回结果
		// ③没有结果就找当前类的父类的所有注解，调用searchWithGetSemanticsInAnnotations返回结果，再没有结果就返回null
		//总结：调用searchWithGetSemanticsInAnnotations解析当前注解返回结果，结果为null，则继续找父注解，直到无结果返回
	private static &lt;T&gt; T searchWithGetSemanticsInAnnotations(@Nullable AnnotatedElement element,
			List&lt;Annotation&gt; annotations, @Nullable Class&lt;? extends Annotation&gt; annotationType,
			@Nullable String annotationName, @Nullable Class&lt;? extends Annotation&gt; containerType,
			Processor&lt;T&gt; processor, Set&lt;AnnotatedElement&gt; visited, int metaDepth) {

		// Search in annotations
		for (Annotation annotation : annotations) {
			Class&lt;? extends Annotation&gt; currentAnnotationType = annotation.annotationType();
			if (!AnnotationUtils.isInJavaLangAnnotationPackage(currentAnnotationType)) {//判断是否是jdk本身的注解
				if (currentAnnotationType == annotationType ||
						currentAnnotationType.getName().equals(annotationName) ||
						processor.alwaysProcesses()) {
					T result = processor.process(element, annotation, metaDepth);
					if (result != null) {
						if (processor.aggregates() &amp;&amp; metaDepth == 0) {
							processor.getAggregatedResults().add(result);
						}
						else {
							return result;
						}
					}
				}
				// Repeatable annotations in container?
				else if (currentAnnotationType == containerType) {
					for (Annotation contained : getRawAnnotationsFromContainer(element, annotation)) {
						T result = processor.process(element, contained, metaDepth);
						if (result != null) {
							// No need to post-process since repeatable annotations within a
							// container cannot be composed annotations.
							//不需要进行后处理，因为容器内的可重复注释不能组成注释
							processor.getAggregatedResults().add(result);
						}
					}
				}
			}
		}

		// Recursively search in meta-annotations
		//递归搜索元注解
		for (Annotation annotation : annotations) {
			Class&lt;? extends Annotation&gt; currentAnnotationType = annotation.annotationType();
			if (hasSearchableMetaAnnotations(currentAnnotationType, annotationType, annotationName)) {//根据传入的三个类型判断是不是Spring本身的注解
				T result = searchWithGetSemantics(currentAnnotationType, annotationType,
						annotationName, containerType, processor, visited, metaDepth + 1);
				if (result != null) {
					processor.postProcess(element, annotation, result);
					if (processor.aggregates() &amp;&amp; metaDepth == 0) {
						processor.getAggregatedResults().add(result);
					}
					else {
						return result;
					}
				}
			}
		}

		return null;
	}
		@Nullable
	//获得合并的注解
	// MergedAnnotationAttributesProcessor
	//将注解里面所有的方法合并 成key为MethodName,value为holdler或者String最后//处理别名
	public static AnnotationAttributes getMergedAnnotationAttributes(AnnotatedElement element,
			String annotationName, boolean classValuesAsString, boolean nestedAnnotationsAsMap) {

		AnnotationAttributes attributes = searchWithGetSemantics(element, null, annotationName,
				new MergedAnnotationAttributesProcessor(classValuesAsString, nestedAnnotationsAsMap));
		AnnotationUtils.postProcessAnnotationAttributes(element, attributes, classValuesAsString, nestedAnnotationsAsMap);
		return attributes;
	}
}
</code></pre></div><h1>14. AnnotationScopeMetadataResolver implements ScopeMetadataResolver</h1>
<p>public class AnnotationScopeMetadataResolver implements ScopeMetadataResolver {<br>
private final ScopedProxyMode defaultProxyMode;</p>
<pre><code>public AnnotationScopeMetadataResolver() {
	this.defaultProxyMode = ScopedProxyMode.NO;
}
//解析Scope的注解
public ScopeMetadata resolveScopeMetadata(BeanDefinition definition) {
	ScopeMetadata metadata = new ScopeMetadata();
	if (definition instanceof AnnotatedBeanDefinition) {
		AnnotatedBeanDefinition annDef = (AnnotatedBeanDefinition) definition;
		AnnotationAttributes attributes = AnnotationConfigUtils.attributesFor(
				annDef.getMetadata(), this.scopeAnnotationType);//获得Scope所有的方法及属性值
		if (attributes != null) {
			metadata.setScopeName(attributes.getString("value"));
			ScopedProxyMode proxyMode = attributes.getEnum("proxyMode");
			if (proxyMode == ScopedProxyMode.DEFAULT) {
				proxyMode = this.defaultProxyMode;
			}
			metadata.setScopedProxyMode(proxyMode);
		}
	}
	return metadata;
}
</code></pre>
<p>}</p>
<h1>15. AnnotationBeanNameGenerator</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class AnnotationBeanNameGenerator implements BeanNameGenerator {
		@Override
	public String generateBeanName(BeanDefinition definition, BeanDefinitionRegistry registry) {
		if (definition instanceof AnnotatedBeanDefinition) {
			String beanName = determineBeanNameFromAnnotation((AnnotatedBeanDefinition) definition);
			if (StringUtils.hasText(beanName)) {
				// Explicit bean name found.
				return beanName;
			}
		}
		// Fallback: generate a unique default bean name.
		return buildDefaultBeanName(definition, registry);
	}
	@Nullable
	//从注解上决定Bean名字，从所有的属性里面读出value，如果没有则返回null
	protected String determineBeanNameFromAnnotation(AnnotatedBeanDefinition annotatedDef) {
		AnnotationMetadata amd = annotatedDef.getMetadata();
		Set&lt;String&gt; types = amd.getAnnotationTypes();
		String beanName = null;
		for (String type : types) {
			AnnotationAttributes attributes = AnnotationConfigUtils.attributesFor(amd, type);
			if (attributes != null &amp;&amp; isStereotypeWithNameValue(type, amd.getMetaAnnotationTypes(type), attributes)) {
				Object value = attributes.get("value");
				if (value instanceof String) {
					String strVal = (String) value;
					if (StringUtils.hasLength(strVal)) {
						if (beanName != null &amp;&amp; !strVal.equals(beanName)) {
							throw new IllegalStateException("Stereotype annotations suggest inconsistent " +
									"component names: '" + beanName + "' versus '" + strVal + "'");
						}
						beanName = strVal;
					}
				}
			}
		}
		return beanName;
	}

	protected String buildDefaultBeanName(BeanDefinition definition, BeanDefinitionRegistry registry) {
		return buildDefaultBeanName(definition);
	}

	/**
	 * Derive a default bean name from the given bean definition.
	 * &lt;p&gt;The default implementation simply builds a decapitalized version
	 * of the short class name: e.g. "mypackage.MyJdbcDao" -&gt; "myJdbcDao".
	 * &lt;p&gt;Note that inner classes will thus have names of the form
	 * "outerClassName.InnerClassName", which because of the period in the
	 * name may be an issue if you are autowiring by name.
	 * @param definition the bean definition to build a bean name for
	 * @return the default bean name (never {@code null})
	 */
	protected String buildDefaultBeanName(BeanDefinition definition) {
		String beanClassName = definition.getBeanClassName();
		Assert.state(beanClassName != null, "No bean class name set");
		String shortClassName = ClassUtils.getShortName(beanClassName);
		return Introspector.decapitalize(shortClassName);
	}
}
</code></pre></div><h1>16. BeanDefinitionHolder implements BeanMetadataElement</h1>
<p>public class BeanDefinitionHolder implements BeanMetadataElement {<br>
public BeanDefinitionHolder(BeanDefinition beanDefinition, String beanName) {<br>
this(beanDefinition, beanName, null);<br>
}<br>
public BeanDefinitionHolder(BeanDefinition beanDefinition, String beanName, @Nullable String[] aliases) {<br>
Assert.notNull(beanDefinition, "BeanDefinition must not be null");<br>
Assert.notNull(beanName, "Bean name must not be null");<br>
this.beanDefinition = beanDefinition;<br>
this.beanName = beanName;<br>
this.aliases = aliases;<br>
}<br>
}</p>
<h1>17. ClassUtils</h1>
<p>public abstract class ClassUtils {<br>
private static final char PACKAGE_SEPARATOR = '.';<br>
private static final char INNER_CLASS_SEPARATOR = '$";</p>
<pre><code>public static String getShortName(String className) {
	Assert.hasLength(className, "Class name must not be empty");
	int lastDotIndex = className.lastIndexOf(PACKAGE_SEPARATOR);
	int nameEndIndex = className.indexOf(CGLIB_CLASS_SEPARATOR);
	if (nameEndIndex == -1) {
		nameEndIndex = className.length();
	}
	String shortName = className.substring(lastDotIndex + 1, nameEndIndex);
	shortName = shortName.replace(INNER_CLASS_SEPARATOR, PACKAGE_SEPARATOR);
	return shortName;
}

public static String getShortName(String className) {
	Assert.hasLength(className, "Class name must not be empty");
	int lastDotIndex = className.lastIndexOf(PACKAGE_SEPARATOR);
	int nameEndIndex = className.indexOf(CGLIB_CLASS_SEPARATOR);
	if (nameEndIndex == -1) {
		nameEndIndex = className.length();
	}
	String shortName = className.substring(lastDotIndex + 1, nameEndIndex);
	shortName = shortName.replace(INNER_CLASS_SEPARATOR, PACKAGE_SEPARATOR);
	return shortName;
}
</code></pre>
<p>}</p>
<h1>18. Introspector</h1>
<p>public class Introspector {<br>
public static String decapitalize(String name) {<br>
if (name == null || name.length() == 0) {<br>
return name;<br>
}<br>
if (name.length() &gt; 1 &amp;&amp; Character.isUpperCase(name.charAt(1)) &amp;&amp;<br>
Character.isUpperCase(name.charAt(0))){<br>
return name;<br>
}<br>
char chars[] = name.toCharArray();<br>
chars[0] = Character.toLowerCase(chars[0]);<br>
return new String(chars);<br>
}<br>
}</p>
<h1>19. AnnotationConfigApplicationContext创建流程</h1>
<ul>
<li>
<p>创建AnnotationConfigApplicationContext</p>
<ul>
<li>属性ResourcePatternResolver resourcePatternResolver：new PathMatchingResourcePatternResolver(this);（AbstractApplicationContext构造）
<ul>
<li>属性ResourceLoader resourceLoader：AnnotationConfigApplicationContext:DefaultResourceLoader</li>
</ul>
</li>
<li>属性ClassLoader classLoader：AppClassLoader();（DefaultResourceLoader构造）</li>
<li>属性DefaultListableBeanFactory beanFactory：new DefaultListableBeanFactory();（GenericApplicationContext构造）
<ul>
<li>属性<code>Comparator&lt;Object&gt;</code> dependencyComparator: new AnnotationAwareOrderComparator();//排序BeanPostprocessor</li>
<li>属性AutowireCandidateResolver autowireCandidateResolver：new ContextAnnotationAutowireCandidateResolver();</li>
<li>属性<code>Map&lt;String,BeanDefinition&gt;</code> beanDefinitionMap = new ConcurrentHashMap&lt;&gt;(256)
<ul>
<li>RootBeanDefinition(ConfigurationClassPostProcessor.class implements BeanDefinitionRegistryPostProcessor): internalConfigurationAnnotationProcessor//注解后置处理器</li>
<li>RootBeanDefinition(AutowiredAnnotationBeanPostProcessor.class): internalAutowiredAnnotationProcessor</li>
<li>RootBeanDefinition(RequiredAnnotationBeanPostProcessor.class): internalRequiredAnnotationProcessor</li>
<li>RootBeanDefinition(CommonAnnotationBeanPostProcessor.class): internalCommonAnnotationProcessor</li>
<li>RootBeanDefinition(EventListenerMethodProcessor.class): internalEventListenerProcessor</li>
<li>RootBeanDefinition(DefaultEventListenerFactory.class): internalEventListenerFactory</li>
</ul>
</li>
<li>属性<code>List&lt;String&gt;</code> beanDefinitionNames = new ArrayList&lt;&gt;(256)
<ul>
<li>"org.springframework.context.annotation.internalConfigurationAnnotationProcessor"//注解后置处理器</li>
<li>"org.springframework.context.annotation.internalAutowiredAnnotationProcessor"</li>
<li>"org.springframework.context.annotation.internalRequiredAnnotationProcessor"</li>
<li>"org.springframework.context.annotation.internalCommonAnnotationProcessor"</li>
<li>"org.springframework.context.event.internalEventListenerProcessor"</li>
<li>"org.springframework.context.event.internalEventListenerFactory"</li>
</ul>
</li>
</ul>
</li>
<li>属性ConfigurableEnvironment environment：new StandardEnvironment();</li>
<li>属性AnnotatedBeanDefinitionReader reader：new AnnotatedBeanDefinitionReader();
<ul>
<li>属性BeanDefinitionRegistry registry：AnnotationConfigApplicationContext</li>
<li>属性ConditionEvaluator conditionEvaluator：new ConditionEvaluator();
<ul>
<li>属性ConditionContextImpl context：new ConditionContextImpl();
<ul>
<li>属性BeanDefinitionRegistry registry: AnnotationConfigApplicationContext</li>
<li>属性ConfigurableListableBeanFactory beanFactory: DefaultListableBeanFactory</li>
<li>属性Environment environment：StandardEnvironment</li>
<li>属性ResourceLoader resourceLoader：DefaultResourceLoader</li>
<li>属性ClassLoader classLoader：AppClassLoader</li>
</ul>
</li>
</ul>
</li>
<li>属性默认ScopeMetadataResolver scopeMetadataResolver = new AnnotationScopeMetadataResolver()</li>
<li>属性默认BeanNameGenerator beanNameGenerator = new AnnotationBeanNameGenerator()</li>
</ul>
</li>
<li>属性ClassPathBeanDefinitionScanner scanner：new ClassPathBeanDefinitionScanner()
<ul>
<li>属性BeanDefinitionRegistry registry：AnnotationConfigApplicationContext</li>
<li>属性<code>List&lt;TypeFilter&gt;</code> includeFilters = new LinkedList&lt;&gt;()
<ul>
<li>new AnnotationTypeFilter(Component.class)</li>
</ul>
</li>
<li>属性Environment environment：StandardEnvironment</li>
<li>属性ResourcePatternResolver resourcePatternResolver：AnnotationConfigApplicationContext（DefaultResourceLoader）</li>
<li>属性MetadataReaderFactory metadataReaderFactory：new CachingMetadataReaderFactory()（属性省略）</li>
</ul>
</li>
</ul>
</li>
<li>
<p>AnnotatedBeanDefinitionReader.register方法将class注册到DefaultListableBeanFactory的beanDefinitionMap中</p>
<ul>
<li>构造AnnotatedGenericBeanDefinition
<ul>
<li>属性beanClass：class</li>
<li>属性AnnotationMetadata metadata：new StandardAnnotationMetadata(beanClass, true)
<ul>
<li>属性Annotation[] annotations: class.getAnnotations();</li>
<li>属性boolean nestedAnnotationsAsMap：true;</li>
<li>属性Class&lt;?&gt; introspectedClass：class</li>
</ul>
</li>
</ul>
</li>
<li>调用ConditionEvaluator.shouSkip判断是否是conditional注解，若是无需注册</li>
<li>调用scopeMetadataResolver.resolveScopeMetadata判断是否被@Scope注解注解了，并解析Value属性和proxyMode</li>
<li>调用beanNameGenerator.generateBeanName得到BeanName</li>
<li>调用processCommonDefinitionAnnotations判断是否被lazy，Primary，DependsOn，Role，Description注解，给AnnotatedGenericBeanDefinition设置相应的属性</li>
<li>调用AnnotationConfigUtils.applyScopedProxyMode判断是否要是多例的</li>
<li>调用BeanDefinitionReaderUtils.registerBeanDefinition将AnnotatedGenericBeanDefinition注册到DefaultListableBeanFactory的beanDefinitionMap中，注意别名的注册</li>
</ul>
</li>
<li>
<p>AnnotationConfigApplicationContext的refresh()方法</p>
<ul>
<li>
<p>prepareRefresh()</p>
<ul>
<li>属性long startupDate：System.currentTimeMillis()记录启动时间</li>
<li>属性AtomicBoolean active：true</li>
<li>属性AtomicBoolean closed：false</li>
<li>初始化系统属性initPropertySources钩子方法</li>
<li>使用ConfigurablePropertyResolver校验设置的setRequiredProperties环境参数（getEnvironment().validateRequiredProperties）(没看)</li>
<li>属性<code>Set&lt;ApplicationListener&lt;?&gt;&gt;</code> earlyApplicationListeners：new LinkedHashSet&lt;&gt;();</li>
<li>属性<code>Set&lt;ApplicationEvent&gt;</code> earlyApplicationEvents：new LinkedHashSet&lt;&gt;()</li>
</ul>
</li>
<li>
<p>ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory();</p>
<ul>
<li>refreshBeanFactory()；由于AnnotationConfigApplicationContext继承了GenericApplicationContext，复写了refreshBeanFactory()方法，只给AnnotationConfigApplicationContext的beanFactory设置了一个SerializationId</li>
</ul>
</li>
<li>
<p>prepareBeanFactory(beanFactory);</p>
<ul>
<li>给AnnotationConfigApplicationContext的beanFactory设置ClassLoader beanClassLoader：AppClassLoader</li>
<li>给AnnotationConfigApplicationContext的beanFactory设置BeanExpressionResolver beanExpressionResolver：new StandardBeanExpressionResolver(AppClassLoader)</li>
<li>给AnnotationConfigApplicationContext的beanFactory设置<code>Set&lt;PropertyEditorRegistrar&gt;</code> propertyEditorRegistrars：add ResourceEditorRegistrar(StandardEnvironment)</li>
</ul>
<p>// Configure the bean factory with context callbacks.</p>
<ul>
<li>给AnnotationConfigApplicationContext的beanFactory设置<code>List&lt;BeanPostProcessor&gt;</code> beanPostProcessors：
<ul>
<li>add new ApplicationContextAwareProcessor(this)</li>
<li>add new ApplicationListenerDetector(this)</li>
</ul>
</li>
<li>给AnnotationConfigApplicationContext的beanFactory设置<code>Set&lt;Class&lt;?&gt;&gt;</code> ignoredDependencyInterfaces：
<ul>
<li>add EnvironmentAware.class</li>
<li>add EmbeddedValueResolverAware.class</li>
<li>add ResourceLoaderAware.class</li>
<li>add ApplicationEventPublisherAware.class</li>
<li>add MessageSourceAware.class</li>
<li>add ApplicationContextAware.class</li>
</ul>
</li>
<li>给AnnotationConfigApplicationContext的beanFactory设置<code>Map&lt;Class&lt;?&gt;</code>, Object&gt; resolvableDependencies
<ul>
<li>put BeanFactory.class, BeanFactory</li>
<li>put ResourceLoader.class, this</li>
<li>put ApplicationEventPublisher.class, this</li>
<li>put ApplicationContext.class, this</li>
</ul>
</li>
<li>if (beanFactory.containsBean(LOAD_TIME_WEAVER_BEAN_NAME)) {<br>
beanFactory.addBeanPostProcessor(new LoadTimeWeaverAwareProcessor(beanFactory));<br>
// Set a temporary ClassLoader for type matching.<br>
beanFactory.setTempClassLoader(new ContextTypeMatchClassLoader(beanFactory.getBeanClassLoader()));<br>
}</li>
<li>给AnnotationConfigApplicationContext的beanFactory设置<code>Map&lt;String,Object&gt;</code> singletonObjects
<ul>
<li><code>&lt;environment,StandardEnvironment&gt;</code></li>
<li><code>&lt;systemProperties,properties&gt;</code>,</li>
<li><code>&lt;systemEnvironment,Map&gt;</code></li>
</ul>
</li>
<li>给AnnotationConfigApplicationContext的beanFactory设置<code>Set&lt;String&gt;</code> registeredSingletons：
<ul>
<li>"environment"</li>
<li>"systemProperties"</li>
<li>"systemEnvironment"</li>
</ul>
</li>
<li>给<code>Set&lt;String&gt;</code> manualSingletonNames添加
<ul>
<li>"environment"</li>
<li>"systemProperties"</li>
<li>"systemEnvironment"</li>
</ul>
</li>
<li>将上一步三个对象放入到singletonObjects</li>
</ul>
</li>
<li>
<p>postProcessBeanFactory(beanFactory)钩子方法（没看）</p>
</li>
<li>
<p>invokeBeanFactoryPostProcessors(beanFactory)</p>
<ul>
<li>调用PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors
<ul>
<li>判断beanFacctory是否实现了BeanDefinitionRegistry接口
<ul>
<li>创建<code>List&lt;BeanFactoryPostProcessor&gt;</code> regularPostProcessors = new ArrayList&lt;&gt;();存放实现了BeanDefinitionRegistryPostProcessor</li>
<li>创建<code>List&lt;BeanDefinitionRegistryPostProcessor&gt;</code> registryProcessors = new ArrayList&lt;&gt;();存放实现了BeanDefinitionRegistryPostProcessor</li>
<li>遍历BeanFactoryPostProcessor，找到BeanDefinitionRegistryPostProcessor实现类调用postProcessBeanDefinitionRegistry方法，并放入到registryProcessors中，其他放入regularPostProcessors中</li>
<li>遍历beanFactory中的beanDefinitionNames找到同时实现了BeanDefinitionRegistryPostProcessor.class和PriorityOrdered.class的类，按实现了AnnotationAwareOrderComparator接口进行排序，（这个方法里面找到ConfigurationClassPostProcessor）调用其postProcessBeanDefinitionRegistry实现接口方法
<ul>
<li>ConfigurationClassPostProcessor调用postProcessBeanDefinitionRegistry(本质调用processConfigBeanDefinitions)重点
<ul>
<li>扫描已经注册的BeanDefinition,找到所有Component、ComponentScan、Import、ImportResource、或者Configuration注解的类并解析order注解，最后按order排序，创建ConfigurationClassParser，并循环做如下解析(本质doProcessConfigurationClass)
<ul>
<li>解析@PropertySource注解（待看），使用componentScanParser找上面的解析@ComponentScan，解析到那个类之后再doProcessConfigurationClass一遍（递归）</li>
<li>解析@Import、@ImportResource</li>
<li>从配置类@Configuration中解析@Bean，找到的所有类加入到BeanFactory中</li>
<li>创建ConfigurationClassBeanDefinitionReader，找到相关@Bean里面的bean定义，找到@Import的资源加载进来</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>除了上面的后置处理器外，找到有@orderd注解的重复上面的步骤</li>
<li>找到除了上面2种后置处理器外的接口，重复上面的步骤</li>
<li>调用上面收集到的regularPostProcessors和registryProcessors的postProcessBeanFactory方法</li>
</ul>
</li>
<li>没实现则直接遍历BeanFactoryPostProcessors调用postProcessBeanFactory方法</li>
<li>最后调用除了上面的所有实现了BeanFactoryPostProcessor接口的类，分成priorityOrdered.class\ordered.class\其他\各自排序完成后调用postProcessBeanFactory方法</li>
</ul>
</li>
<li>检查如果搜索到LoadTimeWeaver，需要准备织入
<ul>
<li>if (beanFactory.getTempClassLoader() == null &amp;&amp; beanFactory.containsBean(LOAD_TIME_WEAVER_BEAN_NAME)) {</li>
<li>beanFactory.addBeanPostProcessor(new LoadTimeWeaverAwareProcessor(beanFactory));</li>
<li>beanFactory.setTempClassLoader(new ContextTypeMatchClassLoader(beanFactory.getBeanClassLoader()));</li>
<li>}</li>
</ul>
</li>
</ul>
</li>
<li>
<p>registerBeanPostProcessors(beanFactory)</p>
<ul>
<li>找到所有BeanPostProcessor.class的类名字</li>
<li>beanFactory的BeanPostProcessor添加BeanPostProcessorChecker</li>
<li>从beanFactory找到实现了BeanPostProcessor.class的类，同时priorityOrdered.class\ordered.class\nonOrdered各自排序，并将其注册到AnnotationConfigApplicationContext的beanPostProcessors中，将上面三种类中同时实现了MergedBeanDefinitionPostProcessor接口的类排序后也注册进去</li>
<li>beanFactory的BeanPostProcessor添加ApplicationListenerDetector</li>
</ul>
</li>
<li>
<p>初始化国际化initMessageSource();</p>
</li>
<li>
<p>注册广播initApplicationEventMulticaster()</p>
</li>
<li>
<p>onRefresh()启动别的容器的子类</p>
</li>
<li>
<p>registerListeners()注册监听类</p>
</li>
<li>
<p>finishBeanFactoryInitialization(beanFactory)初始化所有的bean（本质调用preInstantiateSingletons）</p>
<ul>
<li><code>beanFactory的List&lt;StringValueResolver&gt;</code> embeddedValueResolvers添加getEnvironment().resolvePlaceholders(strVal)(待看)</li>
<li>String[] weaverAwareNames = beanFactory.getBeanNamesForType(LoadTimeWeaverAware.class, false, false);<br>
for (String weaverAwareName : weaverAwareNames) {<br>
getBean(weaverAwareName);<br>
}</li>
<li>beanFactory.configurationFrozen = true;</li>
<li>beanFactory.frozenBeanDefinitionNames = StringUtils.toStringArray(this.beanDefinitionNames);</li>
<li>beanFactory.preInstantiateSingletons();
<ul>
<li>遍历beanDefinitionNames、调用getMergedLocalBeanDefinition判断BeanDefinition当且仅当非抽象类、单例、非懒加载时
<ul>
<li>isFactoryBean()判断是否是FactoryBean实现类(待看)
<ul>
<li>如果实现了FactoryBean而且是SmartFactoryBean类型且isEagerInit，则getBean初始化</li>
</ul>
</li>
<li>当不是FactoryBean实现类时,直接getBean初始化</li>
<li>getBean(name)-&gt;doGetBean(name)方法
<ul>
<li>如果该name是FactoryBean，那么截取掉&amp;，得到BeanName</li>
<li>getSingleton(beanName,true)</li>
<li>如果getSingleton!=null,getObjectForBeanInstance();(待看)</li>
<li>如果getSingleton==null,第一次进来
<ul>
<li>如果prototypesCurrentlyInCreation找到它，则抛出循环依赖的异常</li>
<li>从mergedBeanDefinitions查找，没有则从父容器中doGetBean继续找</li>
<li>如果是typeCheckOnly-&gt;添加到<code>Set&lt;String&gt;</code> alreadyCreated</li>
<li>并将其他的BeanDefinition、GenericBeanDefinition转成RootBeanDefinition(getMergedBeanDefinition())</li>
<li>判断BeanDefinition的dependsOn关系，如果dependentBeanMap中有则抛出循环依赖异常，否则记录到dependentBeanMap并getBean找到对应的类</li>
<li>如果是单例，调用getSingleton(beanName,CreatBean());
<ul>
<li>复制RootBeanDefinition，遍历MethodOverrides调用prepareMethodOverrides，（解析@ Lookup和lookup-method标签得到的）</li>
<li>自定义Bean的调用——遍历BeanPostProcessor中实现InstantiationAwareBeanPostProcessor的类，调用postProcessBeforeInstantiation创建对象，如果有对象则调用postProcessAfterInitialization，如果没有的话，就执行doCreateBean由spring产生
<ul>
<li>通过createBeanInstance获得BeanWrapper
<ul>
<li>从父类中拿到实例(待看)</li>
<li>从FactoryMethod中拿到实例(待看)</li>
<li>判断是否有@AutoWired相关的，找到则autowireConstructor(待看)</li>
<li>没有与@AutoWired相关的，调用SimpleInstantiationStrategy.instantiateBean通过反射创建(待看)</li>
</ul>
</li>
<li>将resolvedTargetType赋给RootBeanDefinition的resolvedTargetType</li>
<li>遍历BeanPostProcessor中实现了MergedBeanDefinitionPostProcessor的postProcessMergedBeanDefinition方法，并将其postProcessed置为true</li>
<li>如果是allowCircularReferences、singletonsCurrentlyInCreation、单例的情况下，先放入到singletonFactories、registeredSingletons、移走earlySingletonObjects三级缓存中防止循环依赖</li>
<li>populateBean：填充属性
<ul>
<li>如果含有InstantiationAwareBeanPostProcessors且非synthetic合成，则遍历BeanPostProcessors调用InstantiationAwareBeanPostProcessor的postProcessAfterInstantiation</li>
<li>判断@AutoWired属性并且完成属性注入(待看)</li>
<li>initializeBean：初始化属性</li>
<li>非合成类则遍历BeanPostProcessor调用postProcessBeforeInitialization</li>
<li>非合成类则遍历BeanPostProcessor调用postProcessAfterInitialization</li>
</ul>
</li>
<li>registerDisposableBeanIfNecessary();(待看)</li>
</ul>
</li>
</ul>
</li>
<li>如果是多例(待看)</li>
<li>其他情况(待看)</li>
<li>最后大家都调用getObjectForBeanInstance（判断是否实现了FactoryBean，不是FactoryBean直接返回传入的对象）(待看)</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>遍历beanDefinitionNames调用实现了SmartInitializingSingleton接口bean的afterSingletonsInstantiated方法</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>解析XML</p>
</li>
<li>
<p>resourcePatternResolver().getResources(location)-&gt;new ClassPathContextResource(location) implements Resource -&gt;new EncodedResource(Resource) implements InputStreamSource<br>
-&gt;classLoader.getResourceAsStream Inputstream -&gt;InputSource-&gt;DOMParser.Document</p>
</li>
<li>
<p>PathMatchingResourcePatternResolver解析basePackage</p>
</li>
<li>
<p><code>Enumeration&lt;URL&gt;</code> classLoder.getResource() -&gt;<code>Set&lt;Resource&gt;</code></p>
</li>
</ul>
<h1>20. Spring AnnotatedElementUtils遍历搜索注解的属性的方法</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>//搜索本注解及其父类的@inherited注解的集合
private static &lt;T&gt; T searchWithGetSemantics(
	AnnotatedElement element,//含有注解的类
	@Nullable Class&lt;? extends Annotation&gt; annotationType, 
	@Nullable String annotationName,
	@Nullable Class&lt;? extends Annotation&gt; containerType, //可重复注解的容器对象(暂时看全部都是为null，功能未知)
	Processor&lt;T&gt; processor,//实现了Processor接口的接口类，通过Processor来对元素进行处理
	Set&lt;AnnotatedElement&gt; visited, //已经访问的元素：用set防止重复，并终止递归
	int metaDepth//注解深度，控制注解收集，processor只收集第一次拿到的结果
	) {
	if (visited.add(element)) {
		try {
			List&lt;Annotation&gt; declaredAnnotations = Arrays.asList(element.getDeclaredAnnotations());
			T result = searchWithGetSemanticsInAnnotations(element, declaredAnnotations,
				annotationType, annotationName, containerType, processor, visited, metaDepth);
			if (result != null) {return result;}
			if (element instanceof Class) {  // otherwise getAnnotations doesn't return anything new
				Class&lt;?&gt; superclass = ((Class) element).getSuperclass();
				if (superclass != null &amp;&amp; superclass != Object.class) {
					List&lt;Annotation&gt; inheritedAnnotations = new LinkedList&lt;&gt;();
					for (Annotation annotation : element.getAnnotations()) {//拿到从父类继承过来的@inherited注解再找一遍
						if (!declaredAnnotations.contains(annotation)) {
							inheritedAnnotations.add(annotation);
						}
					}
					// Continue searching within inherited annotations
					result = searchWithGetSemanticsInAnnotations(element, inheritedAnnotations,
					annotationType, annotationName, containerType, processor, visited, metaDepth);
					if (result != null) {
						return result;
					}
				}
			}
		}
		catch (Throwable ex) {
			AnnotationUtils.handleIntrospectionFailure(element, ex);
		}
	}

	return null;
}
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>//搜索本注解及其注解的注解
private static &lt;T&gt; T searchWithGetSemanticsInAnnotations(
	@Nullable AnnotatedElement element,//含有注解的类
	List&lt;Annotation&gt; annotations, //被搜索的注解列表
	@Nullable Class&lt;? extends Annotation&gt; annotationType,//需要搜索的注解
	@Nullable String annotationName, //需要搜索的注解的全类名
	@Nullable Class&lt;? extends Annotation&gt; containerType,//可重复注解的容器对象(暂时看全部都是为null，功能未知)
	Processor&lt;T&gt; processor, //实现了Processor接口的接口类，通过Processor来对元素进行处理
	Set&lt;AnnotatedElement&gt; visited, //已经访问的元素：用set防止重复，并终止递归
	int metaDepth //注解深度，控制注解收集，processor只收集第一次拿到的结果
	) {

		for (Annotation annotation : annotations) {
			Class&lt;? extends Annotation&gt; currentAnnotationType = annotation.annotationType();
			//判断是否是jdk本身的注解:currentAnnotationType.getName()判断是否是java.lang.annotation开头
			if (!AnnotationUtils.isInJavaLangAnnotationPackage(currentAnnotationType)) {
				//判断类型一致，全类名一致、或者Processor接口alwaysProcesses决定必须执行process
				if (currentAnnotationType == annotationType ||
					currentAnnotationType.getName().equals(annotationName) ||
					processor.alwaysProcesses()) {
					T result = processor.process(element, annotation, metaDepth);
					if (result != null) {
						//Processor接口aggregates和metaDepth为0是决定是否要收集结果到processor
						if (processor.aggregates() &amp;&amp; metaDepth == 0) {
							processor.getAggregatedResults().add(result);
						}
						else {
							return result;
						}
					}
				}
				// Repeatable annotations in container?
				//全部为null，基本没啥用这个方法，功能未知，可能是@Repeatable注解?
				else if (currentAnnotationType == containerType) {
					for (Annotation contained : getRawAnnotationsFromContainer(element, annotation)) {
						T result = processor.process(element, contained, metaDepth);
						if (result != null) {
							processor.getAggregatedResults().add(result);
						}
					}
				}
			}
		}

		//递归搜索注解上的注解,递归搜索元注解，然后调用过postProcess后置处理
		for (Annotation annotation : annotations) {
			Class&lt;? extends Annotation&gt; currentAnnotationType = annotation.annotationType();
			//currentAnnotationType不是java.lang.annotation开头，annotationType, annotationName不是以java开头
			if (hasSearchableMetaAnnotations(currentAnnotationType, annotationType, annotationName)) {
				//递归搜索注解上的注解
				T result = searchWithGetSemantics(currentAnnotationType, annotationType,
						annotationName, containerType, processor, visited, metaDepth + 1);
				if (result != null) {
					//调用processor的后置处理结果处理结果
					processor.postProcess(element, annotation, result);
					//Processor接口aggregates和metaDepth为0是决定是否要收集结果到processor
					if (processor.aggregates() &amp;&amp; metaDepth == 0) {
						processor.getAggregatedResults().add(result);
					}
					else {
						return result;
					}
				}
			}
		}

		return null;
	}
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>Processor接口实现类之一 MergedAnnotationAttributesProcessor
private static class MergedAnnotationAttributesProcessor implements Processor&lt;AnnotationAttributes&gt; {
		private final boolean classValuesAsString;
		private final boolean nestedAnnotationsAsMap;
		private final boolean aggregates;
		private final List&lt;AnnotationAttributes&gt; aggregatedResults;

		MergedAnnotationAttributesProcessor() {this(false, false, false);}

		MergedAnnotationAttributesProcessor(boolean classValuesAsString, boolean nestedAnnotationsAsMap) {
			this(classValuesAsString, nestedAnnotationsAsMap, false);
		}

		MergedAnnotationAttributesProcessor(boolean classValuesAsString, 
			boolean nestedAnnotationsAsMap, boolean aggregates) {
			this.classValuesAsString = classValuesAsString;
			this.nestedAnnotationsAsMap = nestedAnnotationsAsMap;
			this.aggregates = aggregates;
			this.aggregatedResults = (aggregates ? new ArrayList&lt;&gt;() : Collections.emptyList());
		}

		@Override
		public boolean alwaysProcesses() {return false;}

		@Override
		public boolean aggregates() {return this.aggregates;}

		@Override
		public List&lt;AnnotationAttributes&gt; getAggregatedResults() {
			return this.aggregatedResults;
		}

		@Override
		@Nullable
		public AnnotationAttributes process(@Nullable AnnotatedElement annotatedElement, Annotation annotation, int metaDepth) {
			return AnnotationUtils.retrieveAnnotationAttributes(annotatedElement, annotation,
					this.classValuesAsString, this.nestedAnnotationsAsMap);
		}

		@Override
		public void postProcess(@Nullable AnnotatedElement element, Annotation annotation, AnnotationAttributes attributes) {
			annotation = AnnotationUtils.synthesizeAnnotation(annotation, element);
			Class&lt;? extends Annotation&gt; targetAnnotationType = attributes.annotationType();

			// Track which attribute values have already been replaced so that we can short
			// circuit the search algorithms.
			Set&lt;String&gt; valuesAlreadyReplaced = new HashSet&lt;&gt;();

			for (Method attributeMethod : AnnotationUtils.getAttributeMethods(annotation.annotationType())) {
				String attributeName = attributeMethod.getName();
				String attributeOverrideName = AnnotationUtils.getAttributeOverrideName(attributeMethod, targetAnnotationType);

				// Explicit annotation attribute override declared via @AliasFor
				if (attributeOverrideName != null) {
					if (valuesAlreadyReplaced.contains(attributeOverrideName)) {
						continue;
					}

					List&lt;String&gt; targetAttributeNames = new ArrayList&lt;&gt;();
					targetAttributeNames.add(attributeOverrideName);
					valuesAlreadyReplaced.add(attributeOverrideName);

					// Ensure all aliased attributes in the target annotation are overridden. (SPR-14069)
					List&lt;String&gt; aliases = AnnotationUtils.getAttributeAliasMap(targetAnnotationType).get(attributeOverrideName);
					if (aliases != null) {
						for (String alias : aliases) {
							if (!valuesAlreadyReplaced.contains(alias)) {
								targetAttributeNames.add(alias);
								valuesAlreadyReplaced.add(alias);
							}
						}
					}

					overrideAttributes(element, annotation, attributes, attributeName, targetAttributeNames);
				}
				// Implicit annotation attribute override based on convention
				else if (!AnnotationUtils.VALUE.equals(attributeName) &amp;&amp; attributes.containsKey(attributeName)) {
					overrideAttribute(element, annotation, attributes, attributeName, attributeName);
				}
			}
		}
	}
AnnotationUtils
//检索注解里面的方法并返回AnnotationAttributes(非常常用)
static AnnotationAttributes retrieveAnnotationAttributes(
	@Nullable Object annotatedElement, 
	Annotation annotation,
	boolean classValuesAsString, 
	boolean nestedAnnotationsAsMap
	) {

	Class&lt;? extends Annotation&gt; annotationType = annotation.annotationType();
	AnnotationAttributes attributes = new AnnotationAttributes(annotationType);

	for (Method method : getAttributeMethods(annotationType)) {
		try {
			Object attributeValue = method.invoke(annotation);
			Object defaultValue = method.getDefaultValue();
			if (defaultValue != null &amp;&amp; ObjectUtils.nullSafeEquals(attributeValue, defaultValue)) {
				attributeValue = new DefaultValueHolder(defaultValue);
			}
			attributes.put(method.getName(),
					adaptValue(annotatedElement, attributeValue, classValuesAsString, nestedAnnotationsAsMap));
		}
		catch (Throwable ex) {
			if (ex instanceof InvocationTargetException) {
				Throwable targetException = ((InvocationTargetException) ex).getTargetException();
				rethrowAnnotationConfigurationException(targetException);
			}
			throw new IllegalStateException("Could not obtain annotation attribute value for " + method, ex);
		}
	}

	return attributes;
}

//先从缓存里面去，没有则取出与传入接口的所有相关方法并设置为允许访问，最后把结果以 key 为annotationType 值为List&lt;Method&gt; attributeMethodsCache缓存起来，
static List&lt;Method&gt; getAttributeMethods(Class&lt;? extends Annotation&gt; annotationType) {
	List&lt;Method&gt; methods = attributeMethodsCache.get(annotationType);
	if (methods != null) {return methods;}
	methods = new ArrayList&lt;&gt;();
	for (Method method : annotationType.getDeclaredMethods()) {
		//(method != null &amp;&amp; method.getParameterCount() == 0 &amp;&amp; method.getReturnType() != void.class);
		if (isAttributeMethod(method)) {//判断是否是注解的方法
			ReflectionUtils.makeAccessible(method);
			methods.add(method);
		}
	}

	attributeMethodsCache.put(annotationType, methods);
	return methods;
}

</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>spring三级缓存
DefaultSingletonBeanRegistry
//从singletonObjects找
	// 在singletonsCurrentlyInCreation的单例，从earlySingletonObjects中找
	// allowEarlyReference，那么从singletonFactories找，并将对象singletonFactories放到earlySingletonObjects中
	protected Object getSingleton(String beanName, boolean allowEarlyReference) {
		Object singletonObject = this.singletonObjects.get(beanName);
		if (singletonObject == null &amp;&amp; isSingletonCurrentlyInCreation(beanName)) {
			synchronized (this.singletonObjects) {
				singletonObject = this.earlySingletonObjects.get(beanName);
				if (singletonObject == null &amp;&amp; allowEarlyReference) {
					ObjectFactory&lt;?&gt; singletonFactory = this.singletonFactories.get(beanName);
					if (singletonFactory != null) {
						singletonObject = singletonFactory.getObject();
						this.earlySingletonObjects.put(beanName, singletonObject);
						this.singletonFactories.remove(beanName);
					}
				}
			}
		}
		return singletonObject;
	}
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>//从mergedBeanDefinitions中找到RootBeanDefinition
	protected RootBeanDefinition getMergedLocalBeanDefinition(String beanName) throws BeansException {
		RootBeanDefinition mbd = this.mergedBeanDefinitions.get(beanName);
		if (mbd != null) {return mbd;}
		return getMergedBeanDefinition(beanName, getBeanDefinition(beanName));//getBeanDefinition从beanDefinitionMap找BeanDefinition
	}
	protected RootBeanDefinition getMergedBeanDefinition(String beanName, BeanDefinition bd)
		throws BeanDefinitionStoreException {
		return getMergedBeanDefinition(beanName, bd, null);
	}
	//如果给定bean的定义是子bean定义，则通过与父bean合并返回给定bean的RootBeanDefinition
	//在mergedBeanDefinitions找-&gt;RootBeanDefinition类型则复制，否则之间创建
	// -&gt;从父容器的ConfigurableBeanFactory得到getMergedBeanDefinition，构造RootBeanDefinition，设置Scope
	//缓存到mergedBeanDefinitions
	protected RootBeanDefinition getMergedBeanDefinition(
			String beanName, BeanDefinition bd, @Nullable BeanDefinition containingBd)
			throws BeanDefinitionStoreException {

		synchronized (this.mergedBeanDefinitions) {
			RootBeanDefinition mbd = null;
			if (containingBd == null) {
				mbd = this.mergedBeanDefinitions.get(beanName);
			}

			if (mbd == null) {
				if (bd.getParentName() == null) {
					if (bd instanceof RootBeanDefinition) {
						mbd = ((RootBeanDefinition) bd).cloneBeanDefinition();
					}
					else {
						mbd = new RootBeanDefinition(bd);
					}
				}
				else {
					// Child bean definition: needs to be merged with parent.
					BeanDefinition pbd;
					try {
						String parentBeanName = transformedBeanName(bd.getParentName());
						if (!beanName.equals(parentBeanName)) {
							pbd = getMergedBeanDefinition(parentBeanName);
						}
						else {
							BeanFactory parent = getParentBeanFactory();
							if (parent instanceof ConfigurableBeanFactory) {
								pbd = ((ConfigurableBeanFactory) parent).getMergedBeanDefinition(parentBeanName);
							}
							else {
								throw new NoSuchBeanDefinitionException(parentBeanName,
										"Parent name '" + parentBeanName + "' is equal to bean name '" + beanName +
										"': cannot be resolved without a ConfigurableBeanFactory parent");
							}
						}
					}
					catch (NoSuchBeanDefinitionException ex) {
						throw new BeanDefinitionStoreException(bd.getResourceDescription(), beanName,
								"Could not resolve parent bean definition '" + bd.getParentName() + "'", ex);
					}
					// Deep copy with overridden values.
					mbd = new RootBeanDefinition(pbd);
					mbd.overrideFrom(bd);
				}

				// Set default singleton scope, if not configured before.
				if (!StringUtils.hasLength(mbd.getScope())) {
					mbd.setScope(SCOPE_SINGLETON);
				}

				// A bean contained in a non-singleton bean cannot be a singleton itself.
				// Let's correct this on the fly here, since this might be the result of
				// parent-child merging for the outer bean, in which case the original inner bean
				// definition will not have inherited the merged outer bean's singleton status.
				if (containingBd != null &amp;&amp; !containingBd.isSingleton() &amp;&amp; mbd.isSingleton()) {
					mbd.setScope(containingBd.getScope());
				}

				// Cache the merged bean definition for the time being
				// (it might still get re-merged later on in order to pick up metadata changes)
				if (containingBd == null &amp;&amp; isCacheBeanMetadata()) {
					this.mergedBeanDefinitions.put(beanName, mbd);
				}
			}

			return mbd;
		}
	}
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>ClassUtils中计算class及其父类的所有符合的method的个数
public static int getMethodCountForName(Class&lt;?&gt; clazz, String methodName) {
		Assert.notNull(clazz, "Class must not be null");
		Assert.notNull(methodName, "Method name must not be null");
		int count = 0;
		Method[] declaredMethods = clazz.getDeclaredMethods();
		for (Method method : declaredMethods) {
			if (methodName.equals(method.getName())) {
				count++;
			}
		}
		Class&lt;?&gt;[] ifcs = clazz.getInterfaces();
		for (Class&lt;?&gt; ifc : ifcs) {
			count += getMethodCountForName(ifc, methodName);
		}
		if (clazz.getSuperclass() != null) {
			count += getMethodCountForName(clazz.getSuperclass(), methodName);
		}
		return count;
	}
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class RootBeanDefinition extends AbstractBeanDefinition,BeanMetadataAttributeAccessor,AttributeAccessorSupport
	implements BeanDefinition,Cloneable,BeanMetadataElement,AttributeAccessor,Serializable{
	
	//RootBeanDefinition
	private BeanDefinitionHolder decoratedDefinition;
	private AnnotatedElement qualifiedElement;
	boolean allowCaching = true;
	boolean isFactoryMethodUnique = false;
	volatile ResolvableType targetType;
	volatile Class&lt;?&gt; resolvedTargetType;//包可见的字段，用于缓存给定bean定义的确定类
	volatile ResolvableType factoryMethodReturnType;//包可见字段，用于缓存泛型工厂方法的返回类型

	final Object constructorArgumentLock = new Object();下面四个构造函数字段的公共锁
	Executable resolvedConstructorOrFactoryMethod;//包可见字段，用于缓存已解析的构造函数或工厂方法
	boolean constructorArgumentsResolved = false;//包可见的字段，将构造函数参数标记为已解析
	Object[] resolvedConstructorArguments;//包可见的字段，用于缓存完全解析的构造函数参数
	Object[] preparedConstructorArguments;//包可见的字段，用于缓存部分准备的构造函数参数

	final Object postProcessingLock = new Object();//下面两个后处理字段的通用锁
	boolean postProcessed = false;//包可见的字段，指示已经应用了MergedBeanDefinitionPostProcessor
	volatile Boolean beforeInstantiationResolved;//包可见字段，指示实例化前的后处理程序已经启动

	private Set&lt;Member&gt; externallyManagedConfigMembers;
	private Set&lt;String&gt; externallyManagedInitMethods;
	private Set&lt;String&gt; externallyManagedDestroyMethods;

	//AbstractBeanDefinition
	private String scope = SCOPE_DEFAULT;
	public static final String SCOPE_DEFAULT = "";//@Scope相关,除非被父bean定义覆盖，否则等同于单例状态
	public static final int AUTOWIRE_NO = AutowireCapableBeanFactory.AUTOWIRE_NO;//常数，表示根本没有外部自动装配
	public static final int AUTOWIRE_BY_NAME = AutowireCapableBeanFactory.AUTOWIRE_BY_NAME;//常量，按名称指示自动装配bean属性
	public static final int AUTOWIRE_BY_TYPE = AutowireCapableBeanFactory.AUTOWIRE_BY_TYPE;//按类型指示自动装配bean属性的常量
	public static final int AUTOWIRE_CONSTRUCTOR = AutowireCapableBeanFactory.AUTOWIRE_CONSTRUCTOR;//常量，指示自动装配构造函数
	@Deprecated
	public static final int AUTOWIRE_AUTODETECT = AutowireCapableBeanFactory.AUTOWIRE_AUTODETECT;//常量，指示通过bean类的内省来确定适当的自动装配策略

	public static final int DEPENDENCY_CHECK_NONE = 0;//表示根本没有依赖项检查的常量
	public static final int DEPENDENCY_CHECK_OBJECTS = 1;//常量，指示对对象引用进行依赖项检查
	public static final int DEPENDENCY_CHECK_SIMPLE = 2;//常量，指示对“简单”属性的依赖项检查
	public static final int DEPENDENCY_CHECK_ALL = 3;//常量，指示对所有属性进行依赖项检查
	public static final String INFER_METHOD = "(inferred)";//常量，指示容器应该尝试推断bean的销毁方法名，而不是显式地指定方法名 
	//@Value专门设计为在方法名中包含否则不合法的字符 确保与具有相同名称的合法命名方法不发生冲突


	private volatile Object beanClass;
	private boolean abstractFlag = false;
	private boolean lazyInit = false;
	private int autowireMode = AUTOWIRE_NO;
	private int dependencyCheck = DEPENDENCY_CHECK_NONE;
	private String[] dependsOn;

	private boolean autowireCandidate = true;//是否被认为是自动类型装配，不影响名字装配
	private boolean primary = false;//优先被依赖的类@primary/primary标签
	private final Map&lt;String, AutowireCandidateQualifier&gt; qualifiers = new LinkedHashMap&lt;&gt;();
	private Supplier&lt;?&gt; instanceSupplier;
	private boolean nonPublicAccessAllowed = true;
	private boolean lenientConstructorResolution = true;//使多个构造函数的参数数量相同、类型存在父子类、接口实现类关系也能正常创建bean

	private String factoryBeanName;
	private String factoryMethodName;

	private ConstructorArgumentValues constructorArgumentValues;
	private MutablePropertyValues propertyValues;
	private MethodOverrides methodOverrides = new MethodOverrides();//@lookup/&lt;lookup-method&gt;

	private String initMethodName;//&lt;init-method&gt;/@PostConstruct(java自己的注解)
	private String destroyMethodName;//&lt;destroy-method&gt;/@PreDestroy(java自己的注解)
	private boolean enforceInitMethod = true;//是否执行init-method，程序设置
	private boolean enforceDestroyMethod = true;//是否执行destroy-method，程序设置
	
	private boolean synthetic = false;//非应用自己定义的，类似Aop产生的对象

	private int role = BeanDefinition.ROLE_APPLICATION;
	//BeanDefinition
	int ROLE_APPLICATION = 0;//用户定义的bean
	int ROLE_SUPPORT = 1;//指示BeanDefinition是某个较大配置(通常是外部组件定义)的支持部分。
	int ROLE_INFRASTRUCTURE = 2;//内部注册的bean类似internalConfigurationAnnotationProcessor
	//</code></pre></div>]]></content:encoded>
    </item>
    <item>
      <title>Quartz</title>
      <link>https://javaguide.cn/backend/jobscheduling/quartz.html</link>
      <guid>https://javaguide.cn/backend/jobscheduling/quartz.html</guid>
      <source url="https://javaguide.cn/rss.xml">Quartz</source>
      <description>quartz是用于执行定时任务的框架 1. Quartz的介绍 Quartz是OpenSymphony开源组织在Job scheduling领域又一个开源项目，它可以与J2EE与J2SE应用程序相结合也可以单独使用。 Quartz可以用来创建简单或为运行十个，百个，甚至是好几万个Jobs这样复杂的程序。Jobs可以做成标准的Java组件或 EJBs。 ...</description>
      <category>后端</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>quartz是用于执行定时任务的框架</p>
<!--more-->
<h1>1. Quartz的介绍</h1>
<p>Quartz是OpenSymphony开源组织在Job scheduling领域又一个开源项目，它可以与J2EE与J2SE应用程序相结合也可以单独使用。<br>
Quartz可以用来创建简单或为运行十个，百个，甚至是好几万个Jobs这样复杂的程序。Jobs可以做成标准的Java组件或 EJBs。</p>
<h1>2. Quartz的使用</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>创建maven工程，导入spring和quartz相关依赖
&lt;!-- 引入quartz对应的依赖 --&gt;
&lt;dependency&gt;
	&lt;groupId&gt;org.quartz-scheduler&lt;/groupId&gt;
	&lt;artifactId&gt;quartz&lt;/artifactId&gt;
	&lt;version&gt;2.2.3&lt;/version&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
	&lt;groupId&gt;org.quartz-scheduler&lt;/groupId&gt;
	&lt;artifactId&gt;quartz-jobs&lt;/artifactId&gt;
	&lt;version&gt;2.2.3&lt;/version&gt;
&lt;/dependency&gt;

创建任务类
public class MyJob {
	public void run() {
		System.out.println("自定义的作业类执行了：" + 
				new SimpleDateFormat("yyyy-MM-dd HH:mm:ss").format(new Date()));
	}
}

在spring配置文件中配置任务类
&lt;!-- 注册自定义作业类 --&gt;
&lt;bean id="myJob" class="com.itheima.quartz.MyJob"&gt;&lt;/bean&gt;

在spring配置文件中配置JobDetail
&lt;!-- 配置JobDetail --&gt;
&lt;bean id="jobDetail" class="org.springframework.scheduling.quartz.MethodInvokingJobDetailFactoryBean"&gt;
	&lt;!-- 注入目标对象 --&gt;
	&lt;property name="targetObject" ref="myJob"/&gt;
	&lt;!-- 注入目标方法 --&gt;
	&lt;property name="targetMethod" value="run"/&gt;
&lt;/bean&gt;

在spring配置文件中配置触发器
&lt;!-- 配置触发器 --&gt;
&lt;bean id="myTrigger" class="org.springframework.scheduling.quartz.CronTriggerFactoryBean"&gt;
	&lt;!-- 注入任务详情对象 --&gt;
	&lt;property name="jobDetail" ref="jobDetail"/&gt;
	&lt;!-- 注入cron表达式，通过这个表达式指定触发的时间点 --&gt;
	&lt;property name="cronExpression"&gt;
		&lt;value&gt;0/2 * * * * ? 2017-2099&lt;/value&gt;
	&lt;/property&gt;
&lt;/bean&gt;

在spring配置文件中配置scheduler
&lt;!-- 配置调度工厂 --&gt;
&lt;bean id="schedulerFactoryBean" class="org.springframework.scheduling.quartz.SchedulerFactoryBean"&gt;
	&lt;!-- 注入触发器 --&gt;
	&lt;property name="triggers"&gt;
		&lt;list&gt;
			&lt;ref bean="myTrigger"/&gt;
		&lt;/list&gt;
	&lt;/property&gt;
&lt;/bean&gt;
</code></pre></div>]]></content:encoded>
    </item>
    <item>
      <title>ActiveMQ</title>
      <link>https://javaguide.cn/backend/mq/activemq.html</link>
      <guid>https://javaguide.cn/backend/mq/activemq.html</guid>
      <source url="https://javaguide.cn/rss.xml">ActiveMQ</source>
      <description>[toc] 1. ActiveMQ介绍 ActiveMQ 是Apache出品，最流行的，能力强劲的开源消息总线。 主要特点： 多种语言和协议编写客户端。应用协议: OpenWire,Stomp REST,WS Notification,XMPP,AMQP 完全支持JMS1.1和J2EE 1.4规范 (持久化,XA消息,事务) 通过了常见J2EE服务器(...</description>
      <category>后端</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<!--more-->
<p>[toc]</p>
<h1>1. ActiveMQ介绍</h1>
<ul>
<li>ActiveMQ 是Apache出品，最流行的，能力强劲的开源消息总线。</li>
<li>主要特点：
<ul>
<li>多种语言和协议编写客户端。应用协议: OpenWire,Stomp REST,WS Notification,XMPP,AMQP</li>
<li>完全支持JMS1.1和J2EE 1.4规范 (持久化,XA消息,事务)</li>
<li>通过了常见J2EE服务器(如 Geronimo,JBoss 4, GlassFish,WebLogic)的测试,其中通过JCA 1.5 resource adaptors的配置,可以让ActiveMQ可以自动的部署到任何兼容J2EE 1.4 商业服务器上</li>
<li>支持多种传送协议:in-VM,TCP,SSL,NIO,UDP,JGroups,JXTA</li>
<li>支持通过JDBC和journal提供高速的消息持久化</li>
<li>从设计上保证了高性能的集群,客户端-服务器,点对点</li>
<li>支持Ajax</li>
<li>支持与Axis的整合</li>
<li>可以很容易得调用内嵌JMS provider,进行测试</li>
</ul>
</li>
</ul>
<h1>2. ActiveMQ的消息形式</h1>
<ul>
<li>点对点的，即一个生产者和一个消费者一一对应；</li>
<li>发布/订阅模式，即一个生产者产生消息并进行发送后，可以由多个消费者进行接收。</li>
<li>JMS定义了五种不同的消息正文格式，以及调用的消息类型，允许你发送并接收以一些不同形式的数据，提供现有消息格式的一些级别的兼容性。
<ul>
<li>StreamMessage -- Java原始值的数据流</li>
<li>MapMessage--一套名称-值对</li>
<li>TextMessage--一个字符串对象</li>
<li>ObjectMessage--一个序列化的 Java对象</li>
<li>BytesMessage--一个字节的数据流</li>
</ul>
</li>
</ul>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/92a0cb632b97d682ef936.png" alt="图片1.png" tabindex="0"><figcaption>图片1.png</figcaption></figure>
<h1>3. ActiveMQ使用</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>使用bin目录下的activemq命令启动：./activemq start 
关闭：./activemq stop
查看状态：./activemq status
注意：如果ActiveMQ整合spring使用不要使用activemq-all-5.12.0.jar包。建议使用5.11.2
进入管理后台：http://192.168.25.168:8161/admin用户名：admin密码：admin
</code></pre></div><div class="language-java" data-ext="java" data-title="java"><pre class="language-java"><code><span class="token class-name">Queue</span>
	<span class="token class-name">Producer</span>
	生产者：生产消息，发送端。
	把jar包添加到工程中。使用<span class="token number">5.11</span><span class="token number">.2</span>版本的jar包。

	第一步：创建<span class="token class-name">ConnectionFactory</span>对象，需要指定服务端ip及端口号。
	第二步：使用<span class="token class-name">ConnectionFactory</span>对象创建一个<span class="token class-name">Connection</span>对象。
	第三步：开启连接，调用<span class="token class-name">Connection</span>对象的start方法。
	第四步：使用<span class="token class-name">Connection</span>对象创建一个<span class="token class-name">Session</span>对象。
	第五步：使用<span class="token class-name">Session</span>对象创建一个<span class="token class-name">Destination</span>对象（topic、queue），此处创建一个<span class="token class-name">Queue</span>对象。
	第六步：使用<span class="token class-name">Session</span>对象创建一个<span class="token class-name">Producer</span>对象。
	第七步：创建一个<span class="token class-name">Message</span>对象，创建一个<span class="token class-name">TextMessage</span>对象。
	第八步：使用<span class="token class-name">Producer</span>对象发送消息。
	第九步：关闭资源。
	<span class="token annotation punctuation">@Test</span>
	<span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">testQueueProducer</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">{</span>
		<span class="token comment">// 第一步：创建ConnectionFactory对象，需要指定服务端ip及端口号。</span>
		<span class="token comment">//brokerURL服务器的ip及端口号</span>
		<span class="token class-name">ConnectionFactory</span> connectionFactory <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ActiveMQConnectionFactory</span><span class="token punctuation">(</span><span class="token string">"tcp://192.168.25.168:61616"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
		<span class="token comment">// 第二步：使用ConnectionFactory对象创建一个Connection对象。</span>
		<span class="token class-name">Connection</span> connection <span class="token operator">=</span> connectionFactory<span class="token punctuation">.</span><span class="token function">createConnection</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
		<span class="token comment">// 第三步：开启连接，调用Connection对象的start方法。</span>
		connection<span class="token punctuation">.</span><span class="token function">start</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
		<span class="token comment">// 第四步：使用Connection对象创建一个Session对象。</span>
		<span class="token comment">//第一个参数：是否开启事务。true：开启事务，第二个参数忽略。</span>
		<span class="token comment">//第二个参数：当第一个参数为false时，才有意义。消息的应答模式。1、自动应答2、手动应答。一般是自动应答。</span>
		<span class="token class-name">Session</span> session <span class="token operator">=</span> connection<span class="token punctuation">.</span><span class="token function">createSession</span><span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token class-name">Session</span><span class="token punctuation">.</span><span class="token constant">AUTO_ACKNOWLEDGE</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
		<span class="token comment">// 第五步：使用Session对象创建一个Destination对象（topic、queue），此处创建一个Queue对象。</span>
		<span class="token comment">//参数：队列的名称。</span>
		<span class="token class-name">Queue</span> queue <span class="token operator">=</span> session<span class="token punctuation">.</span><span class="token function">createQueue</span><span class="token punctuation">(</span><span class="token string">"test-queue"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
		<span class="token comment">// 第六步：使用Session对象创建一个Producer对象。</span>
		<span class="token class-name">MessageProducer</span> producer <span class="token operator">=</span> session<span class="token punctuation">.</span><span class="token function">createProducer</span><span class="token punctuation">(</span>queue<span class="token punctuation">)</span><span class="token punctuation">;</span>
		<span class="token comment">// 第七步：创建一个Message对象，创建一个TextMessage对象。</span>
		<span class="token comment">/*TextMessage message = new ActiveMQTextMessage();
		message.setText("hello activeMq,this is my first test.");*/</span>
		<span class="token class-name">TextMessage</span> textMessage <span class="token operator">=</span> session<span class="token punctuation">.</span><span class="token function">createTextMessage</span><span class="token punctuation">(</span><span class="token string">"hello activeMq,this is my first test."</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
		<span class="token comment">// 第八步：使用Producer对象发送消息。</span>
		producer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span>textMessage<span class="token punctuation">)</span><span class="token punctuation">;</span>
		<span class="token comment">// 第九步：关闭资源。</span>
		producer<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
		session<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
		connection<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
	<span class="token punctuation">}</span>

	<span class="token class-name">Consumer</span>
	消费者：接收消息。
	第一步：创建一个<span class="token class-name">ConnectionFactory</span>对象。
	第二步：从<span class="token class-name">ConnectionFactory</span>对象中获得一个<span class="token class-name">Connection</span>对象。
	第三步：开启连接。调用<span class="token class-name">Connection</span>对象的start方法。
	第四步：使用<span class="token class-name">Connection</span>对象创建一个<span class="token class-name">Session</span>对象。
	第五步：使用<span class="token class-name">Session</span>对象创建一个<span class="token class-name">Destination</span>对象。和发送端保持一致queue，并且队列的名称一致。
	第六步：使用<span class="token class-name">Session</span>对象创建一个<span class="token class-name">Consumer</span>对象。
	第七步：接收消息。
	第八步：打印消息。
	第九步：关闭资源
	<span class="token annotation punctuation">@Test</span>
	<span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">testQueueConsumer</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">{</span>
		<span class="token comment">// 第一步：创建一个ConnectionFactory对象。</span>
		<span class="token class-name">ConnectionFactory</span> connectionFactory <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ActiveMQConnectionFactory</span><span class="token punctuation">(</span><span class="token string">"tcp://192.168.25.168:61616"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
		<span class="token comment">// 第二步：从ConnectionFactory对象中获得一个Connection对象。</span>
		<span class="token class-name">Connection</span> connection <span class="token operator">=</span> connectionFactory<span class="token punctuation">.</span><span class="token function">createConnection</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
		<span class="token comment">// 第三步：开启连接。调用Connection对象的start方法。</span>
		connection<span class="token punctuation">.</span><span class="token function">start</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
		<span class="token comment">// 第四步：使用Connection对象创建一个Session对象。</span>
		<span class="token class-name">Session</span> session <span class="token operator">=</span> connection<span class="token punctuation">.</span><span class="token function">createSession</span><span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token class-name">Session</span><span class="token punctuation">.</span><span class="token constant">AUTO_ACKNOWLEDGE</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
		<span class="token comment">// 第五步：使用Session对象创建一个Destination对象。和发送端保持一致queue，并且队列的名称一致。</span>
		<span class="token class-name">Queue</span> queue <span class="token operator">=</span> session<span class="token punctuation">.</span><span class="token function">createQueue</span><span class="token punctuation">(</span><span class="token string">"test-queue"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
		<span class="token comment">// 第六步：使用Session对象创建一个Consumer对象。</span>
		<span class="token class-name">MessageConsumer</span> consumer <span class="token operator">=</span> session<span class="token punctuation">.</span><span class="token function">createConsumer</span><span class="token punctuation">(</span>queue<span class="token punctuation">)</span><span class="token punctuation">;</span>
		<span class="token comment">// 第七步：接收消息。</span>
		consumer<span class="token punctuation">.</span><span class="token function">setMessageListener</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">MessageListener</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
			
			<span class="token annotation punctuation">@Override</span>
			<span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">onMessage</span><span class="token punctuation">(</span><span class="token class-name">Message</span> message<span class="token punctuation">)</span> <span class="token punctuation">{</span>
				<span class="token keyword">try</span> <span class="token punctuation">{</span>
					<span class="token class-name">TextMessage</span> textMessage <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token class-name">TextMessage</span><span class="token punctuation">)</span> message<span class="token punctuation">;</span>
					<span class="token class-name">String</span> text <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">;</span>
					<span class="token comment">//取消息的内容</span>
					text <span class="token operator">=</span> textMessage<span class="token punctuation">.</span><span class="token function">getText</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
					<span class="token comment">// 第八步：打印消息。</span>
					<span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">;</span>
				<span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">JMSException</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>
					e<span class="token punctuation">.</span><span class="token function">printStackTrace</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
				<span class="token punctuation">}</span>
			<span class="token punctuation">}</span>
		<span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
		<span class="token comment">//等待键盘输入</span>
		<span class="token class-name">System</span><span class="token punctuation">.</span>in<span class="token punctuation">.</span><span class="token function">read</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
		<span class="token comment">// 第九步：关闭资源</span>
		consumer<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
		session<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
		connection<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
	<span class="token punctuation">}</span>
</code></pre></div><div class="language-java" data-ext="java" data-title="java"><pre class="language-java"><code><span class="token class-name">Topic</span>
	<span class="token class-name">Producer</span>
	使用步骤：
	第一步：创建<span class="token class-name">ConnectionFactory</span>对象，需要指定服务端ip及端口号。
	第二步：使用<span class="token class-name">ConnectionFactory</span>对象创建一个<span class="token class-name">Connection</span>对象。
	第三步：开启连接，调用<span class="token class-name">Connection</span>对象的start方法。
	第四步：使用<span class="token class-name">Connection</span>对象创建一个<span class="token class-name">Session</span>对象。
	第五步：使用<span class="token class-name">Session</span>对象创建一个<span class="token class-name">Destination</span>对象（topic、queue），此处创建一个<span class="token class-name">Topic</span>对象。
	第六步：使用<span class="token class-name">Session</span>对象创建一个<span class="token class-name">Producer</span>对象。
	第七步：创建一个<span class="token class-name">Message</span>对象，创建一个<span class="token class-name">TextMessage</span>对象。
	第八步：使用<span class="token class-name">Producer</span>对象发送消息。
	第九步：关闭资源。

	<span class="token annotation punctuation">@Test</span>
	<span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">testTopicProducer</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">{</span>
		<span class="token comment">// 第一步：创建ConnectionFactory对象，需要指定服务端ip及端口号。</span>
		<span class="token comment">// brokerURL服务器的ip及端口号</span>
		<span class="token class-name">ConnectionFactory</span> connectionFactory <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ActiveMQConnectionFactory</span><span class="token punctuation">(</span><span class="token string">"tcp://192.168.25.168:61616"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
		<span class="token comment">// 第二步：使用ConnectionFactory对象创建一个Connection对象。</span>
		<span class="token class-name">Connection</span> connection <span class="token operator">=</span> connectionFactory<span class="token punctuation">.</span><span class="token function">createConnection</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
		<span class="token comment">// 第三步：开启连接，调用Connection对象的start方法。</span>
		connection<span class="token punctuation">.</span><span class="token function">start</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
		<span class="token comment">// 第四步：使用Connection对象创建一个Session对象。</span>
		<span class="token comment">// 第一个参数：是否开启事务。true：开启事务，第二个参数忽略。</span>
		<span class="token comment">// 第二个参数：当第一个参数为false时，才有意义。消息的应答模式。1、自动应答2、手动应答。一般是自动应答。</span>
		<span class="token class-name">Session</span> session <span class="token operator">=</span> connection<span class="token punctuation">.</span><span class="token function">createSession</span><span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token class-name">Session</span><span class="token punctuation">.</span><span class="token constant">AUTO_ACKNOWLEDGE</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
		<span class="token comment">// 第五步：使用Session对象创建一个Destination对象（topic、queue），此处创建一个topic对象。</span>
		<span class="token comment">// 参数：话题的名称。</span>
		<span class="token class-name">Topic</span> topic <span class="token operator">=</span> session<span class="token punctuation">.</span><span class="token function">createTopic</span><span class="token punctuation">(</span><span class="token string">"test-topic"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
		<span class="token comment">// 第六步：使用Session对象创建一个Producer对象。</span>
		<span class="token class-name">MessageProducer</span> producer <span class="token operator">=</span> session<span class="token punctuation">.</span><span class="token function">createProducer</span><span class="token punctuation">(</span>topic<span class="token punctuation">)</span><span class="token punctuation">;</span>
		<span class="token comment">// 第七步：创建一个Message对象，创建一个TextMessage对象。</span>
		<span class="token comment">/*
		* TextMessage message = new ActiveMQTextMessage(); message.setText(
		* "hello activeMq,this is my first test.");
		*/</span>
		<span class="token class-name">TextMessage</span> textMessage <span class="token operator">=</span> session<span class="token punctuation">.</span><span class="token function">createTextMessage</span><span class="token punctuation">(</span><span class="token string">"hello activeMq,this is my topic test"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
		<span class="token comment">// 第八步：使用Producer对象发送消息。</span>
		producer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span>textMessage<span class="token punctuation">)</span><span class="token punctuation">;</span>
		<span class="token comment">// 第九步：关闭资源。</span>
		producer<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
		session<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
		connection<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
	<span class="token punctuation">}</span>

	<span class="token class-name">Consumer</span>
	消费者：接收消息。
	第一步：创建一个<span class="token class-name">ConnectionFactory</span>对象。
	第二步：从<span class="token class-name">ConnectionFactory</span>对象中获得一个<span class="token class-name">Connection</span>对象。
	第三步：开启连接。调用<span class="token class-name">Connection</span>对象的start方法。
	第四步：使用<span class="token class-name">Connection</span>对象创建一个<span class="token class-name">Session</span>对象。
	第五步：使用<span class="token class-name">Session</span>对象创建一个<span class="token class-name">Destination</span>对象。和发送端保持一致topic，并且话题的名称一致。
	第六步：使用<span class="token class-name">Session</span>对象创建一个<span class="token class-name">Consumer</span>对象。
	第七步：接收消息。
	第八步：打印消息。
	第九步：关闭资源
	<span class="token annotation punctuation">@Test</span>
	<span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">testTopicConsumer</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">{</span>
		<span class="token comment">// 第一步：创建一个ConnectionFactory对象。</span>
		<span class="token class-name">ConnectionFactory</span> connectionFactory <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ActiveMQConnectionFactory</span><span class="token punctuation">(</span><span class="token string">"tcp://192.168.25.168:61616"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
		<span class="token comment">// 第二步：从ConnectionFactory对象中获得一个Connection对象。</span>
		<span class="token class-name">Connection</span> connection <span class="token operator">=</span> connectionFactory<span class="token punctuation">.</span><span class="token function">createConnection</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
		<span class="token comment">// 第三步：开启连接。调用Connection对象的start方法。</span>
		connection<span class="token punctuation">.</span><span class="token function">start</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
		<span class="token comment">// 第四步：使用Connection对象创建一个Session对象。</span>
		<span class="token class-name">Session</span> session <span class="token operator">=</span> connection<span class="token punctuation">.</span><span class="token function">createSession</span><span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token class-name">Session</span><span class="token punctuation">.</span><span class="token constant">AUTO_ACKNOWLEDGE</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
		<span class="token comment">// 第五步：使用Session对象创建一个Destination对象。和发送端保持一致topic，并且话题的名称一致。</span>
		<span class="token class-name">Topic</span> topic <span class="token operator">=</span> session<span class="token punctuation">.</span><span class="token function">createTopic</span><span class="token punctuation">(</span><span class="token string">"test-topic"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
		<span class="token comment">// 第六步：使用Session对象创建一个Consumer对象。</span>
		<span class="token class-name">MessageConsumer</span> consumer <span class="token operator">=</span> session<span class="token punctuation">.</span><span class="token function">createConsumer</span><span class="token punctuation">(</span>topic<span class="token punctuation">)</span><span class="token punctuation">;</span>
		<span class="token comment">// 第七步：接收消息。</span>
		consumer<span class="token punctuation">.</span><span class="token function">setMessageListener</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">MessageListener</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>

			<span class="token annotation punctuation">@Override</span>
			<span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">onMessage</span><span class="token punctuation">(</span><span class="token class-name">Message</span> message<span class="token punctuation">)</span> <span class="token punctuation">{</span>
				<span class="token keyword">try</span> <span class="token punctuation">{</span>
					<span class="token class-name">TextMessage</span> textMessage <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token class-name">TextMessage</span><span class="token punctuation">)</span> message<span class="token punctuation">;</span>
					<span class="token class-name">String</span> text <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">;</span>
					<span class="token comment">// 取消息的内容</span>
					text <span class="token operator">=</span> textMessage<span class="token punctuation">.</span><span class="token function">getText</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
					<span class="token comment">// 第八步：打印消息。</span>
					<span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">;</span>
				<span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">JMSException</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>
					e<span class="token punctuation">.</span><span class="token function">printStackTrace</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
				<span class="token punctuation">}</span>
			<span class="token punctuation">}</span>
		<span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
		<span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"topic的消费端03。。。。。"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
		<span class="token comment">// 等待键盘输入</span>
		<span class="token class-name">System</span><span class="token punctuation">.</span>in<span class="token punctuation">.</span><span class="token function">read</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
		<span class="token comment">// 第九步：关闭资源</span>
		consumer<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
		session<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
		connection<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
	<span class="token punctuation">}</span>
</code></pre></div>]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/92a0cb632b97d682ef936.png" type="image/png"/>
    </item>
    <item>
      <title>RabbitMQ</title>
      <link>https://javaguide.cn/backend/mq/rabbitmq.html</link>
      <guid>https://javaguide.cn/backend/mq/rabbitmq.html</guid>
      <source url="https://javaguide.cn/rss.xml">RabbitMQ</source>
      <description>RabbitMQ是什么？有什么特点？ RabbitMQ 是一个由 Erlang 语言开发的 AMQP 的开源实现。 可靠性（Reliability） 灵活的路由（Flexible Routing）：在消息进入队列之前，通过 Exchange 来路由消息的。对于典型的路由功能，RabbitMQ 已经提供了一些内置的 Exchange 来实现。针对更复杂的...</description>
      <category>后端</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<!--more-->
<h2>RabbitMQ是什么？有什么特点？</h2>
<ul>
<li>RabbitMQ 是一个由 Erlang 语言开发的 AMQP 的开源实现。</li>
<li>可靠性（Reliability）</li>
<li>灵活的路由（Flexible Routing）：在消息进入队列之前，通过 Exchange 来路由消息的。对于典型的路由功能，RabbitMQ 已经提供了一些内置的 Exchange 来实现。针对更复杂的路由功能，可以将多个 Exchange 绑定在一起，也通过插件机制实现自己的 Exchange 。</li>
<li>消息集群（Clustering）多个 RabbitMQ 服务器可以组成一个集群，形成一个逻辑 Broker 。</li>
<li>高可用（Highly Available Queues）：队列可以在集群中的机器上进行镜像，使得在部分节点出问题的情况下队列仍然可用。</li>
<li>多种协议（Multi-protocol）RabbitMQ 支持多种消息队列协议，比如 STOMP、MQTT 等等。</li>
<li>多语言客户端（Many Clients）RabbitMQ 几乎支持所有常用语言，比如 Java、.NET、Ruby 等等</li>
<li>管理界面（Management UI）RabbitMQ 提供了一个易用的用户界面，使得用户可以监控和管理消息 Broker 的许多方面。</li>
<li>跟踪机制（Tracing）如果消息异常，RabbitMQ 提供了消息跟踪机制，使用者可以找出发生了什么。</li>
<li>插件机制（Plugin System）RabbitMQ 提供了许多插件，来从多方面进行扩展，也可以编写自己的插件。</li>
</ul>
<h2>RabbitMQ架构</h2>
<ul>
<li>RabbitMQ 整体上是一个生产者与消费者模型，主要负责接收、存储和转发消息。从计算机术语层面来说， RabbitMQ 模型更像是一种交换机模型。 RabbitMQ主要包含下面几个部分：
<ul>
<li>Producer投递消息</li>
<li>Consumer接收消息</li>
<li>QueueRabbitMQ不支持队列层面广播消费</li>
<li>Exchange生产者将消息发到交换器，交换器再将数据路由到队列。如果路由不到，或许会返回给生产者，或许直接丢弃。包括fanout、direct、topic、headers类型</li>
<li>Broker一个Broker可以看做一个RabbitMQ服务节点或者服务实例</li>
<li>RoutingKey路由键，指定这个消息的路由规则</li>
<li>BindingKey绑定键，关联交换器与队列</li>
<li>payload消息体</li>
<li>标签（Label）用来表述消息，比如一个交换器的名称和一个路由键。生产者把消息交由RabbitMO， RabbitMQ 之后会根据标签把消息发送给感兴趣的消费者（Consumer）在消息路由的过程中，消息的标签会丢弃，存入到队列中的消息只有消息体，消费者只会消费到消息体，也就不知道消息的生产者是谁，当然消费者也不需要知道。<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/d8d150d08c11c7e9502e2.jpg" alt="RabbitMQ架构.jpg"></li>
</ul>
</li>
</ul>
<h2>RabbitMQ消息消费过程√</h2>
<ul>
<li>生产者发送消息
<ul>
<li>生产者连接到 RabbitMO Broker，建立一个TCP 连接（Connection），开启一个信道（Channel）</li>
<li>生产者声明一个Exchange(交换器)，并设置相关属性，比如交换机类型、是否持久化等</li>
<li>生产者声明一个队列并设置相关属性，比如是否排他、是否持久化、是否自动删除等</li>
<li>生产者通过 bindingKey(绑定 Key)将交换器和队列绑定(binding)起来</li>
<li>生产者发送消息至 RabbitMO Broker，其中包含routingKey(路由键)、交换器等信息</li>
<li>相应的交换器根据接收到的路由键routingKey查找相匹配的队列。</li>
<li>如果找到，则将从生产者发送过来的消息存入相应的队列中。</li>
<li>如果没有找到，则根据生产者配置的属性选择丢弃还是回退给生产者</li>
<li>关闭信道。</li>
<li>关闭连接。</li>
</ul>
</li>
<li>消费者接收消息
<ul>
<li>消费者连接到 RabbitMQ Broker，建立一个连接（Connection），开启一个信道（Channel）。连接到 RabbitMQ，准备进行通信。</li>
<li>消费者向 RabbitMQ Broker 请求消费相应队列中的消息，消费者声明消费某个队列的消息，可能会设置相应的回调函数，以及做一些准备工作</li>
<li>等待 RabbitMQ Broker 回应并投递相应队列中的消息，消费者开始从队列中接收消息。</li>
<li>消费者确认（ack）接收到的消息。收到消息后，消费者发送确认信号，表示已成功处理该消息。</li>
<li>RabbitMQ 从队列中删除相应已经被确认的消息。消息被确认后，从队列中移除，确保不再被投递。</li>
<li>关闭信道。</li>
<li>关闭与RabbitMQ Broker的连接</li>
</ul>
</li>
</ul>
<h2>如何保证消息不丢失？可靠性传输？</h2>
<h3>生产者丢失了数据</h3>
<ul>
<li>RabbitMQ 提供事务功能，就是生产者发送数据之前开启 RabbitMQ 事务channel.txSelect，然后发送消息，如果消息没有成功被 RabbitMQ 接收到，那么生产者会收到异常报错，此时就可以回滚事务channel.txRollback，然后重试发送消息；如果收到了消息，那么可以提交事务channel.txCommit</li>
<li>RabbitMQ 提供 confirm 模式，每次写的消息都会分配一个唯一的 id，然后如果写入了 RabbitMQ 中，首先会发送到Exchange，无论成功与否都回调函数confirm()返回ack消息。第二步从Exchange路由分配到Queue中，如果失败则回调函数returnedMessage()。</li>
<li>事务机制和 confirm 机制最大的不同在于，事务机制是同步的，你提交一个事务之后会阻塞在那儿，但是 confirm 机制是异步的，你发送个消息之后就可以发送下一个消息，然后那个消息 RabbitMQ 接收了之后会异步回调你的一个接口通知你这个消息接收到了。所以一般在生产者这块避免数据丢失，都是用 confirm 机制的。</li>
</ul>
<h3>RabbitMQ（broker）丢失了数据</h3>
<ul>
<li>创建 queue 的时候将其设置为持久化保证 RabbitMQ 持久化 queue 的元数据， durable 设置为 true.创建Exchange时设置为持久化</li>
<li>发送消息的时候将消息的 deliveryMode 设置为 2。就是将消息设置为持久化的，此时 RabbitMQ 就会将消息持久化到磁盘上去。</li>
</ul>
<h3>消费端丢失数据</h3>
<ul>
<li>RabbitMQ 提供的自动 ack 机制，将acknowledge-mode改为手动模式，业务处理成功后通过一个 api 来调用关闭 RabbitMQ 的自动ack ，如果RabbitMQ认为你还没处理完，这个时候 RabbitMQ 会把这个消费分配给别的 consumer 去处理，消息是不会丢的。</li>
</ul>
<h2>顺序消息</h2>
<h3>错乱场景</h3>
<ul>
<li>一个queue对应多个consumer，consumer从MQ里面读取数据是有序的，但是无法保证先读到消息的consumer一定先完成操作，这样就会出现消息并没有按照顺序执行，造成数据顺序错误。</li>
<li>一个queue对应一个consumer，但是consumer里面进行了多线程消费</li>
</ul>
<h3>解决方案</h3>
<ul>
<li>根据业务拆分成不同queue，比如同一个订单号用同一个queue，同一个queue使用同一个consumer去消费</li>
<li>一个queue对应一个consumer，然后这个consumer内部用内存队列做排队,分发给不同线程去处理</li>
</ul>
<h2>高可用</h2>
<h3>普通集群模式(非高可用)</h3>
<ul>
<li>在多台机器上启动多个 RabbitMQ 实例，每个机器启动一个。queue只会放在一个 RabbitMQ 实例上，但是每个实例都同步 queue 的元数据（queue 的一些配置信息包括 queue 所在实例）。消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从 queue 所在实例上拉取数据过来。此时要么消费者每次随机连接一个实例然后拉取数据，要么固定连接那个 queue 所在实例消费数据，前者有数据拉取的开销，后者导致单实例性能瓶颈。而且如果那个放 queue 的实例宕机了，会导致接下来其他实例就无法从那个实例拉取，如果你开启了消息持久化，让 RabbitMQ 落地存储消息的话，消息不一定会丢，得等这个实例恢复了，然后才可以继续从这个 queue 拉取数据。这就没有什么所谓的高可用性，这方案主要是提高吞吐量的，就是说让集群中多个节点来服务某个 queue 的读写操作</li>
</ul>
<h3>在镜像集群模式(高可用)</h3>
<ul>
<li>每个 RabbitMQ 节点都有这个 queue 的一个完整镜像，包含 queue 的全部数据(元数据和消息)。然后每次你写消息到 queue 的时候，都会自动把消息同步到多个实例的 queue 上</li>
<li>在RabbitMQ管理控制台新增一个镜像集群模式的策略，指定的时候是可以要求数据同步到所有节点的，也可以要求同步到指定数量的节点，再次创建 queue 的时候，应用这个策略，就会自动将数据同步到其他的节点上去了</li>
<li>优点，高可用，某个节点宕机不影响集群，别的 consumer 都可以到其它节点上去消费数据</li>
<li>缺点，性能开销太大，消息需要同步到所有机器上，导致网络带宽压力和消耗很重；扩展性可言太差，加的机器也包含了这个 queue 的所有数据，并没有办法线性扩展你的 queue</li>
<li>另外，由于每个节点都保存了副本，所以我们还可以通过HAProxy实现负载均衡</li>
</ul>
]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/d8d150d08c11c7e9502e2.jpg" type="image/jpeg"/>
    </item>
    <item>
      <title>RocketMQ</title>
      <link>https://javaguide.cn/backend/mq/rocketmq.html</link>
      <guid>https://javaguide.cn/backend/mq/rocketmq.html</guid>
      <source url="https://javaguide.cn/rss.xml">RocketMQ</source>
      <description>1. 什么是rocketmq？ 2. RocketMQ 由哪些角色组成？ 3. RocketMQ 的整体流程？ 4. Producer 发送消息有几种方式？ 5. 消费者消费模式有几种？ 6. 消费者获取消息有几种模式？ 7. 如何对消息进行重放？ 8. 顺序消息 9. 如何防止消息丢失？可靠性传输？ 10. 高可用 1. 什么是rocketmq？ R...</description>
      <category>后端</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<!-- TOC -->
<ul>
<li><a href="#1-%E4%BB%80%E4%B9%88%E6%98%AFrocketmq">1. 什么是rocketmq？</a></li>
<li><a href="#2-rocketmq-%E7%94%B1%E5%93%AA%E4%BA%9B%E8%A7%92%E8%89%B2%E7%BB%84%E6%88%90">2. RocketMQ 由哪些角色组成？</a></li>
<li><a href="#3-rocketmq-%E7%9A%84%E6%95%B4%E4%BD%93%E6%B5%81%E7%A8%8B">3. RocketMQ 的整体流程？</a></li>
<li><a href="#4-producer-%E5%8F%91%E9%80%81%E6%B6%88%E6%81%AF%E6%9C%89%E5%87%A0%E7%A7%8D%E6%96%B9%E5%BC%8F">4. Producer 发送消息有几种方式？</a></li>
<li><a href="#5-%E6%B6%88%E8%B4%B9%E8%80%85%E6%B6%88%E8%B4%B9%E6%A8%A1%E5%BC%8F%E6%9C%89%E5%87%A0%E7%A7%8D">5. 消费者消费模式有几种？</a></li>
<li><a href="#6-%E6%B6%88%E8%B4%B9%E8%80%85%E8%8E%B7%E5%8F%96%E6%B6%88%E6%81%AF%E6%9C%89%E5%87%A0%E7%A7%8D%E6%A8%A1%E5%BC%8F">6. 消费者获取消息有几种模式？</a></li>
<li><a href="#7-%E5%A6%82%E4%BD%95%E5%AF%B9%E6%B6%88%E6%81%AF%E8%BF%9B%E8%A1%8C%E9%87%8D%E6%94%BE">7. 如何对消息进行重放？</a></li>
<li><a href="#8-%E9%A1%BA%E5%BA%8F%E6%B6%88%E6%81%AF">8. 顺序消息</a></li>
<li><a href="#9-%E5%A6%82%E4%BD%95%E9%98%B2%E6%AD%A2%E6%B6%88%E6%81%AF%E4%B8%A2%E5%A4%B1%E5%8F%AF%E9%9D%A0%E6%80%A7%E4%BC%A0%E8%BE%93">9. 如何防止消息丢失？可靠性传输？</a></li>
<li><a href="#10-%E9%AB%98%E5%8F%AF%E7%94%A8">10. 高可用</a></li>
</ul>
<!-- /TOC -->
<h1>1. 什么是rocketmq？</h1>
<ul>
<li>RocketMQ 是阿里巴巴在 2012 年开源的分布式消息中间件</li>
<li>RocketMQ在阿里集团被广泛应用在订单，交易，充值，流计算，消息推送，日志流式处理， binglog 分发等场景。</li>
</ul>
<h1>2. RocketMQ 由哪些角色组成？</h1>
<ul>
<li>生产者（Producer）：负责产生消息，生产者向消息服务器发送由业务应用程序系统生成的消息。</li>
<li>消费者（Consumer）：负责消费消息，消费者从消息服务器拉取信息并将其输入用户应用程序。</li>
<li>消息服务器（Broker）：是消息存储中心，主要作用是接收来自 Producer 的消息并存储， Consumer 从这里取得消息。</li>
<li>名称服务器（NameServer）：用来保存 Broker 相关 Topic 等元信息并给 Producer ，提供 Consumer 查找 Broker 信息。</li>
</ul>
<h1>3. RocketMQ 的整体流程？</h1>
<ul>
<li>Nameserver启动后监听端口，等待 Broker、Producer、Consumer 连上来，相当于一个路由控制中心。</li>
<li>Broker启动，跟所有的 Namesrv 保持长连接，定时发送心跳包（包含当前 Broker 信息(IP+端口等)以及存储所有 Topic 信息。注册成功后，Nameserver集群中就有Topic跟Broker的映射关系）收发消息前，先创建Topic 。创建 Topic时，需要指定该Topic要存储在哪些Broker上。也可以在发送消息时自动创建Topic</li>
<li>Producer 发送消息。启动时，先跟 Namesrv 集群中的其中一台建立长连接，并从Namesrv 中获取当前发送的 Topic 存在哪些 Broker 上，然后跟对应的 Broker 建立长连接，直接向 Broker 发消息。</li>
<li>Consumer 消费消息。跟其中一台 Namesrv 建立长连接，获取当前订阅 Topic 存在哪些 Broker 上，然后直接跟 Broker 建立连接通道，开始消费消息。</li>
</ul>
<h1>4. Producer 发送消息有几种方式？</h1>
<ul>
<li>同步方式</li>
<li>异步方式</li>
<li>Oneway 方式 适合大数据场景，允许有一定消息丢失的场景。如日志</li>
</ul>
<h1>5. 消费者消费模式有几种？</h1>
<ul>
<li>集群消费：一个 Consumer Group 中的各个 Consumer 实例分摊去消费消息，即一条消息只会被 Consumer Group 中的一个Consumer消费一次。</li>
<li>广播消费：一 个Consumer Group 下的各个 Consumer 实例都投递一遍。即一条消息消息会被 Consumer Group 中的每个Consumer消费一次。</li>
</ul>
<h1>6. 消费者获取消息有几种模式？</h1>
<ul>
<li>PushConsumer推送模式:（虽然 RocketMQ 使用的是长轮询）的消费者。消息的能及时被消费。使用非常简单，内部已处理如线程池消费、流控、负载均衡、异常处理等等的各种场景。</li>
<li>PullConsumer拉取模式的消费者。应用主动控制拉取的时机，怎么拉取，怎么消费等。主动权更高。但要自己处理各种场景。</li>
</ul>
<h1>7. 如何对消息进行重放？</h1>
<ul>
<li>消费位点就是一个数字，把 Consumer Offset 改一下，就可以达到重放的目的了。</li>
</ul>
<h1>8. 顺序消息</h1>
<ul>
<li>生产者必须单一生产者串行发送,使用 MessageQueueSelector 为某一批消息（通常是有相同的唯一标示id）选择同一个 Queue ，则这一批消息的消费将是顺序消息（并由同一个consumer完成消费）。</li>
<li>消费者类型必须为PushConsumer消息消费的顺序性需要由业务方自行保证。</li>
<li>普通顺序消息:正常情况下可以保证完全的顺序消息，但是一旦发生异常，Broker 宕机或重启，由于队列总数发生发化，消费者会触发负载均衡，而默认地负载均衡算法采取哈希取模平均，这样负载均衡分配到定位的队列会发化，使得队列可能分配到别的实例上，则会短暂地出现消息顺序不一致。如果业务能容忍在集群异常情况（如某个 Broker 宕机或者重启）下，消息短暂的乱序，使用普通顺序方式比较合适。</li>
<li>严格顺序消息：无论正常异常情况都能保证顺序，牺牲了分布式 Failover 特性，即 Broker 集群中只要有一台机器不可用，则整个集群都不可用，服务可用性大大降低。如果服务器部署为同步双写模式，此缺陷可通过备机自动切换为主避免，不过仍然会存在几分钟的服务不可用。（依赖同步双写，主备自动切换，自动切换功能目前并未实现）</li>
</ul>
<h1>9. 如何防止消息丢失？可靠性传输？</h1>
<ul>
<li>
<p>生产者将消息发送给Rocket MQ的时候，如果出现了网络抖动或者通信异常等问题，消息就有可能会丢失。（rocketmq事务，先发送half消息，然后rocketmq返回ack，执行本地事务，成功则发送commit，失败rollback，如果commit或者rollback消息处理会有消息状态回查）</p>
</li>
<li>
<p>RocketMQ为了减少磁盘的IO，会先将消息写入到os cache中，而不是直接写入到磁盘中，隔一段时间后异步持久化到磁盘，在os cache中消息就有可能会丢失（rocketmq集群，异步刷盘策略改为同步刷盘，异步复制改为同步复制）</p>
</li>
<li>
<p>消费者成功从RocketMQ中获取到了消息，还没有将消息完全消费完的时候，就通知RocketMQ我已经将消息消费了，然后消费者宕机，但是RocketMQ认为消费者已经成功消费了数据，所以数据依旧丢失了。<br>
当你的消息处理完毕之后，才会返回ConsumeConcurrentlyStatus.CONSUME_SUCCESS 只有返回了CONSUME_SUCCESS，消费者才会告诉RocketMQ我已经消费完了，此时如果消费者宕机，消息已经处理完了，也就不会丢失消息了</p>
</li>
<li>
<p>RocketMQ 采用文件系统的方式来存储消息，消息的主要存储文件包括 CommitLog 文件、ConsumeQueue 文件、IndexFile 文件。</p>
</li>
<li>
<p>Producer 将消息发送到 Broker 后，Broker 会采用同步或者异步的方式把消息写入到 CommitLog。RocketMQ 所有的消息都会存放在 CommitLog 中。对 CommitLog 写之前会加锁。只要消息被持久化到磁盘文件 CommitLog，那么就可以保证 Producer 发送的消息不会丢失。commitLog是顺序写的</p>
</li>
<li>
<p>CommitLog 持久化后，会把里面的消息 Dispatch 到对应的 Consume Queue 上，是一个逻辑队列，存储了这个 Queue 在 CommitLog 中的起始 Offset，log 大小和 MessageTag 的 hashCode。</p>
</li>
<li>
<p>当消费者进行消息消费时，会先读取 ConsumerQueue，逻辑消费队列 ConsumeQueue 保存了指定 Topic 下的队列消息在 CommitLog 中的起始物理偏移量 Offset，消息大小、和消息 Tag 的 HashCode 值</p>
</li>
<li>
<p>直接从 ConsumerQueue 中读取消息是没有数据的，真正的消息主体在 CommitLog 中，所以还需要从 CommitLog 中读取消息。</p>
</li>
<li>
<p>消费用的观察者模式</p>
</li>
</ul>
<h1>10. 高可用</h1>
<ul>
<li>多节点（集群）多副本模式-异步复制</li>
<li>多节点（集群）多副本模式-同步复制</li>
</ul>
]]></content:encoded>
    </item>
    <item>
      <title>Hibernate</title>
      <link>https://javaguide.cn/backend/ormframework/hibernate.html</link>
      <guid>https://javaguide.cn/backend/ormframework/hibernate.html</guid>
      <source url="https://javaguide.cn/rss.xml">Hibernate</source>
      <description>hibernate 1. hibernate介绍 2. hibernate框架5.0的搭建 3. hibernate-API 4. hibernate对象状态（3种） 5. hibernate一级缓存+快照 6. hibernate事务 7. no-session问题及其解决方案 8. hibernate关系映射 8.1. 一对多|多对一 8.2. 多...</description>
      <category>后端</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>hibernate</p>
<!--more-->
<!-- TOC -->
<ul>
<li><a href="#1-hibernate%E4%BB%8B%E7%BB%8D">1. hibernate介绍</a></li>
<li><a href="#2-hibernate%E6%A1%86%E6%9E%B650%E7%9A%84%E6%90%AD%E5%BB%BA">2. hibernate框架5.0的搭建</a></li>
<li><a href="#3-hibernate-api">3. hibernate-API</a></li>
<li><a href="#4-hibernate%E5%AF%B9%E8%B1%A1%E7%8A%B6%E6%80%813%E7%A7%8D">4. hibernate对象状态（3种）</a></li>
<li><a href="#5-hibernate%E4%B8%80%E7%BA%A7%E7%BC%93%E5%AD%98%E5%BF%AB%E7%85%A7">5. hibernate一级缓存+快照</a></li>
<li><a href="#6-hibernate%E4%BA%8B%E5%8A%A1">6. hibernate事务</a></li>
<li><a href="#7-no-session%E9%97%AE%E9%A2%98%E5%8F%8A%E5%85%B6%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88">7. no-session问题及其解决方案</a></li>
<li><a href="#8-hibernate%E5%85%B3%E7%B3%BB%E6%98%A0%E5%B0%84">8. hibernate关系映射</a>
<ul>
<li><a href="#81-%E4%B8%80%E5%AF%B9%E5%A4%9A%E5%A4%9A%E5%AF%B9%E4%B8%80">8.1. 一对多|多对一</a></li>
<li><a href="#82-%E5%A4%9A%E5%AF%B9%E5%A4%9A">8.2. 多对多</a></li>
</ul>
</li>
<li><a href="#9-%E6%9F%A5%E8%AF%A2%E6%80%BB%E7%BB%93session">9. 查询总结(session)</a>
<ul>
<li><a href="#91-oid%E6%9F%A5%E8%AF%A2-get">9.1. oid查询-get</a></li>
<li><a href="#92-%E5%AF%B9%E8%B1%A1%E5%B1%9E%E6%80%A7%E5%AF%BC%E8%88%AA%E6%9F%A5%E8%AF%A2">9.2. 对象属性导航查询</a></li>
<li><a href="#93-hql%E6%9F%A5%E8%AF%A2-%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%9A%84%E6%9F%A5%E8%AF%A2%E8%AF%AD%E8%A8%80%E5%A4%9A%E8%A1%A8%E6%9F%A5%E8%AF%A2">9.3. HQL查询-面向对象的查询语言(多表查询)</a></li>
<li><a href="#94-%E5%8E%9F%E7%94%9Fsql%E5%A4%8D%E6%9D%82%E7%9A%84%E4%B8%9A%E5%8A%A1%E6%9F%A5%E8%AF%A2">9.4. 原生SQL：复杂的业务查询</a></li>
<li><a href="#95-criteria%E5%8D%95%E8%A1%A8%E6%9D%A1%E4%BB%B6%E6%9F%A5%E8%AF%A2">9.5. Criteria：(单表条件查询)</a></li>
</ul>
</li>
<li><a href="#10-%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96">10. 查询优化</a></li>
<li><a href="#11-hibernate%E6%8C%81%E4%B9%85%E5%B1%82%E6%8A%BD%E5%8F%96">11. hibernate持久层抽取</a></li>
</ul>
<!-- /TOC -->
<h1>1. hibernate介绍</h1>
<ul>
<li>hibernate是一款orm（orm:object relationg mapping. 对象关系映射）框架</li>
<li>其主要作用是在编程中，把面向对象的概念跟数据库中表的概念对应起来</li>
<li>hibernate官网<a href="http://hibernate.org/" target="_blank" rel="noopener noreferrer">http://hibernate.org/</a></li>
<li>hibernate文档<a href="http://hibernate.org/orm/documentation/5.4/" target="_blank" rel="noopener noreferrer">http://hibernate.org/orm/documentation/5.4/</a></li>
<li>操作数据库的时候,可以以面向对象的方式来完成.不需要书写SQL语句</li>
<li>orm分4级：hibernate属于完全面向对象操作数据库、mybatis属于2级、dbutils属于1级</li>
</ul>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/2204f0c7b2f5291d24e6d.png" alt="hibernate.jpg" tabindex="0"><figcaption>hibernate.jpg</figcaption></figure>
<h1>2. hibernate框架5.0的搭建</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>导包：web-content --&gt;web-INF--&gt;lib
hibernate-commons-annotations-5.0.1.Final.jar
hibernate-core-5.0.7.Final.jar
hibernate-jpa-2.1-api-1.0.0.Final.jar
jandex-2.0.0.Final.jar
javassist-3.18.1-GA.jar
jboss-logging-3.3.0.Final.jar
antlr-2.7.7.jar
dom4j-1.6.1.jar
geronimo-jta_1.1_spec-1.1.1.jar
mysql驱动包mysql-connector-java-5.1.7-bin.jar

建库建表，创建实体src目录的domain包下创建实体对象类(遵循以下规则)
- 不要用final修饰class,hibernate用cglib代理生成代理对象.代理对象是继承被代理对象.若被final修饰.将无法生成代理
- 成员变量私有,属性使用包装类型
- 提供get/set方法访问.需提供属性			
- 提供无参数构造
- 持久化类需要提供oid.与数据库中的主键列对应

orm元数据配置表与实体对象的关系配置文件src-&gt;表名.hbm.xml
- 导入mapping约束 window菜单--&gt; preference--&gt;cata
- 位置：Web App Libraries--hibernate-core-5.0.7.final.jar-org.hibernate-hibernate-mapping-3.0.dtd
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;!DOCTYPE hibernate-mapping PUBLIC 
"-//Hibernate/Hibernate Mapping DTD 3.0//EN"
"http://www.hibernate.org/dtd/hibernate-mapping-3.0.dtd"&gt;
&lt;!-- package属性:填写一个包名.在元素内部凡是需要书写完整类名的属性,可以直接写简单类名了. --&gt;
&lt;hibernate-mapping package="" &gt;
	&lt;!--class元素: 配置实体与表的对应关系的 name: 完整类名 table:数据库表名--&gt;
	&lt;class name="" table="" &gt;
		&lt;!-- id元素:配置主键映射的属性 name: 填写主键对应属性名
			column(可选): 填写表中的主键列名.默认值:列名会默认使用属性名
			type(可选):填写列(属性)的类型.hibernate会自动检测实体的属性类型.
					每个类型有三种填法: java类型|hibernate类型|数据库类型
			not-null(可选):配置该属性(列)是否不能为空. 默认值:false
			length(可选):配置数据库中列的长度. 默认值:使用数据库类型的最大长度--&gt;
		&lt;id name=""  column=""&gt;//属性名和列名
			&lt;generator class="native"&gt;&lt;/generator&gt;
			&lt;!--generator主键生成策略
			代理主键：
			identity : 主键自增.由数据库来维护主键值.录入时不需要指定主键.
			sequence: Oracle中的主键生成策略.
			hilo(了解): 高低位算法.主键自增.由hibernate来维护.开发时不使用.
			native:hilo+sequence+identity 自动三选一策略.（使用这个换数据库不用改）
			increment(了解): 主键自增.由hibernate来维护.每次插入前先查询表中id最大值+1作为新主键值.线程不安全，效率低开发不使用
			uuid: 产生随机字符串作为主键. 主键类型必须为string 类型.

			自然主键：assigned:自然主键生成策略. hibernate不会管理主键值.录入时指定主键. --&gt;
		&lt;/id&gt;
		&lt;property name="" column="" &gt;&lt;/property&gt;&lt;!--与上面差不多--&gt;
	&lt;/class&gt;
&lt;/hibernate-mapping&gt;

主配置文件(src目录--&gt;hibernate.cfg.xml)
- 导入configuration约束window菜单--&gt; preference--&gt;cata
- 位置Web App Libraries--hibernate-core-5.0.7.final.jar-org.hibernate-hibernate-configuration-3.0.dtd
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;!DOCTYPE hibernate-configuration PUBLIC
"-//Hibernate/Hibernate Configuration DTD 3.0//EN"
"http://www.hibernate.org/dtd/hibernate-configuration-3.0.dtd"&gt;
&lt;hibernate-configuration&gt;
	&lt;session-factory&gt;
		&lt;property name="hibernate.connection.driver_class"&gt;com.mysql.jdbc.Driver&lt;/property&gt; 
		&lt;property name="hibernate.connection.url"&gt;jdbc:mysql:///hibernate&lt;/property&gt;
		&lt;property name="hibernate.connection.username"&gt;root&lt;/property&gt;
		&lt;property name="hibernate.connection.password"&gt;1234&lt;/property&gt;
		&lt;property name="hibernate.dialect"&gt;org.hibernate.dialect.MySQLDialect&lt;/property&gt;

		&lt;property name="hibernate.show_sql"&gt;true&lt;/property&gt;
		&lt;property name="hibernate.format_sql"&gt;true&lt;/property&gt;
		&lt;!-- ## auto schema export  自动导出表结构. 自动建表
		create自动建表.每次框架运行都创建新表.以前表将会被覆盖,表数据会丢失.(开发测试使用)
		create-drop自动建表.每次框架运行结束都会将所有表删除.(开发环境中测试使用)
		update(推荐)自动生成表.如果已经存在不会再生成.如果表有变动.自动更新表(不删除任何数据)
		validate校验.不自动生成表.每次启动会校验数据库中表是否正确.校验失败.--&gt;
		&lt;property name="hibernate.hbm2ddl.auto"&gt;update&lt;/property&gt;	
		&lt;mapping resource="com/hechuangjun/domain/Customer.hbm.xml" /&gt;//引入orm元数据
		&lt;!--指定数据库的隔离级别
		hibernate.connection.isolation 1|2|4|8		
		0001	1	读未提交
		0010	2	读已提交
		0100	4	可重复读（mysql）默认
		1000	8	串行化--&gt;
		&lt;property name="hibernate.connection.isolation"&gt;4&lt;/property&gt;
		&lt;!-- 指定session与当前线程绑定 --&gt;
		&lt;property name="hibernate.current_session_context_class"&gt;thread&lt;/property&gt;
	&lt;/session-factory&gt;
&lt;/hibernate-configuration&gt;

测试
class Test Hibernate {
	@Test
	public void fun(){
		Configuration configuration = new Configuration().configure();
		SessionFactory sessionfactory = configuration.buildSessionFactory();
		Session session = sessionfactory.openSession();
		Transaction tx = session.beginTransaction();
		//</code></pre></div>]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/2204f0c7b2f5291d24e6d.png" type="image/png"/>
    </item>
    <item>
      <title>Mybatis</title>
      <link>https://javaguide.cn/backend/ormframework/mybatis.html</link>
      <guid>https://javaguide.cn/backend/ormframework/mybatis.html</guid>
      <source url="https://javaguide.cn/rss.xml">Mybatis</source>
      <description>Mybatis 1. Mybatis介绍 2. Mybatis架构 3. Mybatis入门程序 4. Mapper动态代理开发持久层方法 5. SqlMapConfig.xml配置文件 6. Mapper.xml 7. Mybatis整合spring 8. Mybatis逆向工程（了解） 9. 分页插件PageHelper 1. Mybatis介绍 ...</description>
      <category>后端</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>Mybatis</p>
<!--more-->
<!-- TOC -->
<ul>
<li><a href="#1-mybatis%E4%BB%8B%E7%BB%8D">1. Mybatis介绍</a></li>
<li><a href="#2-mybatis%E6%9E%B6%E6%9E%84">2. Mybatis架构</a></li>
<li><a href="#3-mybatis%E5%85%A5%E9%97%A8%E7%A8%8B%E5%BA%8F">3. Mybatis入门程序</a></li>
<li><a href="#4-mapper%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%E5%BC%80%E5%8F%91%E6%8C%81%E4%B9%85%E5%B1%82%E6%96%B9%E6%B3%95">4. Mapper动态代理开发持久层方法</a></li>
<li><a href="#5-sqlmapconfigxml%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6">5. SqlMapConfig.xml配置文件</a></li>
<li><a href="#6-mapperxml">6. Mapper.xml</a></li>
<li><a href="#7-mybatis%E6%95%B4%E5%90%88spring">7. Mybatis整合spring</a></li>
<li><a href="#8-mybatis%E9%80%86%E5%90%91%E5%B7%A5%E7%A8%8B%E4%BA%86%E8%A7%A3">8. Mybatis逆向工程（了解）</a></li>
<li><a href="#9-%E5%88%86%E9%A1%B5%E6%8F%92%E4%BB%B6pagehelper">9. 分页插件PageHelper</a></li>
</ul>
<!-- /TOC -->
<h1>1. Mybatis介绍</h1>
<ul>
<li>MyBatis是优秀的持久层框架，对jdbc的操作数据库的过程进行封装</li>
<li>使开发者只需要关注SQL本身，而不需要花费精力去处理例如注册驱动、创建connection、创建statement、手动设置参数、结果集检索等jdbc繁杂的过程代码</li>
<li>Mybatis通过xml或注解的方式将要执行的各种statement（statement、preparedStatemnt、CallableStatement）配置起来。并通过java对象和statement中的sql进行映射生成最终执行的sql语句，最后由mybatis框架执行sql并将结果映射成java对象并返回</li>
</ul>
<h1>2. Mybatis架构</h1>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/1500ef07f438bf61f8679.png" alt="mybatis.png" tabindex="0"><figcaption>mybatis.png</figcaption></figure>
<h1>3. Mybatis入门程序</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>导包
commons-logging-1.1.1.jar
javassist-3.17.1-GA.jar
log4j-1.2.17.jar
log4j-api-2.0-rc1.jar
log4j-core-2.0-rc1.jar
slf4j-api-1.7.5.jar
slf4j-log4j12-1.7.5.jar
asm-3.3.1.jar
cglib-2.2.2.jar

在src下创建log4j.properties
# Global logging configuration
log4j.rootLogger=DEBUG, stdout
# Console output...
log4j.appender.stdout=org.apache.log4j.ConsoleAppender
log4j.appender.stdout.layout=org.apache.log4j.PatternLayout
log4j.appender.stdout.layout.ConversionPattern=%5p [%t] - %m%n
mybatis默认使用log4j作为输出日志信息。
	
在src下创建SqlMapConfig.xml
SqlMapConfig.xml是mybatis核心配置文件，内容为数据源、事务管理
&lt;?xml version="1.0" encoding="UTF-8" ?&gt;
	&lt;!DOCTYPE configuration
	PUBLIC "-//mybatis.org//DTD Config 3.0//EN"
	"http://mybatis.org/dtd/mybatis-3-config.dtd"&gt;
	&lt;configuration&gt;
		&lt;!-- 和spring整合后 environments配置将废除 --&gt;
		&lt;environments default="development"&gt;
			&lt;environment id="development"&gt;
			&lt;!-- 使用jdbc事务管理 --&gt;
			&lt;transactionManager type="JDBC" /&gt;
				&lt;!-- 数据库连接池 --&gt;
				&lt;dataSource type="POOLED"&gt;
					&lt;property name="driver" value="com.mysql.jdbc.Driver" /&gt;
					&lt;property name="url" value="jdbc:mysql://localhost:3306/mybatis?characterEncoding=utf-8" /&gt;
					&lt;property name="username" value="root" /&gt;
					&lt;property name="password" value="root" /&gt;
				&lt;/dataSource&gt;
			&lt;/environment&gt;
		&lt;/environments&gt;
		&lt;!--加载配置文件--&gt;
		&lt;mappers&gt;
			&lt;mapper resource="sqlmap/User.xml"/&gt;
		&lt;/mappers&gt;
	&lt;/configuration&gt;

创建pojo类生成set、get方法并创建对应的表

在src下的sqlmap目录下创建sql映射文件User.xml
mybatis框架需要加载Mapper.xml映射文件 将user.xml添加在SqlMapConfig.xml
&lt;?xml version="1.0" encoding="UTF-8" ?&gt;
	&lt;!DOCTYPE mapper
	PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN"
	"http://mybatis.org/dtd/mybatis-3-mapper.dtd"&gt;
	&lt;!-- namespace：命名空间，用于隔离sql --&gt;
	&lt;mapper namespace="test"&gt;
	&lt;!-- id:statement的id 或者叫做sql的id--&gt;
	&lt;!-- parameterType:声明输入参数的类型 --&gt;
	&lt;!-- resultType:声明输出结果的类型，应该填写pojo的全路径 --&gt;
	&lt;!-- #{}：输入参数的占位符，相当于jdbc的？ --&gt;
	&lt;!--实现根据id查询用户（传入基本值）--&gt;
	&lt;select id="queryUserById" parameterType="int" resultType="cn.mybatis.pojo.User"&gt;
		SELECT * FROM `user` WHERE id  = #{id}
	&lt;/select&gt;
	&lt;!-- 如果返回多个结果，mybatis会自动把返回的结果放在list容器中 --&gt;
	&lt;!-- resultType的配置和返回一个结果的配置一样 --&gt;
	&lt;!-- ①方式一：实现根据用户名模糊查询用户 --&gt;
	&lt;select id="queryUserByUsername1" parameterType="string" resultType="cn.itcast.mybatis.pojo.User"&gt;
		SELECT * FROM `user` WHERE username LIKE #{username}
	&lt;/select&gt;
	&lt;!-- ②方式二：实现根据用户名模糊查询用户--&gt;
	&lt;!-- 如果传入的参数是简单数据类型，${}里面必须写value --&gt;
	&lt;select id="queryUserByUsername2" parameterType="string" resultType="cn.itcast.mybatis.pojo.User"&gt;
		SELECT * FROM `user` WHERE username LIKE '%${value}%'
	&lt;/select&gt;
	&lt;!-- 实现添加用户(传入对象) --&gt;
	&lt;insert id="saveUser" parameterType="cn.itcast.mybatis.pojo.User"&gt;
		INSERT INTO `user`
		(username,birthday,sex,address) VALUES
		(#{username},#{birthday},#{sex},#{address})
	&lt;/insert&gt;	
	&lt;!-- mysql自增主键返回--&gt;
	&lt;insert id="saveUser" parameterType="cn.mybatis.pojo.User"&gt;
	&lt;!-- selectKey 标签实现主键返回 --&gt;
	&lt;!-- keyColumn:主键对应的表中的哪一列 --&gt;
	&lt;!-- keyProperty：主键对应的pojo中的哪一个属性 --&gt;
	&lt;!-- order：设置在执行insert语句前执行查询id的sql，
	在执行insert语句之后执行查询id的sql --&gt;
	&lt;!-- resultType：设置返回的id的类型 --&gt;
	&lt;!-- LAST_INSERT_ID():是mysql的函数，返回auto_increment自增列新记录id值--&gt;
	&lt;selectKey keyColumn="id" keyProperty="id" order="AFTER" resultType="int"&gt;
		SELECT LAST_INSERT_ID()
	&lt;/selectKey&gt;
		INSERT INTO `user`
		(username,birthday,sex,address) VALUES
		(#{username},#{birthday},#{sex},#{address})
	&lt;/insert&gt;
	&lt;!--mysql uuid实现主键返回 注意这里使用的order是“BEFORE”--&gt;
	&lt;selectKey keyColumn="id" keyProperty="id" order="BEFORE" resultType="string"&gt;
		SELECT LAST_INSERT_ID()
	&lt;/selectKey&gt;
		INSERT INTO `user`
		(username,birthday,sex,address) VALUES
		(#{username},#{birthday},#{sex},#{address})
	&lt;/insert&gt;
	&lt;!--修改用户（传入对象）--&gt;
	&lt;update id="updateUserById" parameterType="cn.mybatis.pojo.User"&gt;
		UPDATE `user` SET username = #{username} WHERE id = #{id}
	&lt;/update&gt;		
	&lt;!-- 删除用户 --&gt;
	&lt;delete id="deleteUserById" parameterType="int"&gt;
		delete from user where id=#{id}
	&lt;/delete&gt;	
&lt;/mapper&gt;
		
测试程序：
1. 创建SqlSessionFactoryBuilder对象
2. 加载SqlMapConfig.xml配置文件
3. 创建SqlSessionFactory对象
4. 创建SqlSession对象
5. 执行SqlSession对象执行查询，获取结果User
6. 打印结果
7. 释放资源

public class MybatisTest {
	private SqlSessionFactory sqlSessionFactory = null;
	@Before
	public void init() throws Exception {
		SqlSessionFactoryBuilder sqlSessionFactoryBuilder = new SqlSessionFactoryBuilder();
		InputStream inputStream = Resources.getResourceAsStream("SqlMapConfig.xml");
		this.sqlSessionFactory = sqlSessionFactoryBuilder.build(inputStream);
	}
	@Test
	public void testQueryUserById() throws Exception {
		SqlSession sqlSession = sqlSessionFactory.openSession();
		Object user = sqlSession.selectOne("queryUserById", 1);
		sqlSession.close();
	}
	@Test
	public void testQueryUserByUsername1() throws Exception {
		SqlSession sqlSession = sqlSessionFactory.openSession();
		List&lt;Object&gt; list =  sqlSession.selectList("queryUserByUsername1", "%王%");
		for (Object user : list) {
			System.out.println(user);
		}
		sqlSession.close();
	}
	@Test
	public void testQueryUserByUsername2() throws Exception {
		SqlSession sqlSession = sqlSessionFactory.openSession();
		List&lt;Object&gt; list = sqlSession.selectList("queryUserByUsername2", "王");
		for (Object user : list) {
			System.out.println(user);
		}
		sqlSession.close();
	}	
	@Test
	public void testSaveUser() {
		SqlSession sqlSession = sqlSessionFactory.openSession();
		User user = new User();
		user.setUsername("张飞");
		user.setSex("1");
		user.setBirthday(new Date());
		user.setAddress("蜀国");
		sqlSession.insert("saveUser", user);
		System.out.println(user);
		sqlSession.commit();
		sqlSession.close();
	}
	@Test
	public void testUpdateUserById() {
		SqlSession sqlSession = sqlSessionFactory.openSession();
		User user = new User();
		user.setId(26);
		user.setUsername("关羽");
		user.setSex("1");
		user.setBirthday(new Date());
		user.setAddress("蜀国");
		sqlSession.update("updateUserById", user);
		sqlSession.commit();
		sqlSession.close();
	}
	@Test
	public void testDeleteUserById() {
		SqlSession sqlSession = sqlSessionFactory.openSession();
		sqlSession.delete("deleteUserById", 48);
		sqlSession.commit();
		sqlSession.close();
	}
}
</code></pre></div><h1>4. Mapper动态代理开发持久层方法</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>	Mapper接口开发方法只需编写Mapper接口（Dao接口），由Mybatis框架根据接口定义创建接口的动态代理对象遵循以下规范：
	1、Mapper.xml文件中的namespace与mapper接口的完整类名相同。
	2、Mapper接口方法名和Mapper.xml中定义的每个statement的id相同 
	3、Mapper接口方法的输入参数类型和mapper.xml中定义的每个sql的parameterType的类型相同
	4、Mapper接口方法的输出参数类型和mapper.xml中定义的每个sql的resultType的类型相同

	Mapper.xml(映射文件)必须满足规范
	&lt;?xml version="1.0" encoding="UTF-8" ?&gt;
		&lt;!DOCTYPE mapper
		PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN"
		"http://mybatis.org/dtd/mybatis-3-mapper.dtd"&gt;
		&lt;!-- namespace：命名空间，用于隔离sql 还有一个很重要的作用，使用动态代理开发DAO，
		1. namespace必须和Mapper接口类路径一致 --&gt;
		&lt;mapper namespace="cn.itcast.mybatis.mapper.UserMapper"&gt;
			&lt;!-- 根据用户id查询用户 --&gt;
			&lt;!-- 2. id必须和Mapper接口方法名一致 --&gt;
			&lt;!-- 3. parameterType必须和接口方法参数类型一致 --&gt;
			&lt;!-- 4. resultType必须和接口方法返回值类型一致 --&gt;
			&lt;select id="queryUserById" parameterType="int" resultType="cn.itcast.mybatis.pojo.User"&gt;
				select * from user where id = #{id}
			&lt;/select&gt;

			&lt;!-- 根据用户名查询用户 --&gt;
			&lt;select id="queryUserByUsername" parameterType="string" resultType="cn.itcast.mybatis.pojo.User"&gt;
				select * from user where username like '%${value}%'
			&lt;/select&gt;
		&lt;/mapper&gt;
	UserMapper(接口文件)
	public interface UserMapper {
		User queryUserById(int id);
		List&lt;User&gt; queryUserByUsername(String username);
		}
	SqlMapConfig.xml文件(一样)
	测试
	public class UserMapperTest {
		private SqlSessionFactory sqlSessionFactory;
		@Before
		public void init() throws Exception {
			SqlSessionFactoryBuilder sqlSessionFactoryBuilder = new SqlSessionFactoryBuilder();
			InputStream inputStream = Resources.getResourceAsStream("SqlMapConfig.xml");
			this.sqlSessionFactory = sqlSessionFactoryBuilder.build(inputStream);
		}
		@Test
		public void testQueryUserById() {
			SqlSession sqlSession = this.sqlSessionFactory.openSession();
			UserMapper userMapper = sqlSession.getMapper(UserMapper.class);
			User user = userMapper.queryUserById(1);
			System.out.println(user);
			sqlSession.close();
		}

		@Test
		public void testQueryUserByUsername() {
			SqlSession sqlSession = this.sqlSessionFactory.openSession();
			UserMapper userMapper = sqlSession.getMapper(UserMapper.class);
			List&lt;User&gt; list = userMapper.queryUserByUsername("张");
			for (User user : list) {
				System.out.println(user);
			}
			sqlSession.close();
			}
		}
	}
</code></pre></div><h1>5. SqlMapConfig.xml配置文件</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>	SqlMapConfig.xml中配置的内容和顺序如下：
	properties（属性）
	settings（全局配置参数）
	typeAliases（类型别名）
	typeHandlers（类型处理器）
	objectFactory（对象工厂）
	plugins（插件）
	environments（环境集合属性对象）
	environment（环境子属性对象）
	transactionManager（事务管理）
	dataSource（数据源）
	mappers（映射器）
	
	properties（属性）
	SqlMapConfig.xml可以引用java属性文件中的配置信息如下：
	在src下定义db.properties文件
	jdbc.driver=com.mysql.jdbc.Driver
	jdbc.url=jdbc:mysql://localhost:3306/mybatis?characterEncoding=utf-8
	jdbc.username=root
	jdbc.password=root

	MyBatis加载属性顺序：在properties元素中resource或 url 加载的属性，它会覆盖已读取的同名属性。 

	&lt;configuration&gt;
		&lt;!-- 是用resource属性加载外部配置文件 --&gt;
		&lt;properties resource="db.properties"&gt;
			&lt;!-- 在properties内部用property定义属性 --&gt;
			&lt;!-- 如果外部配置文件有该属性，则内部定义属性被外部属性覆盖 --&gt;
			&lt;property name="jdbc.username" value="root123" /&gt;
			&lt;property name="jdbc.password" value="root123" /&gt;	
		&lt;/properties&gt;
		&lt;typeAliases&gt;
			&lt;!-- 单个别名定义 在mapper.xml配置文件中，就可以使用设置的别名user了，别名大小写不敏感--&gt;
			&lt;typeAlias alias="user" type="cn.itcast.mybatis.pojo.User" /&gt;
			&lt;!-- 批量别名定义，扫描整个包下的类，别名为类名（大小写不敏感） --&gt;
			&lt;package name="cn.itcast.mybatis.pojo" /&gt;
			&lt;package name="其它包" /&gt;
		&lt;/typeAliases&gt;
		&lt;!-- 和spring整合后 environments配置将废除 --&gt;
		&lt;environments default="development"&gt;
			&lt;environment id="development"&gt;
				&lt;!-- 使用jdbc事务管理 --&gt;
				&lt;transactionManager type="JDBC" /&gt;
				&lt;!-- 数据库连接池 --&gt;
				&lt;dataSource type="POOLED"&gt;
					&lt;property name="driver" value="${jdbc.driver}" /&gt;
					&lt;property name="url" value="${jdbc.url}" /&gt;
					&lt;property name="username" value="${jdbc.username}" /&gt;
					&lt;property name="password" value="${jdbc.password}" /&gt;
				&lt;/dataSource&gt;
			&lt;/environment&gt;
		&lt;/environments&gt;
		&lt;mappers&gt;
			&lt;!-- mappers（映射器）加载Mapper.xml配置文件 --&gt;
			&lt;!-- ①使用相对于类路径的资源（现在的使用方式）原始dao第一种有用--&gt;
			&lt;mapper resource="sqlmap/User.xml" /&gt;
			&lt;!-- ②使用mapper接口类路径--&gt;
			&lt;!-- 要求mapper接口名称和mapper映射文件名称相同，且在同一个目录中 --&gt;
			&lt;!-- &lt;mapper class="cn.mybatis.mapper.UserMapper"/&gt;--&gt;
			&lt;!--③注册指定包下的所有mapper接口--&gt;
			&lt;!--&lt;package name="cn.itcast.mybatis.mapper"/&gt;--&gt;
			&lt;!--要求mapper接口名称和mapper映射文件名称相同，且放在同一个目录中。--&gt;
			&lt;!--整合spring后用代理方式开发的话，后两者没有用（默认）--&gt;			
		&lt;/mappers&gt;
	&lt;/configuration&gt;

</code></pre></div><table>
<thead>
<tr>
<th style="text-align:center">mybatis支持别名</th>
<th style="text-align:center">映射的类型</th>
<th style="text-align:center">别名</th>
<th style="text-align:center">映射的类型</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">_byte</td>
<td style="text-align:center">byte</td>
<td style="text-align:center">byte</td>
<td style="text-align:center">Byte</td>
</tr>
<tr>
<td style="text-align:center">_long</td>
<td style="text-align:center">long</td>
<td style="text-align:center">long</td>
<td style="text-align:center">Long</td>
</tr>
<tr>
<td style="text-align:center">_short</td>
<td style="text-align:center">short</td>
<td style="text-align:center">short</td>
<td style="text-align:center">Short</td>
</tr>
<tr>
<td style="text-align:center">_int</td>
<td style="text-align:center">int</td>
<td style="text-align:center">int</td>
<td style="text-align:center">Integer</td>
</tr>
<tr>
<td style="text-align:center">_integer</td>
<td style="text-align:center">int</td>
<td style="text-align:center">integer</td>
<td style="text-align:center">Integer</td>
</tr>
<tr>
<td style="text-align:center">_double</td>
<td style="text-align:center">double</td>
<td style="text-align:center">double</td>
<td style="text-align:center">Double</td>
</tr>
<tr>
<td style="text-align:center">_float</td>
<td style="text-align:center">float</td>
<td style="text-align:center">float</td>
<td style="text-align:center">Float</td>
</tr>
<tr>
<td style="text-align:center">_boolean</td>
<td style="text-align:center">boolean</td>
<td style="text-align:center">boolean</td>
<td style="text-align:center">Boolean</td>
</tr>
<tr>
<td style="text-align:center">string</td>
<td style="text-align:center">String</td>
<td style="text-align:center">date</td>
<td style="text-align:center">Date</td>
</tr>
<tr>
<td style="text-align:center">decimal</td>
<td style="text-align:center">BigDecimal</td>
<td style="text-align:center">bigdecimal</td>
<td style="text-align:center">BigDecimal</td>
</tr>
<tr>
<td style="text-align:center">map</td>
<td style="text-align:center">Map</td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
<h1>6. Mapper.xml</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>If标签
&lt;!--注意字符串类型的数据需要要做不等于空字符串校验。--&gt;
&lt;select id="queryUserByWhere" parameterType="user" resultType="user"&gt;
	SELECT id, username, birthday, sex, address FROM `user`
	WHERE 1=1
	&lt;if test="sex != null and sex != ''"&gt;
		AND sex = #{sex}
	&lt;/if&gt;
	&lt;if test="username != null and username != ''"&gt;
		AND username LIKE
		'%${username}%'
	&lt;/if&gt;
&lt;/select&gt;

Where标签
上面的sql还有where 1=1 这样的语句，很麻烦，可以使用where标签进行改造,只能处理前面的and，不能处理后置and
	改造UserMapper.xml，如下
	&lt;select id="queryUserByWhere" parameterType="user" resultType="user"&gt;
		SELECT id, username, birthday, sex, address FROM `user`
		&lt;!-- where标签可以自动添加where，同时处理sql语句中第一个and关键字 --&gt;
		&lt;where&gt;
			&lt;if test="sex != null"&gt;
				AND sex = #{sex}
			&lt;/if&gt;
			&lt;if test="username != null and username != ''"&gt;
				AND username LIKE
				'%${username}%'
			&lt;/if&gt;
		&lt;/where&gt;
	&lt;/select&gt;

Sql片段
Sql中可将重复的sql提取出来，使用时用include引用即可，达到sql重用的目的
&lt;select id="queryUserByWhere" parameterType="user" resultType="user"&gt;
	&lt;!-- SELECT id, username, birthday, sex, address FROM `user` --&gt;
	&lt;!-- 使用include标签加载sql片段；refid是sql片段id --&gt;
	SELECT &lt;include refid="userFields" /&gt; FROM `user`
&lt;/select&gt;

&lt;!-- 声明sql片段 如果要使用别的Mapper.xml配置的sql片段，可以在refid前面加上对应的Mapper.xml的namespace
refid="com.junye.userFields"--&gt;
&lt;sql id="userFields"&gt;
	id, username, birthday, sex, address
&lt;/sql&gt;

foreach标签
向sql传递数组或List，mybatis使用foreach解析
Integer[]→ collection="array"、
List&lt;Integer&gt;→ collection="list"
如果以上两个东西放进类中被包装了，那么用属性名表示
&lt;select id="queryUserByIds" parameterType="queryVo" resultType="user"&gt;
	SELECT * FROM `user`
	&lt;where&gt;
		&lt;!-- foreach标签，进行遍历 --&gt;
		&lt;!-- collection：遍历的集合，这里是QueryVo的ids属性 --&gt;
		&lt;!-- item：遍历的项目，可以随便写，，但是和后面的#{}里面要一致 --&gt;
		&lt;!-- open：在前面添加的sql片段 --&gt;
		&lt;!-- close：在结尾处添加的sql片段 --&gt;
		&lt;!-- separator：指定遍历的元素之间使用的分隔符 --&gt;
		&lt;foreach collection="ids" item="item" open="id IN (" close=")" separator=","&gt;
			#{item}
		&lt;/foreach&gt;
	&lt;/where&gt;
&lt;/select&gt;

一对多查询
在UserMapper.xml添加sql，如下：
resultMap，数据库字段与对象字段不一致时使用
&lt;resultMap type="user" id="userOrderResultMap"&gt;
	&lt;id property="id" column="id" /&gt;
	&lt;result property="username" column="username" /&gt;
	&lt;result property="birthday" column="birthday" /&gt;
	&lt;result property="sex" column="sex" /&gt;
	&lt;result property="address" column="address" /&gt;

	&lt;!-- 配置一对多的关系 --&gt;
	&lt;collection property="orders" javaType="list" ofType="order"&gt;
		&lt;!-- 配置主键，是关联Order的唯一标识 --&gt;
		&lt;id property="id" column="oid" /&gt;
		&lt;result property="number" column="number" /&gt;
		&lt;result property="createtime" column="createtime" /&gt;
		&lt;result property="note" column="note" /&gt;
	&lt;/collection&gt;
&lt;/resultMap&gt;
</code></pre></div><h1>7. Mybatis整合spring</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>整合思路
SqlSessionFactory对象应该放到spring容器中作为单例存在
Mapper代理形式中，应该从spring容器中直接获得mapper的代理对象
数据库的连接以及数据库连接池事务管理都交给spring容器来完成。

mybatis整合原理
SqlSessionFactoryBean implements FactoryBean&lt;SqlSessionFactory&gt;重写getobject方法返回SqlSessionFactory注入到spring中，
而SqlSessionFactoryBean将由开发人员在spring中声明，完美整合

整合需要的jar包
spring-core-4.1.3.RELEASE.jar
spring-expression-4.1.3.RELEASE.jar
spring-jdbc-4.1.3.RELEASE.jar
spring-jms-4.1.3.RELEASE.jar
spring-messaging-4.1.3.RELEASE.jar
spring-tx-4.1.3.RELEASE.jar
spring-web-4.1.3.RELEASE.jar
spring-webmvc-4.1.3.RELEASE.jar
aopalliance-1.0.jar
asm-3.3.1.jar
aspectjweaver-1.6.11.jar
cglib-2.2.2.jar
commons-dbcp-1.2.2.jar
commons-logging-1.1.1.jar
commons-pool-1.3.jar
javassist-3.17.1-GA.jar
jstl-1.2.jar
junit-4.9.jar
log4j-1.2.17.jar
log4j-api-2.0-rc1.jar
log4j-core-2.0-rc1.jar
mybatis-3.2.7.jar
mybatis-spring-1.2.2.jar
mysql-connector-java-5.1.7-bin.jar
slf4j-api-1.7.5.jar
slf4j-log4j12-1.7.5.jar
spring-aop-4.1.3.RELEASE.jar
spring-aspects-4.1.3.RELEASE.jar
spring-beans-4.1.3.RELEASE.jar
spring-context-4.1.3.RELEASE.jar
spring-context-support-4.1.3.RELEASE.jar


创建工程
sqlmapConfig.xml
&lt;?xml version="1.0" encoding="UTF-8" ?&gt;
	&lt;!DOCTYPE configuration
	PUBLIC "-//mybatis.org//DTD Config 3.0//EN"
	"http://mybatis.org/dtd/mybatis-3-config.dtd"&gt;
&lt;configuration&gt;
	&lt;!-- 设置别名 --&gt;
	&lt;typeAliases&gt;
		&lt;!-- 2. 指定扫描包，会把包内所有的类都设置别名，别名的名称就是类名，大小写不敏感 --&gt;
		&lt;package name="cn.itcast.mybatis.pojo" /&gt;
	&lt;/typeAliases&gt;
&lt;/configuration&gt;

applicationContext.xml
	SqlSessionFactoryBean属于mybatis-spring这个jar包
	对于spring来说，mybatis是另外一个架构，需要整合jar包。
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
	&lt;beans xmlns="http://www.springframework.org/schema/beans"
	xmlns:context="http://www.springframework.org/schema/context" 
	xmlns:p="http://www.springframework.org/schema/p"
	xmlns:aop="http://www.springframework.org/schema/aop" 
	xmlns:tx="http://www.springframework.org/schema/tx"
	xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
	xsi:schemaLocation="http://www.springframework.org/schema/beans 
	http://www.springframework.org/schema/beans/spring-beans-4.0.xsd
	http://www.springframework.org/schema/context 
	http://www.springframework.org/schema/context/spring-context-4.0.xsd
	http://www.springframework.org/schema/aop 
	http://www.springframework.org/schema/aop/spring-aop-4.0.xsd 
	http://www.springframework.org/schema/tx 
	http://www.springframework.org/schema/tx/spring-tx-4.0.xsd
	http://www.springframework.org/schema/util 
	http://www.springframework.org/schema/util/spring-util-4.0.xsd"&gt;
	&lt;context:property-placeholder location="classpath:db.properties" /&gt;
	&lt;bean id="dataSource" class="org.apache.commons.dbcp.BasicDataSource" destroy-method="close"&gt;
		&lt;property name="driverClassName" value="${jdbc.driver}" /&gt;
		&lt;property name="url" value="${jdbc.url}" /&gt;
		&lt;property name="username" value="${jdbc.username}" /&gt;
		&lt;property name="password" value="${jdbc.password}" /&gt;
		&lt;property name="maxActive" value="10" /&gt;
		&lt;property name="maxIdle" value="5" /&gt;
	&lt;/bean&gt;
	&lt;!-- 配置SqlSessionFactory --&gt;
	&lt;bean id="sqlSessionFactory" class="org.mybatis.spring.SqlSessionFactoryBean"&gt;
		&lt;!-- 配置mybatis核心配置文件 --&gt;
		&lt;property name="configLocation" value="classpath:SqlMapConfig.xml" /&gt;
		&lt;!-- 配置数据源 --&gt;
		&lt;property name="dataSource" ref="dataSource" /&gt;
	&lt;/bean&gt;
&lt;/beans&gt;
db.properties、log4j.properties

Dao开发(使用Mapper代理开发方式)
编写UserMapper.xml配置文件，如下：
	&lt;?xml version="1.0" encoding="UTF-8" ?&gt;
	&lt;!DOCTYPE mapper
	PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN"
	"http://mybatis.org/dtd/mybatis-3-mapper.dtd"&gt;
	&lt;mapper namespace="cn.itcast.mybatis.mapper.UserMapper"&gt;
		&lt;!-- 根据用户id查询 --&gt;
		&lt;select id="queryUserById" parameterType="int" resultType="user"&gt;
			select * from user where id = #{id}
		&lt;/select&gt;
	&lt;/mapper&gt;

UserMapper接口实现类
public interface UserMapper {
	User queryUserById(int id);
}
扫描包形式配置mapper（注意这个自动寻找sqlsession，所以不用注入sqlsession，自动扫描该包下，
不包括子包的所有接口，默认加载该包下的与接口同名的xml文件作为Mapper，也可以在sqlMapper中配置mapper resource以加载其他的Mapper
没找到mapper.xml就报错，可以在sqlMapperConfig.xml配置mapper resource解决当默认和自己配的文件一样的时候，优先加载默认位置的
每个mapper代理对象的id就是类名，首字母小写
&lt;!-- 扫描包方式配置代理 --&gt;
&lt;bean class="org.mybatis.spring.mapper.MapperScannerConfigurer"&gt;
	&lt;!-- 配置Mapper接口 --&gt;
	&lt;property name="basePackage" value="cn.mybatis.mapper" /&gt;
&lt;/bean&gt;
</code></pre></div><h1>8. Mybatis逆向工程（了解）</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>	生成逆向工程代码
	找到下图所示的java文件，执行工程main主函数,
	刷新工程，发现代码生成

	注意
	1.逆向工程生成的代码只能做单表查询
	2.不能在生成的代码上进行扩展，因为如果数据库变更，
	需要重新使用逆向工程生成代码，原来编写的代码就被覆盖了。
	3.一张表会生成4个文件

	使用官方网站的Mapper自动生成工具mybatis-generator-core-1.3.2
	来生成po类和Mapper映射文件
	导入逆向工程
	修改配置文件
	在generatorConfig.xml中配置Mapper生成的详细信息，
	1.修改要生成的数据库表
	2.pojo文件所在包路径
	3.Mapper所在的包路径
	&lt;?xml version="1.0" encoding="UTF-8"?&gt;
	&lt;!DOCTYPE generatorConfiguration
	PUBLIC "-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN"
	"http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd"&gt;

	&lt;generatorConfiguration&gt;
		&lt;context id="testTables" targetRuntime="MyBatis3"&gt;
		&lt;commentGenerator&gt;
			&lt;!-- 是否去除自动生成的注释 true：是 ： false:否 --&gt;
			&lt;property name="suppressAllComments" value="true" /&gt;
		&lt;/commentGenerator&gt;
			&lt;!--数据库连接的信息：驱动类、连接地址、用户名、密码 --&gt;
			&lt;jdbcConnection driverClass="com.mysql.jdbc.Driver" connectionURL="jdbc:mysql://localhost:3306/mybatis" 
				userId="root" password="root"&gt;
			&lt;/jdbcConnection&gt;
			&lt;!-- &lt;jdbcConnection driverClass="oracle.jdbc.OracleDriver" connectionURL="jdbc:oracle:thin:@127.0.0.1:1521:yycg" 
				userId="yycg" password="yycg"&gt; &lt;/jdbcConnection&gt; --&gt;
			&lt;!-- 默认false，把JDBC DECIMAL 和 NUMERIC 类型解析为 Integer，为 true时把JDBC DECIMAL 和 NUMERIC 类型解析为java.math.BigDecimal --&gt;
			&lt;javaTypeResolver&gt;
				&lt;property name="forceBigDecimals" value="false" /&gt;
			&lt;/javaTypeResolver&gt;

		&lt;!-- targetProject:生成PO类的位置 --&gt;
		&lt;javaModelGenerator targetPackage="cn.itcast.ssm.po" targetProject=".\src"&gt;
			&lt;!-- enableSubPackages:是否让schema作为包的后缀 --&gt;
			&lt;property name="enableSubPackages" value="false" /&gt;
			&lt;!-- 从数据库返回的值被清理前后的空格 --&gt;
			&lt;property name="trimStrings" value="true" /&gt;
		&lt;/javaModelGenerator&gt;

		&lt;!-- targetProject:mapper映射文件生成的位置 --&gt;
		&lt;sqlMapGenerator targetPackage="cn.itcast.ssm.mapper" targetProject=".\src"&gt;
			&lt;!-- enableSubPackages:是否让schema作为包的后缀 --&gt;
			&lt;property name="enableSubPackages" value="false" /&gt;
		&lt;/sqlMapGenerator&gt;
		&lt;!-- targetPackage：mapper接口生成的位置 --&gt;
		&lt;javaClientGenerator type="XMLMAPPER" targetPackage="cn.itcast.ssm.mapper" targetProject=".\src"&gt;
			&lt;!-- enableSubPackages:是否让schema作为包的后缀 --&gt;
		&lt;property name="enableSubPackages" value="false" /&gt;
			&lt;/javaClientGenerator&gt;
			&lt;!-- 指定数据库表 --&gt;
			&lt;table schema="" tableName="user"&gt;&lt;/table&gt;
			&lt;table schema="" tableName="order"&gt;&lt;/table&gt;
		&lt;/context&gt;
	&lt;/generatorConfiguration&gt;
	

</code></pre></div><h1>9. 分页插件PageHelper</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>目前支持Oracle,Mysql,MariaDB,SQLite,Hsqldb,PostgreSQL六种数据库分页。

把PageHelper依赖的jar包添加到工程中。官方提供的代码对逆向工程支持的不好，使用参考资料中的pagehelper-fix。

第二步：在Mybatis配置xml中配置拦截器插件:
&lt;plugins&gt;
    &lt;!-- com.github.pagehelper为PageHelper类所在包名 --&gt;
    &lt;plugin interceptor="com.github.pagehelper.PageHelper"&gt;
        &lt;!-- 设置数据库类型 Oracle,Mysql,MariaDB,SQLite,Hsqldb,PostgreSQL六种数据库--&gt;        
        &lt;property name="dialect" value="mysql"/&gt;
    &lt;/plugin&gt;
&lt;/plugins&gt;

第三步：在代码中使用
1、设置分页信息：
//获取第1页，10条内容，默认查询总数count
PageHelper.startPage(1, 10);

//紧跟着的第一个select方法会被分页
List&lt;Country&gt; list = countryMapper.selectIf(1);

2、取分页信息
//分页后，实际返回的结果list类型是Page&lt;E&gt;，如果想取出分页信息，需要强制转换为Page&lt;E&gt;，
Page&lt;Country&gt; listCountry = (Page&lt;Country&gt;)list;
listCountry.getTotal();

3、取分页信息的第二种方法
//获取第1页，10条内容，默认查询总数count
PageHelper.startPage(1, 10);
List&lt;Country&gt; list = countryMapper.selectAll();
//用PageInfo对结果进行包装
PageInfo page = new PageInfo(list);
//测试PageInfo全部属性
//PageInfo包含了非常全面的分页属性
assertEquals(1, page.getPageNum());
assertEquals(10, page.getPageSize());
assertEquals(1, page.getStartRow());
assertEquals(10, page.getEndRow());
assertEquals(183, page.getTotal());
assertEquals(19, page.getPages());
assertEquals(1, page.getFirstPage());
assertEquals(8, page.getLastPage());
assertEquals(true, page.isFirstPage());
assertEquals(false, page.isLastPage());
assertEquals(false, page.isHasPreviousPage());
assertEquals(true, page.isHasNextPage());

@Test
public void testPageHelper() throws Exception {
	//初始化spring容器
	ApplicationContext applicationContext = new ClassPathXmlApplicationContext("classpath:spring/applicationContext-*.xml");
	//获得Mapper的代理对象
	TbItemMapper itemMapper = applicationContext.getBean(TbItemMapper.class);
	//设置分页信息
	PageHelper.startPage(1, 30);
	//执行查询
	TbItemExample example = new TbItemExample();
	List&lt;TbItem&gt; list = itemMapper.selectByExample(example);
	//取分页信息
	PageInfo&lt;TbItem&gt; pageInfo = new PageInfo&lt;&gt;(list);
	System.out.println(pageInfo.getTotal());
	System.out.println(pageInfo.getPages());
	System.out.println(pageInfo.getPageNum());
	System.out.println(pageInfo.getPageSize());
}
</code></pre></div>]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/1500ef07f438bf61f8679.png" type="image/png"/>
    </item>
    <item>
      <title>Http</title>
      <link>https://javaguide.cn/backend/protocol/http.html</link>
      <guid>https://javaguide.cn/backend/protocol/http.html</guid>
      <source url="https://javaguide.cn/rss.xml">Http</source>
      <description>http 1. http协议 2. Tomcat(轻量级应用服务器，支持Servlet和jsp规范)目录结构（了解） 3. WEB项目目录结构 4. 软件架构 5. WEB服务器 6. WEB资源：存在于web应用服务器可供外界访问的资源就是web资源 1. http协议 超文本传输协议，用于定义WEB服务器和WEB浏览器之间交换数据的过程 特点：HT...</description>
      <category>理论</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>http</p>
<!--more-->
<!-- TOC -->
<ul>
<li><a href="#1-http%E5%8D%8F%E8%AE%AE">1. http协议</a></li>
<li><a href="#2-tomcat%E8%BD%BB%E9%87%8F%E7%BA%A7%E5%BA%94%E7%94%A8%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%94%AF%E6%8C%81servlet%E5%92%8Cjsp%E8%A7%84%E8%8C%83%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84%E4%BA%86%E8%A7%A3">2. Tomcat(轻量级应用服务器，支持Servlet和jsp规范)目录结构（了解）</a></li>
<li><a href="#3-web%E9%A1%B9%E7%9B%AE%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84">3. WEB项目目录结构</a></li>
<li><a href="#4-%E8%BD%AF%E4%BB%B6%E6%9E%B6%E6%9E%84">4. 软件架构</a></li>
<li><a href="#5-web%E6%9C%8D%E5%8A%A1%E5%99%A8">5. WEB服务器</a></li>
<li><a href="#6-web%E8%B5%84%E6%BA%90%E5%AD%98%E5%9C%A8%E4%BA%8Eweb%E5%BA%94%E7%94%A8%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%8F%AF%E4%BE%9B%E5%A4%96%E7%95%8C%E8%AE%BF%E9%97%AE%E7%9A%84%E8%B5%84%E6%BA%90%E5%B0%B1%E6%98%AFweb%E8%B5%84%E6%BA%90">6. WEB资源：存在于web应用服务器可供外界访问的资源就是web资源</a></li>
</ul>
<!-- /TOC -->
<h1>1. http协议</h1>
<ul>
<li>超文本传输协议，用于定义WEB服务器和WEB浏览器之间交换数据的过程</li>
<li>特点：HTTP协议默认端口80，响应和请求必须成对，先有请求后有响应</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align:center">http协议组成</th>
<th style="text-align:center">组成</th>
<th style="text-align:center">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Http请求协议</td>
<td style="text-align:center">请求行</td>
<td style="text-align:center">POST/day09/01.http/from.html HTTP/1.1请求格式的第一行</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">①请求方式get：请求参数在url后面,例:x.html?a=a&amp;b=b url长度限制get请求数据大小，没有请求体，不安全</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">Post：请求参数在请求体，长度无限制，安全,除了表单的method为post外，其他都是get请求</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">②统一资源定位符URl 协议://域名:端口号/资源位置?参数=值</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">③协议版本</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">请求头</td>
<td style="text-align:center">Host：localhost:8080</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">User-Agent\refer:防盗链（判断它是不是以什么开头就行startswith）</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">if-modified-since:浏览器最后一次缓存时间</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">cookie:浏览器缓存的一种</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">请求体</td>
<td style="text-align:center">a=a&amp;b=b 一般只有post请求方式才有，都是用户表单提交的数据</td>
</tr>
<tr>
<td style="text-align:center">Http响应协议</td>
<td style="text-align:center">响应行</td>
<td style="text-align:center">HTTP/1.1 200 OK 协议/版本 状态码</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">200：成功302：重定向304：访问本地缓存404：找不到资源500：服务器内部错误</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">响应头</td>
<td style="text-align:center">服务器通过响应头来控制浏览器的行为，不同头浏览器的操作不同</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">Location:指定响应的路径，需要与状态码302配合使用</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">Content-Type:响应正文的类型(MIME类型)text/html:charset=UTF-8</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">Content-Disposition:通过浏览器以下载的方式解析正文attachment;filename=xx.zip</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">Set-Cookie:服务器向浏览器写入cookie</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">响应体</td>
<td style="text-align:center">服务器发给浏览器的正文、响应体是服务器回写给客户端的页面正文</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">浏览器将正文加载到内存，然后解析渲染显示页面内容</td>
</tr>
</tbody>
</table>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/306a175def763027c2977.png" alt="http请求.png" tabindex="0"><figcaption>http请求.png</figcaption></figure>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/e60aaac0f67769eb9b331.png" alt="http响应.png" tabindex="0"><figcaption>http响应.png</figcaption></figure>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>可以用 telnet 程序测试 telnet 192.168.80.1 8080
get 请求示例

GET /test2?name=1i&amp;age=10 HTTP/1.1
Host:1ocalhost

post 请求示例
PosT /test2 HTTP/1.1 
Host: localhost
Content-Type:application/x-www-form-urlencoded
Content-Length:10

name=zhang&amp;age=10

// java求urlencode utf-8
bytel]bytes ="张".getBytes(standardcharsets.UTF_8);
System.out.println(bytes);
bytes:[-27，-68，-96]
右键-查看方式-Hex查看16进制

application/x-www-form-urlencoed 格式细节
。参数分成名字和值，中间用=分隔
。多个参数使用 &amp; 进行分隔
。【张】等特殊字符需要用 encodeURIComponent()编码为【%E5%BC%A0】后才能发送
encodeURIComponent("张")
%E5%BC%AB

可以用谷歌浏览器的控制台求数据长度
"name=zhang&amp;age=18".length
求urlencode

json 请求示例
PosT /test3 HTTP/1.1
Host: 1ocalhost
Content-Type:application/json
Content-Length:25
{"name": "zhang" , "age" : 18}

后端@RequestBody对象接收
{"属性名":属性值}
字符串"”
数字
true, false
null
属性值中文也可以，不用urlencode
求长度'{"name":"张","age":18}'.length

multipart 请求示例
PosT /test2 HTTP/1.1
Host: 1ocalhost
Content-Type:mutipart/form-data;boundary=123
content-Length:125

--123
Content-Disposition:form-data;name-"'name

1isi
--123
Content-Disposition:form-data; name="age"

39
--123--

boundary=123 用来定义分隔符
起始分隔符是 --分隔符
结束分隔符是 --分隔符--

使用length计算时，会忽略/r/n，导致len减少

客户端发送
编码
o application/x-www-form-urlencoded :url 编码
o application/json: utf-8 编码
o multipart/form-data:每部分编码可以不同
表单只支持以 application/x-www-form-urlencoded 和multipart/form-data 格式发送数据
文件上传需要用 multipart/form-data 格式
js 代码可以支持任意格式发送数据

服务端接收
对application/x-www-form-urlencoded 和multipart/form-data格式的数据，Spring 接收方式是统一的，只需要用java bean 的属性名对应请求参数名即可
对于 applicaiton/json 格式的数据，Spring 接收需要使用@RequestBody 注解+java bean 的方式

session 原理
Http 无状态，有会话
。无状态是指，请求之间相互盘立，第一次请求的数据，第二次请求不能重用name=zhang
，有会话是指，客户端和服务端都有相应的技术，可以暂存数据，让数据在请求间共享
服务端使用了 session 技术来暂存数据
存
GET /s1?name=zhang HTTP/1.1
Host: 1ocalhost
取
GET /S2 HTTP/1.1
Host: 1ocalhost
Cookie:ISESSIONID=BF219FEFB6FF6960DA2537CDDED6C393

@RequestMapping("/s1")
@ResponseBody
public string sl(
HttpSession session,string name){
	session.setAttribute( name:"name", name);
	return"数据已存储";
}
@RequestMapping("/s2")
#ResponseBody
public string s2(Httpsession session){
	return "取出数据"+session.getAttribute( name:"name");
}

生成 token
GET /j1?name=zhang&amp;pass=123 HTTP/1.1
Host: 1ocalhost

校验 token
GET /2 HTTP/1.1Host:1ocalhost
Authorization:
eyihbGcioijIuzIlNi19.eyzdwIioijhzGlpbi19.G4xp74SX4dECKIwhK2kRmj1w157nSAR0OBMSpQ-108

RequestMapping("/j1")
ResponseBody
public string j1(string name,string pass){
	if("zhang".equals(name)&amp;&amp;"123".equals(pass)){
		string token =wts.builder().setsubject(name).signwith(key).compact
		return"验证身份通过:"+token;
    } else {
		return“验证身份失败";
	}
}
RequestMapping("/j2")
ResponseBody
public string j2(@RequestHeader string authorization){
    try {
        System.out.println(authorization);
        Jws&lt;Claims&gt; jws = Jwts.parserBuilder().setsigningKey(key).build().pa
        return“校验通过，你是:"+jws.getBody().getSubject();
    }catch(Exception e){
        return“校验失败";
    }
}

header(签名算法) payload(数据) 签名 最后一段数据与前两个数加服务器的Key签名生成

String token = "eyJhbGci0iJIUzI1NiJ9.eyJzdWIi0iJ6aGFuZyJ9._1-P_TLLZQPb1_LCYGWPLMZaKQ8MCW_PLBbYPZ30X28";

System.out.printin(new string(Base64.getDecoder().decode("eyIhbGci0iJIUzI1NiJ9")));

System.out.printin(new string(Base64.getDecoder().decode("eyJzdWIi0iJ6aGFuZyJ9")));

String str ="""{"sub":"admin"}"“";
System.out.println(Base64.getEncoder().encodeTostring(str.getBytes(standardcharsets.UTF_8)));
</code></pre></div><figure><img src="https://i2.wp.com/wx4.sinaimg.cn/large/0070JETugy1i41p4pix52j30qp0efwf5.jpg" alt="1.png" tabindex="0"><figcaption>1.png</figcaption></figure>
<figure><img src="https://i3.wp.com/wx4.sinaimg.cn/large/0070JETugy1i41p55yez6j30mo0e2js1.jpg" alt="2.png" tabindex="0"><figcaption>2.png</figcaption></figure>
<h1>2. Tomcat(轻量级应用服务器，支持Servlet和jsp规范)目录结构（了解）</h1>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/9a417a4b6d5586ad9e533.png" alt="tomcat目录.png" tabindex="0"><figcaption>tomcat目录.png</figcaption></figure>
<ul>
<li>conf：配置文件目录 (config /configuration)
<ul>
<li>核心配置文件：server.xml</li>
<li>用户权限配置文件：tomcat-users.xml</li>
<li>所有web项目默认配置文件：web.xml</li>
</ul>
</li>
<li>bin：脚本目录
<ul>
<li>启动脚本：startup.bat</li>
<li>停止脚本：shutdown.bat</li>
</ul>
</li>
<li>lib：依赖库，tomcat和web项目中需要使用的jar包
<ul>
<li>logs：日志文件.</li>
<li>localhost_access_log.<em>.txt tomcat记录用户访问信息，星</em>表示时间。</li>
<li>例如：localhost_access_log.2016-02-28.txt</li>
</ul>
</li>
<li>temp：临时文件目录，文件夹内内容可以任意删除
<ul>
<li>webapps：默认情况下发布WEB项目所存放的目录</li>
<li>work：tomcat处理JSP的工作目录</li>
</ul>
</li>
</ul>
<h1>3. WEB项目目录结构</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>	项目名称(webapps：)		
	|</code></pre></div>]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/306a175def763027c2977.png" type="image/png"/>
    </item>
    <item>
      <title>MQTT</title>
      <link>https://javaguide.cn/backend/protocol/mqtt.html</link>
      <guid>https://javaguide.cn/backend/protocol/mqtt.html</guid>
      <source url="https://javaguide.cn/rss.xml">MQTT</source>
      <description>MQTT协议 1. 注意事项 2. MQTT客户端 3. spring整合MQTT 1. 注意事项 同一个clientId重复连接会导致连接断开 MQTT订阅上下线的主题为 $SYS/brokers/+/clients/+/connected $SYS/brokers/+/clients/+/disconnected $SYS/brokers/+/cl...</description>
      <category>理论</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>MQTT协议</p>
<!--more-->
<!-- TOC -->
<ul>
<li><a href="#1-%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9">1. 注意事项</a></li>
<li><a href="#2-mqtt%E5%AE%A2%E6%88%B7%E7%AB%AF">2. MQTT客户端</a></li>
<li><a href="#3-spring%E6%95%B4%E5%90%88mqtt">3. spring整合MQTT</a></li>
</ul>
<!-- /TOC -->
<h1>1. 注意事项</h1>
<ul>
<li>同一个clientId重复连接会导致连接断开</li>
<li>MQTT订阅上下线的主题为
<ul>
<li>$SYS/brokers/+/clients/+/connected</li>
<li>$SYS/brokers/+/clients/+/disconnected</li>
<li>$SYS/brokers/+/clients/#</li>
<li>$SYS/#</li>
</ul>
</li>
</ul>
<h1>2. MQTT客户端</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>import java.io.FileNotFoundException;
import java.io.IOException;
import java.security.KeyManagementException;
import java.security.KeyStoreException;
import java.security.cert.CertificateException;
import org.eclipse.paho.client.mqttv3.MqttClient;
import org.eclipse.paho.client.mqttv3.MqttConnectOptions;
import org.eclipse.paho.client.mqttv3.MqttException;
import org.eclipse.paho.client.mqttv3.MqttMessage;
import org.eclipse.paho.client.mqttv3.persist.MemoryPersistence;

public class MqttPublishSample {
	public static void main(String[] args) throws KeyManagementException, CertificateException, FileNotFoundException, IOException, KeyStoreException {
		String topic        = "MQTT Examples";
		String content      = "Message from MqttPublishSample";
		int qos             = 2;
		String broker       = "tcp://127.0.0.1:11883";
		String broker       = "ssl://10.110.111.251:8883";
		String clientId     = "JavaSample";
		MemoryPersistence persistence = new MemoryPersistence();

		try {
			MqttClient sampleClient = new MqttClient(broker, clientId, persistence);
			MqttConnectOptions connOpts = new MqttConnectOptions();
			connOpts.setCleanSession(true);
			System.out.println("Connecting to broker: "+broker);
			sampleClient.connect(connOpts);
			System.out.println("Connected");
			System.out.println("Publishing message: "+content);
			MqttMessage message = new MqttMessage(content.getBytes());
			message.setQos(qos);
			sampleClient.publish(topic, message);
			System.out.println("Message published");
			sampleClient.disconnect();
			System.out.println("Disconnected");
			System.exit(0);
		} catch(MqttException me) {
			System.out.println("reason "+me.getReasonCode());
			System.out.println("msg "+me.getMessage());
			System.out.println("loc "+me.getLocalizedMessage());
			System.out.println("cause "+me.getCause());
			System.out.println("excep "+me);
			me.printStackTrace();
		} 
	}
}
</code></pre></div><h1>3. spring整合MQTT</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code># 定义mqtt的配置类

package com.junye.test;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.context.annotation.Scope;
import org.springframework.stereotype.Component;

@Component
@Data
public class ClientConfig {
	@Value("tcp://127.0.0.1:11883")
	private String broker;
	@Value("admin")
	private String user;
	@Value("public")
	private String password;
	private int qos = 2;
	private String clientId;
}

# 定义RemoteClient接口

package com.junye.test;
import org.eclipse.paho.client.mqttv3.MqttException;
public interface RemoteClient {
	void init(String broker, String user, String password) throws MqttException;
	void publish(String topic, String message, int qos) throws MqttException;
	void subscribe(String topic, OnMessageListener listener) throws MqttException;
	void unSubscribe(String topic) throws MqttException;
	void close() throws MqttException;
}

# 实现RemoteClient接口RemoteClientImpl类

package com.junye.test;
import java.util.UUID;
import org.eclipse.paho.client.mqttv3.IMqttDeliveryToken;
import org.eclipse.paho.client.mqttv3.MqttCallback;
import org.eclipse.paho.client.mqttv3.MqttClient;
import org.eclipse.paho.client.mqttv3.MqttConnectOptions;
import org.eclipse.paho.client.mqttv3.MqttException;
import org.eclipse.paho.client.mqttv3.MqttMessage;
import org.eclipse.paho.client.mqttv3.persist.MemoryPersistence;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.util.Assert;
@Data
public class RemoteClientImpl implements RemoteClient {  
	private String broker;
	private String user;
	private String password;
	private int qos = 2;
	private String clientId;  
	private MqttClient client;  

	public RemoteClientImpl() {  
		this(UUID.randomUUID().toString());  
	}  

	public BasicRemoteClient(String clientId) {  
		this.clientId = clientId;  
	}  

	public void init(String broker, String user, String password) throws MqttException {  
		MemoryPersistence persistence = new MemoryPersistence();  
		client = new MqttClient(broker, clientId, persistence);  
		MqttConnectOptions options = new MqttConnectOptions();  

		options.setCleanSession(true);  
		options.setUserName(user);  
		options.setPassword(password.toCharArray());  
		client.connect(options);  
	}  

	public void init() throws MqttException {  
		MemoryPersistence persistence = new MemoryPersistence();  
		client = new MqttClient(broker, clientId, persistence);  
		MqttConnectOptions options = new MqttConnectOptions();  
		options.setCleanSession(true);  
		options.setUserName(user);  
		options.setPassword(password.toCharArray());  
		client.connect(options);  
	}  


	public void publish(String topic, String message, int qos) throws MqttException {  
		MqttMessage mqttMessage = new MqttMessage(message.getBytes());  
		mqttMessage.setQos(qos);  
		client.publish(topic, mqttMessage);  
	}  

	public void subscribe(String topic, final OnMessageListener listener) throws MqttException {  
		try {  
			client.subscribe(topic, this.qos);
			client.setCallback(new MqttCallback(){
				@Override
				public void connectionLost(Throwable cause) {
					try {
						init();
						System.out.println("重连");
					} catch (MqttException e) {
						// TODO Auto-generated catch block
						e.printStackTrace();
					}
				}

				@Override
				public void messageArrived(String topic2, MqttMessage message) throws Exception {
					listener.handleMessage(topic2, message.toString());  
				}

				@Override
				public void deliveryComplete(IMqttDeliveryToken token) {
					System.out.println("成功");
					logger.info("deliveryComplete {}", token);
				}
			});
		} catch (MqttException e) {  
			throw e;  
		}  
	}  

	public void unSubscribe(String topic) throws MqttException {  
		client.unsubscribe(topic);  
	}  

	@Override  
	public void close() throws MqttException {  
		client.disconnect();  
	}  

}

# 定义监听接口OnMessageListener用于传入RemoteClient处理信息
public interface OnMessageListener {
	void handleMessage(String topic, String message);
}
# 自定义Bean注入
//自定义Basic的注入，直接当成一个普通的Bean即可，只是初始化的方法自定义了
@Component
public class BasicRemoteClientFactory implements FactoryBean&lt;RemoteClient&gt;{

	@Autowired
	private ClientConfig clientConfig;
	public void setClientConfig(ClientConfig clientConfig) {
		this.clientConfig = clientConfig;
	}
	@Override
	public RemoteClient getObject() throws Exception {
		BasicRemoteClient client = new BasicRemoteClient();
		if(clientConfig.getClientId()!=null){
			client.setClientId(clientConfig.getClientId());
		}
		client.init(clientConfig.getBroker(), clientConfig.getUser(), clientConfig.getPassword());
		client.setQos(clientConfig.getQos());
		return (RemoteClient) client;
	}

	@Override
	public Class&lt;?&gt; getObjectType() {
		return BasicRemoteClient.class;
	}

	@Override
	public boolean isSingleton() {
		return false;
	}
}
# 定义抽象类BaseMqttSubscriber用于多个Controller继承（可选）
	public abstract class BaseMqttSubscriber {
		protected Logger logger =LoggerFactory.getLogger(this.getClass());
		@Value("TEST")
		private String clientId;

		public void setClientId(String clientId) {
			this.clientId = clientId;
		}

		@Autowired
		private ClientConfig clientConfig;

		public void setClientConfig(ClientConfig clientConfig) {
			this.clientConfig = clientConfig;
		}


		public RemoteClient getMqttClient() throws Exception {
			clientConfig.setClientId(clientId);//override the clientId;
			BasicRemoteClientFactory factory=new BasicRemoteClientFactory();
			factory.setClientConfig(clientConfig);
			return factory.getObject();
		}
	}
# 定义HelloController测试
package com.junye.test;
import java.util.HashMap;
import java.util.Map;
import javax.annotation.PostConstruct;
import org.eclipse.paho.client.mqttv3.MqttException;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;
@RestController
public class HelloController extends BaseMqttSubscriber{
	@RequestMapping("/hello")
	public Map&lt;String, Object&gt; index(String test,String test2) throws MqttException, Exception {
		Map&lt;String , Object&gt; result=new HashMap&lt;String,Object&gt;();
		result.put("test", test);
		Demo demo=new Demo("junye", "1");
		result.put("Demo", demo);
		this.getMqttClient().publish("/test", "hahah", 2);
		System.out.println("chenggong");
		return result;
	}
	@PostConstruct
	public void init() throws MqttException, Exception {
		System.out.println("qidong");
		this.getMqttClient().subscribe("/test", new OnMessageListener() {
			@Override
			public void handleMessage(String topic, String message)  {
			System.out.println("test");
			}
		});	
	}  
}
# 定义springboot入口
package com.junye.test;
import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.EnableAutoConfiguration;
import org.springframework.boot.autoconfigure.SpringBootApplication;

@SpringBootApplication
@EnableAutoConfiguration
public class MainApplication {
	public static void main(String[] args) {
		SpringApplication.run(MainApplication.class, args);
	}	
}
</code></pre></div><h1>4. JavaScript连接emq</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>&lt;!DOCTYPE html&gt;
&lt;html&gt;
&lt;head&gt;
	&lt;meta charset="UTF-8"&gt;
	&lt;title&gt;Insert title here&lt;/title&gt;
&lt;/head&gt;
&lt;script src="https://cdnjs.cloudflare.com/ajax/libs/paho-mqtt/1.0.1/mqttws31.js" type="text/javascript"&gt;&lt;/script&gt;
&lt;script&gt;
window.onload=function(){
	client = new Paho.MQTT.Client(location.hostname, Number(8083), "clientId");
	client.onConnectionLost = onConnectionLost;
	client.onMessageArrived = onMessageArrived;
	client.connect({onSuccess:onConnect});
	//,onFailure : artmisMqttOnError
	function onConnect() {
		// Once a connection has been made, make a subscription and send a message.
		alert("connect");
		console.log("onConnect");
		client.subscribe("/World");
		message = new Paho.MQTT.Message("Hello");
		message.destinationName = "/World";
		client.send(message);
	};
	function onConnectionLost(responseObject) {
		if (responseObject.errorCode !== 0){
			console.log("onConnectionLost:"+responseObject.errorMessage);
			alter("lost");
		}
	};
	function onMessageArrived(message) {
		console.log("onMessageArrived:"+message.payloadString);
		alert(message.payloadString);
		client.disconnect();
	};
}

&lt;/script&gt;
&lt;body&gt;
xxx
&lt;/body&gt;
&lt;/html&gt;
</code></pre></div>]]></content:encoded>
    </item>
    <item>
      <title>webservice</title>
      <link>https://javaguide.cn/backend/protocol/webservice.html</link>
      <guid>https://javaguide.cn/backend/protocol/webservice.html</guid>
      <source url="https://javaguide.cn/rss.xml">webservice</source>
      <description>WebService是用来开发分布式的互操作应用程序 1. WebService介绍 2. SOAP和WSDL 3. 基于jdk1.7发布一个WebService服务 4. apache CXF入门 1. WebService介绍 图片1.png图片1.png 2. SOAP和WSDL 3. 基于jdk1.7发布一个WebService服务 图片2.p...</description>
      <category>后端</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>WebService是用来开发分布式的互操作应用程序</p>
<!--more-->
<!-- TOC -->
<ul>
<li><a href="#1-webservice%E4%BB%8B%E7%BB%8D">1. WebService介绍</a></li>
<li><a href="#2-soap%E5%92%8Cwsdl">2. SOAP和WSDL</a></li>
<li><a href="#3-%E5%9F%BA%E4%BA%8Ejdk17%E5%8F%91%E5%B8%83%E4%B8%80%E4%B8%AAwebservice%E6%9C%8D%E5%8A%A1">3. 基于jdk1.7发布一个WebService服务</a></li>
<li><a href="#4-apache-cxf%E5%85%A5%E9%97%A8">4. apache CXF入门</a></li>
</ul>
<!-- /TOC -->
<h1>1. WebService介绍</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>Web service是一个平台独立的，低耦合的，自包含的、基于可编程的web的应用程序，
可使用开放的XML（标准通用标记语言下的一个子集）标准来描述、发布、发现、协调和配置这些应用程序，用于开发分布式的互操作的应用程序 
Web Service技术， 能使得运行在不同机器上的不同应用无须借助附加的、专门的第三方软件或硬件， 就可相互交换数据或集成。依据Web Service规范实施的应用之间， 无论它们所使用的语言、 平台或内部协议是什么， 
都可以相互交换数据
Web Service是自描述、 自包含的可用网络模块，可以执行具体的业务功能。
Web Service也很容易部署， 因为它们基于一些常规的产业标准以及已有的一些技术，诸如标准通用标记语言下的子集XML、HTTP。Web Service减少了应用接口的花费。
Web Service为整个企业甚至多个组织之间的业务流程的集成提供了一个通用机制

WebService通过HTTP POST方式接受客户的请求,实现两个系统之间的远程调用
WebService与客户端之间一般使用SOAP协议传输XML数据
它本身就是为了跨平台或跨语言而设计的

调用网络上的WebService服务http://webxml.com.cn/
</code></pre></div><figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/d9e138740635ff40f1378.png" alt="图片1.png" tabindex="0"><figcaption>图片1.png</figcaption></figure>
<h1>2. SOAP和WSDL</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>SOAP（Simple Object Access Protocol）：简单对象访问协议
SOAP作为一个基于XML语言的协议用于在网上传输数据。
SOAP = 在HTTP的基础上+XML数据。都是post请求
SOAP是基于HTTP的。!!!!!!!!!!!!!!!!
SOAP的组成如下：
Envelope – 必须的部分。以XML的根元素出现。
Headers – 可选的。
Body – 必须的。在body部分，包含要执行的服务器的方法。和发送到服务器的数据。

示例：
POST /WebServices/IpAddressSearchWebService.asmx HTTP/1.1
Host: ws.webxml.com.cn
Content-Type: text/xml; charset=utf-8
Content-Length: length
SOAPAction: "http://WebXml.com.cn/getCountryCityByIp"

&lt;?xml version="1.0" encoding="utf-8"?&gt;
&lt;soap:Envelope xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:xsd="http://www.w3.org/2001/XMLSchema" xmlns:soap="http://schemas.xmlsoap.org/soap/envelope/"&gt;
  &lt;soap:Body&gt;
	&lt;getCountryCityByIp xmlns="http://WebXml.com.cn/"&gt;
	  &lt;theIpAddress&gt;string&lt;/theIpAddress&gt;
	&lt;/getCountryCityByIp&gt;
  &lt;/soap:Body&gt;
&lt;/soap:Envelope&gt;
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>WSDL Web服务描述语言
WSDL(WebService Description Language):web 服务描述语言
就是一个xml文档，用于描述当前服务的一些信息（服务名称、服务的发布地址、服务提供的方法、方法的参数类型、方法的返回值类型等）
</code></pre></div><h1>3. 基于jdk1.7发布一个WebService服务</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>服务端发布
第一步：创建一个Java项目
第二步：创建一个类，加入Webservice注解
第三步：提供一个方法sayHello
第四步：在main方法中调用jdk提供的发布服务的方法
第五步：访问服务的wsdl文档（服务的发布地址+?wsdl）http://192.168.115.87:8080/hello?wsdl
import javax.jws.WebService;
import javax.xml.ws.Endpoint;
@WebService
public class HelloService {
	public String sayHello(String name,int i){
		System.out.println("服务端的sayHello方法被调用了。。。。");
		return "helle" + name;
	}
	
	public static void main(String[] args) {
		String address = "http://192.168.115.87:8080/hello";
		Object implementor = new HelloService();
		Endpoint.publish(address, implementor);
	}
}
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>客户端调用
//使用wsimport命令解析wsdl文件生成本地代码,把本地代码拷到项目中
//通过本地代码创建一个代理对象
//通过代理对象实现远程调用
public class App {
	public static void main(String[] args) {
		HelloServiceService ss = new HelloServiceService();
		//创建客户端代理对象，用于远程调用
		HelloService proxy = ss.getHelloServicePort();
		String ret = proxy.sayHello("小明", 10);
		System.out.println(ret);
	}
}

</code></pre></div><figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/f0324ee4eed25d8d96ac1.png" alt="图片2.png" tabindex="0"><figcaption>图片2.png</figcaption></figure>
<h1>4. apache CXF入门</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>官网：cxf.apache.org
Apache CXF = Celtix + Xfire 
支持多种协议：SOAP1.1,1.2、XML/HTTP
CORBA（Common Object Request Broker Architecture公共对象请求代理体系结构,早期语言使用的WS。C,c++,C#） 
并可以与Spring进行快速无缝的整合,灵活的部署：可以运行在Tomcat,Jboss,Jetty(内置),IBMWS,BeaWL上面。

服务端开发
第一步：创建动态web项目
第二步：导入CXF相关jar包
&lt;dependency&gt;
	&lt;groupId&gt;org.apache.cxf&lt;/groupId&gt;
	&lt;artifactId&gt;cxf-rt-frontend-jaxws&lt;/artifactId&gt;
	&lt;version&gt;3.0.1&lt;/version&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
	&lt;groupId&gt;org.apache.cxf&lt;/groupId&gt;
	&lt;artifactId&gt;cxf-rt-transports-http&lt;/artifactId&gt;
	&lt;version&gt;3.0.1&lt;/version&gt;
&lt;/dependency&gt;
第三步：在web.xml中配置CXF框架提供的一个Servlet
&lt;!-- 配置CXF框架提供的Servlet --&gt;
&lt;servlet&gt;
	&lt;servlet-name&gt;cxf&lt;/servlet-name&gt;
	&lt;servlet-class&gt;org.apache.cxf.transport.servlet.CXFServlet&lt;/servlet-class&gt;
	&lt;!-- 通过初始化参数指定CXF框架的配置文件位置 默认cxf-servlet.xml--&gt;
	&lt;init-param&gt;
		&lt;param-name&gt;config-location&lt;/param-name&gt;
		&lt;param-value&gt;classpath:cxf.xml&lt;/param-value&gt;
	&lt;/init-param&gt;
&lt;/servlet&gt;
&lt;servlet-mapping&gt;
	&lt;servlet-name&gt;cxf&lt;/servlet-name&gt;
	&lt;url-pattern&gt;/service/*&lt;/url-pattern&gt;
&lt;/servlet-mapping&gt;
第四步：在类路径下提供cxf.xml
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;beans xmlns="http://www.springframework.org/schema/beans"
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xmlns:jaxws="http://cxf.apache.org/jaxws"
xmlns:soap="http://cxf.apache.org/bindings/soap"
xsi:schemaLocation="http://www.springframework.org/schema/beans 
					http://www.springframework.org/schema/beans/spring-beans.xsd
					http://cxf.apache.org/bindings/soap 
					http://cxf.apache.org/schemas/configuration/soap.xsd
					http://cxf.apache.org/jaxws 
					http://cxf.apache.org/schemas/jaxws.xsd"&gt;
	&lt;!-- 引入CXF Bean定义如下,早期的版本中使用 --&gt;
	&lt;import resource="classpath:META-INF/cxf/cxf.xml" /&gt;
	&lt;import resource="classpath:META-INF/cxf/cxf-extension-soap.xml" /&gt;
	&lt;import resource="classpath:META-INF/cxf/cxf-servlet.xml" /&gt;

&lt;/beans&gt;
第五步：开发一个接口和实现类
@WebService
public interface HelloService {
	public String sayHello(String name);
}
public class HelloServiceImpl implements HelloService{
	public String sayHello(String name) {
		System.out.println("基于CXF开发的服务端sayHello方法被调用了。。。。");
		return "hello " + name;
	}
}
第六步：在cxf.xml中注册服务
&lt;bean id="helloService" class="com.itheima.service.HelloServiceImpl"/&gt;
&lt;!-- 注册服务 --&gt;
&lt;jaxws:server id="myService" address="/cxfService"&gt;
	&lt;jaxws:serviceBean&gt;
		&lt;ref bean="helloService"/&gt;
	&lt;/jaxws:serviceBean&gt;
&lt;/jaxws:server&gt;
最后请求http://ip:port/projectName/service/cxfService

客户端开发
第一步：创建Java项目并导入CXF相关jar包
第二步：使用wsimport或者CXF提供wsdl2java生成本地代码，只需要生成接口文件
第三步：将接口文件复制到项目中
第四步：提供spring配置文件，注册客户端代理对象
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;beans xmlns="http://www.springframework.org/schema/beans"
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xmlns:jaxws="http://cxf.apache.org/jaxws"
xmlns:soap="http://cxf.apache.org/bindings/soap"
xsi:schemaLocation="http://www.springframework.org/schema/beans 
					http://www.springframework.org/schema/beans/spring-beans.xsd
					http://cxf.apache.org/bindings/soap 
					http://cxf.apache.org/schemas/configuration/soap.xsd
					http://cxf.apache.org/jaxws 
					http://cxf.apache.org/schemas/jaxws.xsd"&gt;
	&lt;!-- 引入CXF Bean定义如下,早期的版本中使用 --&gt;
	&lt;import resource="classpath:META-INF/cxf/cxf.xml" /&gt;
	&lt;import resource="classpath:META-INF/cxf/cxf-extension-soap.xml" /&gt;
	&lt;import resource="classpath:META-INF/cxf/cxf-servlet.xml" /&gt;
	
	&lt;!-- 注册CXF客户端代理对象，通过spring框架创建这个代理对象，使用代理对象实现远程调用 --&gt;
	&lt;jaxws:client id="myClient" 
				address="http://192.168.115.87:8080/cxf_service/service/cxfService" 
				serviceClass="cn.itcast.client.HelloService"&gt;
	&lt;/jaxws:client&gt;
&lt;/beans&gt;
第五步：读取spring配置文件，创建spring工厂，从工厂中获取代理对象，实现远程调用
public class App {
	public static void main(String[] args) {
		ApplicationContext ctx = new ClassPathXmlApplicationContext("cxf.xml");
		HelloService proxy = (HelloService) ctx.getBean("myClient");
		String ret = proxy.sayHello("test");
		System.out.println(ret);
	}
}
</code></pre></div>]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/d9e138740635ff40f1378.png" type="image/png"/>
    </item>
    <item>
      <title>websocket</title>
      <link>https://javaguide.cn/backend/protocol/websocket.html</link>
      <guid>https://javaguide.cn/backend/protocol/websocket.html</guid>
      <source url="https://javaguide.cn/rss.xml">websocket</source>
      <description>1. websocket与http的比较 2. 服务端 2.1. pom.xml 2.2. java 3. springboot整合websocket 3.1. pom.xml 3.2. WebSocketConfig、WebSocketInterceptor、MyWebSocketHandler 3.3. SseEmitter 4. 客户端连接 前端...</description>
      <category>后端</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<!-- TOC -->
<ul>
<li><a href="#1-websocket%E4%B8%8Ehttp%E7%9A%84%E6%AF%94%E8%BE%83">1. websocket与http的比较</a></li>
<li><a href="#2-%E6%9C%8D%E5%8A%A1%E7%AB%AF">2. 服务端</a>
<ul>
<li><a href="#21-pomxml">2.1. pom.xml</a></li>
<li><a href="#22-java">2.2. java</a></li>
</ul>
</li>
<li><a href="#3-springboot%E6%95%B4%E5%90%88websocket">3. springboot整合websocket</a>
<ul>
<li><a href="#31-pomxml">3.1. pom.xml</a></li>
<li><a href="#32-websocketconfigwebsocketinterceptormywebsockethandler">3.2. WebSocketConfig、WebSocketInterceptor、MyWebSocketHandler</a></li>
<li><a href="#33-sseemitter">3.3. SseEmitter</a></li>
</ul>
</li>
<li><a href="#4-%E5%AE%A2%E6%88%B7%E7%AB%AF%E8%BF%9E%E6%8E%A5-%E5%89%8D%E7%AB%AFjs%E5%AF%B9%E8%B1%A1websocket%E5%92%8Ceventsource%E5%88%86%E5%88%AB%E7%94%A8%E4%BA%8E%E8%BF%9E%E6%8E%A5%E8%BF%99%E4%B8%A4%E7%A7%8D%E6%9C%8D%E5%8A%A1">4. 客户端连接 前端js对象WebSocket和EventSource分别用于连接这两种服务。</a></li>
<li><a href="#5-nginx%E9%9C%80%E8%A6%81%E7%9A%84%E9%A2%9D%E5%A4%96%E9%85%8D%E7%BD%AE">5. Nginx需要的额外配置</a>
<ul>
<li><a href="#51-eventsource">5.1. EventSource</a></li>
<li><a href="#52-websocket">5.2. WebSocket</a></li>
</ul>
</li>
<li><a href="#6-%E5%B7%B2%E7%9F%A5%E9%97%AE%E9%A2%98">6. 已知问题</a></li>
<li><a href="#7-%E8%8E%B7%E5%BE%97httpssession%E7%9A%84%E6%96%B9%E6%B3%95">7. 获得httpssession的方法</a>
<ul>
<li><a href="#71-gethttpsessionconfigurator">7.1. GetHttpSessionConfigurator</a></li>
<li><a href="#72-%E5%9C%A8serverendpoint%E6%B3%A8%E8%A7%A3%E9%87%8C%E9%9D%A2%E6%B7%BB%E5%8A%A0configurator%E5%B1%9E%E6%80%A7">7.2. 在@ServerEndpoint注解里面添加configurator属性</a></li>
<li><a href="#73-%E5%9C%A8onopen%E6%96%B9%E6%B3%95%E9%87%8C%E5%8A%A0%E5%85%A5%E5%8F%82%E6%95%B0endpointconfig-config%E5%8D%B3%E5%8F%AF%E8%8E%B7%E5%8F%96httpsession">7.3. 在onOpen方法里加入参数EndpointConfig config即可获取HttpSession</a></li>
</ul>
</li>
</ul>
<!-- /TOC -->
<!--more-->
<h1>1. websocket与http的比较</h1>
<ul>
<li>WebSocket协议实现了浏览器与服务器的全双工通信，扩展了浏览器与服务端的通信功能，使服务端也能主动向客户端发送数据。JavaEE 7中出了JSR-356:Java API for WebSocket规范。不少Web容器，如Tomcat,Nginx,Jetty等都支持WebSocket。Tomcat从7.0.27开始支持 WebSocket，从7.0.47开始支持JSR-356，下面的Demo代码也是需要部署在Tomcat7.0.47（不包括）以上的版本才能运行</li>
<li>webscoket相比于http的优势主要有服务器能主动发信息给前端,发的信息是轻量级的，所以服务器的压力较少</li>
</ul>
<h1>2. 服务端</h1>
<h2>2.1. pom.xml</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>&lt;dependencies&gt;
	&lt;dependency&gt;
	&lt;groupId&gt;javax&lt;/groupId&gt;
	&lt;artifactId&gt;javaee-api&lt;/artifactId&gt;
	&lt;version&gt;7.0&lt;/version&gt;
	&lt;/dependency&gt;
&lt;/dependencies&gt;
</code></pre></div><h2>2.2. java</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>package com.junye.testwebsocket;
import java.io.IOException;
import java.util.concurrent.CopyOnWriteArraySet;
import javax.websocket.*;
import javax.websocket.server.ServerEndpoint;

@ServerEndpoint("/websocket")
public class TestWebscoket {
	/**
	* @ServerEndpoint 注解是一个类层次的注解，它的功能主要是将目前的类定义成一个websocket服务器端,
	* 注解的值将被用于监听用户连接的终端访问URL地址,客户端可以通过这个URL来连接到WebSocket服务器端
	*/
	
	//与某个客户端的连接会话，需要通过它来给客户端发送数据
	private Session session;
	
	/**
	* 连接建立成功调用的方法
	* @param session  可选的参数。
	*	session为与某个客户端的连接会话，需要通过它来给客户端发送数据
	*/
	@OnOpen
	public void onOpen(Session session){
		this.session = session;
	}

	/**
	* 连接关闭调用的方法
	*/
	@OnClose
	public void onClose(){
		System.out.println("连接关闭");
	}

	/**
	* 收到客户端消息后调用的方法
	* @param message 客户端发送过来的消息
	* @param session 可选的参数
	*/
	@OnMessage
	public void onMessage(String message, Session session) {
		System.out.println("来自客户端的消息:" + message);
	}

	/**
	* 发生错误时调用
	* @param session
	* @param error
	*/
	@OnError
	public void onError(Session session, Throwable error){
		System.out.println("发生错误");
		error.printStackTrace();
	}

	/**
	* 这个方法与上面几个方法不一样。没有用注解，是根据自己需要添加的方法。
	* @param message
	* @throws IOException
	*/
	public void sendMessage(String message) throws IOException{
		this.session.getBasicRemote().sendText(message);
		//this.session.getAsyncRemote().sendText(message);
	}
}
</code></pre></div><h1>3. springboot整合websocket</h1>
<h2>3.1. pom.xml</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>&lt;dependencies&gt;
	&lt;dependency&gt;
	&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
	&lt;artifactId&gt;spring-boot-starter-websocket&lt;/artifactId&gt;
	&lt;/dependency&gt;
&lt;/dependencies&gt;
</code></pre></div><h2>3.2. WebSocketConfig、WebSocketInterceptor、MyWebSocketHandler</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>@Configuration
@EnableWebSocket
public class WebSocketConfig implements WebSocketConfigurer {
  @Bean
  public TextWebSocketHandler myWebSocketHandler() {
    return new MyWebSocketHandler();
  }
  @Override
  public void registerWebSocketHandlers(WebSocketHandlerRegistry registry) {
    registry.addHandler(myWebSocketHandler(), "/myweb/socket").addInterceptors(new WebSocketInterceptor()).setAllowedOrigins("*");//https://www.cnblogs.com/exmyth/p/11720371.html  
    //registry.addHandler(myWebSocketHandler(), "/myweb/sockjs").addInterceptors(new WebSocketInterceptor()).withSockJS();  
  }
  @Bean
  public TaskScheduler taskScheduler() {//避免找不到TaskScheduler Bean
    ThreadPoolTaskScheduler taskScheduler = new ThreadPoolTaskScheduler();
    taskScheduler.setPoolSize(10);
    taskScheduler.initialize();
    return taskScheduler;
  }
}
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class WebSocketInterceptor extends HttpSessionHandshakeInterceptor {
  @Override
  public boolean beforeHandshake(ServerHttpRequest request, ServerHttpResponse response, WebSocketHandler wsHandler, Map&lt;String, Object&gt; attributes) throws Exception {
    String channel = ((ServletServerHttpRequest)request).getServletRequest().getParameter("ch");
    attributes.put("channel", channel);//传参
    return super.beforeHandshake(request, response, wsHandler, attributes);
  }
  @Override
  public void afterHandshake(ServerHttpRequest request, ServerHttpResponse response, WebSocketHandler wsHandler, Exception ex) {
    super.afterHandshake(request, response, wsHandler, ex);
  }
}
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>@Slf4j
public class MyWebSocketHandler extends TextWebSocketHandler{
  @Autowired MyWebSocketService myWebSocketService;//注入需要的Service
  @Override
  public void afterConnectionEstablished(WebSocketSession session) throws Exception {
    String channel = (String)session.getAttributes().get("channel");//获取参数
    //记下session和参数用于下一步发消息...
  }
  @Override
  public void afterConnectionClosed(WebSocketSession session, CloseStatus status) throws Exception {
    String channel = (String)session.getAttributes().get("channel");
    //做会话关闭后的处理...
  }
  @Override
  protected void handleTextMessage(WebSocketSession session, TextMessage message) throws Exception {
    log.debug("receive text message: " + message.getPayload());
    //收到消息的处理...
  }
  public void send(WebSocketSession session, String text) {
    try {
      TextMessage message = new TextMessage(text);
      session.sendMessage(message);//发送消息的方法
    } catch (Exception e) {
      e.printStackTrace();
    }
  }
}
</code></pre></div><h2>3.3. SseEmitter</h2>
<ul>
<li>Controller方法返回SseEmitter对象即可为客户端提供EventSource</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>private static Set&lt;SseEmitter&gt; emitters = new HashSet&lt;&gt;();
@RequestMapping("/myweb/eventsource")
@ResponseBody
SseEmitter eventSource(String ch) {
	SseEmitter emitter = new SseEmitter(0L);
	emitters.put(emitter);//记下emitter用于之后发送数据
	emitter.onCompletion(() -&gt; {
		emitters.remove(emitter);//做连接关闭后的处理(ch, emitter)...
	});
	emitter.onTimeout(() -&gt; {
		emitter.complete();
	});
	emitter.onError((e) -&gt; {
		emitter.completeWithError(e);
	});
	return emitter;
	}
	向所有的emitters发送数据text

	SseEventBuilder builder = SseEmitter.event().data(text);
	emitters.forEach(emitter -&gt; {
	try {
		emitter.send(builder);
	} catch (Exception e) {
		errors.add(emitter);
	}
});
</code></pre></div><h1>4. 客户端连接 前端js对象WebSocket和EventSource分别用于连接这两种服务。</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>&lt;!DOCTYPE html&gt;
&lt;html&gt;
	&lt;head&gt;
	&lt;title&gt;Java后端WebSocket的Tomcat实现&lt;/title&gt;
	&lt;/head&gt;
&lt;body&gt;
	Welcome&lt;br/&gt;&lt;input id="text" type="text"/&gt;
	&lt;button onclick="send()"&gt;发送消息&lt;/button&gt;
	&lt;hr/&gt;
	&lt;button onclick="closeWebSocket()"&gt;关闭WebSocket连接&lt;/button&gt;
	&lt;hr/&gt;
	&lt;button onclick="onclear()"&gt;清空&lt;/button&gt;
	&lt;hr/&gt;
	&lt;div id="message"&gt;&lt;/div&gt;
&lt;/body&gt;

&lt;script type="text/javascript"&gt;
     var websocket = null;
     //判断当前浏览器是否支持WebSocket
     if ('WebSocket' in window) {
         websocket = new WebSocket("ws://localhost:8080/testwebscoket/websocket");
     }
    else {
         alert('当前浏览器 Not support websocket')
    }
     //连接发生错误的回调方法
     websocket.onerror = function () {
         setMessageInnerHTML("WebSocket连接发生错误");
    };
 
     //连接成功建立的回调方法
     websocket.onopen = function () {
         setMessageInnerHTML("WebSocket连接成功");
     }
 
     //接收到消息的回调方法
     websocket.onmessage = function (event) {
         setMessageInnerHTML(event.data);
     }
 
     //连接关闭的回调方法
     websocket.onclose = function () {
         setMessageInnerHTML("WebSocket连接关闭");
     }
 
     //监听窗口关闭事件，当窗口关闭时，主动去关闭websocket连接，
	 //防止连接还没断开就关闭窗口，server端会抛异常。
     window.onbeforeunload = function () {
         closeWebSocket();
     }
 
     //将消息显示在网页上
     function setMessageInnerHTML(innerHTML) {
         document.getElementById('message').innerHTML += innerHTML + '&lt;br/&gt;';
    }
 
    //关闭WebSocket连接
     function closeWebSocket() {
         websocket.close();
     }
 
     //发送消息
     function send() {
         var message = document.getElementById('text').value;
         websocket.send(message);
     }
	 function onclear(){
        document.getElementById('message').innerHTML = "";
    }
	&lt;/script&gt;
&lt;/html&gt;
</code></pre></div><h1>5. Nginx需要的额外配置</h1>
<h2>5.1. EventSource</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>proxy_http_version 1.1;
proxy_set_header Connection '';
proxy_buffering off;
proxy_cache off;
gzip off;
chunked_transfer_encoding off;
</code></pre></div><h2>5.2. WebSocket</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>proxy_http_version 1.1;
proxy_set_header Upgrade $http_upgrade;
proxy_set_header Connection "Upgrade";
</code></pre></div><h1>6. 已知问题</h1>
<ul>
<li>火狐下EventSource中断之后不会自动重连。</li>
<li>IE系列浏览器都不支持EventSource。</li>
</ul>
<h1>7. 获得httpssession的方法</h1>
<ul>
<li>由于WebSocket与Http协议的不同，故在使用常用的HttpSession方面就存在了一些问题。</li>
</ul>
<h2>7.1. GetHttpSessionConfigurator</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>package per.zww.web;
import javax.servlet.http.HttpSession;
import javax.websocket.HandshakeResponse;
import javax.websocket.server.HandshakeRequest;
import javax.websocket.server.ServerEndpointConfig;
import javax.websocket.server.ServerEndpointConfig.Configurator;
/*
* 获取HttpSession
* 
*/
public class GetHttpSessionConfigurator extends Configurator {
	@Override
	public void modifyHandshake(ServerEndpointConfig sec,HandshakeRequest request, HandshakeResponse response) {
		// TODO Auto-generated method stub
		HttpSession httpSession=(HttpSession) request.getHttpSession();
		sec.getUserProperties().put(HttpSession.class.getName(),httpSession);
	}
}
</code></pre></div><h2>7.2. 在@ServerEndpoint注解里面添加configurator属性</h2>
<ul>
<li>@ServerEndpoint(value="/socketTest",configurator=GetHttpSessionConfigurator.class)</li>
</ul>
<h2>7.3. 在onOpen方法里加入参数EndpointConfig config即可获取HttpSession</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>@OnOpen
public void onOpen(Session session,EndpointConfig config) {
	HttpSession httpSession= (HttpSession) config.getUserProperties().get(HttpSession.class.getName());
	if (httpSession == null){  
		httpSession = new HttpSession() {  
			@Override  
			public long getCreationTime() {  return 0;  }  

			@Override  
			public String getId() {  return null;  }  

			@Override  
			public long getLastAccessedTime() {  return 0;  }  

			@Override  
			public ServletContext getServletContext() {  return null;  }  

			@Override  
			public void setMaxInactiveInterval(int i) {}  

			@Override  
			public int getMaxInactiveInterval() {  return 0;  }  

			@Override  
			public HttpSessionContext getSessionContext() {  return null;  }  

			@Override  
			public Object getAttribute(String s) {  return null;  }  

			@Override  
			public Object getValue(String s) {  return null;  }  

			@Override  
			public Enumeration&lt;String&gt; getAttributeNames() {  return null;  }  

			@Override  
			public String[] getValueNames() {  return new String[0];  }  

			@Override  
			public void setAttribute(String s, Object o) {}  

			@Override  
			public void putValue(String s, Object o) {}  

			@Override  
			public void removeAttribute(String s) {}  

			@Override  
			public void removeValue(String s) {}  

			@Override  
			public void invalidate() {}  

			@Override  
			public boolean isNew() {  return false; }  
		};  
	}
	sessionMap.put(session.getId(), session);
}
</code></pre></div>]]></content:encoded>
    </item>
    <item>
      <title>xml</title>
      <link>https://javaguide.cn/backend/protocol/xml.html</link>
      <guid>https://javaguide.cn/backend/protocol/xml.html</guid>
      <source url="https://javaguide.cn/rss.xml">xml</source>
      <description>xml 1. xml介绍 2. xml语法: 3. xml约束 3.1. DTD约束 3.2. Schema约束 3.3. xml解析 3.4. 解析开发包 3.5. DOM解析原理及结构模型 1. xml介绍 xml:Extensible Markup Language 可扩展的标记语言，标签可自定义，其他与Html相似 用作:配置文件/存放数据 2...</description>
      <category>理论</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>xml</p>
<!--more-->
<!-- TOC -->
<ul>
<li><a href="#1-xml%E4%BB%8B%E7%BB%8D">1. xml介绍</a></li>
<li><a href="#2-xml%E8%AF%AD%E6%B3%95">2. xml语法:</a></li>
<li><a href="#3-xml%E7%BA%A6%E6%9D%9F">3. xml约束</a>
<ul>
<li><a href="#31-dtd%E7%BA%A6%E6%9D%9F">3.1. DTD约束</a></li>
<li><a href="#32-schema%E7%BA%A6%E6%9D%9F">3.2. Schema约束</a></li>
</ul>
</li>
<li><a href="#33-xml%E8%A7%A3%E6%9E%90">3.3. xml解析</a></li>
<li><a href="#34-%E8%A7%A3%E6%9E%90%E5%BC%80%E5%8F%91%E5%8C%85">3.4. 解析开发包</a></li>
<li><a href="#35-dom%E8%A7%A3%E6%9E%90%E5%8E%9F%E7%90%86%E5%8F%8A%E7%BB%93%E6%9E%84%E6%A8%A1%E5%9E%8B">3.5. DOM解析原理及结构模型</a></li>
</ul>
<!-- /TOC -->
<h1>1. xml介绍</h1>
<ul>
<li>xml:Extensible Markup Language 可扩展的标记语言，标签可自定义，其他与Html相似</li>
<li>用作:配置文件/存放数据</li>
</ul>
<h1>2. xml语法:</h1>
<ul>
<li>文档声明:必须从文档的0行0列位置开始;必须以&lt;?xml开头，以?&gt;结束;
<ul>
<li>&lt;?xml version="1.0" encoding="UTF-8"?&gt;</li>
<li>文档声明只有三个属性
<ul>
<li>1.version：指定xml文档版本，必须属性，只选1.0版</li>
<li>2.encoding：指定当前文档的编码，可选属性，默认值是utf-8;</li>
<li>3.standalone:指定文档独立性，可选属性，默认值为yes，表示当前文档是独立的文档；no表示当前文档不是独立文档，依赖外部文件</li>
</ul>
</li>
</ul>
</li>
<li>元素
<ul>
<li>&lt;servlet&gt;</li>
<li>普通元素的结构由开始标签，元素体，结束标签组成&lt;a&gt;&lt;/a&gt;</li>
<li>元素体可以是元素或者文本&lt;a&gt;&lt;b&gt;文本&lt;/b&gt;&lt;/a&gt;</li>
<li>空元素只有开始标签，无结束标签，元素必须自己闭合&lt;c/&gt;</li>
<li>元素命名区分大小写，不能空格冒号，不建议各种xml开头</li>
<li>格式化良好的xml有一个根元素</li>
</ul>
</li>
<li>属性
<ul>
<li>&lt;web-app version="2.5"&gt;</li>
<li>位于元素的开始标签中，属性=属性值</li>
<li>属性值必须单引号或者双引</li>
<li>一个元素可以有n个不同名属性</li>
<li>属性名不能空格冒号，必须字母开头</li>
</ul>
</li>
<li>注释 &lt;!--注释--&gt;</li>
</ul>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/d5cf38d9a11590a845bb2.png" alt="xml转义字符.png" tabindex="0"><figcaption>xml转义字符.png</figcaption></figure>
<ul>
<li>&lt;![CDATA[需要大量转义字符原来的字符]]&gt;</li>
</ul>
<h1>3. xml约束</h1>
<h2>3.1. DTD约束</h2>
<ul>
<li>
<p>文档类型定义，约束XML元素及其子元素的名称及顺序、属性等</p>
</li>
<li>
<p>文档声明：&lt;?xml version="1.0" encoding="UTF-8"?&gt;后面</p>
<ul>
<li>内部DTD:&lt;!DOCTYPE 根标签名  [语法....]&gt;只对当前的xml有效</li>
<li>外部DTD--本地文件:&lt;!DOCTYPE 根标签名 SYSTEM "xxxx.dtd"&gt;</li>
<li>外部DTD--网络:&lt;!DOCTYPE 根标签名 PUBLIC "名称" "路径"&gt;一般由框架提供</li>
</ul>
</li>
<li>
<p>元素声明&lt;!ELEMENT 标签名 [符号|约束]&gt;</p>
<ul>
<li>&lt;!ELEMENT hibernate-mapping (meta*)&gt;</li>
<li>符号：？+ *  , | ()   “文嘉兴”</li>
<li>约束：#PCDATA 表示内容是文本不是子标签</li>
<li>后面没加符号的表示有且只有一次，()分组并指示子元素个数及顺序</li>
</ul>
</li>
</ul>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/71ba34c1b3ed854bd6ae4.png" alt="dtd元素声明.png" tabindex="0"><figcaption>dtd元素声明.png</figcaption></figure>
<ul>
<li>属性声明&lt;!ATTLIST 标签名 属性描述 属性描述2 ...&gt;
<ul>
<li>&lt;!ATTLIST hibernate-mapping schema CDATA #IMPLIED&gt;</li>
<li>属性描述
<ul>
<li>属性名：自定义</li>
<li>属性类型：CDATA ，ID ，枚举（xx|）</li>
<li>属性约束：#REQUIRED （必须） #IMPLIED（可选）</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2>3.2. Schema约束</h2>
<ul>
<li>
<p>比DTD功能强、扩展名为xsd、支持命名空间、数据类型更完善</p>
</li>
<li>
<p>命名空间(解决多个xsd的元素和属性名冲突的问题)</p>
<ul>
<li>给schema文档起一个名称，只是建议采用是url进行命名。是不是官方文档看那个url</li>
<li>能在xml中区别多个约束文档中，重名的元素、属性等内容。</li>
<li>缺省命名空间（默认）:&lt;xxx xmlns=""   &gt;使用元素或属性时不加前缀&lt;xxx&gt;</li>
<li>显示命名空间:&lt;xsd xmlns:别名=""&gt;使用元素或属性时加前缀&lt;别名:xxx&gt;</li>
<li>只要url一样，两种声明方式一样</li>
</ul>
</li>
<li>
<p>文档声明</p>
<ul>
<li>&lt;xxx xmlns="...."xmlns:xsi="<a href="http://www.w3.org/2001/XMLSchema-instance" target="_blank" rel="noopener noreferrer">http://www.w3.org/2001/XMLSchema-instance</a>" xsi:schemaLocation="名称  路径   名称2 路径2  ....."&gt;  .....</li>
<li>&lt;web-app xmlns="<a href="http://www.example.org/web-app_2_5" target="_blank" rel="noopener noreferrer">http://www.example.org/web-app_2_5</a>" 自定义文档命名空间（包名）<br>
xmlns:xsi="<a href="http://www.w3.org/2001/XMLSchema-instance" target="_blank" rel="noopener noreferrer">http://www.w3.org/2001/XMLSchema-instance</a>"（官方文档命名空间）<br>
xsi:schemaLocation="<a href="http://www.example.org/web-app_2_5" target="_blank" rel="noopener noreferrer">http://www.example.org/web-app_2_5</a> web-app_2_5.xsd" 使用了官方文档的自定义文档位置属性（包里面的具体类）version="2.5"&gt;</li>
</ul>
</li>
</ul>
<h1>3.3. xml解析</h1>
<ul>
<li>DOM解析
<ul>
<li>将xml文档加载到内存形成树结构，形成Document对象
<ul>
<li>优点:元素与元素有结构关系，能CRUD，</li>
<li>缺点：文档太大易内存溢出</li>
</ul>
</li>
</ul>
</li>
<li>SAX解析
<ul>
<li>事件驱动的方式逐行边读边解析，每执行一行都触发相应的事件
<ul>
<li>优点：文档大也不内存溢出，速度快</li>
<li>缺点：只读，不能CRUD，运行后释放资源</li>
</ul>
</li>
</ul>
</li>
<li>PULL:安卓内置的xml解析方式，类似sax（了解）</li>
</ul>
<h1>3.4. 解析开发包</h1>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/a77f965211515afaa58ae.png" alt="xml解析开发包.png" tabindex="0"><figcaption>xml解析开发包.png</figcaption></figure>
<h1>3.5. DOM解析原理及结构模型</h1>
<ul>
<li>原理:将整个xml文档加载到内存，生成一个DOM树并获得Document对象以完成DOM操作</li>
</ul>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/d5859ea3930b7466265ed.png" alt="dom解析原理.png" tabindex="0"><figcaption>dom解析原理.png</figcaption></figure>
]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/d5cf38d9a11590a845bb2.png" type="image/png"/>
    </item>
    <item>
      <title>ElasticSearch</title>
      <link>https://javaguide.cn/backend/searchengine/elasticsearch.html</link>
      <guid>https://javaguide.cn/backend/searchengine/elasticsearch.html</guid>
      <source url="https://javaguide.cn/rss.xml">ElasticSearch</source>
      <description>ElasticSearch ElasticSearch介绍 注意： 在没有创建库的时候搜索，ES会创建一个库并自动创建该字段并且设置为String类型也就是text 什么是elasticsearch？一个开源的分布式搜索引擎，可以用来实现从海量数据存储、搜索、分析等功能。底层是基于lucene(Java语言的搜索引擎类库)来实现。 什么是elastic...</description>
      <category>后端</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<!--more-->
<h1>ElasticSearch</h1>
<h2>ElasticSearch介绍</h2>
<ul>
<li>注意： 在没有创建库的时候搜索，ES会创建一个库并自动创建该字段并且设置为String类型也就是text</li>
<li>什么是elasticsearch？一个开源的分布式搜索引擎，可以用来实现从海量数据存储、搜索、分析等功能。底层是基于lucene(Java语言的搜索引擎类库)来实现。</li>
<li>什么是elastic stack（ELK）？以elasticsearch为核心的技术栈，包括beats、Logstash、kibana(可视化界面)、elasticsearch，被广泛应用在日志数据分析、实时监控等领域：</li>
<li>什么是Lucene？Apache的开源搜索引擎类库，提供了搜索引擎的核心API</li>
</ul>
<h2>es参考文档</h2>
<ul>
<li><a href="https://www.cnblogs.com/buchizicai/p/17093719.html" target="_blank" rel="noopener noreferrer">https://www.cnblogs.com/buchizicai/p/17093719.html</a></li>
</ul>
<h2>正向索引和倒排索引</h2>
<ul>
<li>
<p>倒排索引的概念是基于MySQL这样的正向索引而言的。</p>
</li>
<li>
<p>正向索引：设置了索引的查询速度快，但要是模糊查询则就很慢！需要全表扫描</p>
</li>
<li>
<p>倒排索引</p>
<ul>
<li>词条（Term）：对文档数据或用户搜索数据，利用某种算法分词，得到的具备含义的词语就是词条。例如：我是中国人，就可以分为：我、是、中国人、中国、国人这样的几个词条</li>
<li>创建倒排索引流程：
<ul>
<li>将每一个文档的数据利用算法分词，得到一个个词条</li>
<li>创建表，每行数据包括词条、词条所在文档id、位置等信息</li>
<li>因为词条唯一性，可以给词条创建索引，例如hash表结构索引</li>
</ul>
</li>
<li>查询时虽然要先查询倒排索引，再查询倒排索引，但是无论是词条、还是文档id都建立了索引，查询速度非常快！无需全表扫描。</li>
</ul>
</li>
<li>
<p>正向和倒排对比</p>
<ul>
<li>正向索引是最传统的，根据id索引的方式。但根据词条查询时，必须先逐条获取每个文档，然后判断文档中是否包含所需要的词条，是根据文档找词条的过程。</li>
<li>而倒排索引则相反，是先找到用户要搜索的词条，根据词条得到保护词条的文档的id，然后根据id获取文档。是根据词条找文档的过程。</li>
</ul>
</li>
<li>
<p>正向索引：</p>
<ul>
<li>优点：可以给多个字段创建索引、根据索引字段搜索、排序速度非常快</li>
<li>缺点：根据非索引字段，或者索引字段中的部分词条查找时，只能全表扫描。</li>
</ul>
</li>
<li>
<p>倒排索引：</p>
<ul>
<li>优点：根据词条搜索、模糊搜索时，速度非常快</li>
<li>缺点：只能给词条创建索引，而不是字段、无法根据字段做排序</li>
</ul>
</li>
</ul>
<h2>ES数据库基本概念</h2>
<table>
<thead>
<tr>
<th style="text-align:center">MySQL</th>
<th style="text-align:center">Elasticsearch</th>
<th style="text-align:center">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Table</td>
<td style="text-align:center">Index</td>
<td style="text-align:center">索引(index)，就是文档的集合，类似数据库的表(table)</td>
</tr>
<tr>
<td style="text-align:center">Row</td>
<td style="text-align:center">Document</td>
<td style="text-align:center">文档（Document），就是一条条的数据，类似数据库中的行（Row），文档都是JSON格式</td>
</tr>
<tr>
<td style="text-align:center">Column</td>
<td style="text-align:center">Field</td>
<td style="text-align:center">字段（Field），就是JSON文档中的字段，类似数据库中的列（Column）</td>
</tr>
<tr>
<td style="text-align:center">Schema</td>
<td style="text-align:center">Mapping</td>
<td style="text-align:center">Mapping（映射）是索引中文档的约束，例如字段类型约束。类似数据库的表结构（Schema）</td>
</tr>
<tr>
<td style="text-align:center">SQL</td>
<td style="text-align:center">DSL</td>
<td style="text-align:center">DSL是elasticsearch提供的JSON风格的请求语句，用来操作elasticsearch，实现CRUD</td>
</tr>
</tbody>
</table>
<h2>Mapping属性</h2>
<ul>
<li>type：字段数据类型，常见的简单类型有：
<ul>
<li>字符串：text（可分词的文本）、keyword（不可分词，只能整体搜索，不支持搜索部分内容。例如：品牌、国家、ip地址）</li>
<li>数值：long、integer、short、byte、double、float、</li>
<li>布尔：boolean</li>
<li>日期：date</li>
<li>对象：object</li>
<li>geo_point地理坐标:由纬度(latitude)和经度(longitude)确定的一个点。例如:"32.8752345,120.2981576"</li>
<li>geo_shape:有多个geo_point组成的复杂几何图形。例如一条直线，"LINESTRING(-770365338.897676,-77009051 38.889939)"</li>
<li>completion：用来实现自动补全功能。这个查询会匹配以用户输入内容开头的词条并返回。字段的内容一般是用来补全的多个词条形成的数组。</li>
</ul>
</li>
<li>index：是否创建索引，默认为true</li>
<li>analyzer：使用哪种分词器</li>
<li>properties：该字段的子字段</li>
<li>copy_to:将当前字段值拷贝到另一个字段上，供用户搜索</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>例如下面的json文档：

{
    "age": 21,
    "weight": 52.1,
    "isMarried": false,
    "info": "真相只有一个！",
    "email": "zy@itcast.cn",
    "score": [99.1, 99.5, 98.9],
    "name": {
        "firstName": "柯",
        "lastName": "南"
    }
}
对应的每个字段映射（mapping）：
age：类型为 integer；参与搜索，因此需要index为true；无需分词器
weight：类型为float；参与搜索，因此需要index为true；无需分词器
isMarried：类型为boolean；参与搜索，因此需要index为true；无需分词器
info：类型为字符串，需要分词，因此是text；参与搜索，因此需要index为true；分词器可以用ik_smart
email：类型为字符串，但是不需要分词，因此是keyword；不参与搜索，因此需要index为false；无需分词器
score：虽然是数组，但是我们只看元素的类型，类型为float；参与搜索，因此需要index为true；无需分词器
name：类型为object，需要定义多个子属性
name.firstName；类型为字符串，但是不需要分词，因此是keyword；参与搜索，因此需要index为true；无需分词器
name.lastName；类型为字符串，但是不需要分词，因此是keyword；参与搜索，因此需要index为true；无需分词器
</code></pre></div><h2>mysql与elasticsearch比较</h2>
<ul>
<li>Mysql：擅长事务类型操作，可以确保数据的安全和一致性.对安全性要求较高的写操作，使用mysql实现</li>
<li>Elasticsearch：擅长海量数据的搜索、分析、计算.对查询性能要求较高的搜索需求，使用elasticsearch实现</li>
<li>两者再基于某种方式，实现数据的同步，保证一致性</li>
</ul>
<h2>分词器</h2>
<ul>
<li>分词器的作用是什么？创建倒排索引时对文档分词、用户搜索时，对输入的内容分词搜索</li>
<li>IK分词器有几种模式？ik_smart：智能切分、粗粒度；ik_max_word：最细切分，细粒度</li>
<li>IK分词器如何拓展词条？如何停用词条？利用config目录的IkAnalyzer.cfg.xml文件添加拓展词典和停用词典；在词典中添加拓展词条或者停用词条</li>
<li>注意:只有类型是text的才能分词</li>
</ul>
<h2>docker部署单点es</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>docker run -d \
	--name es \
    -e "ES_JAVA_OPTS=-Xms512m -Xmx512m" \
    -e "discovery.type=single-node" \
    -v es-data:/usr/share/elasticsearch/data \
    -v es-plugins:/usr/share/elasticsearch/plugins \
    --privileged \
    -p 9200:9200 \
    -p 9300:9300 \
elasticsearch:7.12.1
</code></pre></div><p>-e "cluster.name=es-docker-cluster"：设置集群名称<br>
-e "http.host=0.0.0.0"：监听的地址，可以外网访问<br>
-e "ES_JAVA_OPTS=-Xms512m -Xmx512m"：内存大小<br>
-e "discovery.type=single-node"：非集群模式<br>
-v es-data:/usr/share/elasticsearch/data：挂载逻辑卷，绑定es的数据目录<br>
-v es-logs:/usr/share/elasticsearch/logs：挂载逻辑卷，绑定es的日志目录<br>
-v es-plugins:/usr/share/elasticsearch/plugins：挂载逻辑卷，绑定es的插件目录<br>
--privileged：授予逻辑卷访问权<br>
--network es-net ：加入一个名为es-net的网络中<br>
-p 9200:9200：端口映射配置</p>
<ul>
<li>下载ik分词器并安装
<ul>
<li>在线安装：./bin/elasticsearch-plugin install elasticsearch-analysis-ik-7.12.1.zip</li>
<li>离线安装：下载包后，放到plugins文件夹下</li>
<li>修改配置文件,并添加/停用自定义分词字典</li>
</ul>
</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;!DOCTYPE properties SYSTEM "http://java.sun.com/dtd/properties.dtd"&gt;
&lt;properties&gt;
	&lt;comment&gt;IK Analyzer 扩展配置&lt;/comment&gt;
	&lt;!--用户可以在这里配置自己的扩展字典 --&gt;
	&lt;entry key="ext_dict"&gt;xxx.dic&lt;/entry&gt;
	 &lt;!--用户可以在这里配置自己的扩展停止词字典--&gt;
	&lt;entry key="ext_stopwords"&gt;&lt;/entry&gt;
	&lt;!--用户可以在这里配置远程扩展字典 --&gt;
	&lt;!-- &lt;entry key="remote_ext_dict"&gt;words_location&lt;/entry&gt; --&gt;
	&lt;!--用户可以在这里配置远程扩展停止词字典--&gt;
	&lt;!-- &lt;entry key="remote_ext_stopwords"&gt;words_location&lt;/entry&gt; --&gt;
&lt;/properties&gt;
</code></pre></div><ul>
<li>下载拼音分词器并安装
<ul>
<li>在线安装: ./bin/elasticsearch-plugin install <a href="https://github.com/medcl/elasticsearch-analysis-pinyin" target="_blank" rel="noopener noreferrer">https://github.com/medcl/elasticsearch-analysis-pinyin</a></li>
<li>离线安装：下载包后，放到plugins文件夹下</li>
</ul>
</li>
<li>安装/移除windows服务./bin/elasticsearch-plugin elasticsearch-service.bat start/remove</li>
<li>重置密码:./bin elasticsearch-reset-password -u elastic</li>
</ul>
<h1>ES基本命令</h1>
<ul>
<li>分词分析与自定义分词器</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>
POST /_analyze
{
  "analyzer": "ik_max_word",//分词器模式
  "text": "黑马程序员学习java太棒了"
}
# elasticsearch中分词器（analyzer）的组成包含三部分：
  - character filters：在tokenizer之前对文本进行处理。例如删除字符、替换字符
  - tokenizer：将文本按照一定的规则切割成词条（term）。例如keyword，就是不分词；还有ik_smart
  - tokenizer filter：将tokenizer输出的词条做进一步处理。例如大小写转换、同义词处理、拼音处理等
PUT /test
{
  "settings": {
    "analysis": {
      "analyzer": { // 自定义分词器
        "my_analyzer": {  // 分词器名称
          "tokenizer": "ik_max_word",
          "filter": "py"
        }
      },
      "filter": {   // 自定义tokenizer filter
        "py": {  // 过滤器名称
          "type": "pinyin", // 过滤器类型，这里是pinyin
		  "keep_full_pinyin": false,
          "keep_joined_full_pinyin": true,
          "keep_original": true,
          "limit_first_letter_length": 16,
          "remove_duplicated_term": true,
          "none_chinese_pinyin_tokenize": false
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "name": {
        "type": "text",
        "analyzer": "my_analyzer",
        "search_analyzer": "ik_smart"
      }
    }
  }
}
</code></pre></div><ul>
<li>索引库的CRUD</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code># 创建索引库和映射
PUT /索引库名称
{
  "mappings": {
    "properties": {
      "testtext":{
        "type": "text",
        "analyzer": "ik_smart"
      },
      "testnumber":{
        "type": "text",
        "analyzer":"ik_max_word"
      },
      "testobject":{
        "properties": {
          "testobjectproperties": {
            "type": "keyword"
          }
        }
      }
    }
  }
}

# 查询索引库 GET /索引库名

# 修改索引库（只能增加新的字段到mapping中）/索引库名/_mapping
# 倒排索引结构一旦数据结构改变（比如分词器），就需要重新创建倒排索引，因此索引库创建后无法修改mapping中已有的字段。但可以添加新的字段到mapping中，因为不会对倒排索引产生影响。
{
  "properties": {
    "testtext2":{
      "type": "text",
      "analyzer": "ik_max_word"
    }
  }
}


# 删除索引库：DELETE /索引库名
</code></pre></div><ul>
<li>文档操作</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code># 创建文档：POST /{索引库名}/_doc/文档id（没有则会立即创建）
POST /索引库名/_doc/文档id
{
    "字段1": "值1",
    "字段2": "值2",
    "字段3": {
        "子属性1": "值3",
        "子属性2": "值4"
    },
    // ...
}

# 查询文档：GET /{索引库名}/_doc/文档id
# 批量查询：查询该索引库下的全部文档 GET /{索引库名称}/_search

# 删除文档：DELETE /{索引库名}/_doc/文档id


# 全量修改文档：PUT /{索引库名}/_doc/文档id
# 本质：根据指定的id删除文档，不管id存不存在都新增一个相同id的文档
{
  "testtext":"斑猪活动实在太棒了2",
  "testnumber":321,
  "testobject":{
      "testobjectproperties": "斑猪秀秀也不错2"
  }
}


# 增量修改文档 ：POST /{索引库名}/_update/文档id { "doc": {字段}}
{
  "doc":{
    "testtext":"斑猪活动实在太棒了3",
    "testnumber":321,
    "testobject":{
        "testobjectproperties": "斑猪秀秀也不错3"
    }
  }
}
</code></pre></div><ul>
<li>查询</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code># Elasticsearch提供了基于JSON的DSL（Domain Specific Language）来定义查询。常见的查询类型包括：
  - 查询所有：查询出所有数据，一般测试用。例如：match_all
  - 全文检索（full text）查询：利用分词器对用户输入内容分词，然后去倒排索引库中匹配
    - match:根据一个字段查询【推荐：使用copy_to构造all字段】
    - multi_match:根据多个字段查询，参与查询字段越多，查询性能越差。建议采用copy_to，然后单字段查询的方式
  - 精确查询：
    - term:根据精确词条值查找数据，一般是查找keyword、数值、日期、boolean等类型字段。例如：ids、range、term
    - range：根据数值范围查询，可以是数值、日期的范围
  - 地理（geo）查询：根据经纬度查询。附近的地点。矩形氛围搜索，原型范围搜索 。例如：geo_distance、geo_bounding_box
  - 复合（compound）查询：复合查询可以将上述各种查询条件组合起来，合并查询条件。例如：bool、function_score
  - suggest查询: 用于实现搜索框自动补全功能
# 查询语法 
GET /{索引库名}/_search
{
  "query": {
    "查询类型": {
      "查询条件(属性名)": "条件值"
    }
  }
}
# match
{
  "query": {
    "match": {
      "testtext": "斑猪"
    }
  }
}
# mulit_match
{
  "query": {
    "mulit_match": {
      "query": "斑猪",
      "fields": ["testtext", " testtext2"]
    }
  }
}
# term
{
  "query": {
    "term": {
      "testtext": "斑猪"
    }
  }
}
# range:
{
  "query": {
    "range": {
      "testnumber": {
        "gte":100,
        "lte":200
      }
    }
  }
}
# 矩形范围查询
// geo_bounding_box查询
GET /indexName/_search
{
  "query": {
    "geo_bounding_box": {
      "testgeo_point": {
        "top_left": { // 左上点
          "lat": 31.1,
          "lon": 121.5
        },
        "bottom_right": { // 右下点
          "lat": 30.9,
          "lon": 121.7
        }
      }
    }
  }
}
# 附近(圆形)查询
{
  "query": {
    "geo_distance": {
      "distance": "15km", // 半径
      "testgeo_point": "31.21,121.5" // 圆心
    }
  }
}
# 复合查询
# fuction score：算分函数查询，可以控制文档相关性算分，控制文档排名(广告优先)。三要素：过滤条件(哪些文档要加分)、算分函数(如何计算function score)、加权方式(function score 与 query score如何运算)
# bool query：布尔查询，利用逻辑关系组合多个其它的查询，实现复杂搜索
# elasticsearch会根据词条和文档的相关度做打分，包括TF-IDF算法、BM25算法。TF-IDF算法缺点是词条频率越高，文档得分也会越高，单个词条对文档影响较大。而BM25则会让单个词条的算分有一个上限，曲线更加平滑
# match查询结果会根据文档与搜索词条的关联度打分（_score），返回结果时按照分值降序排列
{
  "query": {
    "function_score": {
      //搜索时，参与打分的字段越多，查询的性能也越差。建议搜索框的关键字搜索，是全文检索查询，使用must查询，参与算分；其它过滤条件采用filter查询。不参与算分           
      "query": { // 原始查询算分，搜索文档并根据相关性基于BM25算法打分
          "bool": {
              "must": [ //必须匹配每个子查询，类似“与”
                  {"term": {"city": "上海" }}
              ],
              "should": [ //选择性匹配子查询，类似“或”
                  {"term": {"brand": "皇冠假日" }},
                  {"term": {"brand": "华美达" }}
              ],
              "must_not": [ //必须不匹配，不参与算分，类似“非”
                  { "range": { "price": { "lte": 500 } }}
              ],
              "filter": [ //必须匹配，不参与算分
                  { "range": {"score": { "gte": 45 } }}
              ]
          }
      },
      "functions": [ // 算分函数算分
        {
          "filter": { // 符合条件的才会重新算分
            "term": {
              "brand": "如家"
            }
          },
          "weight": 2 // 算分权重为2，函数结果是常量
          "field_value_factor": 以文档中的某个字段值作为函数结果
          "random_score":以随机数作为函数结果
          "script_score":自定义算分函数算法
        }
      ],
      "boost_mode": "sum"//算分函数和原始查询的算分，两者结果的运算方式，包括sum、avg、max、min、multiply(相乘)、replace(function score替换query score)
    }
  }  
}

# Completion Suggester查询实现自动补全功能。参与补全查询的字段必须是completion类型。
// 创建索引库
PUT test
{
  "mappings": {
    "properties": {
      "title":{
        "type": "completion"
      }
    }
  }
}
//然后插入下面的数据：
POST test/_doc
{
  "title": ["Sony", "WH-1000XM3"]
}
POST test/_doc
{
  "title": ["SK-II", "PITERA"]
}
POST test/_doc
{
  "title": ["Nintendo", "switch"]
}
// 自动补全查询
GET /test/_search
{
  "suggest": {
    "title_suggest": {	//设置这个自动查询操作的名称
      "text": "s", // 关键字
      "completion": {
        "field": "title", // 补全查询的字段名
        "skip_duplicates": true, // 跳过重复的
        "size": 10 // 获取前10条结果
      }
    }
  }
}
</code></pre></div><ul>
<li>搜索结果分类</li>
<li>查询的DSL是一个大的JSON对象，包含下列属性：
<ul>
<li>query：查询条件</li>
<li>from和size：分页条件 elasticsearch会禁止from+ size 超过10000的请求.默认情况下只返回top10的数据</li>
<li>sort：排序条件 在使用排序后就不会进行算分了，根据排序设置的规则排列\普通字段是根据字典序排序\地理坐标是根据距离远近排序</li>
<li>highlight：高亮条件 高亮是对关键字高亮，因此搜索条件必须带有关键字，而不能是范围这样的查询。非搜索字段高亮，则需要添加一个属性：required_field_match=false</li>
<li>aggs：定义聚合
<ul>
<li>桶（Bucket）聚合：用来对文档做分组
<ul>
<li>term：按照文档字段值分组，例如按照品牌值分组、按照国家分组</li>
<li>Date Histogram：按照日期阶梯分组，例如一周为一组，或者一月为一组</li>
</ul>
</li>
<li>度量（Metric）聚合：用以计算一些值，比如：最大值Max、最小值Min、平均值Avg,Stats：同时求max、min、avg、sum等等</li>
<li>管道（pipeline）聚合：其它聚合的结果为基础做聚合.如：用桶聚合实现种类排序，然后使用度量聚合实现各个桶的最大值、最小值、平均值等</li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>{
  "query": { //查询条件
    "match": {
      "name":"如家"
    }
  },
  "from":0，// 分页开始的位置 分页条件
  "size": 20，// 期望获取的文档总数
  "sort": [ //当第一个条件相等时，再按照第二个条件排序，以此类推
    { "price":"asc"}，// 普通排序
    "_geo_distance" : { // 距离排序
      "location" : "31.040699,121.618075"，
      "order" : "asc",
      "unit" : "km"
    }
  ]
  "highlight":{
    "fields":{ // 高亮字段
      "name": {
        "pre_tags": "&lt;em&gt;",用来标记高亮字段的前置标签
        "post_tags": "&lt;/em&gt;"用来标记高亮字段的后置标签
      }
    }
  }
  "aggs":{ //定义聚合 参加聚合的字段必须是keyword、日期、数值、布尔类型
    "brandAgg":{ //聚合名字
      "terms":{ // 聚合的类型，按照品牌值聚合，所以选择term
        "field":"brand"，// 参与聚合的字段
        "order":{
          "doc_count": "asc" //.对聚合结果按照doc_count升序排列
        }
        "size":20 // 聚合结果数量【设置多少就最多只显示多少】
      }
    }
  }
}

</code></pre></div><h1>RestAPI</h1>
<ul>
<li>ES官方提供了各种不同语言的客户端操作ES。本质就是组装DSL语句，通过http请求发送给ES。官方文档地址：<a href="https://www.elastic.co/guide/en/elasticsearch/client/index.html" target="_blank" rel="noopener noreferrer">https://www.elastic.co/guide/en/elasticsearch/client/index.html</a></li>
<li>Java HighLevel Rest Client客户端。API操作elasticsearch的流程基本类似。核心是client.indices()方法来获取索引库的操作对象。</li>
<li>API索引库操作的基本步骤：
<ul>
<li>初始化RestHighLevelClient</li>
<li>创建XxxIndexRequest。XXX是Create、Get、Delete</li>
<li>准备DSL（ Create时需要，其它是无参）</li>
<li>发送请求。调用RestHighLevelClient#indices().xxx()方法，xxx是create、exists、delete</li>
</ul>
</li>
<li>mapping映射分析
<ul>
<li>根据MySQL数据库表结构（建表语句），去写索引库结构JSON。表和索引库一一对应</li>
<li>注意：地理坐标、组合字段。索引库里的地理坐标是一个字段：坐标：维度,精度 。copy_to组合字段作用是供用户查询（输入关键字可以查询多个字段）</li>
<li>mapping映射要考虑的信息包括：字段名、字段数据类型、是否参与搜索、是否需要分词、分词的分词器(ik_max_word)</li>
</ul>
</li>
</ul>
<h1>springboot整合es客户端</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-data-elasticsearch&lt;/artifactId&gt;
&lt;/dependency&gt;

spring:
  elasticsearch:
    rest:
      password: elasticBanzhu
      username: elastic
      connection-timeout: 1s
      uris: 127.0.0.1:9200
      read-timeout: 30s
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>@Document(indexName = "action", // 索引名
  shards = 1, // 默认索引分区数
  replicas = 0, // 每个分区的备份数
  refreshInterval = "-1" // 刷新间隔
)
@Data
public class ActionDO {
    CustomConversions customConversions;
    @Id
    private Integer id;

    @Field(analyzer = "ik_max_word", type = FieldType.Text)
    private String title;

    @Field(analyzer = "ik_smart", type = FieldType.Text)
    private String title2;
}

public interface ActionRepository extends ElasticsearchRepository&lt;ActionDO, Integer&gt; {}

@Service
public class ActionESServiceImpl implements ActionESService {

    @Autowired
    private ElasticsearchRestTemplate elasticsearchRestTemplate;
    @Resource
    private ActionRepository actionRepository;

    @Override
    public void saveAction(){
        ActionDO actionDO = new ActionDO();
        actionDO.setId(1);
        actionDO.setTitle("我是测试活动");
        elasticsearchRestTemplate.save(actionDO);
    }

    @Override
    public void updateAction(){
        ActionDO actionDO = new ActionDO();
        actionDO.setId(1);
        actionDO.setTitle("我是测试更新活动");
        actionRepository.save(actionDO);
    }

    @Override
    public void deleteActionById(){
        actionRepository.deleteById(1);
    }

    @Override
    public void selectById(){
        Iterable&lt;ActionDO&gt; actionDOS = actionRepository.findAllById(Arrays.asList(1, 4));
        actionDOS.forEach(System.out::println);
    }
}
</code></pre></div><h1>ES与MySQL数据同步</h1>
<ul>
<li>同步调用:实现简单，粗暴、业务耦合度高</li>
<li>异步通知【常用】：低耦合，实现难度一般、依赖mq的可靠性</li>
<li>监听binlog：解耦合，开启binlog增加数据库负担、实现复杂度高。基于canal监听binlog变化，实时更新elasticsearch中的内容</li>
</ul>
<h1>ES集群搭建</h1>
<ul>
<li>创建ES集群：至少有4G的内存空间
<ul>
<li>创建docker-compose文件</li>
<li>es运行需要修改一些linux系统权限，修改/etc/sysctl.conf文件并添加vm.max_map_count=262144，执行sysctl -p生效</li>
<li>docker-compose up -d启动集群</li>
</ul>
</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>version: '2.2'
services:
  es01:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.12.1
    container_name: es01
    environment:
      - node.name=es01
      - cluster.name=es-docker-cluster
      - discovery.seed_hosts=es02,es03
      - cluster.initial_master_nodes=es01,es02,es03
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - data01:/usr/share/elasticsearch/data
    ports:
      - 9200:9200
    networks:
      - elastic
  es02:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.12.1
    container_name: es02
    environment:
      - node.name=es02
      - cluster.name=es-docker-cluster
      - discovery.seed_hosts=es01,es03
      - cluster.initial_master_nodes=es01,es02,es03
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - data02:/usr/share/elasticsearch/data
    networks:
      - elastic
  es03:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.12.1
    container_name: es03
    environment:
      - node.name=es03
      - cluster.name=es-docker-cluster
      - discovery.seed_hosts=es01,es02
      - cluster.initial_master_nodes=es01,es02,es03
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - data03:/usr/share/elasticsearch/data
    networks:
      - elastic

volumes:
  data01:
    driver: local
  data02:
    driver: local
  data03:
    driver: local

networks:
  elastic:
    driver: bridge
</code></pre></div><h1>集群状态监控</h1>
<ul>
<li>kibana或者cerebro来监控es集群状态，官方网址：<a href="https://github.com/lmenezes/cerebro" target="_blank" rel="noopener noreferrer">https://github.com/lmenezes/cerebro</a></li>
</ul>
<h1>集群其他问题</h1>
<ul>
<li>master eligible节点的作用是什么？参与集群选主（主节点可以管理集群状态、管理分片信息、处理创建和删除索引库的请求）</li>
<li>data节点的作用是什么？数据的CRUD</li>
<li>coordinator节点的作用是什么？路由请求到其它节点。合并查询到的结果，返回给用户</li>
</ul>
<h1>集群职责划分</h1>
<ul>
<li>通过改变配置文件中的 true——&gt; false 来改变职责。如data数据职责节点就只保留data为true其他为false</li>
<li>注意：每个节点都是路由，这样可以保证不管哪个节点接收到请求可以分给其他人已经从其他人那接收信息。</li>
<li>默认情况下，集群中的任何一个节点都同时具备下述四种角色。<br>
|节点类型|配置参数|默认值|节点职责|要求|<br>
|:-😐:-😐:-😐:-😐:-😐<br>
|master eligible|node.master|true|备选主节点:主节点可以管理和记录集群状态、决定。分片在哪个节点、处理创建和删除索引库的请求|对CPU要求高，但是内存要求低|<br>
|data|node.data|true|数据节点:存储数据、搜索、聚合、CRUD|对CPU和内存要求都高|<br>
|ingest|node.ingest|true|数据存储之前的预处理|<br>
|coordinating|上面3个参数都为false则为coordinating节点|无|路由请求到其它节点。合并其它节点处理的结果，返回给用户|对网络带宽、CPU要求高|<br>
image</li>
</ul>
<h1>脑裂问题</h1>
<ul>
<li>ES 7.0后默认配置了(eligible节点数量+1)/2来解决脑裂问题</li>
<li>脑裂是因为集群中的节点失联导致的。假设集群中有三个节点，主节点node1与node2和3失联，重新选举，node3成为主节点，node1自成集群，node2、3自成集群，网络恢复后，2个集群状态不一致</li>
<li>解决脑裂的方案是，要求选票超过(eligible节点数量 + 1)/ 2 才能当选为主，因此eligible节点数量最好是奇数。对应配置项是discovery.zen.minimum_master_nodes，在es7.0以后，已经成为默认配置，因此一般不会发生脑裂问题</li>
</ul>
<h1>集群分布式存储</h1>
<ul>
<li>当新增文档时，elasticsearch会通过hash算法来计算文档应该存储到哪个分片，保证数据均衡，shard = hash(_routing文档id) % number_of_shards分片数</li>
<li>算法与分片数量有关，因此索引库一旦创建，分片数量不能修改！</li>
</ul>
<h1>集群分布式查询原理：</h1>
<ul>
<li>elasticsearch的查询分成两个阶段：
<ul>
<li>scatter phase：分散阶段，coordinating node会把请求分发到每一个分片</li>
<li>gather phase：聚集阶段，coordinating node汇总data node的搜索结果，并处理为最终结果集返回给用户</li>
</ul>
</li>
</ul>
<h1>集群故障转移</h1>
<ul>
<li>集群的master节点会监控集群中的节点状态，如果发现有节点宕机，会立即将宕机节点的分片数据迁移到其它节点，确保数据安全，这个叫做故障转移。</li>
<li>ES默认配置好了有集群故障转移</li>
</ul>
]]></content:encoded>
    </item>
    <item>
      <title>lucene</title>
      <link>https://javaguide.cn/backend/searchengine/lucene.html</link>
      <guid>https://javaguide.cn/backend/searchengine/lucene.html</guid>
      <source url="https://javaguide.cn/rss.xml">lucene</source>
      <description>lucene 1. 全文检索介绍 2. Lucene介绍 3. Lucene实现全文检索的流程 4. Lucene使用 1. 全文检索介绍 数据分类 结构化数据：指具有固定格式或有限长度的数据，如数据库，元数据等。 非结构化数据：指不定长或无固定格式的数据，如邮件，word文档等磁盘上的文件 顺序扫描法(Serial Scanning)顺序遍历所有文档...</description>
      <category>后端</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>lucene</p>
<!--more-->
<!-- TOC -->
<ul>
<li><a href="#1-%E5%85%A8%E6%96%87%E6%A3%80%E7%B4%A2%E4%BB%8B%E7%BB%8D">1. 全文检索介绍</a></li>
<li><a href="#2-lucene%E4%BB%8B%E7%BB%8D">2. Lucene介绍</a></li>
<li><a href="#3-lucene%E5%AE%9E%E7%8E%B0%E5%85%A8%E6%96%87%E6%A3%80%E7%B4%A2%E7%9A%84%E6%B5%81%E7%A8%8B">3. Lucene实现全文检索的流程</a></li>
<li><a href="#4-lucene%E4%BD%BF%E7%94%A8">4. Lucene使用</a></li>
</ul>
<!-- /TOC -->
<h1>1. 全文检索介绍</h1>
<ul>
<li>数据分类
<ul>
<li>结构化数据：指具有固定格式或有限长度的数据，如数据库，元数据等。</li>
<li>非结构化数据：指不定长或无固定格式的数据，如邮件，word文档等磁盘上的文件
<ul>
<li>顺序扫描法(Serial Scanning)顺序遍历所有文档的内容,直到扫描完所有的文档,如利用windows的搜索也可以搜索文件内容，只是慢</li>
<li>全文检索(Full-text Search)先从非结构化数据中提取出的然后重新组织的信息(索引)再对索引进行搜索</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1>2. Lucene介绍</h1>
<ul>
<li>Lucene是apache下的一个开放源代码的全文检索引擎工具包。提供了完整的查询引擎和索引引擎，部分文本分析引擎。</li>
<li>对于数据量大、数据结构不固定的数据可采用全文检索方式搜索，比如百度、Google等搜索引擎、论坛站内搜索、电商网站站内搜索等。</li>
</ul>
<h1>3. Lucene实现全文检索的流程</h1>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/eabbde040a19fe3ae942a.png" alt="图片1.png" tabindex="0"><figcaption>图片1.png</figcaption></figure>
<ul>
<li>绿色表示索引过程，对要搜索的原始内容进行索引构建一个索引库，索引过程包括：确定原始内容即要搜索的内容→采集文档→创建文档→分析文档→索引文档</li>
<li>红色表示搜索过程，从索引库中搜索内容，搜索过程包括：用户通过搜索界面→创建查询→执行搜索，从索引库搜索→渲染搜索结果</li>
</ul>
<h1>4. Lucene使用</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>从官方网站：http://lucene.apache.org/ 下载Lucene4.10.3，并解压。
Jdk要求：1.7以上

jar包
lucene-core-4.10.3.jar
lucene-analyzers-common-4.10.3.jar
lucene-queryparser-4.10.3.jar
其它：
commons-io-2.4.jar
junit-4.9.jar

功能一：创建索引库
使用indexwriter对象创建索引
第一步：创建一个java工程，并导入jar包。
第二步：创建一个indexwriter对象。
1）指定索引库的存放位置Directory对象
2）指定一个分析器，对文档内容进行分析。
第二步：创建document对象。
第三步：创建field对象，将field添加到document对象中。
第四步：使用indexwriter对象将document对象写入索引库，此过程进行索引创建。并将索引和document对象写入索引库。
第五步：关闭IndexWriter对象。

@Test
public void createIndex() throws Exception {
	//指定索引库存放的路径
	//D:\temp\0108\index
	Directory directory = FSDirectory.open(new File("D:\\temp\\0108\\index"));
	//索引库还可以存放到内存中
	//Directory directory = new RAMDirectory();
	//创建一个标准分析器
	//Analyzer analyzer = new StandardAnalyzer();// 官方推荐
	Analyzer analyzer = new IKAnalyzer();// 官方推荐
	//创建indexwriterCofig对象
	//第一个参数： Lucene的版本信息，可以选择对应的lucene版本也可以使用LATEST
	//第二根参数：分析器对象
	IndexWriterConfig config = new IndexWriterConfig(Version.LATEST, analyzer);
	//创建indexwriter对象
	IndexWriter indexWriter = new IndexWriter(directory, config);
	//原始文档的路径D:\传智播客\01.课程\04.lucene\01.参考资料\searchsource
	File dir = new File("D:\\传智播客\\01.课程\\04.lucene\\01.参考资料\\searchsource");
	for (File f : dir.listFiles()) {
		//文件名
		String fileName = f.getName();
		//文件内容
		String fileContent = FileUtils.readFileToString(f);
		//文件路径
		String filePath = f.getPath();
		//文件的大小
		long fileSize  = FileUtils.sizeOf(f);
		//创建文件名域
		//第一个参数：域的名称
		//第二个参数：域的内容
		//第三个参数：是否存储
		Field fileNameField = new TextField("filename", fileName, Store.YES);
		//Field域的属性
		//是否分析：是否对域的内容进行分词处理。前提是我们要对域的内容进行查询。
		//是否索引：将Field分析后的词或整个Field值进行索引，只有索引方可搜索到。
		//比如：商品名称、商品简介分析后进行索引，订单号、身份证号不用分析但也要索引，这些将来都要作为查询条件。
		//是否存储：将Field值存储在文档中，存储在文档中的Field才可以从Document中获取
		//是否存储的标准：是否要将内容展示给用户
		//比如：商品名称、订单号，凡是将来要从Document中获取的Field都要存储。
		//文件内容域
		Field fileContentField = new TextField("content", fileContent, Store.YES);
		//文件路径域（不分析、不索引、只存储）
		Field filePathField = new StoredField("path", filePath);
		//文件大小域
		Field fileSizeField = new LongField("size", fileSize, Store.YES);
		
		//创建document对象
		Document document = new Document();
		document.add(fileNameField);
		document.add(fileContentField);
		document.add(filePathField);
		document.add(fileSizeField);
		//创建索引，并写入索引库
		indexWriter.addDocument(document);
	}
	//关闭indexwriter
	indexWriter.close();
}
</code></pre></div><p><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/ee25b2bd28aa2f116963c.png" alt="图片6.png"><br>
使用Luke工具查看索引文件<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/88cb3f7a269de2dce082e.png" alt="图片7.png"></p>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>功能二：查询索引
实现步骤
第一步：创建一个Directory对象，也就是索引库存放的位置。
第二步：创建一个indexReader对象，需要指定Directory对象。
第三步：创建一个indexsearcher对象，需要指定IndexReader对象
第四步：创建一个TermQuery对象，指定查询的域和查询的关键词。
第五步：执行查询。
第六步：返回查询结果。遍历查询结果并输出。
第七步：关闭IndexReader对象

@Test
public void searchIndex() throws Exception {
	//指定索引库存放的路径
	//D:\temp\0108\index
	Directory directory = FSDirectory.open(new File("D:\\temp\\0108\\index"));
	//创建indexReader对象
	IndexReader indexReader = DirectoryReader.open(directory);
	//创建indexsearcher对象
	IndexSearcher indexSearcher = new IndexSearcher(indexReader);
	//创建一个TermQuery对象，指定查询的域和查询的关键词。
	Query query = new TermQuery(new Term("filename", "apache"));
	//执行查询
	//第一个参数是查询对象，第二个参数是查询结果返回的最大值
	//indexSearcher.search(query, n)	根据Query搜索，返回评分最高的n条记录
	//indexSearcher.search(query, filter, n)	根据Query搜索，添加过滤策略，返回评分最高的n条记录
	//indexSearcher.search(query, n, sort)	根据Query搜索，添加排序策略，返回评分最高的n条记录
	//indexSearcher.search(booleanQuery, filter, n, sort)	根据Query搜索，添加过滤策略，添加排序策略，返回评分最高的n条记录
	TopDocs topDocs = indexSearcher.search(query, 10);

	//查询结果的总条数
	//TopDocs.totalHits：是匹配索引库中所有记录的数量
	//TopDocs.scoreDocs：匹配相关度高的前边记录数组，scoreDocs的长度小于等于search方法指定的参数n
	System.out.println("查询结果的总条数："+ topDocs.totalHits);
	//遍历查询结果
	//topDocs.scoreDocs存储了document对象的id
	for (ScoreDoc scoreDoc : topDocs.scoreDocs) {
		//scoreDoc.doc属性就是document对象的id
		//根据document的id找到document对象
		Document document = indexSearcher.doc(scoreDoc.doc);
		System.out.println(document.get("filename"));
		//System.out.println(document.get("content"));
		System.out.println(document.get("path"));
		System.out.println(document.get("size"));
	}
	//关闭indexreader对象
	indexReader.close();
}
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>功能三：支持中文分词
分析器（Analyzer）的执行过程语汇单元的生成过程：Reader-&gt;Tokenizer-&gt;TokenFilter-&gt;TokenFilter-&gt;TokenFilter-&gt;Tokens
要看分析器的分析效果，只需要看Tokenstream中的内容就可以了。每个分析器都有一个方法tokenStream，返回一个tokenStream对象。

分析器的分词效果
//查看标准分析器的分词效果
@Test
public void testTokenStream() throws Exception {
	//创建一个标准分析器对象
	Analyzer analyzer = new IKAnalyzer();
	//获得tokenStream对象
	//第一个参数：域名，可以随便给一个
	//第二个参数：要分析的文本内容
	TokenStream tokenStream = analyzer.tokenStream("test", "The Spring Framework provides a comprehensive programming and configuration model.");
	//添加一个引用，可以获得每个关键词
	CharTermAttribute charTermAttribute = tokenStream.addAttribute(CharTermAttribute.class);
	//添加一个偏移量的引用，记录了关键词的开始位置以及结束位置
	OffsetAttribute offsetAttribute = tokenStream.addAttribute(OffsetAttribute.class);
	//将指针调整到列表的头部
	tokenStream.reset();
	//遍历关键词列表，通过incrementToken方法判断列表是否结束
	while(tokenStream.incrementToken()) {
		//关键词的起始位置
		System.out.println("start-&gt;" + offsetAttribute.startOffset());
		//取关键词
		System.out.println(charTermAttribute);
		//结束位置
		System.out.println("end-&gt;" + offsetAttribute.endOffset());
	}
	tokenStream.close();
}
IKAnalyzer.cfg.xml扩展ik分析器
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;!DOCTYPE properties SYSTEM "http://java.sun.com/dtd/properties.dtd"&gt;  
&lt;properties&gt;  
	&lt;comment&gt;IK Analyzer 扩展配置&lt;/comment&gt;
	&lt;!--用户可以在这里配置自己的扩展字典 --&gt;
	&lt;entry key="ext_dict"&gt;ext.dic;&lt;/entry&gt; 
	
	&lt;!--用户可以在这里配置自己的扩展停止词字典--&gt;
	&lt;entry key="ext_stopwords"&gt;stopword.dic;&lt;/entry&gt; 
	
&lt;/properties&gt;
中文分析器
Lucene自带中文分词器
StandardAnalyzer：单字分词：就是按照中文一个字一个字地进行分词。如：“我爱中国”， 效果：“我”、“爱”、“中”、“国”。
CJKAnalyzer：二分法分词：按两个字进行切分。如：“我是中国人”，效果：“我是”、“是中”、“中国”“国人”。
上边两个分词器无法满足需求。SmartChineseAnalyzer 对中文支持较好，但扩展性差，扩展词库，禁用词库和同义词库等不好处理
第三方中文分析器IK-analyzer(zhongdian)： 最新版在https://code.google.com/p/ik-analyzer/上，支持Lucene 4.10从2006年12月推出1.0版开始， 
IKAnalyzer已经推出了4个大版本。最初，它是以开源项目Luence为应用主体的，结合词典分词和文法分析算法的中文分词组件。
从3.0版本开 始，IK发展为面向Java的公用分词组件，独立于Lucene项目，同时提供了对Lucene的默认优化实现。
在2012版本中，IK实现了简单的分词 歧义排除算法，标志着IK分词器从单纯的词典分词向模拟语义分词衍化。 


IKAnalyzer
使用方法：
第一步：把jar包添加到工程中
第二步：把配置文件和扩展词典和停用词词典添加到classpath下
注意：mydict.dic和ext_stopword.dic文件的格式为UTF-8，注意是无BOM 的UTF-8 编码。
使用EditPlus.exe保存为无BOM 的UTF-8 编码格式
Analyzer使用时机
索引时使用Analyzer
输入关键字进行搜索，当需要让该关键字与文档域内容所包含的词进行匹配时需要对文档域内容进行分析，
需要经过Analyzer分析器处理生成语汇单元（Token）。分析器分析的对象是文档中的Field域。
当Field的属性tokenized（是否分词）为true时会对Field值进行分析，如下图：
对于一些Field可以不用分析：
1、不作为查询条件的内容，比如文件路径
2、不是匹配内容中的词而匹配Field的整体内容，比如订单号、身份证号等。

搜索时使用Analyzer
对搜索关键字进行分析和索引分析一样，使用Analyzer对搜索关键字进行分析、分词处理，
使用分析后每个词语进行搜索。比如：搜索关键字：spring web ，经过分析器进行分词，
得出：spring  web拿词去索引词典表查找 ，找到索引链接到Document，解析Document内容。
对于匹配整体Field域的查询可以在搜索时不分析，比如根据订单号、身份证号查询等。
注意：搜索使用的分析器要和索引使用的分析器一致。
</code></pre></div><figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/70c59e47babacadd5ed42.png" alt="图片10.png" tabindex="0"><figcaption>图片10.png</figcaption></figure>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>索引库的维护
索引库的添加
	向索引库中添加document对象。
	第一步：先创建一个indexwriter对象
	第二步：创建一个document对象
	第三步：把document对象写入索引库
	第四步：关闭indexwriter。

	//添加索引
	@Test
	public void addDocument() throws Exception {
		//索引库存放路径
		Directory directory = FSDirectory.open(new File("D:\\temp\\0108\\index"));	
		IndexWriterConfig config = new IndexWriterConfig(Version.LATEST, new IKAnalyzer());
		//创建一个indexwriter对象
		IndexWriter indexWriter = new IndexWriter(directory, config);
		//创建一个Document对象
		Document document = new Document();
		//向document对象中添加域。
		//不同的document可以有不同的域，同一个document可以有相同的域。
		document.add(new TextField("filename", "新添加的文档", Store.YES));
		document.add(new TextField("content", "新添加的文档的内容", Store.NO));
		document.add(new TextField("content", "新添加的文档的内容第二个content", Store.YES));
		document.add(new TextField("content1", "新添加的文档的内容要能看到", Store.YES));
		//添加文档到索引库
		indexWriter.addDocument(document);
		//关闭indexwriter
		indexWriter.close();	
	}

索引库删除
	将索引目录的索引信息全部删除，直接彻底删除，无法恢复。此方法慎用！！
	//删除全部索引
	@Test
	public void deleteAllIndex() throws Exception {
		IndexWriter indexWriter = getIndexWriter();
		//删除全部索引
		indexWriter.deleteAll();
		//关闭indexwriter
		indexWriter.close();
	}

指定查询条件删除
	//根据查询条件删除索引
	@Test
	public void deleteIndexByQuery() throws Exception {
		IndexWriter indexWriter = getIndexWriter();
		//创建一个查询条件
		Query query = new TermQuery(new Term("filename", "apache"));
		//根据查询条件删除
		indexWriter.deleteDocuments(query);
		//关闭indexwriter
		indexWriter.close();
	}

索引库的修改
	原理就是先删除后添加。
	//修改索引库
	@Test
	public void updateIndex() throws Exception {
		IndexWriter indexWriter = getIndexWriter();
		//创建一个Document对象
		Document document = new Document();
		//向document对象中添加域。
		//不同的document可以有不同的域，同一个document可以有相同的域。
		document.add(new TextField("filename", "要更新的文档", Store.YES));
		document.add(new TextField("content", "2013年11月18日 - Lucene 简介 Lucene 是一个基于 Java 的全文信息检索工具包,"+"
		它不是一个完整的搜索应用程序,而是为你的应用程序提供索引和搜索功能。", Store.YES));
		//先根据content域为java查找到文档，新文档覆盖该文档，原文档的content域及其文档本身不再存在于新索引库中，被整个新文档的域和新文档本身取代
		//先根据content域为java查找到文档，如果有就更新它(如果有多条，最后更新后只有一条)。如果没有就新增.
		indexWriter.updateDocument(new Term("content", "java"), document);
		//关闭indexWriter
		indexWriter.close();
	}

索引库查询（重点）
	对要搜索的信息创建Query查询对象，Lucene会根据Query查询对象生成最终的查询语法，
	可通过两种方法创建查询对象：
	1）使用Lucene提供Query子类
	Query是一个抽象类，lucene提供了很多查询对象，比如TermQuery项精确查询，NumericRangeQuery数字范围查询等。
	Query query = new TermQuery(new Term("name", "lucene"));

	2）使用QueryParse解析查询表达式
	QueryParse会将用户输入的查询表达式解析成Query对象实例。
	QueryParser queryParser = new QueryParser("name", new IKAnalyzer());
	Query query = queryParser.parse("name:lucene");


使用query的子类查询
	MatchAllDocsQuery
	使用MatchAllDocsQuery查询索引目录中的所有文档
	@Test
	public void testMatchAllDocsQuery() throws Exception {
		IndexSearcher indexSearcher = getIndexSearcher();
		//创建查询条件
		Query query = new MatchAllDocsQuery();
		//执行查询
		printResult(query, indexSearcher);
	}

	TermQuery
	TermQuery，通过项查询，TermQuery不使用分析器所以建议匹配不分词的Field域查询，比如订单号、分类ID号等。
	指定要查询的域和要查询的关键词。
	@Test
	public void testTermQuery() throws Exception {
		IndexSearcher indexSearcher = getIndexSearcher();
		//创建查询对象
		Query query = new TermQuery(new Term("content", "lucene"));
		//执行查询
		TopDocs topDocs = indexSearcher.search(query, 10);
		//共查询到的document个数
		System.out.println("查询结果总数量：" + topDocs.totalHits);
		//遍历查询结果
		for (ScoreDoc scoreDoc : topDocs.scoreDocs) {
			Document document = indexSearcher.doc(scoreDoc.doc);
			System.out.println(document.get("filename"));
			//System.out.println(document.get("content"));
			System.out.println(document.get("path"));
			System.out.println(document.get("size"));
		}
		//关闭indexreader
		indexSearcher.getIndexReader().close();
	}

	NumericRangeQuery
	可以根据数值范围查询。
	//数值范围查询
	@Test
	public void testNumericRangeQuery() throws Exception {
		IndexSearcher indexSearcher = getIndexSearcher();
		//创建查询
		//参数：
		//1.域名
		//2.最小值
		//3.最大值
		//4.是否包含最小值
		//5.是否包含最大值
		Query query = NumericRangeQuery.newLongRange("size", 1l, 1000l, true, true);
		//执行查询
		printResult(query, indexSearcher);
	}

	BooleanQuery
	可以组合查询条件。
	//组合条件查询
	@Test
	public void testBooleanQuery() throws Exception {
		IndexSearcher indexSearcher = getIndexSearcher();
		//创建一个布尔查询对象
		BooleanQuery query = new BooleanQuery();
		//创建第一个查询条件
		Query query1 = new TermQuery(new Term("filename", "apache"));
		Query query2 = new TermQuery(new Term("content", "apache"));
		//组合查询条件
		//Occur.MUST：必须满足此条件，相当于and
		//Occur.SHOULD：应该满足，但是不满足也可以，相当于or
		//Occur.MUST_NOT：必须不满足。相当于not
		query.add(query1, Occur.MUST);
		query.add(query2, Occur.MUST);
		//执行查询
		printResult(query, indexSearcher);
	}

	


使用queryparser查询
	通过QueryParser也可以创建Query，QueryParser提供一个Parse方法，此方法可以直接根据查询语法来查询。
	Query对象执行的查询语法可通过System.out.println(query);查询。
	需要使用到分析器。建议创建索引时使用的分析器和查询索引时使用的分析器要一致。

	需要加入queryParser依赖的jar包。
	lucene-queryparser-4.10.3.jar
	@Test
	public void testQueryParser() throws Exception {
		IndexSearcher indexSearcher = getIndexSearcher();
		//创建queryparser对象
		//第一个参数默认搜索的域*:*全部查的语法
		//第二个参数就是分析器对象
		QueryParser queryParser = new QueryParser("content", new IKAnalyzer());
		//执行*:*
		Query query = queryParser.parse("Lucene是java开发的");
		//执行fileName:test
		//Query query = queryParser.parse("fileName:test");
		//执行查询
		printResult(query, indexSearcher);
	}

查询语法
1、基础的查询语法，关键词查询：
	域名+“：”+搜索的关键字
	例如：content:java
2、范围查询
	域名+“:”+[最小值 TO 最大值]
	例如：size:[1 TO 1000]
	范围查询在lucene中支持数值类型，不支持字符串类型。在solr中支持字符串类型。
3、组合条件查询
1）+条件1 +条件2：两个条件之间是并且的关系and
例如：+filename:apache +content:apache
2）+条件1 条件2：必须满足第一个条件，应该满足第二个条件
例如：+filename:apache content:apache
3）条件1 条件2：两个条件满足其一即可。
例如：filename:apache content:apache
4）-条件1 条件2：必须不满足条件1，要满足条件2
例如：-filename:apache content:apache
Occur.MUST 查询条件必须满足，相当于and	+（加号）
Occur.SHOULD 查询条件可选，相当于or 空（不用符号）
Occur.MUST_NOT 查询条件不能满足，相当于not非	-（减号）

第二种写法：
条件1 AND 条件2
条件1 OR 条件2
条件1 NOT 条件2

MultiFieldQueryParser
可以指定多个默认搜索域
@Test
public void testMultiFiledQueryParser() throws Exception {
	IndexSearcher indexSearcher = getIndexSearcher();
	//可以指定默认搜索的域是多个
	String[] fields = {"filename", "content"};
	//创建一个MulitFiledQueryParser对象
	MultiFieldQueryParser queryParser = new MultiFieldQueryParser(fields, new IKAnalyzer());
	Query query = queryParser.parse("java AND apache");
	System.out.println(query);
	//执行查询
	printResult(query, indexSearcher);
	
	}
</code></pre></div>]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/eabbde040a19fe3ae942a.png" type="image/png"/>
    </item>
    <item>
      <title>solr</title>
      <link>https://javaguide.cn/backend/searchengine/solr.html</link>
      <guid>https://javaguide.cn/backend/searchengine/solr.html</guid>
      <source url="https://javaguide.cn/rss.xml">solr</source>
      <description>solr 1. solr介绍 2. Solr与Lucene的区别 3. Solr安装及配置 4. Solr管理索引库 5. 使用SolrJ管理索引库 6. 什么是SolrCloud 7. Solr集群的系统架构 8. 需要实现的solr集群架构 9. solrcloud的搭建 1. solr介绍 Solr是Apache下的一个顶级开源项目，它是基于Lu...</description>
      <category>后端</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>solr</p>
<!--more-->
<!-- TOC -->
<ul>
<li><a href="#1-solr%E4%BB%8B%E7%BB%8D">1. solr介绍</a></li>
<li><a href="#2-solr%E4%B8%8Elucene%E7%9A%84%E5%8C%BA%E5%88%AB">2. Solr与Lucene的区别</a></li>
<li><a href="#3-solr%E5%AE%89%E8%A3%85%E5%8F%8A%E9%85%8D%E7%BD%AE">3. Solr安装及配置</a></li>
<li><a href="#4-solr%E7%AE%A1%E7%90%86%E7%B4%A2%E5%BC%95%E5%BA%93">4. Solr管理索引库</a></li>
<li><a href="#5-%E4%BD%BF%E7%94%A8solrj%E7%AE%A1%E7%90%86%E7%B4%A2%E5%BC%95%E5%BA%93">5. 使用SolrJ管理索引库</a></li>
<li><a href="#6-%E4%BB%80%E4%B9%88%E6%98%AFsolrcloud">6. 什么是SolrCloud</a></li>
<li><a href="#7-solr%E9%9B%86%E7%BE%A4%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84">7. Solr集群的系统架构</a></li>
<li><a href="#8-%E9%9C%80%E8%A6%81%E5%AE%9E%E7%8E%B0%E7%9A%84solr%E9%9B%86%E7%BE%A4%E6%9E%B6%E6%9E%84">8. 需要实现的solr集群架构</a></li>
<li><a href="#9-solrcloud%E7%9A%84%E6%90%AD%E5%BB%BA">9. solrcloud的搭建</a></li>
</ul>
<!-- /TOC -->
<h1>1. solr介绍</h1>
<ul>
<li>Solr是Apache下的一个顶级开源项目，它是基于Lucene的全文搜索服务器。Solr提供了比Lucene更为丰富的查询语言，<br>
同时实现了可配置、可扩展，并对索引、搜索性能进行了优化。</li>
<li>Solr可以独立运行，运行在Jetty、Tomcat等这些Servlet容器中</li>
<li>Solr用 POST 方法向 Solr 服务器发送一个描述 Field 及其内容的 XML 文档，Solr根据xml文档添加、删除、更新索引 。</li>
<li>Solr 搜索只需要发送 HTTP GET 请求，然后对 Solr 返回Xml、json等格式的查询结果进行解析，组织页面布局。</li>
<li>Solr不提供构建UI的功能，Solr提供了一个管理界面，通过管理界面可以查询Solr的配置和运行情况。</li>
</ul>
<h1>2. Solr与Lucene的区别</h1>
<ul>
<li>Lucene是一个开放源代码的全文检索引擎工具包，它不是一个完整的全文检索引擎，Lucene提供了完整的查询引擎和索引引擎，目的是为软件开发人员提供一个简单易用的工具包，以方便的在目标系统中实现全文检索的功能，或者以Lucene为基础构建全文检索引擎。</li>
<li>Solr的目标是打造一款企业级的搜索引擎系统，它是一个搜索引擎服务，可以独立运行，通过Solr可以非常快速的构建企业的搜索引擎，通过Solr也可以高效的完成站内搜索功能。</li>
</ul>
<h1>3. Solr安装及配置</h1>
<ul>
<li>从Solr官方网站（<a href="http://lucene.apache.org/solr/" target="_blank" rel="noopener noreferrer">http://lucene.apache.org/solr/</a> ）下载Solr4.10.3，根据Solr的运行环境，Linux下需要下载lucene-4.10.3.tgz，windows下需要下载lucene-4.10.3.zip。</li>
<li>Solr使用指南可参考：<a href="https://wiki.apache.org/solr/FrontPage" target="_blank" rel="noopener noreferrer">https://wiki.apache.org/solr/FrontPage</a></li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>Solr的文件夹结构
	bin：solr的运行脚本
	contrib：solr的一些贡献软件/插件，用于增强solr的功能。
	dist：该目录包含build过程中产生的war和jar文件，以及相关的依赖文件。
	docs：solr的API文档
	licenses：solr相关的一些许可信息
	example：solr工程的例子目录：
		example/solr：包含了默认配置信息的Solr home目录(Solr运行的主目录,包括了运行Solr实例所有的配置文件和数据文件)。
		一个SolrHome可以包括多个SolrCore（Solr实例），每个SolrCore提供单独的搜索和索引服务。
			example/solr/collection1包含了一个solr Core实例目录
				SolrCore名称不固定，一个solr运行实例对外单独提供索引和搜索接口和一个索引目录。
				一个solrcore相当于mysql中一个数据库。Solrcore之间是相互隔离。
				一个Solr工程可以运行多个SolrCore（Solr实例），一个Core对应一个索引目录。
			example/solr/collection1/data 该目录存放索引文件需要创建
			example/solr/collection1/core.properties配置solrcore实例名字
				example/solr/collection1/conf/solrconfig.xml配置实例的相关信息
				example/solr/collection1/conf/schema.xml配置中文分析器，定义索引数据类型
			example/solr/solr.xml
			example/solr/zoo.cfg
		example/multicore：该目录包含了在Solr的multicore中设置的多个Core目录。 
		example/webapps/solr.war：该目录中包括一个solr.war，该war可作为solr的运行实例工程。
			example/webapps/solr.war/web.xml配置了solrhome的位置
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>solr的安装	
	solr 需要运行在一个Servlet容器中，Solr4.10.3要求jdk使用1.7以上，Solr默认提供Jetty
	①将solr.war解压到tomcat的webapp目录中
	②把\solr-4.10.3\example\lib\ext目录下的所有的jar包添加到solr工程中的lib文件夹下
	cp * /usr/local/solr/tomcat/webapps/solr/WEB-INF/lib/
	③配置solrHome和solrCore。把\solr-4.10.3\example\solr文件夹复制并重命名为solrhome(更容易理解)
		Xml的配置信息：
		Lib：solr服务依赖的扩展包，默认的路径是collection1\lib文件夹，如果没有就创建一个
		dataDir：配置了索引库的存放路径。默认路径是collection1\data文件夹，如果没有data文件夹，会自动创建。
		requestHandler：
		查询时用url：name="/select"
		&lt;requestHandler name="/select" class="solr.SearchHandler"&gt;
			&lt;lst name="defaults"&gt;
			&lt;str name="echoParams"&gt;explicit&lt;/str&gt;
			&lt;int name="rows"&gt;10&lt;/int&gt;
			&lt;str name="df"&gt;text&lt;/str&gt;
			&lt;/lst&gt;
		&lt;/requestHandler&gt;
		维护索引时用url：name="/select"
		&lt;requestHandler name="/update" class="solr.UpdateRequestHandler"&gt;
			&lt;!-- See below for information on defining
				updateRequestProcessorChains that can be used by name
				on each Update Request
			--&gt;
			&lt;!--
			&lt;lst name="defaults"&gt;
				&lt;str name="update.chain"&gt;dedupe&lt;/str&gt;
			&lt;/lst&gt;
			--&gt;
		&lt;/requestHandler&gt;
	第六步：告诉solr服务器配置文件也就是solrHome的位置。
	修改solr.war的web.xml使用jndi的方式告诉solr服务器。Solr/home名称必须是固定的。
	&lt;env-entry&gt;
       &lt;env-entry-name&gt;solr/home&lt;/env-entry-name&gt;
       &lt;env-entry-value&gt;/put/your/solr/home/here&lt;/env-entry-value&gt;
       &lt;env-entry-type&gt;java.lang.String&lt;/env-entry-type&gt;
    &lt;/env-entry&gt;

	第七步：启动tomcat
	第八步：访问http://localhost:8080/solr/

	Solr后台管理
	Solr Core 是Solr的一个独立运行实例单位，它可以对外提供索引和搜索服务，
	添加solrcore：
	第一步：复制collection1改名为collection2
	第二步：修改collection文件夹里的core.properties。name=collection2
	第三步：重启tomcat
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>配置中文分析器
	Schema.xml在SolrCore的conf目录下，它是Solr数据表配置文件，它定义了加入索引的数据的数据类型的。
	主要包括FieldTypes、Fields和其他的一些缺省设置。
	
	FieldType域类型定义
	text_general是Solr默认提供的FieldType，通过它说明FieldType定义的内容:
	&lt;fieldType name="text_general" class="solr.TextField" positionIncrementGap="100"&gt;
		&lt;!--name：是这个FieldType的名称
		class：是Solr提供的包solr.TextField，solr.TextField 允许用户通过分析器来定制索引和查询，分析器包括一个分词器（tokenizer）和多个过滤器（filter）
		positionIncrementGap：可选属性，定义在同一个文档中此类型数据的空白间隔，避免短语匹配错误，此值相当于Lucene的短语查询设置slop值，根据经验设置为100。--&gt;
      &lt;analyzer type="index"&gt;
        &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
        &lt;filter class="solr.StopFilterFactory" ignoreCase="true" words="stopwords.txt" /&gt;
        &lt;!-- in this example, we will only use synonyms at query time
        	&lt;filter class="solr.SynonymFilterFactory" synonyms="index_synonyms.txt" ignoreCase="true" expand="false"/&gt;
        --&gt;
        &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
      &lt;/analyzer&gt;
      &lt;analyzer type="query"&gt;
	  	&lt;!--
		在FieldType定义的时候最重要的就是定义这个类型的数据在建立索引和进行查询的时候要使用的分析器analyzer,包括分词和过滤
		索引分析器中：使用solr.StandardTokenizerFactory标准分词器，solr.StopFilterFactory停用词过滤器，solr.LowerCaseFilterFactory小写过滤器。
		搜索分析器中：使用solr.StandardTokenizerFactory标准分词器，solr.StopFilterFactory停用词过滤器，这里还用到了solr.SynonymFilterFactory同义词过滤器。
		--&gt;
        &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
        &lt;filter class="solr.StopFilterFactory" ignoreCase="true" words="stopwords.txt" /&gt;
        &lt;filter class="solr.SynonymFilterFactory" synonyms="synonyms.txt" ignoreCase="true" expand="true"/&gt;
        &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
      &lt;/analyzer&gt;
    &lt;/fieldType&gt;

	Field定义
	&lt;!--filed定义包括name,type（为之前定义过的各种FieldType）,indexed（是否被索引）,
	stored（是否被储存），multiValued（是否存储多个值）等属性。
	multiValued：该Field如果要存储多个值时设置为true，solr允许一个Field存储多个值，
	比如存储一个用户的好友id（多个），商品的图片（多个，大图和小图），通过使用solr查询要看出返回给客户端是数组：--&gt;
	&lt;field name="name" type="text_general" indexed="true" stored="true"/&gt;
	&lt;field name="features" type="text_general" indexed="true" stored="true" multiValued="true"/&gt;
	
	
	&lt;!--uniqueKey Solr中默认定义唯一主键key为id域，
	Solr在删除、更新索引时使用id域进行判断，也可以自定义唯一主键。注意在创建索引时必须指定唯一约束。--&gt;
	&lt;uniqueKey&gt;id&lt;/uniqueKey&gt;
	
	
	copyField复制域
	&lt;!--copyField复制域，可以将多个Field复制到一个Field中，以便进行统一的检索：
	根据关键字只搜索text域的内容就相当于搜索title和content，将title和content复制到text中，如下：--&gt;
	&lt;field name="title" type="text_general" indexed="true" stored="true" multiValued="true"/&gt;
	&lt;field name="content" type="text_general" indexed="false" stored="true" multiValued="true"/&gt;
	&lt;field name="text" type="text_general" indexed="true" stored="false" multiValued="true"/&gt;
	&lt;copyField source="title" dest="text"/&gt;
	&lt;copyField source="content" dest="text"/&gt;
	
	dynamicField（动态字段）
	&lt;!--动态字段就是不用指定具体的名称，只要定义字段名称的规则，例如定义一个 dynamicField，name 为*_i，
	定义它的type为text，那么在使用这个字段的时候，任何以_i结尾的字段都被认为是符合这个定义的，
	例如：name_i，gender_i，school_i等。--&gt;
	&lt;dynamicField name="*_i"  type="int"    indexed="true"  stored="true"/&gt;

	安装中文分词器
	使用IKAnalyzer中文分析器
	第一步：把IKAnalyzer2012FF_u1.jar添加到solr/WEB-INF/lib目录下。
	第二步：复制IKAnalyzer的配置文件	IKAnalyzer.cfg.xml和自定义词典ext.dic;和停用词词典stopword.dic;到solr的classpath下。
	第三步：在schema.xml中添加一个自定义的fieldType，使用中文分析器。
	&lt;!-- IKAnalyzer--&gt;
	&lt;fieldType name="text_ik" class="solr.TextField"&gt;
		&lt;analyzer class="org.wltea.analyzer.lucene.IKAnalyzer"/&gt;
	&lt;/fieldType&gt;

	第四步：定义field，指定field的type属性为text_ik
	&lt;!--IKAnalyzer Field--&gt;
	&lt;field name="title_ik" type="text_ik" indexed="true" stored="true" /&gt;
	&lt;field name="content_ik" type="text_ik" indexed="true" stored="false" multiValued="true"/&gt;

	第四步：重启tomcat
</code></pre></div><h1>4. Solr管理索引库</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>	维护索引
	添加/更新单个文档(通过管理后台添加)
	
	批量导入数据
	使用dataimport插件批量导入数据。
	第一步：把dataimport插件依赖的jar包添加到solrcore（collection1\lib）中，还需要mysql的数据库驱动。
	第二步：配置solrconfig.xml文件，添加一个requestHandler。
	&lt;requestHandler name="/dataimport" class="org.apache.solr.handler.dataimport.DataImportHandler"&gt;
		&lt;lst name="defaults"&gt;
			&lt;str name="config"&gt;data-config.xml&lt;/str&gt;
		&lt;/lst&gt;
	&lt;/requestHandler&gt;
	第三步：创建一个data-config.xml，保存到collection1\conf\目录下
	&lt;?xml version="1.0" encoding="UTF-8" ?&gt;  
	&lt;dataConfig&gt;   
		&lt;dataSource type="JdbcDataSource"   
			driver="com.mysql.jdbc.Driver"   
			url="jdbc:mysql://localhost:3306/lucene"   
			user="root"   
			password="root"/&gt;   
		&lt;document&gt;   
		&lt;entity name="product" query="SELECT pid,name,catalog_name,price,description,picture FROM products "&gt;
			&lt;field column="pid" name="id"/&gt; 
			&lt;field column="name" name="product_name"/&gt; 
			&lt;field column="catalog_name" name="product_catalog_name"/&gt; 
			&lt;field column="price" name="product_price"/&gt; 
			&lt;field column="description" name="product_description"/&gt; 
			&lt;field column="picture" name="product_picture"/&gt; 
		&lt;/entity&gt;   
		&lt;/document&gt;
	&lt;/dataConfig&gt;

	第四步：重启tomcat
	第五步：在管理后台点击“execute”按钮导入数据

	到入数据前会先清空索引库，然后再导入。
	
	删除文档
	删除制定ID的索引 
	&lt;delete&gt;
		&lt;id&gt;8&lt;/id&gt;
	&lt;/delete&gt;
	&lt;commit/&gt;
	删除查询到的索引数据 
	&lt;delete&gt;
		&lt;query&gt;product_catalog_name:幽默杂货&lt;/query&gt;
	&lt;/delete&gt;
	&lt;commit/&gt;
	删除所有索引数据
	&lt;delete&gt;
		&lt;query&gt;*:*&lt;/query&gt;
	&lt;/delete&gt;
	
	查询索引
	通过/select搜索索引，Solr制定一些参数完成不同需求的搜索：
	1.q - 查询字符串，必须的，如果查询所有使用*:*。
	2.fq - （filter query）过虑查询，作用：在q查询符合结果中同时是fq查询符合的，例如：：
	过滤查询价格从1到20的记录。product_price:[1 TO 20]
	也可以在“q”查询条件中使用product_price:[1 TO 20]
	使用“*”表示无限，例如：20以上：product_price:[20 TO *]20以下：product_price:[* TO 20]
	3.sort - 排序，格式：sort=&lt;field name&gt;+&lt;desc|asc&gt;[,&lt;field name&gt;+&lt;desc|asc&gt;]… 。示例： 
	按价格降序
	4.start - 分页显示使用，开始记录下标，从0开始 
	5.rows - 指定返回结果最多有多少条记录，配合start来实现分页。
	6.fl - 指定返回那些字段内容，用逗号或空格分隔多个。
	7.df-指定一个默认搜索Field
	也可以在SolrCore目录 中conf/solrconfig.xml文件中指定默认搜索Field，指定后就可以直接在“q”查询条件中输入关键字。
	&lt;requestHandler name="/select" class="solr.SearchHandler"&gt;
    &lt;!-- default values for query parameters can be specified, these
         will be overridden by parameters in the request
      --&gt;
     &lt;lst name="defaults"&gt;
       &lt;str name="echoParams"&gt;explicit&lt;/str&gt;
       &lt;int name="rows"&gt;10&lt;/int&gt;
       &lt;str name="df"&gt;text&lt;/str&gt;
     &lt;/lst&gt;
	&lt;/requestHandler&gt; 
	8.wt - (writer type)指定输出格式，可以有 xml, json, php, phps, 
	9.hl 是否高亮 ,设置高亮Field，设置格式前缀和后缀
</code></pre></div><h1>5. 使用SolrJ管理索引库</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>	solrj是访问Solr服务的java客户端，提供索引和搜索的请求方法，SolrJ通常在嵌入在业务系统中，通过SolrJ的API接口操作Solr服务，

	c)添加文档
	实现步骤
	第一步：创建一个java工程
	第二步：导入jar包。包括solrJ的jar包。还需要
	第三步：和Solr服务器建立连接。HttpSolrServer对象建立连接。
	第四步：创建一个SolrInputDocument对象，然后添加域。
	第五步：将SolrInputDocument添加到索引库。
	第六步：提交。
	//向索引库中添加索引
		@Test
		public void addDocument() throws Exception {
			//和solr服务器创建连接
			//参数：solr服务器的地址
			SolrServer solrServer = new HttpSolrServer("http://localhost:8080/solr/collection1");
			//创建一个文档对象
			SolrInputDocument document = new SolrInputDocument();
			//向文档中添加域
			//第一个参数：域的名称，域的名称必须是在schema.xml中定义的
			//第二个参数：域的值
			document.addField("id", "c0001");
			document.addField("title_ik", "使用solrJ添加的文档");
			document.addField("content_ik", "文档的内容");
			document.addField("product_name", "商品名称");
			//把document对象添加到索引库中
			solrServer.add(document);
			//提交修改
			solrServer.commit();		
		}
	//删除文档，根据id删除
		@Test
		public void deleteDocumentByid() throws Exception {
			//创建连接
			SolrServer solrServer = new HttpSolrServer("http://localhost:8080/solr");
			//根据id删除文档
			solrServer.deleteById("c0001");
			//提交修改
			solrServer.commit();
		}

	查询语法完全支持Lucene的查询语法。
	//根据查询条件删除文档
		@Test
		public void deleteDocumentByQuery() throws Exception {
			//创建连接
			SolrServer solrServer = new HttpSolrServer("http://localhost:8080/solr");
			//根据查询条件删除文档
			solrServer.deleteByQuery("*:*");
			//提交修改
			solrServer.commit();
		}


	修改文档
	在solrJ中修改没有对应的update方法，只有add方法，只需要添加一条新的文档，
	和被修改的文档id一致就可以修改了。本质上就是先删除后添加。

	查询文档
	简单查询
	//查询索引
		@Test
		public void queryIndex() throws Exception {
			//创建连接
			SolrServer solrServer = new HttpSolrServer("http://localhost:8080/solr");
			//创建一个query对象
			SolrQuery query = new SolrQuery();
			//设置查询条件
			query.setQuery("*:*");
			//执行查询
			QueryResponse queryResponse = solrServer.query(query);
			//取查询结果
			SolrDocumentList solrDocumentList = queryResponse.getResults();
			//共查询到商品数量
			System.out.println("共查询到商品数量:" + solrDocumentList.getNumFound());
			//遍历查询的结果
			for (SolrDocument solrDocument : solrDocumentList) {
				System.out.println(solrDocument.get("id"));
				System.out.println(solrDocument.get("product_name"));
				System.out.println(solrDocument.get("product_price"));
				System.out.println(solrDocument.get("product_catalog_name"));
				System.out.println(solrDocument.get("product_picture"));
				
			}
		}

	复杂查询(最好！！！！！！！！！！！！！！！！！)
	其中包含查询、过滤、分页、排序、高亮显示等处理。
	//复杂查询索引
		@Test
		public void queryIndex2() throws Exception {
			//创建连接
			SolrServer solrServer = new HttpSolrServer("http://localhost:8080/solr");
			//创建一个query对象
			SolrQuery query = new SolrQuery();
			//设置查询条件
			query.setQuery("钻石");
			//过滤条件
			query.setFilterQueries("product_catalog_name:幽默杂货");
			//排序条件
			query.setSort("product_price", ORDER.asc);
			//分页处理
			query.setStart(0);
			query.setRows(10);
			//结果中域的列表
			query.setFields("id","product_name","product_price","product_catalog_name","product_picture");
			//设置默认搜索域
			query.set("df", "product_keywords");
			//高亮显示
			query.setHighlight(true);
			//高亮显示的域
			query.addHighlightField("product_name");
			//高亮显示的前缀
			query.setHighlightSimplePre("&lt;em&gt;");
			//高亮显示的后缀
			query.setHighlightSimplePost("&lt;/em&gt;");
			//执行查询
			QueryResponse queryResponse = solrServer.query(query);
			//取查询结果
			SolrDocumentList solrDocumentList = queryResponse.getResults();
			//共查询到商品数量
			System.out.println("共查询到商品数量:" + solrDocumentList.getNumFound());
			//遍历查询的结果
			for (SolrDocument solrDocument : solrDocumentList) {
				System.out.println(solrDocument.get("id"));
				//取高亮显示
				String productName = "";
				Map&lt;String, Map&lt;String, List&lt;String&gt;&gt;&gt; highlighting = queryResponse.getHighlighting();
				List&lt;String&gt; list = highlighting.get(solrDocument.get("id")).get("product_name");
				//判断是否有高亮内容
				if (null != list) {
					productName = list.get(0);
				} else {
					productName = (String) solrDocument.get("product_name");
				}
				
				System.out.println(productName);
				System.out.println(solrDocument.get("product_price"));
				System.out.println(solrDocument.get("product_catalog_name"));
				System.out.println(solrDocument.get("product_picture"));
				
			}
		}
</code></pre></div><h1>6. 什么是SolrCloud</h1>
<ul>
<li>SolrCloud是Solr提供的分布式搜索方案，当你需要大规模，容错，分布式索引和检索能力时使用 SolrCloud。</li>
<li>SolrCloud是基于Solr和Zookeeper的分布式搜索方案，它的主要思想是使用Zookeeper作为集群的配置信息中心。</li>
<li>它有几个特色功能：1）集中式的配置信息2）自动容错3）近实时搜索4）查询时自动负载均衡</li>
</ul>
<h1>7. Solr集群的系统架构</h1>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/81aca86bd4364734e8d46.png" alt="图片1.png" tabindex="0"><figcaption>图片1.png</figcaption></figure>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>物理结构
三个Solr实例（ 每个实例包括两个Core），组成一个SolrCloud。

逻辑结构
索引集合包括两个Shard（shard1和shard2），shard1和shard2分别由三个Core组成，其中一个Leader两个Replication，Leader是由zookeeper选举产生，
zookeeper控制每个shard上三个Core的索引数据一致，解决高可用问题。
用户发起索引请求分别从shard1和shard2上获取，解决高并发问题。
	
collection
Collection在SolrCloud集群中是一个逻辑意义上的完整的索引结构。它常常被划分为一个或多个Shard（分片），它们使用相同的配置信息。
比如：针对商品信息搜索可以创建一个collection。
collection=shard1+shard2+....+shardX
Core
每个Core是Solr中一个独立运行单位，提供 索引和搜索服务。一个shard需要由一个Core或多个Core组成。由于collection由多个shard组成所以collection一般由多个core组成。
Master或Slave
Master是master-slave结构中的主结点（通常说主服务器），Slave是master-slave结构中的从结点（通常说从服务器或备服务器）。
同一个Shard下master和slave存储的数据是一致的，这是为了达到高可用目的。
Shard
Collection的逻辑分片。每个Shard被化成一个或者多个replication，通过选举确定哪个是Leader。
</code></pre></div><h1>8. 需要实现的solr集群架构</h1>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/6ede782b265996f3c120c.png" alt="图片2.png" tabindex="0"><figcaption>图片2.png</figcaption></figure>
<pre><code>Zookeeper作为集群的管理工具。
1、集群管理：容错、负载均衡。
2、配置文件的集中管理
3、集群的入口
需要实现zookeeper 高可用。需要搭建集群。建议是奇数节点。需要三个zookeeper服务器。
搭建solr集群需要7台服务器。
搭建伪分布式：需要三个zookeeper节点需要四个tomcat节点。建议虚拟机的内容1G以上。
</code></pre>
<h1>9. solrcloud的搭建</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>	Zookeeper集群搭建

	1、需要安装jdk环境。
	2、把zookeeper的压缩包上传到服务器并解压缩tar -zxvf zookeeper-3.4.6.tar.gz。
	3、把zookeeper复制三份。
	[root@localhost ~]# mkdir /usr/java/solr-cloud
	[root@localhost ~]# cp -r zookeeper-3.4.6 /usr/java/solr-cloud/zookeeper01
	[root@localhost ~]# cp -r zookeeper-3.4.6 /usr/java/solr-cloud/zookeeper02
	[root@localhost ~]# cp -r zookeeper-3.4.6 /usr/java/solr-cloud/zookeeper03
	4、在每个zookeeper目录下创建一个data目录mkdir data
	5、在data目录下创建一个myid文件，文件名就叫做“myid”。内容就是每个实例的id。例如1、2、3
	vim data 然后输入i 输入1 输入esc 输入：wq  、cat myid //检查myid的内容1
	6、改配置文件。把conf目录下的zoo_sample.cfg文件改名为zoo.cfg，每个一样配置！
	cp zoo_sample.cfg zoo.cfg
	将datadir=改成data文件夹的地址
	保证clientPort三个不冲突
	然后在最后一行配置
	server.1=192.168.25.135:2881:3881
	server.2=192.168.25.135:2882:3882
	server.3=192.168.25.135:2883:3883
	7、创建全部启动的脚本 start-all.sh :vim start-all.sh
	cd zookeeper01/bin
	./zkServer.sh start
	cd ../../
	cd zookeeper02/bin
	./zkServer.sh start
	cd ../../
	cd zookeeper03/bin
	./zkServer.sh start
	cd ../../
	8、并使用以下命令授权chmod u+x start-all.sh 
	9、查看zookeeper的状态一个leader其他都是follower zookeeper01/bin/zkServer.sh status

	Using config: /usr/java/solr-cloud/zookeeper01/bin/../conf/zoo.cfg
	Stopping zookeeper ... bin/zkServer.sh: 第 143 行:kill: (26838) - 没有那个进程
	STOPPED
	如果关闭zookeeper的时候有这句话 说明端口占用

	查看占用2181端口的程序pid：
	[root@localhost local]# lsof -i:5432

	kill掉该进程
	[root@localhost local]# kill -9 7035
	重新启动即可

	10、创建全部关闭的脚本 start-all.sh :vim shutdown-all.sh
	cd zookeeper01/bin
	./zkServer.sh stop
	cd ../../
	cd zookeeper02/bin
	./zkServer.sh stop
	cd ../../
	cd zookeeper03/bin
	./zkServer.sh stop
	cd ../../
	11、并使用以下命令授权chmod u+x shutdown-all.sh 

	# Solr集群的搭建
	1、复制四个单机版的带solr的tomcat，并修改tomcat端口号、solrhome地址
	2、配置solrCloud相关的配置。每个solrhome下都有一个solr.xml，把其中的ip及端口号配置好。
	vim /usr/java/solr-cloud/solrhome01/solr.xml
	&lt;solrcloud&gt;
		&lt;str name="host"&gt;192.168.25.135&lt;/str&gt;
		&lt;int name="hostPort"&gt;8180&lt;/int&gt;
		&lt;str name="hostContext"&gt;${hostContext:solr}&lt;/str&gt;
		&lt;int name="zkClientTimeout"&gt;${zkClientTimeout:30000}&lt;/int&gt;
		&lt;bool name="genericCoreNodeNames"&gt;${genericCoreNodeNames:true}&lt;/bool&gt;
	&lt;/solrcloud&gt;
	3、让zookeeper统一管理配置文件。需要把solrhome/collection1/conf目录上传到zookeeper。上传任意solrhome中的配置文件即可。
	使用工具上传配置文件：/root/solr-4.10.3/example/scripts/cloud-scripts/zkcli.sh
	./zkcli.sh -zkhost 192.168.25.135:2181,192.168.25.135:2182,192.168.25.135:2183 -cmd upconfig -confdir /usr/local/solr-cloud/solrhome01/collection1/conf -confname myconf
	4、修改tomcat/bin目录下的catalina.sh 文件，关联solr和zookeeper。
	把此配置添加到配置文件中：
	JAVA_OPTS="-DzkHost=192.168.25.135:2181,192.168.25.135:2182,192.168.25.135:2183"
	5、启动每个tomcat实例。要包装zookeeper集群是启动状态。
	6、访问集群
	第十步：创建新的Collection进行分片处理。
	http://192.168.25.135:8180/solr/admin/collections?action=CREATE&amp;name=collection2&amp;numShards=2&amp;replicationFactor=2
	第十一步：删除不用的Collection。
	http://192.168.25.135:8180/solr/admin/collections?action=DELETE&amp;name=collection1

</code></pre></div>]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/81aca86bd4364734e8d46.png" type="image/png"/>
    </item>
    <item>
      <title>shiro</title>
      <link>https://javaguide.cn/backend/securityframework/shiro.html</link>
      <guid>https://javaguide.cn/backend/securityframework/shiro.html</guid>
      <source url="https://javaguide.cn/rss.xml">shiro</source>
      <description>shiro权限控制 1. 权限概述 2. shiro的介绍 3. shiro的使用 36. shiro组件，认证，权限怎么做？ 1. 权限概述 2. shiro的介绍 1.png1.png 3. shiro的使用 36. shiro组件，认证，权限怎么做？ shiro组件 Subject：主体，代表了当前“用户”,表示要和应用交互的东西. Securi...</description>
      <category>后端</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>shiro权限控制</p>
<!--more-->
<!-- TOC -->
<ul>
<li><a href="#1-%E6%9D%83%E9%99%90%E6%A6%82%E8%BF%B0">1. 权限概述</a></li>
<li><a href="#2-shiro%E7%9A%84%E4%BB%8B%E7%BB%8D">2. shiro的介绍</a></li>
<li><a href="#3-shiro%E7%9A%84%E4%BD%BF%E7%94%A8">3. shiro的使用</a></li>
<li><a href="#36-shiro%E7%BB%84%E4%BB%B6%E8%AE%A4%E8%AF%81%E6%9D%83%E9%99%90%E6%80%8E%E4%B9%88%E5%81%9A">36. shiro组件，认证，权限怎么做？</a></li>
</ul>
<!-- /TOC -->
<h1>1. 权限概述</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>认证：系统提供的用于识别用户身份的功能，通常登录功能就是认证功能</code></pre></div>]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/a225ee4bba93bf94ffef9.png" type="image/png"/>
    </item>
    <item>
      <title>SpringSecurity</title>
      <link>https://javaguide.cn/backend/securityframework/springsecurity.html</link>
      <guid>https://javaguide.cn/backend/securityframework/springsecurity.html</guid>
      <source url="https://javaguide.cn/rss.xml">SpringSecurity</source>
      <description>SpringSecurity 1. Spring Security概览 2. Spring Security环境 3. Spring Security中资源、认证与授权 4. Spring Security单体应⽤模式 5. Spring Security微服务架构 6. Spring Security认证模式 6.1. HTTP基础认证 6.2. H...</description>
      <category>后端</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>SpringSecurity</p>
<!--more-->
<!-- TOC -->
<ul>
<li><a href="#1-spring-security%E6%A6%82%E8%A7%88">1. Spring Security概览</a></li>
<li><a href="#2-spring-security%E7%8E%AF%E5%A2%83">2. Spring Security环境</a></li>
<li><a href="#3-spring-security%E4%B8%AD%E8%B5%84%E6%BA%90%E8%AE%A4%E8%AF%81%E4%B8%8E%E6%8E%88%E6%9D%83">3. Spring Security中资源、认证与授权</a></li>
<li><a href="#4-spring-security%E5%8D%95%E4%BD%93%E5%BA%94%E6%A8%A1%E5%BC%8F">4. Spring Security单体应⽤模式</a></li>
<li><a href="#5-spring-security%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84">5. Spring Security微服务架构</a></li>
<li><a href="#6-spring-security%E8%AE%A4%E8%AF%81%E6%A8%A1%E5%BC%8F">6. Spring Security认证模式</a>
<ul>
<li><a href="#61-http%E5%9F%BA%E7%A1%80%E8%AE%A4%E8%AF%81">6.1. HTTP基础认证</a></li>
<li><a href="#62-http%E8%A1%A8%E5%8D%95%E8%AE%A4%E8%AF%81%E9%BB%98%E8%AE%A4">6.2. HTTP表单认证(默认)</a></li>
<li><a href="#63-%E4%B8%A4%E7%A7%8D%E6%A8%A1%E5%BC%8F%E7%9A%84%E8%BE%83">6.3. 两种模式的⽐较</a></li>
</ul>
</li>
<li><a href="#7-%E5%8A%A0%E5%AF%86%E6%8E%A5%E5%8F%A3passwordencoder">7. 加密接口PasswordEncoder</a></li>
<li><a href="#8-spring-security%E4%B8%AD%E7%9A%84%E6%88%B7%E4%B8%8E%E8%AE%A4%E8%AF%81%E5%AF%B9%E8%B1%A1">8. Spring Security中的⽤户与认证对象</a>
<ul>
<li><a href="#81-%E6%88%B7%E5%AF%B9%E8%B1%A1">8.1. ⽤户对象</a></li>
<li><a href="#82-%E8%AE%A4%E8%AF%81%E5%AF%B9%E8%B1%A1">8.2. 认证对象</a></li>
</ul>
</li>
<li><a href="#9-spring-security%E7%9A%84session%E4%BC%9A%E8%AF%9D%E6%8E%A7%E5%88%B6">9. Spring Security的Session会话控制</a></li>
<li><a href="#10-springsecurity%E7%9A%84%E8%BF%87%E6%BB%A4%E9%93%BE%E8%AE%BE%E8%AE%A1">10. SpringSecurity的过滤链设计</a></li>
<li><a href="#11-springsecurity%E7%9A%84securitycontextholder">11. SpringSecurity的SecurityContextHolder</a></li>
<li><a href="#12-rememberme%E6%9C%BA%E5%88%B6">12. RememberMe机制</a></li>
<li><a href="#13-csrf%E6%94%BB%E5%87%BB">13. CSRF攻击</a></li>
<li><a href="#14-spring-security%E5%85%A5%E9%97%A8">14. Spring Security入门</a></li>
<li><a href="#15-springsecurity%E5%9F%BA%E7%A1%80%E8%AE%A4%E8%AF%81">15. SpringSecurity基础认证</a></li>
<li><a href="#16-springsecurity%E5%AE%9E%E7%8E%B0%E5%9F%BA%E4%BA%8Emysql%E5%AE%9A%E4%B9%89%E5%9F%BA%E7%A1%80%E8%AE%A4%E8%AF%81">16. SpringSecurity实现基于MySQL⾃定义基础认证</a></li>
<li><a href="#17-springsecurity%E5%88%A9passwordencoder%E5%AF%B9%E5%AF%86%E7%A0%81%E5%8A%A0%E5%AF%86%E4%BF%9D%E6%8A%A4">17. SpringSecurity利⽤PasswordEncoder对密码加密保护</a></li>
<li><a href="#18-%E5%9F%BA%E4%BA%8E%E8%A1%A8%E5%8D%95%E6%A8%A1%E5%BC%8F%E5%AE%9E%E7%8E%B0%E5%AE%9A%E4%B9%89%E8%AE%A4%E8%AF%81">18. 基于表单模式实现⾃定义认证</a></li>
<li><a href="#19-springsecurity%E5%AE%9E%E7%8E%B0%E8%A1%A8%E5%8D%95%E8%AE%A4%E8%AF%81%E7%99%BB%E5%BD%95%E6%8E%A5%E8%BF%94%E5%9B%9Ejson">19. SpringSecurity实现表单认证登录接⼝返回JSON</a></li>
<li><a href="#20-security-contextholder%E5%AE%9E%E7%8E%B0%E5%AD%90%E7%BA%BF%E7%A8%8B%E8%8E%B7%E5%BE%97%E7%94%A8%E6%88%B7%E4%BF%A1%E6%81%AF">20. Security ContextHolder实现子线程获得用户信息</a></li>
<li><a href="#21-securitycontextholder%E8%8E%B7%E5%8F%96%E5%BD%93%E5%89%8D%E7%99%BB%E5%BD%95%E5%AF%B9%E8%B1%A1">21. SecurityContextHolder获取当前登录对象</a></li>
<li><a href="#22-spring-security%E9%85%8D%E7%BD%AE%E5%AE%9A%E4%B9%89%E8%BF%87%E6%BB%A4%E5%99%A8">22. Spring Security配置⾃定义过滤器</a></li>
<li><a href="#23-spring-security%E6%9D%83%E9%99%90%E6%8E%A7%E5%88%B6">23. Spring Security权限控制</a>
<ul>
<li><a href="#231-%E6%8E%88%E6%9D%83">23.1. 授权</a></li>
<li><a href="#232-%E9%89%B4%E6%9D%83">23.2. 鉴权</a></li>
</ul>
</li>
<li><a href="#24-rbac%E5%9F%BA%E4%BA%8E%E6%9D%83%E9%99%90%E6%8E%A7%E5%88%B6">24. RBAC基于⻆⾊权限控制</a></li>
<li><a href="#25-spring-security-%E5%8C%B9%E9%85%8D%E5%99%A8">25. Spring Security 匹配器</a></li>
<li><a href="#26-spring-security%E5%AE%9E%E7%8E%B0remember-me">26. Spring Security实现Remember Me</a></li>
<li><a href="#27-spring-security%E9%A2%84%E9%98%B2csrf%E6%94%BB%E5%87%BB">27. Spring Security预防CSRF攻击</a></li>
<li><a href="#28-%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A4%E8%AF%81oauth2%E5%8D%8F%E8%AE%AE%E4%BB%8B%E7%BB%8D">28. 分布式认证Oauth2协议介绍</a>
<ul>
<li><a href="#281-oauth2%E5%8D%8F%E8%AE%AE%E7%9A%84%E5%BA%94%E5%9C%BA%E6%99%AF">28.1. OAuth2协议的应⽤场景</a></li>
<li><a href="#282-oauth2%E5%8D%8F%E8%AE%AE%E7%9A%84">28.2. OAuth2协议的⻆⾊</a></li>
<li><a href="#283-oauth2%E5%8D%8F%E8%AE%AE%E7%9A%84%E4%BB%A4%E7%89%8Ctoken">28.3. OAuth2协议的令牌Token</a></li>
<li><a href="#284-oauth2%E5%8D%8F%E8%AE%AE%E4%BD%9C%E6%B5%81%E7%A8%8B">28.4. OAuth2协议⼯作流程</a></li>
<li><a href="#285-oauth2%E4%B8%ADaccess_token%E7%9A%84%E7%A7%98%E5%AF%86">28.5. OAuth2中ACCESS_TOKEN的秘密</a></li>
<li><a href="#286-%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3oauth2-scope%E5%B1%9E%E6%80%A7%E7%9A%84%E4%BD%9C">28.6. 如何理解OAuth2 Scope属性的作⽤</a></li>
</ul>
</li>
<li><a href="#29-oauth2%E5%8D%8F%E8%AE%AE%E5%9B%9B%E7%A7%8D%E6%8E%88%E6%9D%83%E6%A8%A1%E5%BC%8F">29. Oauth2协议四种授权模式</a>
<ul>
<li><a href="#291-%E6%8E%88%E6%9D%83%E7%A0%81%E6%A8%A1%E5%BC%8Fauthorization-code">29.1. 授权码模式（Authorization Code）</a></li>
<li><a href="#292-%E9%9A%90%E5%BC%8F%E6%8E%88%E6%9D%83%E6%A8%A1%E5%BC%8Fimplicit">29.2. 隐式授权模式（Implicit）</a></li>
<li><a href="#293-%E5%AF%86%E7%A0%81%E6%A8%A1%E5%BC%8Fresource-owner-password-credentials">29.3. 密码模式（Resource Owner Password Credentials）</a></li>
<li><a href="#294-%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%A8%A1%E5%BC%8Fclient-credentials">29.4. 客户端模式（Client Credentials）</a></li>
</ul>
</li>
<li><a href="#30-spring-security-oauth2-%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A4%E8%AF%81%E6%B5%81%E7%A8%8B">30. Spring Security Oauth2 分布式认证流程</a></li>
<li><a href="#31-%E6%9E%84%E5%BB%BAoauth2%E8%AE%A4%E8%AF%81%E6%8E%88%E6%9D%83%E4%B8%AD">31. 构建OAuth2认证授权中⼼</a>
<ul>
<li><a href="#311-spring-authorization-server-%E6%8E%88%E6%9D%83%E4%B8%AD%E5%BF%83%E6%9E%84%E5%BB%BAauth-server">31.1. Spring Authorization Server 授权中心构建(auth-server)</a></li>
<li><a href="#312-%E6%9E%84%E5%BB%BAoauth2%E8%B5%84%E6%BA%90%E6%9C%8D%E5%8A%A1%E5%99%A8res-server">31.2. 构建OAuth2资源服务器(res-server)</a></li>
<li><a href="#313-%E6%9E%84%E5%BB%BAoauth2%E5%AE%A2%E6%88%B7%E7%AB%AFclient">31.3. 构建OAuth2客户端client</a></li>
</ul>
</li>
<li><a href="#32-%E5%9F%BA%E4%BA%8Emysql%E7%AE%A1%E7%90%86%E6%8E%88%E6%9D%83%E4%B8%AD%E6%95%B0%E6%8D%AE">32. 基于MySQL管理授权中⼼数据</a></li>
<li><a href="#33-access_token%E9%99%84%E5%8A%A0roles%E6%95%B0%E6%8D%AE">33. ACCESS_TOKEN附加⻆⾊ROLES数据</a></li>
<li><a href="#34-oauth2%E4%B8%8Erbac%E5%8D%8F%E5%90%8C%E4%BD%9C%E4%B8%9A">34. OAuth2与RBAC协同作业</a></li>
<li><a href="#35-%E7%8A%B6%E6%80%81%E7%9A%84access_token%E4%BB%A4%E7%89%8C%E5%A6%82%E4%BD%95%E5%8A%A8%E7%BB%AD%E7%BA%A6">35. ⽆状态的ACCESS_TOKEN令牌如何⾃动续约</a></li>
<li><a href="#shiro%E4%B8%8Espring-security%E5%8C%BA%E5%88%AB">shiro与spring security区别？</a></li>
<li><a href="#37-%E6%97%A7%E7%89%88spring-security%E8%AE%A4%E8%AF%81%E5%92%8C%E9%89%B4%E6%9D%83">37. 旧版spring Security认证和鉴权</a></li>
<li><a href="#38-%E6%97%A7%E7%89%88spring-security-oauth2%E8%AE%A4%E8%AF%81">38. 旧版spring Security oauth2认证</a></li>
<li><a href="#39-springsecurity%E5%8E%9F%E7%90%86%E5%BE%85%E6%95%B4%E7%90%86">39. springsecurity原理（待整理）</a></li>
<li><a href="#40-spring-authorization-server%E5%BE%85%E6%95%B4%E7%90%86">40. Spring Authorization Server（待整理）</a></li>
</ul>
<!-- /TOC -->
<h1>1. Spring Security概览</h1>
<ul>
<li>Spring Security：<a href="https://spring.io/projects/spring-security" target="_blank" rel="noopener noreferrer">https://spring.io/projects/spring-security</a></li>
<li>Spring Security官⽅⽂档：<a href="https://spring.io/projects/spring%EF%BF%BEsecurity#learn" target="_blank" rel="noopener noreferrer">https://spring.io/projects/spring￾security#learn</a></li>
<li>Spring Security是⼀个提供身份验证、授权和针对常⻅攻击的保护的框架。主要功能包括⽤户信息管理、敏感信息加解密、⽤户认证、权限控制、跨站点请求伪造保护、跨域⽀持、全局安全⽅法、单点登录</li>
</ul>
<h1>2. Spring Security环境</h1>
<ul>
<li>jdk8+</li>
<li>SpringBoot2.4+和Spring Security 5.7.0+ 取消了WebSecurityConfigurerAdapter</li>
</ul>
<h1>3. Spring Security中资源、认证与授权</h1>
<ul>
<li>资源（resource）:指需要访问的内容，安全性设计的核⼼⽬标就是对这些资源进⾏保护，确保对它们的访问是安全受控的。例如，在Web应⽤程序中，对外暴露的HTTP端点就可以被理解为资源。</li>
<li>认证（authentication）：对于每次访问请求，系统都能判断出访问者是否具有合法的身份标识。明确“你是谁”，</li>
<li>授权（authorization）。授权是对资源、权限、⻆⾊和⽤户的⼀种组合处理</li>
</ul>
<h1>4. Spring Security单体应⽤模式</h1>
<ul>
<li>⽤户先通过请求传递⽤户身份凭证并完成⽤户认证，然后根据该⽤户所具备的⽤户⻆⾊来获取访问权限，并最终完成对HTTP端点的访问授权。</li>
</ul>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/e03536d14c58fb42b04bc.jpg" alt="singleservice.png" tabindex="0"><figcaption>singleservice.png</figcaption></figure>
<h1>5. Spring Security微服务架构</h1>
<ul>
<li>涉及服务与服务之间的调⽤关系。服务提供者所充当的⻆⾊就是资源服务器，⽽服务消费者就是客户端。所以，各个服务本身既可以是客户端，也可以是资源服务器</li>
<li>需要把认证和授权的过程进⾏集中化管理，授权中⼼⾸先会获取客户端请求中的身份凭证信息，然后基于该身份凭证信息⽣成⼀个令牌（Token），该令牌包含访问权限范围和有效期。客户端获取令牌之后就可以基于该令牌发起对微服务的访问。这时资源服务器需要对该令牌进⾏认证，并根据令牌的权限范围和有效期从授权中⼼获取该请求所能访问的特定资源。在微服务系统中，对外的资源表现形式同样可以理解为⼀个个HTTP端点。</li>
</ul>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/013a129d53f38109a20dc.jpg" alt="microservice.png" tabindex="0"><figcaption>microservice.png</figcaption></figure>
<h1>6. Spring Security认证模式</h1>
<ul>
<li>在Spring Security中，与⽤户认证相关的核⼼概念包括⽤户对象和认证对象、⽤户信息存储和认证⽅式。</li>
<li>Spring Security认证模式包括HTTP基础认证和表单登录认证<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/2750c08889738551b893d.jpg" alt="authentication.png"></li>
</ul>
<h2>6.1. HTTP基础认证</h2>
<ul>
<li>通过HTTP的消息头携带⽤户名和密码进⾏登录验证</li>
</ul>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/cb80a6c09cbd83bd608de.jpg" alt="httpbasicheader.png" tabindex="0"><figcaption>httpbasicheader.png</figcaption></figure>
<h2>6.2. HTTP表单认证(默认)</h2>
<ul>
<li>有登录界⾯并根据业务场景进⾏定制化处理。同时，也需要对登录的过程和结果进⾏细化控制。</li>
</ul>
<h2>6.3. 两种模式的⽐较</h2>
<ul>
<li>都使⽤⽤户名和密码来对客户端进⾏身份验证</li>
<li>基础认证在RFC 7617 中正式定义，Basic Auth使⽤HTTP RequestHeader，以便在向服务器发出请求时提供⽤户名和密码。标题字段本Authorization: Basic Base64-encoded(username:password)凭证是由单个冒号连接的⽤户名和密码的base64编码。 与基于表单模式不同，<strong>基本身份验证不使⽤cookie，因此没有会话或注销⽤户的概念</strong>，这意味着每个请求都必须携带该Request Header才能进⾏身份验证。</li>
<li>表单认证没有被任何RFC形式化。本质上是⼀种编程的身份验证⽅法，⽤于减轻每个请求都必须重新认证的压⼒。⼤多数基于表单的身份认证实现使⽤标准HTML表单字段通过POST请求将⽤户名和密码值传递给服务器。服务器验证所提供的凭据，<strong>并创建⼀个Session会话（有状态）</strong>，该会话绑定到存储在cookie中的SessionId，并在每个http请求上在客户端和服务器之间传递。如果cookie⽆效或⽤户注销，则服务器通常会重定向到登录⻚⾯。</li>
<li>表单认证⽤于对基于web浏览器的客户端和API进⾏身份认证，⽹站应⽤，企业级应⽤，提供登录、注销等操作（有状态）。</li>
<li>基础认证验证⽤于API之间的身份验证（⽆状态）。</li>
</ul>
<h1>7. 加密接口PasswordEncoder</h1>
<ul>
<li>PasswordEncoder接⼝代表密码编码器，⽤于指定密码的具体加密⽅式，以及如何在给定的⼀段加密字符串与明⽂之间完成匹配校验。Spring Security内置了PasswordEncoder接⼝的实现类。
<ul>
<li>NoOpPasswordEncoder：以明⽂形式保存密码，不对密码进⾏编码。通常只⽤于演示</li>
<li>StandardPasswordEncoder：使⽤SHA-256算法对密码执⾏散列操作（过期）</li>
<li>BCryptPasswordEncoder：使⽤bcrypt强散列算法对密码执⾏散列操作</li>
<li>Pbkdf2PasswordEncoder：使⽤PBKDF2算法对密码执⾏散列操作</li>
</ul>
</li>
<li>BCrypt将在内部产⽣随机盐值。每个调⽤将有不同的结果，只需要对密码进⾏⼀次编码。为了使这种随机的盐值能正常⼯作，BCrypt将盐存储在Hash值本身中。例如，以下Hash值:$2aZLhnHxdpHETcxmtEStgpI./Ri1mksgJ9iDP36FmfMdYyVg9g0b2dq.⽤ $ 分隔三个字段： "2a" 代表BCrypt算法版本， "10" 表示算法的强度，"ZLhnHxdpHETcxmtEStgpI." 标识随机⽣成的盐值。基本上，前22个字符是salt。 最后⼀个字段的其余部分是纯⽂本的实际散列内容。</li>
<li>为什么要加盐?加盐保证值不能根据字典得到值，即使得到值也不知道值本身是什么，因为加盐后字符看起来无意义</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>package org.springframework.security.crypto.password;
public interface PasswordEncoder {
  //对原始密码进⾏编码
  String encode(CharSequence rawPassword);
  //对提交的原始密码与库中存储的加密密码进⾏⽐对
  boolean matches(CharSequence rawPassword, String encodedPassword);
  //判断加密密码是否需要再次进⾏加密，默认返回false
  default boolean upgradeEncoding(String encodedPassword) {
    return false;
  }
}
</code></pre></div><h1>8. Spring Security中的⽤户与认证对象</h1>
<h2>8.1. ⽤户对象</h2>
<ul>
<li>⽤来描述⽤户并完成对⽤户信息的管理，涉及4个核⼼⽤户对象</li>
<li>UserDetails：描述Spring Security中的⽤户。</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public interface UserDetails extends Serializable {
  //获取该⽤户的权限信息
  Collection&lt;? extends GrantedAuthority&gt; getAuthorities();
  //获取密码
  String getPassword();
  //获取⽤户名
  String getUsername();
  //判断该账户是否已失效
  boolean isAccountNonExpired();
  //判断该账户是否已被锁定
  boolean isAccountNonLocked();
  //判断该账户的凭证信息是否已失效
  boolean isCredentialsNonExpired();
  //判断该⽤户是否可⽤
  boolean isEnabled();
}
</code></pre></div><ul>
<li>GrantedAuthority：定义⽤户所能执⾏的操作权限</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public interface GrantedAuthority extends Serializable {
 //获取权限信息
 String getAuthority();
}
</code></pre></div><ul>
<li>UserDetailsService：定义对UserDetails的查询操作。</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public interface UserDetailsService {
  //根据⽤户名获取⽤户信息
  UserDetails loadUserByUsername(String username) throws UsernameNotFoundException;
}
</code></pre></div><ul>
<li>UserDetailsManager：扩展UserDetailsService，添加创建⽤户、修改⽤户密码等功能。</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public interface UserDetailsManager extends UserDetailsService {
  //创建⽤户
  void createUser(UserDetails user);
  //更新⽤户
  void updateUser(UserDetails user);
  //删除⽤户
  void deleteUser(String username);
  //修改密码
  void changePassword(String oldPassword, String newPassword);
  //判断指定⽤户名的⽤户是否存在
  boolean userExists(String username);
}
</code></pre></div><h2>8.2. 认证对象</h2>
<ul>
<li>Authentication-认证请求详细信息</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public interface Authentication extends Principal, Serializable {
  //安全主体所具有的权限
  Collection&lt;? extends GrantedAuthority&gt; getAuthorities();
  //证明主体有效性的凭证
  Object getCredentials();
  //认证请求的明细信息
  Object getDetails();
  //主体的标识信息
  Object getPrincipal();
  //是否认证通过
  boolean isAuthenticated();
  //设置认证结果
  void setAuthenticated(boolean isAuthenticated) throws IllegalArgumentException;
}
</code></pre></div><ul>
<li>AuthenticationProvider-认证的业务执⾏者</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public interface AuthenticationProvider {
  //执⾏认证，返回认证结果
  Authentication authenticate(Authentication authentication) throws AuthenticationException;
  //判断是否⽀持当前的认证对象
  boolean supports(Class&lt;?&gt; authentication);
}
</code></pre></div><ul>
<li>Explanation: In the old version you inject AuthenticationManagerBuilder, set userDetailsService,<br>
passwordEncoder and build it. But authenticationManager is already created in this step. It is<br>
created the way we wanted (with userDetailsService and the passwordEncoder).</li>
</ul>
<h1>9. Spring Security的Session会话控制</h1>
<ul>
<li>Spring Security控制会话何时创建以及将如何与之交互
<ul>
<li>always – 如果会话尚不存在，则始终会创建会话</li>
<li>ifRequired – 仅在需要时创建会话 (默认) =&gt;表单认证-后台系统提供登录与注销</li>
<li>never – 该框架永远不会创建会话本身，但如果已经存在，它将使⽤会话</li>
<li>stateless – 不会创建或使⽤任何会话。此配置仅控制Spring Security的功能，⽽不是整个应⽤程序=&gt;基础认证-API认证</li>
</ul>
</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>@Bean
public SecurityFilterChain filterChain(HttpSecurity http) throws Exception
{
  http.sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS);
  ...
}
</code></pre></div><h1>10. SpringSecurity的过滤链设计</h1>
<ul>
<li>在 Spring Security 中，认证、授权等功能都是基于过滤器来完成的。引⼊Spring Security依赖之后，开发者不做任何配置时，自动加载默认过滤器。这些过滤器按照既定的优先级排列，最终形成⼀个过滤器链。开发者也可以⾃定义过滤器，并通过@Order 注解去调整⾃定义过滤器在过滤器链中的位置。</li>
</ul>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/5daa71a0eb9c5c8eaa18f.jpg" alt="defaultfilter.png" tabindex="0"><figcaption>defaultfilter.png</figcaption></figure>
<ul>
<li>默认过滤器并不是直接放在Web项⽬的原⽣过滤器链中，⽽是通过⼀个FilterChainProxy来统⼀管理。Spring Security 中的过滤器链通过FilterChainProxy嵌⼊到Web 项⽬的原⽣过滤器链中。</li>
</ul>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/8db109b4aa659ed9bd2fb.jpg" alt="filterchainproxy.png" tabindex="0"><figcaption>filterchainproxy.png</figcaption></figure>
<ul>
<li>在Spring Security中，这样的过滤器链不仅仅只有⼀个，可能会有多个，如图所示。当存在多个过滤器链时，多个过滤器链之间要指定优先级，当请求到达后，会从FilterChainProxy 进⾏分发，先和哪个过滤器链匹配上，就⽤哪个过滤器链进⾏处理。当系统中存在多个不同的认证体系时，那么使⽤多个过滤器链就⾮常有效。</li>
</ul>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/4b6e6aa7d8d7dae60d69e.jpg" alt="filterchain.png" tabindex="0"><figcaption>filterchain.png</figcaption></figure>
<h1>11. SpringSecurity的SecurityContextHolder</h1>
<ul>
<li>当⽤户登录成功后，Spring Security 会将登录成功的⽤户信息保存到SecurityContextHolder 中。SecurityContextHolder中的数据保存默认是通过ThreadLocal来实现的，使⽤ThreadLocal 创建的变量只能被当前线程访问，不能被其他线程访问和修改，也就是⽤户数据和请求线程绑定在⼀起。当登录请求处理完毕后，Spring Security 会将SecurityContextHolder中的数据拿出来保存到Session中，同时将SecurityContextHolder中的数据清空。以后每当有请求到来时，Spring Security就会先从 Session 中取出⽤户登录数据，保存到SecurityContextHolder 中，⽅便在该请求的后续处理过程中使⽤，同时在请求结束时将SecurityContextHolder中的数据拿出来保存到Session中，然后将SecurityContextHolder中的数据清空。这⼀策略⾮常⽅便⽤户在Controller或者Service层获取当前登录⽤户数据，</li>
</ul>
<h1>12. RememberMe机制</h1>
<ul>
<li>
<p>Remember-Me实现机理是根据⽤户登录信息⽣成 Token 并保存在⽤户浏览器的Cookie 中，当⽤户需要再次登录时，⾃动实现校验并建⽴登录态的⼀种机制。</p>
</li>
<li>
<p>Remember-Me 功能的开启需要在configure(HttpSecurity http)⽅法中通过http.rememberMe()配置，该配置主要会在过滤器链中添加RememberMeAuthenticationFilter过滤器实现⾃动登录。位置在其它认证过滤器之后，其它认证过滤器没有进⾏认证处理时处理</p>
</li>
<li>
<p>Remember-Me 功能是⽤于再次登录（认证）的，⽽不是再次请求<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/77d2e9e49c415e4aaa80a.jpg" alt="rememberme.png"></p>
</li>
<li>
<p>⼯作流程如下：</p>
<ul>
<li>当⽤户成功登录认证后，浏览器中存在两个 Cookie，⼀个是remember-me+有效时间，另⼀个是JSESSIONID。</li>
<li>⽤户再次请求访问时，请求⾸先被SecurityContextPersistenceFilter 过滤器拦截并根据JSESSIONID 获取对应 Session 中存储的 SecurityContext 对象。
<ul>
<li>如果获取到的 SecurityContext 对象中存储了认证⽤户信息对象 Authentiacaion，也就是说线程可以直接获得认证⽤户信息，那么后续的认证过滤器不需要对该请求进⾏拦截，remember-me不起作⽤。</li>
<li>当 JSESSIONID 过期后，浏览器中只存在 remember-me 的Cookie。
<ul>
<li>⽤户再次请求访问时，由于请求没有携带 JSESSIONID，SecurityContextPersistenceFilter 过滤器⽆法获取Session 中的 SecurityContext 对象，也就没法获得认证⽤户信息，后续需要进⾏登录认证。
<ul>
<li>如果没有 remember-me 的 Cookie，浏览器会重定向到登录⻚⾯进⾏表单登录认证；</li>
<li>但是 remember-me 的 Cookie 存在，RememberMeAuthenticationFilter 过滤器会将请求进⾏拦截，根据 remember-me 存储的 Token 值实现⾃动登录，并将成功登录后的认证⽤户信息对象Authentiacaion 存储到 SecurityContext 中。当响应返回时，SecurityContextPersistenceFilter 过滤器会将 SecurityContext 存储在 Session 中，下次请求⼜通过 JSEESIONID 获取认证⽤户信息。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>remember-me 只有在 JSESSIONID 失效和前⾯的过滤器认证失败或者未进⾏认证时才发挥作⽤。此时，只要 remember-me 的Cookie 不过期，我们就不需要填写登录表单，就能实现再次登录，并且 remember-me ⾃动登录成功之后，会⽣成新的 Token 替换旧的Token，相应 Cookie 的 Max-Age 也会重置。</p>
</li>
</ul>
<h1>13. CSRF攻击</h1>
<ul>
<li>CSRF的全称是Cross-Site Request Forgery，翻译成中⽂是跨站请求伪造。</li>
<li>从安全性的⻆度来说，CSRF是⼀种攻击⼿段，即攻击者盗⽤⽤户身份，然后以⽤户名义向第三⽅⽹站发送恶意请求。它诱骗web浏览器在⽤户登录的应⽤程序中执⾏不需要的操作。
<ul>
<li>⽤户A登录X银⾏官⽹，银⾏服务器为⽤户A开辟Session保存认证通过数据，响应返回后⽤户A浏览器的Cookie持有SessionId，下次操作⽆需再次登录</li>
<li>这时⽤户A收到本地电脑某⿊客软件发来的⼴告，⽤户点击后跳转到X钓⻥站，X钓⻥站向X银⾏⽹站发起Redirect“转账”请求</li>
<li>浏览器收到X钓⻥站发来的Rediect“转账”请求，因为⽤户之前已经认证过了，官⽹就认为该⽤户真的要发起“转账”操作，于是⽤户⾦钱就受到损失</li>
</ul>
</li>
<li>CSRF保护的基本思想就是为系统中的每个连接请求加上⼀个随机值，称为csrf_token。当⽤户A向X银⾏发送请求前，X银为其⽣成⼀个Token令牌，⽽在浏览器发送请求时，所提交的数据（Cookie或者Header）中也会有⼀个隐藏的csrf_token。这样X官⽹接收到请求之后，⼀⽅⾯从Session或其他存储介质中提取出csrf_token，另⼀⽅⾯获取来⾃浏览器的csrf_token，将两者进⾏⽐对，如果不⼀致就代表这是⼀个伪造的请求。csrf_token是⼀次性的，使⽤⼀次后会⽴即从Session清楚，下⼀次同样持有相同csrf_token的伪造请求将被拒绝</li>
<li>Spring Security专⻔提供了⼀个过滤器组件——CsrfFilter来实现对CSRF的保护，默认开启。CsrfFilter拦截请求，并允许通过那些使⽤GET、HEAD、TRACE和OPTIONS等HTTP⽅法的请求。⽽对于PUT、POST、DELETE等会修改数据的其他请求CsrfFilter希望接收包含csrf_token值的消息头。如果该消息头不存在或包含不正确的csrf_token值，则Web应⽤程序将拒绝该请求。</li>
<li>CsrfTokenRepository是Token令牌的存储操作类，默认CsrfToken将服务器端Token存储到到Session会话中，如果项⽬不允许使⽤Session可以⾃⼰实现⼀个CsrfTokenRepository将其转存到MySQL、Redis中即可。</li>
</ul>
<h1>14. Spring Security入门</h1>
<ul>
<li>pom.xml</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>&lt;dependency&gt;
 &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
 &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre></div><ul>
<li>application.properties</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>server.port=80
</code></pre></div><ul>
<li>SampleController</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>package com.example.firstspringsecurity.controller;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.RestController;
@RestController
public class SampleController {
  @GetMapping("/hello")
  public String hello() {
    return "Hello World!";
  }
}
</code></pre></div><ul>
<li>日志</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>WARN 19580 </code></pre></div>]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/e03536d14c58fb42b04bc.jpg" type="image/jpeg"/>
    </item>
    <item>
      <title>FastDFS</title>
      <link>https://javaguide.cn/backend/server/fastdfs.html</link>
      <guid>https://javaguide.cn/backend/server/fastdfs.html</guid>
      <source url="https://javaguide.cn/rss.xml">FastDFS</source>
      <description>FastDFS 1. 什么是FastDFS？ FastDFS是用c语言编写的一款国产开源的分布式文件系统。考虑了冗余备份、负载均衡、线性扩容等机制，并注重高可用、高性能等指标，使用FastDFS很容易搭建一套高性能的文件服务器集群提供文件上传、下载等服务。 2. FastDFS架构 FastDFS架构包括Tracker server和Storage s...</description>
      <category>后端</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>FastDFS</p>
<!--more-->
<h1>1. 什么是FastDFS？</h1>
<ul>
<li>FastDFS是用c语言编写的一款国产开源的分布式文件系统。考虑了冗余备份、负载均衡、线性扩容等机制，并注重高可用、高性能等指标，使用FastDFS很容易搭建一套高性能的文件服务器集群提供文件上传、下载等服务。</li>
</ul>
<h1>2. FastDFS架构</h1>
<ul>
<li>FastDFS架构包括Tracker server和Storage server</li>
<li>客户端请求Tracker server来调度Storage server完成文件上传和下载。</li>
<li>Tracker：管理集群，tracker也可以实现集群。每个tracker节点地位平等。收集Storage集群的状态。</li>
<li>Tracker server作用是负载均衡和调度，通过Tracker server在文件上传时可以根据一些策略找到可以将tracker称为追踪服务器或调度服务器。</li>
<li>Storage：实际保存文件,分为多个组，每个组之间保存的文件是不同的。每个组内部可以有多个成员，组成员内部保存的内容是一样的，组成员的地位是一致的，没有主从的概念。</li>
<li>Storage server作用是文件存储，客户端上传的文件最终存储在Storage服务器上，提供文件上传服务。</li>
<li>Storage server没有实现自己的文件系统而是利用操作系统 的文件系统来管理文件。可以将storage称为存储服务器。</li>
</ul>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/ce01ce788e74df3757f7f.png" alt="FastDFS架构.png" tabindex="0"><figcaption>FastDFS架构.png</figcaption></figure>
<h1>3. 文件上传的流程</h1>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/84401f0fda44b9e561f09.png" alt="文件上传流程.png" tabindex="0"><figcaption>文件上传流程.png</figcaption></figure>
<ul>
<li>客户端上传文件后存储服务器将文件ID返回给客户端，此文件ID用于以后访问该文件的索引信息。</li>
<li>文件索引信息包括：组名，虚拟磁盘路径，数据两级目录，文件名。</li>
<li>组名：文件上传后所在的storage组名称，在文件上传成功后有storage服务器返回，需要客户端自行保存。</li>
<li>虚拟磁盘路径：storage配置的虚拟路径，与磁盘选项store_path*对应。如果配置了store_path0则是M00，如果配置了store_path1则是M01，以此类推。</li>
<li>数据两级目录：storage服务器在每个虚拟磁盘路径下创建的两级目录，用于存储数据文件。</li>
<li>文件名：与文件上传时不同。是由存储服务器根据特定信息生成，文件名包含：源存储服务器IP地址、文件创建时间戳、文件大小、随机数和文件拓展名等信息。/group1/M00/02/44/wKgDrE34E8wAAAAAAAGkEIYJK42378.sh</li>
</ul>
<h1>4. 文件下载流程</h1>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/ee213691c6dcea40845d2.png" alt="文件下载流程.png" tabindex="0"><figcaption>文件下载流程.png</figcaption></figure>
<h1>5. 后端FastDFS使用</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class FastDFSTest {
	@Test
	public void testFileUpload() throws Exception {
		// 1、加载配置文件，配置文件中的内容就是tracker服务的地址。tracker_server=192.168.25.133:22122
		ClientGlobal.init("D:/workspaces-itcast/e3-manager-web/src/main/resources/resource/client.conf");
		// 2、创建一个TrackerClient对象。直接new一个。
		TrackerClient trackerClient = new TrackerClient();
		// 3、使用TrackerClient对象创建连接，获得一个TrackerServer对象。
		TrackerServer trackerServer = trackerClient.getConnection();
		// 4、创建一个StorageServer的引用，值为null
		StorageServer storageServer = null;
		// 5、创建一个StorageClient对象，需要两个参数TrackerServer对象、StorageServer的引用
		StorageClient storageClient = new StorageClient(trackerServer, storageServer);
		// 6、使用StorageClient对象上传图片。最后一个参数是元数据，就是图片的详细信息
		//扩展名不带“.”
		String[] strings = storageClient.upload_file("D:/Documents/Pictures/images/200811281555127886.jpg", "jpg", null);
		// 7、返回数组。包含组名和图片的路径。
		for (String string : strings) {
			System.out.println(string);
		}
	}
}
</code></pre></div><h1>6. 前端图片上传功能</h1>
<ul>
<li>使用的是KindEditor的多图片上传插件。</li>
<li>KindEditor 4.x 文档<a href="http://kindeditor.net/doc.php" target="_blank" rel="noopener noreferrer">http://kindeditor.net/doc.php</a></li>
<li>KindEditor的多图片上传插件最后响应的content-type是text/plan格式的json字符串。兼容性是最好的</li>
</ul>
]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/ce01ce788e74df3757f7f.png" type="image/png"/>
    </item>
    <item>
      <title>Hexo</title>
      <link>https://javaguide.cn/backend/server/hexo.html</link>
      <guid>https://javaguide.cn/backend/server/hexo.html</guid>
      <source url="https://javaguide.cn/rss.xml">Hexo</source>
      <description>记录一下搭建博客 1. 配置 2. VSCode配置 1. 配置 2. VSCode配置</description>
      <category>后端</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>记录一下搭建博客</p>
<!--more-->
<!-- TOC -->
<ul>
<li><a href="#1-%E9%85%8D%E7%BD%AE">1. 配置</a></li>
<li><a href="#2-vscode%E9%85%8D%E7%BD%AE">2. VSCode配置</a></li>
</ul>
<!-- /TOC -->
<h1>1. 配置</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code># 安装：node.js、git
# 创建博客文件夹 
- hexo init
# 安装依赖包
- npm install
# 本地调试 浏览器中输入 localhost:4000
- hexo generate 
- hexo server
# 创建  用户名.github.io 仓库
# 编辑本地Hexo目录下文件_config.yml,在最后添加如下代码
deploy:
  type: git
  repository: http://github.com/用户名/用户名.github.io.git
  branch: master
# 部署到github
- hexo generate 
- hexo deploy

# 生成SSH
ssh-keygen -t rsa -C "1105128664@qq.com"，一路回车
找到本用户下的C:\Users\${username}\.ssh\id_rsa把里面的内容复制
在github上面对应的仓库点击Setting，然后点击Deploy Keys
黏贴刚才的内容，Allow write access 打钩，点击Add Key

# 测试上传
ssh -T git@github.com，即使报错也一路点yes,至此配置成功
git config --global user.name "yourusername"
git config --golbal user.email "youremail"
配置以上两个去掉很多警告
</code></pre></div><h1>2. VSCode配置</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>ctrl+shift+P 找到 Markdown Preview Enhanced: Extend Parser，打开 parser.js

修改其中 onWillParseMarkdown 方法为：
  onWillParseMarkdown: async function(markdown) {
    return new Promise((resolve, reject)=&gt; {
      /** 处理 {% asset_img xxx%}**/
      // markdown = markdown.replace(
      // /\{%\s*asset_img\s*(.*)\s*%\}/g,
      // (whole, content) =&gt; (`![](/source/_posts/${markdown.match(/title\: (\S*)/)[1]}/${content})`)
      // )
      /** 处理 [](xxx.html/xxx)**/
      // markdown = markdown.replace(
      //   /\[.*]\(.*\.html\/.*\)/g,
      //   (whole, content) =&gt; (`${whole}`.replace(/\.html\//g,'.md/'))
      //     )
      /** 处理 [](xxx/xxxx.png)**/
      // markdown = markdown.replace(
      //   /!\[.*]\(.*\.(png|jpg|gif)\)/g,
      //   (whole, content) =&gt; (`${whole}`.replace(/]\(/g,'](/docs/.vuepress/public/'))
      // )
  
      /** 处理 [](xxxx.png)**/
      markdown = markdown.replace(
        /!\[.*]\(.*\.(png|jpg|gif)\)/g,
        (whole, content) =&gt; (`${whole}`.replace(/]\(/g,`](./${markdown.match(/title\: (\S*)/)[1]}/`))
      )
  
      return resolve(markdown)
    })
  },
</code></pre></div>]]></content:encoded>
      <enclosure url="https://javaguide.cn/source/_posts/${markdown.match(/title\: (\S*" type="image/"/>
    </item>
    <item>
      <title>Netty</title>
      <link>https://javaguide.cn/backend/server/netty.html</link>
      <guid>https://javaguide.cn/backend/server/netty.html</guid>
      <source url="https://javaguide.cn/rss.xml">Netty</source>
      <description>linux网络I/O模型(对于操作系统而言，底层支持异步I/O通信) linux的内核将所有外部设备都看作一个文件来操作，对文件的读写操作会调用内核提供的系统命令，返回一个file descriptor(fd，文件描述符)。而对一个socket的读写也会有相应的描述符，成为socketfd(socket描述符)，描述符就是一个数字，它只想内核中的一个结...</description>
      <category>后端</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<!-- more -->
<ul>
<li>linux网络I/O模型(对于操作系统而言，底层支持异步I/O通信)
<ul>
<li>linux的内核将所有外部设备都看作一个文件来操作，对文件的读写操作会调用内核提供的系统命令，返回一个file descriptor(fd，文件描述符)。而对一个socket的读写也会有相应的描述符，成为socketfd(socket描述符)，描述符就是一个数字，它只想内核中的一个结构体（文件路径，数据区等一个些属性）</li>
<li>根据UNIX网络编程对I/O模型的分类，UNIX提供了5中I/O模型
<ul>
<li>阻塞I/O模型:缺省情形下，所有文件的操作都是阻塞的。以套接字接口为例：在进程空间中调用recvfrom，其系统调用直到数据包到达且被复制到应用进程的缓冲区中或者发生错误时才返回，在此期间一直会等待，进程在从调用recvfrom开始到它返回的争端时间内都是被阻塞的</li>
<li>非阻塞I/O模型:recvfrom从应用层到内核的时候，如果该缓冲区没有数据的话，就直接返回一个EWOULDBLIOCK错误，一般都对非阻塞I/O模型进行轮询检查这个状态，看内核是不是又数据到来</li>
<li>I/O复用模型:linux提供select/poll，进程通过将一个或多个fd传递给select或epoll系统调用，阻塞在select操作上，这样select/poll可以检测到多个fd是否处于就绪状态，select/poll是顺序扫描fd是否就绪，而且支持的fd数量有限。linux还提供了一个epoll系统调用，epoll使用基于时间驱动方式代替顺序扫描，性能更高。当有fd就绪是，就立即回调函数rollback</li>
<li>信号驱动I/O模型:首先开启套接扣信号驱动I/O功能，并通过系统调用sigaction执行一个信号处理函数（此系统调用立即返回，进程继续工作，非阻塞）。当数据准备就绪时，就为该进程生成一个SIGIO信号，通过信号回调通知应用程序调用recvfrom来读取数据，并通知主循环函数处理数据。</li>
<li>异步I/O:告知内核启动某个操作，并让内核在整个操作完成后（包括将数据从内核复制到用户自己的缓冲区）通知调用者，与信号驱动模型的主要区别是：信号驱动I/O有内核通知我们什么时候开始I/O操作，而异步I/O模型这由内核通知我们I/O操作何时完成</li>
</ul>
</li>
</ul>
</li>
<li>I/O多路复用技术
<ul>
<li>通过把多个I/O的阻塞复用到同一个select的阻塞上，从而使得系统在单线程的情况下可以同时处理多个客户端需求，与传统的多线程/多进程模型相比，I/O多路复用的最大优势是系统开销小，系统不需要创建新的额外进程或者线程。也不需要维护这些进程和线程的运行，降低了系统的苇湖梁，节省系统资源</li>
<li>I/O复用的主要应用场景：服务器需要同时处理多个处于监听状态或者多个连接状态的套接字，多种网络协议的套接字</li>
<li>目前支持I/O多路复用的系统调用有select，pselect，poll，epoll，epoll新特性
<ul>
<li>支持一个进程的socket描述符（FD）不受限制（仅受限于操作系统的最大文件句柄数）：select最大的缺陷是单个进程所打开的FD是有一定限制的，它由FD_SETSIZE设置，默认1024。可以选择修改这个宏然后重新编译内核，但这回带来网络效率的下降。也可以选择多进程的方案（Apache），但创建进程需要付出一定代价，而且进程之间的数据交换非常麻烦。对于没有共享内存的java，需要通过socket通信或者其它方式进行数据同步，带来额外的性能消耗，增加了程序复杂度。1GB内存的机器上大约10万个句柄左右</li>
<li>I/O效率不会随着FD数目的增加而线性下降:传统的select/poll另一个致命弱点就是当你拥有一个很大的socket集合，由于网络延时或者链路空闲，在任一时刻只有少部分的socket是"活跃"的，但是select/poll每次调用都会现行扫描全部的集合，导致效率呈现线性下降。而内核实现中epoll是根据每个fd上面的callback函数实现的，只有活跃的socket才会主动调用callback函数，其它的idle状态socket则不会。epoll实现了一个伪AIO</li>
<li>使用mmap加速内核与用户空间的消息传递:无论select，poll还是epoll都需要内核把FD消息通知给用户空间，如何避免不必要的内存复制就显得非常重要，epoll是通过内核和用户控件mmap同一块内存实现</li>
</ul>
</li>
</ul>
</li>
<li>NIO入门
<ul>
<li>传统的同步阻塞BIO编程:采用BIO通信模型的服务端，通常由一个独立的Acceptor线程负责监听客户端的连接，它接收到客户端连接请求之后未每个客户端创建一个新的线程进行链路处理，处理完成之后，通过输出流返回应答给客户端，线程销毁（典型的已请求一应答通信模型）。该模型最大的问题是当客户端并发访问量增加后，服务端的线程个数和客户端并发访问数成1:1正比关系，并发量很大是，系统会发生线程堆栈溢出、创建新线程失败等问题，导致进程宕机或僵死，不能对外提供服务。</li>
</ul>
</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class TimeServer{
    
    public static void main(String[] args) throws IOException{
        int port = 6666;
        ServerSocket serverSocket = null;
        try {
            serverSocket = new ServerSocket(port);
            Socket socket = null;
            System.out.println("BIOServer listening...");
            while (true){//阻塞
                socket = serverSocket.accept();
                new Thread(new TimeServerHandler(socket)).start();
            }
        } finally {
            if(serverSocket != null){
              serverSocket.close();
              serverSocket = null;
            }
        }
    }
}
 public class TimeServerHandler implements Runnable{
 
    private  Socket socket;
    public TimeServerHandler(Socket socket){
        this.socket = socket;
    }
    @Override
    public void run() {
        BufferedReader bufferedReader = null;
        PrintWriter printWriter = null;
        try {
            bufferedReader = new BufferedReader(new InputStreamReader(socket.getInputStream()));
            printWriter = new PrintWriter(this.socket.getOutputStream(),true);
            String currentTime = null;
            String body = null;
            while (true){
                body = bufferedReader.readLine();
                if(body == null)break;
                System.out.println("The time Server receive oder:" + body);
                currentTime = "QUERY TIME ORDER".equalsIgnoreCase(body)?new java.util.Date(System.currentTimeMillis()).toString():"BAD ORDER";
                printWriter.println(currentTime);
            }
        } catch (IOException e) {
            e.printStackTrace();
            if(bufferedReader != null){
                try {
                    bufferedReader.close();
                } catch (IOException e1) {
                    e1.printStackTrace();
                }
            }
            if(printWriter != null){
                printWriter.close();
                printWriter = null;
            }
            if(this.socket != null){
                try {
                    this.socket.close();
                } catch (IOException e1) {
                    e1.printStackTrace();
                }
                this.socket = null;
            }
        }
    }
}
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class TimeClient {
    public static void main(String[] args) {
        int port = 6666;
        Socket socket = null;
        BufferedReader bufferedReader = null;
        PrintWriter printWriter = null;
        try {
            socket = new Socket("127.0.0.1",port);
            bufferedReader = new BufferedReader(new InputStreamReader(socket.getInputStream()));
            printWriter = new PrintWriter(socket.getOutputStream(),true);
            printWriter.println("QUERY TIME ORDER");
            System.out.println("Send oder 2 server succeed.");
            String resp = bufferedReader.readLine();
            System.out.println("Now is : "+ resp);
        } catch (IOException e) {
            e.printStackTrace();
        } finally {
            if(printWriter != null){
                printWriter.close();
            }
            if(bufferedReader != null){
                try {
                    bufferedReader.close();
                } catch (IOException e) {
                    e.printStackTrace();
                }
            }
            if(socket != null){
                try {
                    socket.close();
                } catch (IOException e) {
                    e.printStackTrace();
                }
            }
        }
    }
}
</code></pre></div><ul>
<li>伪异步I/O编程:为了解决同步阻塞I/O面临的一个链路需要一个线程处理的问题，后来对他的线程模型进行优化，后端通过一个线程池来处理多个客户端的请求接入，形成客户端个数M；线程池最大线程数N的比例关系，其中M可以远远大于N，通过线程池可以灵活地调配线程资源，设置线程的最大值，防止由于海量并发接入导致线程耗尽
<ul>
<li>伪异步I/O通信弊端:
<ul>
<li>java.io.InputStream的read(byte b[])方法在对socket的输入流进行读取操作的时候，会一直阻塞下去，直到发生:1.有数据可读，2.可用数据以及读取完毕，3.空指针异常或者I/O异常。当对方发送请求或者应答消息比较缓慢、或者网络传输比较慢时，读取输入流的一方的通信线程将被长时间阻塞，在此期间其它接入消息只能在消息队列中排队</li>
<li>java.io.OutputStreamwrite(byte b[])方法在对socket的输出流进行写操作时，会一直阻塞下去，直到所有的字节全部写入完毕，或者发生异常。当消息的接收方处理缓慢的时候，将不能及时地从TCP缓冲区读取数据，将导致发送方的TCP windows size不断减小，直到为0，双方处于Keep-Alive状态，消息发送方将不能再向TCP缓冲区写入消息，这时如果饿采用的是同步阻塞I/O，write操作将被五险阻塞，直到TCP windows size 大于0 或者发生I/O异常。</li>
</ul>
</li>
<li>可能的级联故障:
<ul>
<li>服务端处理缓慢，返回应答消息耗费60s,平时只需要10ms</li>
<li>采用伪异步I/O的线程正在读取故障服务节点的响应，由于读取输入流的阻塞的，因此，它将会被同步阻塞60s</li>
<li>假如所有的可用线程都被故障服务器阻塞，那后续所有的I/O消息都将在队列种排队。</li>
<li>由于线程池采用阻塞队列实现，当队列积满之后，后续如队列的操作将被阻塞</li>
<li>由于前端只有一个Acceptor线程接收客户端接入，它被阻塞在线程池同步阻塞队列之后，新的客户端请求消息将被拒绝，客户端会发生大量的连接超时。</li>
<li>由于几乎所有的连接都超时，调用者会认为系统已经崩溃，无法接收新的请求消息</li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class TimeServer{

    public static void main(String[] args) throws IOException{
        int port = 6666;
        ServerSocket serverSocket = null;
        try {
            serverSocket = new ServerSocket(port);
            Socket socket = null;
            System.out.println("BIOServer listening...");
            ExecutorService executorService = new ThreadPoolExecutor(Runtime.getRuntime().availableProcessors(),50,120L, TimeUnit.SECONDS,new ArrayBlockingQueue&lt;Runnable&gt;(10000));
            while (true){//阻塞
                socket = serverSocket.accept();
                executorService.execute(new TimeServerHandler(socket));
            }
        } finally {
            if(serverSocket != null){
                serverSocket.close();
                serverSocket = null;
            }
        }
    }
}
</code></pre></div><ul>
<li>NIO编程:
<ul>
<li>缓冲区Buffer:Buffer是一个对象，包含一些要写入或者读出的数据，在面向流的I/O中，可以直接将数据写入或者将数据直接读到Stream对象中。在NIO库中，写入和读取数据都是用缓冲区进行处理的。缓冲器实质上市一个数组。通常是一个字节数组ByteBuffer，缓冲区提供对数据的结构化访问以及维护读写位置limit等信息。每一种Java基本类型（Boolean除外）都有对应的缓冲区（ByteBuffer、CharBuffer、ShortBuffer、IntBuffer、LongBuffer、FloatBuffer、DoubleBuffer）。其中ByteBuffer还提供特殊的操作，方便网络读写</li>
<li>通道Channel:Channel是一个全双工通道，可以通过它可以双向地读，写入或者同时读写数据，而流只是一个方向上移动，一个流必须是InputSteam或者OutputStream的子类。Channel可以分成两大类：分别是用于网络读写的SelectableChannel和用于文件操作的FileChannel</li>
<li>多路复用器Selector:提供选择已经就绪的任务的能力。Selector会不断地轮询注册在其上的Channel，如果某个Channel上面有新的TCP连接接入、读和写时间，这个Channel就处于就绪状态，会被Selector轮询出来，然后通过SelectionKey就可以获取就绪Channel的集合，进行后续的I/O操作。一个多路复用器Selector可以同时轮询多个Channel。使用epoll实现，并没有最大连接句柄1024/2048的限制（select）。只需一个线程负责Selector的轮询，就可以介入成千上万的客户端</li>
<li>优点:
<ul>
<li>客户端发起的连接操作是异步的，可以通过再多路复用器注册OP_CONNECT等待后续结果，不需要像之前客户端那样被同步阻塞</li>
<li>SocketChannel的读写操作都是一步的，如果没有可读写的数据它不会同步等待，直接返回，这样I/O通信线程就可以处理其他的链路，不需要同步等待这个链路可用</li>
<li>线程模型的优化:JDK的Selector在Linux等主流操作系统上通过epoll实现，它没有句柄数限制（只受限于操作系统的最大句柄数或者对单个进程的句柄限制）。一个Selector线程可以同时处理成千上万个客户端的连接，并且性能不会随着客户端的增加而线性下降</li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class TimeServer{

    public static void main(String[] args) throws IOException{
        int port = 6666;
        MultiplexerTimeServer timeServer = new MultiplexerTimeServer(port);
        new Thread(timeServer,"NIO-MultplexerTimeServer-001").start();
    }

}
public class MultiplexerTimeServer implements Runnable {
    private Selector selector;
    private ServerSocketChannel servChannnel;
    private volatile boolean stop;
    public MultiplexerTimeServer(int port){
      try{
        selector = Selector.open();
        servChannnel = ServerSocketChannel.open();
        servChannnel.configureBlocking(false);
        servChannnel.socket().bind(new InetSocketAddress(port),1024);//https://www.cnblogs.com/qiumingcheng/p/9492962.html
        servChannnel.register(selector, SelectionKey.OP_ACCEPT);
        System.out.println("The time server is start in port :" + port);
      } catch (IOException e) {
            e.printStackTrace();
            System.exit(1);
      }
    }
    public void stop(){
        this.stop = true;
    }
    @Override
    public void run() {
        while (!stop){
            try {
                selector.select(1000);//selector每隔1秒唤醒一次。当有处于就绪状态的Channel时，selector将返回就绪状态的SelectionKey集合，通过对就绪状态的Channel集合进行迭代可以进行网络的异步读写操作
                Set&lt;SelectionKey&gt; selectionKeySet = selector.selectedKeys();
                Iterator&lt;SelectionKey&gt; it = selectionKeySet.iterator();
                SelectionKey selectionKey = null;
                while (it.hasNext()){
                    selectionKey = it.next();
                    it.remove();
                    try {
                        handleInput(selectionKey);
                    }catch (Exception e){
                        if(selectionKey != null){
                            selectionKey.cancel();
                            if(selectionKey.channel() != null){
                                selectionKey.channel().close();
                            }
                        }
                    }
                }
            } catch (IOException e) {
                e.printStackTrace();
            }
        }
        //多路复用器关闭后，所有注册在上面的Channel和Pipe等资源都会被自动去注册并关闭，所有不需要重复释放资源
        if(selector != null){
            try {
                selector.close();
            } catch (IOException e) {
                e.printStackTrace();
            }
        }
    }
    private void handleInput(SelectionKey selectionKey) throws IOException {
        if(selectionKey.isValid()){
            //根据SelectionKey的操作未进行判断即可获知网络事件的类型
            if(selectionKey.isAcceptable()){
                ServerSocketChannel serverSocketChannel = (ServerSocketChannel) selectionKey.channel();//相当于完成了TCP的三次握手，TCP物理链路正式建立
                SocketChannel socketChannel = serverSocketChannel.accept();
                socketChannel.configureBlocking(false);
                socketChannel.register(selector,SelectionKey.OP_READ);
            }
            if(selectionKey.isReadable()){
                SocketChannel socketChannel = (SocketChannel) selectionKey.channel();
                //创建ByteBuffer，事先不知道客户端发送的码流大小，先开辟一个1K的缓冲区
                ByteBuffer readBuffer = ByteBuffer.allocate(1024);
                int readBytes = socketChannel.read(readBuffer);//此时的read非阻塞
                if(readBytes &gt; 0){//读到了字节，对字节进行编解码
                    //调用flip()之后，读/写指针position指到缓冲区头部，并且设置了最多只能读出之前写入的数据长度(而不是整个缓存的容量大小)。相当于limit =&gt; position;position=&gt;0
                    readBuffer.flip();
                    //返回剩余的可用长度，此长度为实际可读取的数据长度，最大自然是底层数组的长度
                    byte[] bytes = new byte[readBuffer.remaining()];
                    //从ByteBuffer中读取byte[]。将缓冲区可读的字节数组复制到新创建的字节数组中
                    readBuffer.get(bytes);
                    String body = new String(bytes,"UTF-8");
                    System.out.println("The Time server receive order:"+body);
                    String currentTime = "QUERY TIME ORDER".equalsIgnoreCase(body)?new java.util.Date(System.currentTimeMillis()).toString():"BAD ORDER";
                    doWrite(socketChannel,currentTime);
                } else if(readBytes &lt; 0){//-1 链路已经关闭，需要关闭SocketChannel，释放资源
                    selectionKey.cancel();
                    socketChannel.close();
                } else {
                    //读到0字节，忽略
                }
            }
        }
    }

    private void doWrite(SocketChannel socketChannel,String response) throws IOException {
        if(response !=null &amp;&amp; response.trim().length() &gt; 0){
            byte[] bytes = response.getBytes();
            ByteBuffer writeBuffer = ByteBuffer.allocate(bytes.length);
            writeBuffer.put(bytes);//将字节数组复制到缓冲区中
            writeBuffer.flip();
            socketChannel.write(writeBuffer);//并不能保证一次性能够把需要发送的字节数组发送完，会出现"写半包"的问题，此时需要注册写操作，不断轮询Selector将没有发送玩的ByteBuffer发送完毕。可以通过ByteBuffer的hasRemaining()方法判断消息是否发送完成。如果发送区的TCP缓冲区满，会导致写半包，此时需要注册监听写操作位，循环写，直到整包消息写入TCP缓冲区
        }
    }

}
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class TimeClient{
  public static void main(String[] args){
        new Thread(new TimeClientHandle("127.0.0.1",6666)).start();
    }
}
public class TimeClientHandle implements Runnable{
    private String host;
    private int port;
    private Selector selector;
    private SocketChannel socketChannel;
    private volatile boolean stop;

    public TimeClientHandle(String host, int port) {
        this.host = host;
        this.port = port;
        try {
            selector = Selector.open();
            socketChannel = SocketChannel.open();
            socketChannel.configureBlocking(false);
        } catch (IOException e) {
            e.printStackTrace();
            System.exit(1);
        }


    }

    @Override
    public void run() {
        try{
            doConnect();
        }catch (IOException e){
            e.printStackTrace();
        }
        while(!stop){
            try {
                selector.select(1000);
                Set&lt;SelectionKey&gt; selectionKeySet = selector.selectedKeys();
                Iterator&lt;SelectionKey&gt; it = selectionKeySet.iterator();
                SelectionKey selectionKey = null;
                while (it.hasNext()) {
                    selectionKey = it.next();
                    it.remove();
                    try {
                        handleInput(selectionKey);
                    } catch (Exception e) {
                        e.printStackTrace();
                        if (selectionKey != null) {
                            selectionKey.cancel();
                            if (selectionKey.channel() != null) {
                                try {
                                    selectionKey.channel().close();
                                } catch (IOException e1) {
                                    e1.printStackTrace();
                                }
                            }
                        }
                    }
                }
            }catch (IOException e2) {
                e2.printStackTrace();
            }
        }
        // 多路复用器关闭后，所有注册在上面的Channel和Pipe等资源都会被自动去注册并关闭，所以不需要重复释放资源
        if(selector != null){
            try {
                selector.close();
            } catch (IOException e) {
                e.printStackTrace();
            }
        }
    }

    private void handleInput(SelectionKey key) throws IOException{
        if(key.isValid()){
            SocketChannel socketChannel = (SocketChannel) key.channel();
            if(key.isConnectable()){//处于连接状态，说明服务端以及返回ACK应答消息
                if(socketChannel.finishConnect()){//客户端连接成功
                    socketChannel.register(selector,SelectionKey.OP_READ);
                    doWrite(socketChannel);
                }else{
                    System.exit(1);
                }
                if(key.isReadable()){
                    ByteBuffer readBuffer = ByteBuffer.allocate(1024);
                    int readBytes = socketChannel.read(readBuffer);
                    if(readBytes &gt; 0){
                        readBuffer.flip();
                        byte[] bytes = new byte[readBuffer.remaining()];
                        readBuffer.get(bytes);
                        String body = new String(bytes,"UTF-8");
                        System.out.println("Now is:"+body);
                        this.stop = true;
                    }else if(readBytes &lt; 0){
                        //对链路关闭
                        key.cancel();
                        socketChannel.close();
                    }else{
                        //读到0字节忽略
                    }
                }
            }
        }
    }

    private void doConnect() throws IOException {
        if(socketChannel.connect(new InetSocketAddress(this.host,this.port))){
            socketChannel.register(selector,SelectionKey.OP_READ);
            doWrite(socketChannel);
        }else{
            socketChannel.register(selector,SelectionKey.OP_CONNECT);//当服务端返回TCP syn-ack消息后，Selector就能够轮询到这个SocketChannel处于连接就绪状态
        }
    }

    private void doWrite(SocketChannel socketChannel) throws IOException{
        byte[] req = "QUERY TIME ORDER".getBytes();
        ByteBuffer writeBuffer = ByteBuffer.allocate(req.length);
        writeBuffer.put(req);
        writeBuffer.flip();
        socketChannel.write(writeBuffer);
        if(!writeBuffer.hasRemaining()){
            System.out.println("Send order 2 server succeed.");
        }
    }
}
</code></pre></div><pre><code>- AIO编程:NIO2.0引入了新的以不同送到的概念，并提供了异步文件通道和异步套接字通道的实现，异步通道提供两种方式获取操作结果。1.通过java.util.concurrent.Future类来表示异步操作的结果，2.在执行异步操作的时候传入一个java.nio.channels。CompletionHandler接口实现类作为操作完成的回调。
- NIO2.0的异步套接字通道是真正的异步非阻塞I/O,它对应UNIX网络编程中时间驱动I/O(AIO),它不需要通过多路复用器（Selector）对注册的通道进行轮询操作即可实现异步读写，异步Socket Channel是被动执行对象，不需要想NIO编程那样创建一个独立的I/O线程处理读写操作，对于AsynchronousServerSocketChannel和AsynChronousSocketChannel，它们都由JDK底层的线程池负责回调并驱动读写操作
</code></pre>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class TimeServer{
    public static void main(String[] args) throws IOException{
        AsyncTimeServerHandler timeServer = new AsyncTimeServerHandler(6666);
        new Thread(timeServer,"AIO-AsyncTimeServerHandler-001").start();
    }

}
public class AsyncTimeServerHandler implements Runnable{
    private int port;
    CountDownLatch latch;
     AsynchronousServerSocketChannel asynchronousServerSocketChannel;
    public AsyncTimeServerHandler(int port){
        this.port = port;
        try {
            asynchronousServerSocketChannel = AsynchronousServerSocketChannel.open();
            asynchronousServerSocketChannel.bind(new InetSocketAddress(port));
            System.out.println("The time server is start in port :" + port);
        } catch (IOException e) {
            e.printStackTrace();
            System.exit(1);
        }
    }

    @Override
    public void run() {
        countDownLatch = new CountDownLatch(1);
        doAccept();
        try{
            countDownLatch.await();
        }catch (InterruptedException e){
            e.printStackTrace();
        }
    }

    private void doAccept(){
        asynchronousServerSocketChannel.accept(this,new AcceptCompletionHandler());
    }


}

public class AcceptCompletionHandler implements CompletionHandler&lt;AsynchronousSocketChannel,AcceptCompletionHandler&gt; {

    @Override
    public void completed(AsynchronousSocketChannel result, AsyncTimeServerHandler attachment) {
        attachment.asynchronousServerSocketChannel.accept(attachment,this);
        ByteBuffer byteBuffer = ByteBuffer.allocate(1024);
        //ByteBuffer dst;接收缓冲区，用于从异步channel中读取数据包
        //Attachment a;异步channel携带的附件，通知回调的时候作为入参使用
        //CompletionHandler&lt;Integer,? super A&gt;;接收通知回调业务的handler
        result.read(byteBuffer,byteBuffer,new ReadCompletionHandler(result));
    }

    @Override
    public void failed(Throwable exc, AIOSocketServer attachment) {
        attachment.countDownLatch.countDown();
    }
}

public class ReadCompletionHandler implements CompletionHandler&lt;Integer,ByteBuffer&gt; {

    private AsynchronousSocketChannel channel;

    public ReadCompletionHandler(AsynchronousSocketChannel channel){
        if(this.channel == null){
            this.channel = channel;
        }

    }

    @Override
    public void completed(Integer result, ByteBuffer attachment) {
        attachment.flip();
        byte[] body = new byte[attachment.remaining()];
        attachment.get(body);
        try {
            String req = new String(body,"UTF-8");
            System.out.println("The time server recive order :"+ req);
            String currentTime = "QUERY TIME ORDER".equalsIgnoreCase(req)?new java.util.Date(System.currentTimeMillis()).toString():"BAD ORDER";
            doWrite(currentTime);
        } catch (UnsupportedEncodingException e) {
            e.printStackTrace();
        }
    }

    @Override
    public void failed(Throwable exc, ByteBuffer attachment) {
        try {
            this.channel.close();
        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    private void doWrite(String currentTime){
        if(currentTime != null &amp;&amp; currentTime.trim().length() &gt; 0){
            byte[] bytes = (currentTime).getBytes();
            ByteBuffer writeBuffer = ByteBuffer.allocate(bytes.length);
            writeBuffer.put(bytes);
            writeBuffer.flip();
            channel.write(writeBuffer, writeBuffer, new CompletionHandler&lt;Integer, ByteBuffer&gt;() {
                @Override
                public void completed(Integer result, ByteBuffer buffer) {
                    //如果没有发送完就继续发送
                    if(buffer.hasRemaining()){
                        channel.write(buffer,buffer,this);
                    }
                }

                @Override
                public void failed(Throwable exc, ByteBuffer attachment) {
                    try {
                        channel.close();
                    } catch (IOException e) {
                        e.printStackTrace();
                    }
                }
            });
        }
    }
}
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class TimeClient{
    public static void main(String[] args) throws IOException{
        new Thread(new AsyncTimeClientHandler(6666),"AIO-AsyncTimeClientHandler-001").start();
    }
}
public class AsyncTimeClientHandler implements Completionhandler&lt;Void,AsycTimeClientHandler&gt;,Runnable{
    private AsynchronousSocketChannel client;
    private String host;
    private int port;
    private CountDownLatch latch;
    public AsyncTimeClientHandler(String host,int port){
        this.host = host;
        this.port = port;
        try{
            client = AsynchronousSocketChannel.open();
        }catch(IOException e){
            e.printStatckTrace();
        }
    }
    @Override
    public void run() {
        latch = new CountDownLatch(1);//防止异步没执行完就线程就退出
        //A attachment: AsynchronousSocketChannel的附件，用于回调通知时作为入参被传递
        //CompletionHandler&lt;Void,? super A&gt; handler: 异步操作回调通知接口，由调用者实现
        client.connect(new InetSocketAddress(host,port),this,this);
        try {
            latch.await();
        } catch (InterruptedException e1){
            e1.printStackTrace();
        }
        try{
            client.close();
        }catch (IOException e){
            e.printStackTrace();
        }
    }



    @Override
    public void completed(Void result, AIOSocketClient attachment) {
        byte[] req = "QUERY TIME ORDER".getBytes();
        ByteBuffer writeBuffer = ByteBuffer.allocate(req.length);
        writeBuffer.put(req);
        writeBuffer.flip();
        client.write(writeBuffer, writeBuffer, new CompletionHandler&lt;Integer, ByteBuffer&gt;() {
            @Override
            public void completed(Integer result, ByteBuffer buffer) {
                if( buffer.hasRemaining()){
                    client.write(buffer,buffer,this);
                }else{
                    ByteBuffer readBuffer = ByteBuffer.allocate(1024);
                    client.read(readBuffer, readBuffer, new CompletionHandler&lt;Integer, ByteBuffer&gt;() {
                        @Override
                        public void completed(Integer result, ByteBuffer buffer) {
                            buffer.flip();
                            byte[] bytes = new byte[buffer.remaining()];
                            buffer.get(bytes);
                            String body;
                            try {
                                body = new String(bytes,"UTF-8");
                                System.out.println("Now is :" + body);
                                latch.countDown();
                            } catch (UnsupportedEncodingException e) {
                                e.printStackTrace();
                            }
                        }

                        @Override
                        public void failed(Throwable exc, ByteBuffer buffer) {
                            try {
                                client.close();
                            } catch (IOException e) {
                                e.printStackTrace();
                            }
                        }
                    });
                }
            }

            @Override
            public void failed(Throwable exc, ByteBuffer buffer) {
                try {
                    client.close();
                    latch.countDown();
                } catch (IOException e) {
                    e.printStackTrace();
                }
            }
        });
    }

    @Override
    public void failed(Throwable exc, AIOSocketClient attachment) {
        exc.printStackTrace();
        try {
            client.close();
            latch.countDown();
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}
</code></pre></div><ul>
<li>不同I/O模型对比</li>
<li>Netty开发</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class TimeServer{
    public void bind(int port) throws Exception{
        EventLoopGroup boosGroup = new NioEventLoopGroup();//一组NIO线程，专门用于处理网络事件 服务端用于接收客户端的链接
        EventLoopGroup workerGroup = new NioEventLoopGroup();//进行SocketChannel的网络读写
        try {
            ServerBootstrap serverBootstrap = new ServerBootstrap();
            serverBootstrap.group(boosGroup,workerGroup)
                    .channel(NioServerSocketChannel.class)//类比ServerSocketChannel
                    .option(ChannelOption.SO_BACKLOG,1024).
                    childHandler(new ChildChannelHandler());//类似Reactor模式中的handler类，主要用于处理网络I/O事件，例如记录日志，对消息进行编解码等。
            ChannelFuture f = serverBootstrap.bind(port).sync();//sync同步阻塞方法等待绑定完成,ChannelFuture 用于异步操作的通知回调
            f.channel().closeFuture().sync();//sync阻塞等待服务端链路关闭后main函数才退出
        }finally {
            boosGroup.shutdownGracefully();
            workerGroup.shutdownGracefully();
        }
    }



    private class ChildChannelHandler extends  ChannelInitializer&lt;SocketChannel&gt;{

        @Override
        protected void initChannel(SocketChannel socketChannel) throws Exception {
            socketChannel.pipeline().addLast(new TimeServerHandler());
        }
    }

    public static void main(String[] args) throws Exception {
        new TimeServer().bind(8080);
    }
}
public class TimeServerHandler extends ChannelHandlerAdapter {
    @Override
    public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
        ByteBuf byteBuf = (ByteBuf) msg;
        byte[] req = new byte[byteBuf.readableBytes()];//readableBytes获取缓冲区可读的字节数
        byteBuf.readBytes(req);
        String body = new String(req,"UTF-8");
        System.out.println("The Time server recevice order :  "+body);
        String currentTime = "QUERY TIME ORDER".equalsIgnoreCase(body)?new java.util.Date(
                System.currentTimeMillis()
        ).toString():"BAD ORDER";
        ByteBuf resp = Unpooled.copiedBuffer(currentTime.getBytes());
        ctx.write(resp);
    }

    @Override
    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {
        ctx.close();//释放和ChannelHandlerContext相关联的句柄等资源
    }

    @Override
    public void channelReadComplete(ChannelHandlerContext ctx) throws Exception {
        ctx.flush();//将消息发送队列中的消息写入到SocketChannel中发送给对方。从性能角度考虑，为了防止频繁地唤醒Selector进行消息发送，Netty的write方法并不直接将消息写入SocketChannel中，调用write方法只是把待发送的消息放到发送缓冲数组中，再通过调用flush方法，将发送缓冲区中的消息全部写到SocketChannel中
    }
}
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class TimeClient {
    public void connect(int port, String host) throws Exception{
        EventLoopGroup group = new NioEventLoopGroup();
        try{
            Bootstrap b = new Bootstrap();
            b.group(group).channel(NioSocketChannel.class)
                    .option(ChannelOption.TCP_NODELAY,true)
                    .handler(new ChannelInitializer&lt;SocketChannel&gt;() {
                        @Override
                        protected void initChannel(SocketChannel socketChannel) throws Exception {
                            socketChannel.pipeline().addLast(new TimeClentHandler());//处理网络I/O事件
                        }
                    });
            ChannelFuture f = b.connect(host,port).sync();
            f.channel().closeFuture().sync();
        }finally {
            group.shutdownGracefully();
        }

    }
    public static void main(String[] args) throws Exception {
        new TimeClient().connect(8080,"127.0.0.1");
    }
}
public class TimeClentHandler extends ChannelHandlerAdapter {
    private final ByteBuf firstMessage;

    public TimeClentHandler() {
        byte[] req = "QUERY TIME ORDER".getBytes();
        firstMessage = Unpooled.buffer(req.length);
        firstMessage.writeBytes(req);
    }

    @Override
    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {
        System.out.println("Unexpected exception from downstram :" +cause.getMessage());
        ctx.close();
    }

    @Override
    public void channelActive(ChannelHandlerContext ctx) throws Exception {
        //当客户端和服务端TCP链路建立成功之后，Netty的NIO线程会调用channelActive方法
        ctx.writeAndFlush(firstMessage);
    }

    @Override
    public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
        ByteBuf byteBuf = (ByteBuf) msg;
        byte[] req = new byte[byteBuf.readableBytes()];
        byteBuf.readBytes(req);
        String body = new String(req,"UTF-8");
        System.out.println("Now is :" + body);
    }


}
</code></pre></div><ul>
<li>TCP粘包/拆包
<ul>
<li>TCP是个流协议，没有没有界限的一串数据。TCP底层并不了解上层业务数据的具体含义，会根据TCP缓冲区的实际情况进行报的划分，所以在业务上认为，一个完整的包可能被TCP拆分成多个包进行发送，也有可能吧多个小的包封装成一个大的数据包发送，就是所谓的TCP的粘包和拆包问题</li>
<li>假设客户端分别发送了两个数据包D1和D2给服务端，由于服务端一次读取到的字节数是不确定的，可能存在以下4种情况
<ul>
<li>服务端分2次读取到了两个独立的数据包，分别是D1和D2，没有粘包和拆包</li>
<li>服务端一次接受到两个数据包，D1和D2粘合在一起，被称为TCP粘包</li>
<li>服务端分两次读取到了两个数据包，第一次读取到了完整的D1包和D2的部分内容，第二次读取到了D2包的剩余内容，这被称为TCP拆包</li>
<li>服务端分两次读取到了两个数据包，第一次读取到了D1包的部分内容D1_1，第二次读取到了D1包的剩余内容D1_2和D2包的整包。</li>
<li>如果此时服务器TCP接收滑动窗口非常小，而数据包D1和D2比较大，很有可能发生第五中可能，即服务端分多次才能将D1和D2包接收完全，期间发生多次拆包</li>
</ul>
</li>
<li>TCP粘包/拆包发生的原因
<ul>
<li>应用程序写入的字节大小大于套接口发送的缓冲区大小</li>
<li>进行MSS（TCP协议的Maxitum Segment Size 最大报文段长度选项）大小的TCP分段</li>
<li>以太网帧的payload大于MTU（Maximum Transmission Unit网络上传送的最大数据包 单位是字节。 大部分网络设备的MTU都是1500）进行IP分片</li>
</ul>
</li>
<li>粘包问题的解决策略
<ul>
<li>消息定长：固定长度为n个字节，空位补弄个</li>
<li>在包尾增加回车换行符进行分割，如FTP协议</li>
<li>将消息分为消息头和消息体，消息头中包含表示消息总长度或者消息体长度的字段，通常涉及思路为消息头的第一个字段用int32表示消息的总长度</li>
<li>Netty提供了半包解码器解决TCP粘包/拆包问题</li>
</ul>
</li>
<li>TCP粘包异常案例</li>
</ul>
</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class TimeServer{
    public void bind(int port) throws Exception{
        EventLoopGroup boosGroup = new NioEventLoopGroup();//一组NIO线程，专门用于处理网络事件 服务端用于接收客户端的链接
        EventLoopGroup workerGroup = new NioEventLoopGroup();//进行SocketChannel的网络读写
        try {
            ServerBootstrap serverBootstrap = new ServerBootstrap();
            serverBootstrap.group(boosGroup,workerGroup)
                    .channel(NioServerSocketChannel.class)//类比ServerSocketChannel
                    .option(ChannelOption.SO_BACKLOG,1024).
                    childHandler(new ChildChannelHandler());//类似Reactor模式中的handler类，主要用于处理网络I/O事件，例如记录日志，对消息进行编解码等。
            ChannelFuture f = serverBootstrap.bind(port).sync();//sync同步阻塞方法等待绑定完成,ChannelFuture 用于异步操作的通知回调
            f.channel().closeFuture().sync();//sync阻塞等待服务端链路关闭后main函数才退出
        }finally {
            boosGroup.shutdownGracefully();
            workerGroup.shutdownGracefully();
        }
    }



    private class ChildChannelHandler extends  ChannelInitializer&lt;SocketChannel&gt;{

        @Override
        protected void initChannel(SocketChannel socketChannel) throws Exception {
            socketChannel.pipeline().addLast(new TimeServerHandler());
        }
    }

    public static void main(String[] args) throws Exception {
        new TimeServer().bind(8080);
    }
}
public class TimeServerHandler extends ChannelHandlerAdapter {
    private int counter;
    @Override
    public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
        ByteBuf byteBuf = (ByteBuf) msg;
        byte[] req = new byte[byteBuf.readableBytes()];
        byteBuf.readBytes(req);
        String body = new String(req,"UTF-8").substring(0,req.length -System.getProperty("line.separator").length());
        System.out.println("The Time server recevice order :  "+body+"; the counter is:" + ++counter);
        String currentTime = "QUERY TIME ORDER".equalsIgnoreCase(body)?new java.util.Date(
                System.currentTimeMillis()
        ).toString():"BAD ORDER";
        currentTime = currentTime + System.getProperty("line.separator");
        ByteBuf resp = Unpooled.copiedBuffer(currentTime.getBytes());
        ctx.writeAndFlush(resp);
    }

    @Override
    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {
        ctx.close();
    }

    @Override
    public void channelReadComplete(ChannelHandlerContext ctx) throws Exception {
        ctx.flush();
    }
}
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class TimeClient {
    public void connect(int port, String host) throws Exception{
        EventLoopGroup group = new NioEventLoopGroup();
        try{
            Bootstrap b = new Bootstrap();
            b.group(group).channel(NioSocketChannel.class)
                    .option(ChannelOption.TCP_NODELAY,true)
                    .handler(new ChannelInitializer&lt;SocketChannel&gt;() {
                        @Override
                        protected void initChannel(SocketChannel socketChannel) throws Exception {
                            socketChannel.pipeline().addLast(new TimeClentHandler());
                        }
                    });
            ChannelFuture f = b.connect(host,port).sync();
            f.channel().closeFuture().sync();
        }finally {
            group.shutdownGracefully();
        }

    }
    public static void main(String[] args) throws Exception {
        new TimeClient().connect(8080,"127.0.0.1");
    }
}
public class TimeClentHandler extends ChannelHandlerAdapter {
    private byte[] req;
    private int counter;

    public TimeClentHandler() {
        req = ("QUERY TIME ORDER" + System.getProperty("line.separator")).getBytes();
    }

    @Override
    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {
        System.out.println("Unexpected exception from downstram :" +cause.getMessage());
        ctx.close();
    }

    @Override
    public void channelActive(ChannelHandlerContext ctx) throws Exception {
        ByteBuf message = null;
        for(int i=0;i&lt;100;i++){
            message = Unpooled.buffer(req.length);
            message.writeBytes(req);
            ctx.writeAndFlush(message);
        }
    }

    @Override
    public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
        ByteBuf byteBuf = (ByteBuf) msg;
        byte[] req = new byte[byteBuf.readableBytes()];
        byteBuf.readBytes(req);
        String body = new String(req,"UTF-8");
        System.out.println("Now is :" + body + ": the counter is : " + ++counter);
    }

}
</code></pre></div><ul>
<li>Netty使用LineBasedFrameDecoder解决TCP粘包问题</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class TimeServer {
    public void bind(int port) throws Exception{
        EventLoopGroup boosGroup = new NioEventLoopGroup();
        EventLoopGroup workerGroup = new NioEventLoopGroup();
        try {
            ServerBootstrap serverBootstrap = new ServerBootstrap();
            serverBootstrap.group(boosGroup,workerGroup)
                    .channel(NioServerSocketChannel.class)
                    .option(ChannelOption.SO_BACKLOG,1024).
                    childHandler(new ChildChannelHandler());
            ChannelFuture f = serverBootstrap.bind(port).sync();
            f.channel().closeFuture().sync();
        }finally {
            boosGroup.shutdownGracefully();
            workerGroup.shutdownGracefully();
        }
    }



    private class ChildChannelHandler extends  ChannelInitializer&lt;SocketChannel&gt;{

        @Override
        protected void initChannel(SocketChannel socketChannel) throws Exception {
            socketChannel.pipeline().addLast(new LineBasedFrameDecoder(1024));
            socketChannel.pipeline().addLast(new StringDecoder());
            socketChannel.pipeline().addLast(new TimeServerHandler());
        }
    }

    public static void main(String[] args) throws Exception {
        new TimeServer().bind(8080);
    }
}
public class TimeServerHandler extends ChannelHandlerAdapter {

    private int counter;

    @Override
    public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
        String body = (String) msg;
        System.out.println("The Time server recevice order :  "+body+"; the counter is:" + ++counter);
        String currentTime = "QUERY TIME ORDER".equalsIgnoreCase(body)?new java.util.Date(
                System.currentTimeMillis()
        ).toString():"BAD ORDER";
        currentTime = currentTime + System.getProperty("line.separator");
        ByteBuf resp = Unpooled.copiedBuffer(currentTime.getBytes());
        ctx.write(resp);
    }

    @Override
    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {
        ctx.close();
    }

    @Override
    public void channelReadComplete(ChannelHandlerContext ctx) throws Exception {
        ctx.flush();
    }
}
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class TimeClient {
    public void connect(int port, String host) throws Exception{
        EventLoopGroup group = new NioEventLoopGroup();
        try{
            Bootstrap b = new Bootstrap();
            b.group(group).channel(NioSocketChannel.class)
                    .option(ChannelOption.TCP_NODELAY,true)
                    .handler(new ChannelInitializer&lt;SocketChannel&gt;() {
                        @Override
                        protected void initChannel(SocketChannel socketChannel) throws Exception {
                            socketChannel.pipeline().addLast(new LineBasedFrameDecoder(1024));
                            socketChannel.pipeline().addLast(new StringDecoder());
                            socketChannel.pipeline().addLast(new TimeClentHandler());

                        }
                    });
            ChannelFuture f = b.connect(host,port).sync();
            f.channel().closeFuture().sync();
        }finally {
            group.shutdownGracefully();
        }

    }
    public static void main(String[] args) throws Exception {
        new TimeClient().connect(8080,"127.0.0.1");
    }
}
public class TimeClentHandler extends ChannelHandlerAdapter {
    private int counter;
    private byte[] req;
    public TimeClentHandler() {
        req = ("QUERY TIME ORDER"+ System.getProperty("line.separator")).getBytes();
    }

    @Override
    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {
        System.out.println("Unexpected exception from downstram :" +cause.getMessage());
        ctx.close();
    }

    @Override
    public void channelActive(ChannelHandlerContext ctx) throws Exception {
        ByteBuf message = null;
        for(int i=0;i&lt;100;i++){
            message = Unpooled.buffer(req.length);
            message.writeBytes(req);
            ctx.writeAndFlush(message);
        }
    }

    @Override
    public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
        String body = (String) msg;
        System.out.println("Now is :" + body +"; the counter is :" + ++counter);
    }


}
</code></pre></div><ul>
<li>LineBasedFrameDecoder和StringDecoder的原理分析
<ul>
<li>LineBasedFrameDecoder的工作原理是它依次遍历ByteBuf中的可读字节，判断看是否有"\n"或者"\r\n"，如果有，就以此位置为结束位置，从可读索引到结束位置区间的字节就组成了一行，它是以换行符未结束标志的解码器，只是携带结束符或者不携带结束符两种解码方式，同时支持配置单行的最大长度。如果连续读取到最大长度后仍然没有发现换行符，就会抛出异常，同时忽略掉之前读到的异常码流。</li>
<li>StringDecoder讲接收到的对象转换成字符串在继续调用后面的handler，LineBasedFrameDecoder组合就是按行切换的文本解码器。</li>
</ul>
</li>
<li>分隔符合定长解码器的应用
<ul>
<li>TCP以流的方式进行数据传输，上层的应用协议为了对消息进行区分
<ul>
<li>消息长度固定，累计读取到长度综合为定长LEN的报文后，就认为读取到了一个完整的消息；将计数器职位，重新开始读取下一个数据报</li>
<li>将回车换行符作为消息结束符，例如FTP协议，这种方式在文本协议中应用比较广泛</li>
<li>将特殊的分隔符作为消息的结束标志，回车换行符就是一种特殊的结束分隔符</li>
<li>通过在消息头中定义长度字段标识消息的总长度</li>
<li>DelimiterBasedFrameDecoder可以自动完成以分隔符做结束标志的解码</li>
<li>FixedLengthFrameDecoder可以自动完成对定长消息的解码</li>
</ul>
</li>
</ul>
</li>
<li>DelimiterBasedFrameDecoder</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class EchoServer{
    public void bind(int port) throws Exception{
        EventLoopGroup boosGroup = new NioEventLoopGroup();
        EventLoopGroup workerGroup = new NioEventLoopGroup();
        try {
            ServerBootstrap serverBootstrap = new ServerBootstrap();
            serverBootstrap.group(boosGroup,workerGroup)
                    .channel(NioServerSocketChannel.class)
                    .option(ChannelOption.SO_BACKLOG,1024)
                    .handler(new LoggingHandler(LogLevel.INFO))
                    .childHandler(new ChannelInitalizer&lt;SocketChannel&gt;(){
                        @Override
                        public void initChannel(SocketChannel ch) throws Exception{
                            ByteBuf delimiter = Unpooled.copideBuffer("$_".getBytes());
                            ch.pipeline().addLast(new DelimiterBasedFrameDecoder(1024,delimiter));//单条消息最大长度，当达到该长度后仍然没有查找到分隔符，就抛出TooLongFrameException异常，防止由于异常码流确实分隔符导致的内存溢出，是可靠性保护，
                            ch.pipeline().addLast(new StringDecode());
                            ch.pipeline().addLast(new EchoServerHandler());
                        }
                    });
            ChannelFuture f = serverBootstrap.bind(port).sync();
            f.channel().closeFuture().sync();
        }finally {
            boosGroup.shutdownGracefully();
            workerGroup.shutdownGracefully();
        }
    }

    public static void main(String[] args) throws Exception {
        new EchoServer().bind(8080);
    }
}
public class EchoServerHandler extends ChannelHandlerAdapter{
    int counter = 0;
    @Override
    public void channelRead(ChannelHandlerContext ctx,Object msg) throws Exception{
        String body = (String) msg;
        System.out.println("This is" + ++counter + "time receive clinet :{" + body + "}");
    }
    @Override
    public void exceptionCaught(ChannelHandlerContext ctx , Throwable cause){
        cause.printStackTrace();
        ctx.close();
    }
}
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class EchoClient {
    public void connect(int port, String host) throws Exception{
        EventLoopGroup group = new NioEventLoopGroup();
        try{
            Bootstrap b = new Bootstrap();
            b.group(group).channel(NioSocketChannel.class)
                    .option(ChannelOption.TCP_NODELAY,true)
                    .handler(new ChannelInitializer&lt;SocketChannel&gt;() {
                        @Override
                        protected void initChannel(SocketChannel socketChannel) throws Exception {
                            ByteBuf delimiter = Unpooled.copideBuffer("$_".getBytes());
                            ch.pipeline().addLast(new DelimiterBasedFrameDecoder(1024,delimiter));//单条消息最大长度，当达到该长度后仍然没有查找到分隔符，就抛出TooLongFrameException异常，防止由于异常码流确实分隔符导致的内存溢出，是可靠性保护，
                            ch.pipeline().addLast(new StringDecode());
                            ch.pipeline().addLast(new EchoClientHandler());

                        }
                    });
            ChannelFuture f = b.connect(host,port).sync();
            f.channel().closeFuture().sync();
        }finally {
            group.shutdownGracefully();
        }

    }
    public static void main(String[] args) throws Exception {
        new EchoClient().connect(8080,"127.0.0.1");
    }
}
public class EchoClentHandler extends ChannelHandlerAdapter {
    private int counter;
    public EchoClentHandler() {}

    @Override
    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {
        System.out.println("Unexpected exception from downstram :" +cause.getMessage());
        ctx.close();
    }

    @Override
    public void channelActive(ChannelHandlerContext ctx) throws Exception {
        for(int i=0;i&lt;100;i++){
            ctx.writeAndFlush(Unpooled.copiedBuffer(ECHO_REQ.getBytes()));
        }
    }

    @Override
    public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
        System.out.println("This is"+ ++counter + "times receive server : [" + msg + "]");
    }
    @Override
    public void channelReadComplete(ChannelHandlerContext ctx) throws Exception {
        ctx.flush();
    }
}
</code></pre></div><ul>
<li>FixedLengthFrameDecoder解码器，无论一次接收到多少数据包，它都会按照构造函数中设置的固定长度进行解码，如果是半包消息，它会缓存半包消息并等待下个包到达后进行拼包，直到读取到一个完整的包</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class EchoServer{
    public void bind(int port) throws Exception{
        EventLoopGroup boosGroup = new NioEventLoopGroup();
        EventLoopGroup workerGroup = new NioEventLoopGroup();
        try {
            ServerBootstrap serverBootstrap = new ServerBootstrap();
            serverBootstrap.group(boosGroup,workerGroup)
                    .channel(NioServerSocketChannel.class)
                    .option(ChannelOption.SO_BACKLOG,1024)
                    .handler(new LoggingHandler(LogLevel.INFO))
                    .childHandler(new ChannelInitalizer&lt;SocketChannel&gt;(){
                        @Override
                        public void initChannel(SocketChannel ch) throws Exception{
                            ch.pipeline().addLast(new FixedLengthFrameDecoder(20));
                            ch.pipeline().addLast(new StringDecoder());
                            ch.pipeline().addLast(new EchoServerHandler());
                        }
                    });
            ChannelFuture f = serverBootstrap.bind(port).sync();
            f.channel().closeFuture().sync();
        }finally {
            boosGroup.shutdownGracefully();
            workerGroup.shutdownGracefully();
        }
    }

    public static void main(String[] args) throws Exception {
        new EchoServer().bind(8080);
    }
}
public class EchoServerHandler extends ChannelHandlerAdapter{
    int counter = 0;
    @Override
    public void channelRead(ChannelHandlerContext ctx,Object msg) throws Exception{
        System.out.println("Receive client [" + msg +"}");
    }
    @Override
    public void exceptionCaught(ChannelHandlerContext ctx , Throwable cause){
        cause.printStackTrace();
        ctx.close();
    }
}
可以用cmd命令telnet localhost 8080 链接服务端
</code></pre></div><ul>
<li>编解码技术
<ul>
<li>基于java提供的对象输入/输出流ObjectInputStream和ObjectOutputStream，可以直接把java对象作为可存储的字节数组写入文件，也可以传输到网络上。java序列化的目的主要有网络传输或者对象持久化</li>
<li>当进行远程跨进程服务调用时，需要把被传输的java字节码编码为字节数组或者ByteBuffer对象。而当远程服务读取到ByteBuffer对象或者字节数组时，需要将其解码为发送时的java对象，被称为java对象编解码技术。java序列化仅仅是java编解码技术的一种。</li>
<li>java序列化缺点：无法跨语言，序列化之后的码流太大，编解码性能太差</li>
</ul>
</li>
<li>Google的Protobuf
<ul>
<li>Protobuf全称Google Protocol Buffers，它由谷歌开源而来，将数据结构以.proto文件进行描述，通过代码生成工具就可以生成对应数据结构的POJO对象和Protobuf的方法和属性。它的特点包括结构化数据存储格式（XML，JSON等），高效的编解码性能，语言无关、平台无关、扩展性好，支持Java语言。</li>
<li>尽管XML的可读性和可扩展性非常好，也非常适合描述数据结构，但是XML解析的时间开销和XML为了可读性而牺牲的空间开销都非常大，不适合做高性能的通信协议。Protobuf使用二进制编码，在空间和性能上具有更大的优势</li>
<li>Protobuf另一个比较吸引人的地方就是他的数据描述文件和代码生成机制，利用数据描述文件对数据结构进行说明的优点如下
<ul>
<li>文本化的数据结构描述语言，可以实现语言与平台无关，适合易购系统间的集成</li>
<li>通过标识字段的顺序，可以实现协议的向前兼容</li>
<li>自动代码生成，不需要手工编写同样数据结构的C++和Java版本</li>
<li>方便后续的管理和维护。相比于代码，结构化的文档更容易管理和维护</li>
</ul>
</li>
</ul>
</li>
<li>Facebook的Thrift
<ul>
<li>Thrift支持Java等多种语言，在多种不同语言之间通信，Thrift可以作为高性能的通信中间件使用，它支持数据（对象）序列化和多种类型的RPC服务。Thrift使用于静态的数据交换，需要先确定好它的数据结构，当数据结构发生变化时，必须重新编辑lDL文件，生成代码和编译，是弱项，适用于搭建大型数据交换及存储的通用工具，对于大型系统中的内部数据传输，相对于JSON和XML的性能和传输大小上都有明显优势</li>
<li>Thrift由5部分组成
<ul>
<li>语言系统一届IDL编译器，负责由用户给定的IDL文件生成相应语言的接口代码</li>
<li>TProtocol：RPC协议层，可以选择多种不同的对象序列化方式，如JSON和Binary</li>
<li>TTransport：RPC传输层，同样可以选择不同的传输层实现，如socket，NIO，MemoryBuffer等</li>
<li>TProcessor:作为协议层和用户提供的服务实现之间的纽带，负责调用服务实现的接口</li>
<li>TServer:聚合Trotocol,TTransport和TProcessor等对象</li>
</ul>
</li>
<li>Thrift通过IDL描述接口和数据结构定义，支持8中Java基本类型，Map，Set和List，功能强大没因为可以定义数据结构中字段的顺序，所以它也可以支持协议的向前兼容</li>
<li>Thrift支持三种比较典型的编解码方式
<ul>
<li>通用的二进制编解码</li>
<li>压缩的二进制编解码</li>
<li>优化的可选字段压缩编解码</li>
</ul>
</li>
</ul>
</li>
<li>JBoss Marshalling
<ul>
<li>JBoss Marshalling是java对象序列化API包，修正了JDK自带序列化包的很多问题，兼容java.io.Serializable接口的兼容；同时增加了一些可调的参数和附加的属性，并且这些参数和特性可通过工厂类进行配置</li>
<li>相比于传统的Java序列化机制，优点如下
<ul>
<li>可插拔的类解析器，提供更加便捷的类加载定制策略，通过一个接口即可实现定制</li>
<li>可插拔的对象替换技术，不需要通过继承的方式</li>
<li>可插拔的预定义类缓存表，可以减小序列化的字节数组长度，提升常用类型的对象序列化性能</li>
<li>无须实现java.io.Serializable接口，即可实现Java序列化</li>
<li>通过缓存技术提升对象的序列化性能</li>
</ul>
</li>
</ul>
</li>
<li>Java序列化
<ul>
<li>最简单的Java的默认序列化，只需要序列化的POJO对象实现java.io.Serializable接口，根据实际情况生成序列ID，这个类就能通过java.io.ObjectInput和java.io.ObjectOutput序列化和反序列化</li>
<li>Netty Java序列化服务端开发（使用ObjectEncoder和ObjectDecoder）对订购请求和应答消息进行序列化</li>
</ul>
</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class SubscribeReq implements Serializable{//1.序列化的POJO对象实现java.io.Serializable接口
    private static final long serialVersionUID = 1L;
    private int subReqID;
    private String userName;
    private String productName;
    private String phoneNumber;
    private String address;
    @Override
    public String toString(){
        return "SubscriberReq[subReqID=" + subReqID + ", userName=" +userName + ",productName=" + productName + ",phoneNumber=" + phoneNumber +",address=" + address + "]";
    }
}
public class SubscribeResp implements Serializable{
    private static final long serialVersionUID = 1L;
    private int subReqID;
    private int respCode;
    private String desc;
    @Override
    public String toString(){
        return "SubscriberResp [subReqID=" + subReqID + ", respCode=" + respCode + ", desc=" + desc +"]";
    }
}
public class SubReqServer{
    public void bind(int port) throws Exception{
        EventLoopGroup boosGroup = new NioEventLoopGroup();
        EventLoopGroup workerGroup = new NioEventLoopGroup();
        try {
            ServerBootstrap serverBootstrap = new ServerBootstrap();
            serverBootstrap.group(boosGroup,workerGroup)
                    .channel(NioServerSocketChannel.class)
                    .option(ChannelOption.SO_BACKLOG,1024)
                    .handler(new LoggingHandler(LogLevel.INFO))
                    .childHandler(new ChannelInitalizer&lt;SocketChannel&gt;(){
                        @Override
                        public void initChannel(SocketChannel ch) throws Exception{
                            //weakCachingConcurrentResolver创建线程安全的WeakReferenceMap对类加载器进行缓存，
                            支持多线程并发访问，当虚拟机内存不足时，会释放缓存中的内存，防止内存泄漏
                            //为了防止异常码流和解码错位导致的内存溢出，将单个对象最大序列化后的字节数组长度设置为1M
                            ch.pipeline().addLast(new ObjectDecoder(1024 * 1024,ClassResolvers.weakCachingConcurrentResolver(this.getClass().getClassLoader())));
                            //ObjectEncoder，可以在消息发送的时候自动将实现的Serializable的POJO对象进行编码，因此用户需亲自对对象进行手工序列化，只需要关注自己的业务逻辑处理即可，对象序列化和反序列化都由netty的对象解码器搞定
                            ch.pipeline().addLast(new ObejectEncoder());
                            ch.pipeline().addLast(new EchoServerHandler());
                        }
                    });
            ChannelFuture f = serverBootstrap.bind(port).sync();
            f.channel().closeFuture().sync();
        }finally {
            boosGroup.shutdownGracefully();
            workerGroup.shutdownGracefully();
        }
    }

    public static void main(String[] args) throws Exception {
        new EchoServer().bind(8080);
    }
}
public class SubReqServerHandler extends ChannelHandlerAdapter {
    @Override
    public void channelRead(ChannelHandlerContext ctx,Object msg) throws Exception{
        SubscribeReq req = (SubscribeReq) msg;
        if("Lilinfeng".equalsIgnoreCase(req.getUserName())){
            System.out.println("Service accept client subscribe req : [" + req.toString() + "]");
            ctx.writeAndFlush(resp(req.getSubReqID));
        }
    }
    private SubscribeResp resp(int subReqID){
        SubscribeResp rep = new SubscribeResp();
        resp.setSubReqID(subReqID);
        resp.setRespCode(0);
        resp.setDes("Netty book order succeed,3 days latter, sent to the designated address");
        return resp;
    }
    @Override
    public void exceptionCaught(ChannelHandlerContext ctx ,Throwable cause){
        cause.printStackTrace();
        ctx.close();
    }
}
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class SubReqClient {
    public void connect(int port, String host) throws Exception{
        EventLoopGroup group = new NioEventLoopGroup();
        try{
            Bootstrap b = new Bootstrap();
            b.group(group).channel(NioSocketChannel.class)
                    .option(ChannelOption.TCP_NODELAY,true)
                    .handler(new ChannelInitializer&lt;SocketChannel&gt;() {
                        @Override
                        protected void initChannel(SocketChannel socketChannel) throws Exception {
                            socketChannel.pipeline().addLast(new ObjectDecoder(1024,ClassResolvers.cacheDisabled(this.getClass().getClassLoader)));
                            socketChannel.pipeline().addLast(new ObjectEncoder());
                            socketChannel.pipeline().addLast(new SubReqClientHandler());

                        }
                    });
            ChannelFuture f = b.connect(host,port).sync();
            f.channel().closeFuture().sync();
        }finally {
            group.shutdownGracefully();
        }

    }
    public static void main(String[] args) throws Exception {
        new SubReqClient().connect(8080,"127.0.0.1");
    }
}
public class SubReqClientHandler extends ChannelHandlerAdapter{
    public SubReqClientHandler(){}
    public void channelActive(ChannelHandlerContext ctx){
        for(int i=0;i&lt;10;i++){
            ctx.write(subReq(i))
        }
        ctx.flush();
    }
    private SubscriberReq subReq(int i){
        SubsribeReq req = new SubscribeReq();
        req.setAddress("南京市江宁区房山国家地质公园")
        req.setPhoneNumber("138XXXXXXXX");
        req.setProductName("Netty 权威指南");
        req.setSubReqID(i);
        req.setUserName("Lilinfeng");
        return req;
    }

    @Override
    public void channelRead(ChannelHandlerContext ctx,Object msg) throws Exception{
        ctx.flush();
    }

    @Override
    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause){
        cause.printStackTrace();
        ctx.close();
    }
}
</code></pre></div><ul>
<li>Google Protobuf编解码
<ul>
<li>Protobuf支持数据结构化一次可以到处使用，甚至跨语言使用，通过代码生成工具可以自动生成不同语言的源代码，甚至可以使用不同版本的数据结构进程间进行数据传递，实现数据结构的向前兼容</li>
<li>ProtobufDecoder仅仅负责解码，不支持读半包。因此，在ProtobufDecoder前面补上能处理读半包的解码器
<ul>
<li>使用Nettty提供的ProtoVarint32FrameDecoder</li>
<li>继承Netty提供的同样半包解码器LengthFieldBasedFrameDecoder</li>
<li>继承ByteToMessageDecoder类，自己处理半包消息</li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>创建SubscribeReq.proto
package netty;
option java_package = "com.phei.netty.codec.protobuf";
option java_outer_Clasaname  = "SubscribeReqProto";

message SubscribeReq{
    required int32 subReqID = 1;
    required string userName = 2;
    required string productName = 3;
    required string address = 4;
}

创建SubscribeResp.proto
package netty;
option java_package = "com.phei.netty.codec.protobuf";
option java_outer_Clasaname  = "SubscribeRespProto";

message SubscribeResp{
    required int32 subReqID = 1;
    required string respCode = 2;
    required string desc = 3;
}
使用cmd proto.exe --java_out=.\src .\netty\SubscribeReq.proto
使用cmd proto.exe --java_out=.\src .\netty\SubscribeResp.proto
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class TestSubscribeReqProto{
    private static byte[] encode(SubscriberReqProto.SubscrobeReq req){
        retrun req.toByteArray();//将SubscribeReq编码为byte数组
    }
    private static SubscriberReqProto.subscribeReq decode(byte[] body)
        {
        return SubscribeReqProto.SubscribeReq.parseFrom(body);//将二进制byte数组解码为原始对象
    }
    private static SubscrobeReqProto.SubscribeReq createSubscribeReq(){
        SubscibeReqProto.SubscribeReq.Builder builder = SubscribeReqProto.,SubscribeReq.newBuilder();
        builder.setSubReqID(1);
        builder.setUserName("Lilinfeng");
        builder.setProductName("Netty Book");
        List&lt;String&gt; address = new ArrayList();
        address.add("NanJing YuHuaTai");
        address.add("BeiJing LiuLiChang");
        builder.addAddAddress(address);
        return  builder.build();
    }
    public static void main(String[] args)throws InvalidProtocolBufferException{
        SubscribeReqProto.SubscribeReq req = createSubscribeReq();
        System.out.println("Before encode:"+req.toString());
        SubscribeReqProto.SubscribeReq req2 = decode(encode(req));
        System.out.println("After decode: "+ req.toString());
        System.out.println("Assert equal:--&gt;" + req2.equals(req));
    }
}
</code></pre></div><ul>
<li>Netty的Protobuf开发</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class SubReqServer{
    public void bind(int port) throws Exception{
        EventLoopGroup boosGroup = new NioEventLoopGroup();
        EventLoopGroup workerGroup = new NioEventLoopGroup();
        try {
            ServerBootstrap serverBootstrap = new ServerBootstrap();
            serverBootstrap.group(boosGroup,workerGroup)
                    .channel(NioServerSocketChannel.class)
                    .option(ChannelOption.SO_BACKLOG,1024)
                    .handler(new LoggingHandler(LogLevel.INFO))
                    .childHandler(new ChannelInitalizer&lt;SocketChannel&gt;(){
                        @Override
                        public void initChannel(SocketChannel ch) throws Exception{
                            
                            ch.pipeline().addLast(new ProtobufVarint32FrameDecoder());
                            
                            ch.pipeline().addLast(new ProtobufDecoder(SubscribeReqProto.SubscribeReq.getDefaultInstance()));
                            ch.pipeline().addLast(new ProtobufVarint32LengthFieldPrepender());
                            ch.pipeline().addLast(new ProtobufEncode());
                            ch.pipeline().addLast(new SubReqServerHandler());
                        }
                    });
            ChannelFuture f = serverBootstrap.bind(port).sync();
            f.channel().closeFuture().sync();
        }finally {
            boosGroup.shutdownGracefully();
            workerGroup.shutdownGracefully();
        }
    }

    public static void main(String[] args) throws Exception {
        new EchoServer().bind(8080);
    }
}
public class SubReqServerHandler extends ChannelHandlerAdapter {
    @Override
    public void channelRead(ChannelHandlerContext ctx,Object msg) throws Exception{
        SubscrobeReqProto.SubscribeReq req = (SubscribeReqProto.SubscribeReq) msg;
        if("Lilinfeng".equalsIgnoreCase(req.getUserName())){
            System.out.print("Service accept client subscribe req: [" + req.toString() + "]");
            ctx.writeAndFlush(resp(req.getSubReqID()));
        }
    }
    private SubscribeResp resp(int subReqID){
        SubscribeResp rep = new SubscribeResp();
        resp.setSubReqID(subReqID);
        resp.setRespCode(0);
        resp.setDes("Netty book order succeed,3 days latter, sent to the designated address");
        return resp;
    }
    @Override
    public void exceptionCaught(ChannelHandlerContext ctx ,Throwable cause){
        cause.printStackTrace();
        ctx.close();
    }
}
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class SubReqClient {
    public void connect(int port, String host) throws Exception{
        EventLoopGroup group = new NioEventLoopGroup();
        try{
            Bootstrap b = new Bootstrap();
            b.group(group).channel(NioSocketChannel.class)
                    .option(ChannelOption.TCP_NODELAY,true)
                    .handler(new ChannelInitializer&lt;SocketChannel&gt;() {
                        @Override
                        protected void initChannel(SocketChannel socketChannel) throws Exception {
                            socketChannel.pipeline().addLast(new ProtobufVarint32FrameDecoder());
                            
                            socketChannel.pipeline().addLast(new ProtobufDecoder(SubscribeRespProto.SubscribeResp.getDefaultInstance()));
                            socketChannel.pipeline().addLast(new ProtobufVarint32LengthFieldPrepender());
                            socketChannel.pipeline().addLast(new ProtobufEncode());
                            socketChannel.pipeline().addLast(new SubReqClientHandler());
                        }
                    });
            ChannelFuture f = b.connect(host,port).sync();
            f.channel().closeFuture().sync();
        }finally {
            group.shutdownGracefully();
        }

    }
    public static void main(String[] args) throws Exception {
        new SubReqClient().connect(8080,"127.0.0.1");
    }
}
public class SubReqClientHandler extends ChannelHandlerAdapter{
    public SubReqClientHandler(){}
    public void channelActive(ChannelHandlerContext ctx){
        for(int i=0;i&lt;10;i++){
            ctx.write(subReq(i))
        }
        ctx.flush();
    }
    private SubscrobeReqProto.SubscribeReq createSubscribeReq(){
        SubscibeReqProto.SubscribeReq.Builder builder = SubscribeReqProto.,SubscribeReq.newBuilder();
        builder.setSubReqID(1);
        builder.setUserName("Lilinfeng");
        builder.setProductName("Netty Book");
        List&lt;String&gt; address = new ArrayList();
        address.add("NanJing YuHuaTai");
        address.add("BeiJing LiuLiChang");
        builder.addAddAddress(address);
        return  builder.build();
    }       

    @Override
    public void channelRead(ChannelHandlerContext ctx,Object msg) throws Exception{
       System.out.println("Receive server response :[" + msg + "]");
    }

    @Override
    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause){
        cause.printStackTrace();
        ctx.close();
    }

    @Override
    public void channelReadComplete(ChannelHandlerContext ctx) throws Exception{
        ctx.flush();
    }
}
</code></pre></div><ul>
<li>JBoss Marshalling编解码开发
<ul>
<li>JBoss Marshalling是一个对象序列化包，对jdk默认的序列化框架进行优化，但有保持跟java.io.Serializable接口的兼容，同时增加了一些可调的参数和附加的特性</li>
<li>Netty的Marshalling支持半包和粘包处理</li>
</ul>
</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class SubReqServer{
    public void bind(int port) throws Exception{
        EventLoopGroup boosGroup = new NioEventLoopGroup();
        EventLoopGroup workerGroup = new NioEventLoopGroup();
        try {
            ServerBootstrap serverBootstrap = new ServerBootstrap();
            serverBootstrap.group(boosGroup,workerGroup)
                    .channel(NioServerSocketChannel.class)
                    .option(ChannelOption.SO_BACKLOG,1024)
                    .handler(new LoggingHandler(LogLevel.INFO))
                    .childHandler(new ChannelInitalizer&lt;SocketChannel&gt;(){
                        @Override
                        public void initChannel(SocketChannel ch) throws Exception{
                            
                            ch.pipeline().addLast(MarshallingCodeCFactory.buildMarshallingDecoder());
                            
                            ch.pipeline().addLast(MarshallingCodeCFactory.buildMarshallingEncoder());
                            ch.pipeline().addLast(new SubReqServerHandler());
                        }
                    });
            ChannelFuture f = serverBootstrap.bind(port).sync();
            f.channel().closeFuture().sync();
        }finally {
            boosGroup.shutdownGracefully();
            workerGroup.shutdownGracefully();
        }
    }

    public static void main(String[] args) throws Exception {
        new EchoServer().bind(8080);
    }
}
public final class MarshallingCodeCFactory{
    public static MarshallingDecoder buildMarshallingDecoder(){
        final MarshallingFactory marshallerFactory = Marshalling.getProvidedMarshallerFactory("serial");
        final MarshallingConfigutation configuration = new MarshallingConfiguration();
        configuration.setVersion(5);
        UnmarshallerProvider provider = new DefalutUnmarshallerProvider(marshallerFactorymconfiguration);
        MarshallingDecoder decoder = new MarshallingDecoder(provider,1024);
        return decoder;
    }
    public static MarshallingEncoder builMarshallingEncoder(){
        final MarshallingFactory marshallerFactory = Marshalling.getProvidedMarshallerFactory("serial");
        final MarshallingConfigutation configuration = new MarshallingConfiguration();
        configuration.setVersion(5);
        MarshallerProvider provider = new DefalutMarshallerProvider(marshallerFactorymconfiguration);
        MarshallingEncoder decoder = new MarshallingEncoder(provider,1024);
        return decoder;
    }
}
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class SubReqClient {
    public void connect(int port, String host) throws Exception{
        EventLoopGroup group = new NioEventLoopGroup();
        try{
            Bootstrap b = new Bootstrap();
            b.group(group).channel(NioSocketChannel.class)
                    .option(ChannelOption.TCP_NODELAY,true)
                    .handler(new ChannelInitializer&lt;SocketChannel&gt;() {
                        @Override
                        protected void initChannel(SocketChannel socketChannel) throws Exception {
                            socketChannel.pipeline().addLast(MarshallingCodeCFactory.buildMarshallingDecoder());
                            
                            socketChannel.pipeline().addLast(MarshallingCodeCFactory.buildMarshallingEncoder());
                            socketChannel.pipeline().addLast(new SubReqClientHandler());
                        }
                    });
            ChannelFuture f = b.connect(host,port).sync();
            f.channel().closeFuture().sync();
        }finally {
            group.shutdownGracefully();
        }

    }
    public static void main(String[] args) throws Exception {
        new SubReqClient().connect(8080,"127.0.0.1");
    }
}
</code></pre></div><ul>
<li>Netty多协议开发和应用
<ul>
<li>HTTP(超文本传输协议)协议是建立在TCP传输协议之上的应用成协议，是一个属于应用层的面向对象的协议，适用于分布式超媒体信息系统，是目前Web开发的主流协议，特定如下
<ul>
<li>支持Client/Server模式</li>
<li>简单：客户想服务端请求服务时，只需指定服务的URL，携带必要的请求参数或者消息体</li>
<li>灵活：HTTP允许传输任意类型的数据对象，传输的内容类型由HTTP消息头中的Content-Type加以标记</li>
<li>无状态：HTTP协议是无状态协议，无状态是指协议对于事务处理没有记忆能力，缺少状态意味着如果后续需要处理之前的信息，则它必须重传，这样可能导致每次连接传送的数据量增大。另一方面，在服务器不需要先前信息时它的应答比较快，负载较轻</li>
</ul>
</li>
</ul>
</li>
<li>Netty HTTP服务端入门开发
<ul>
<li>由于Netty是异步事件驱动的架构，因此基于NIO TCP协议栈开发的HTTP协议栈也是异步非阻塞的</li>
</ul>
</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class HttpFileServer{
    private static final String DEFAULT_URL = "/src/com/phei/netty/";

    public void bind(int port,final String url) throws Exception{
        EventLoopGroup boosGroup = new NioEventLoopGroup();
        EventLoopGroup workerGroup = new NioEventLoopGroup();
        try {
            ServerBootstrap serverBootstrap = new ServerBootstrap();
            serverBootstrap.group(boosGroup,workerGroup)
                    .channel(NioServerSocketChannel.class)
                    .option(ChannelOption.SO_BACKLOG,1024)
                    .handler(new LoggingHandler(LogLevel.INFO))
                    .childHandler(new ChannelInitalizer&lt;SocketChannel&gt;(){
                        @Override
                        public void initChannel(SocketChannel ch) throws Exception{
                            
                            ch.pipeline().addLast("http-decoder",new HttpRequestDecoder());
                            //作用是讲多个消息转换为单一的FullHttpRequest或者FullHttpResponse，原因是HTTP解码器会生成多个消息对象（HttpRequest/HttpResponse、HttpContent、LastHttpContent）
                            ch.pipeline().addLast("http-aggregator",new HttpObjectAggregator(65536));
                            
                            ch.pipeline().addLast("http-encoder",new HttpResponseEncoder());
                            //作用是支持异步发送大的码流（例如大的文件传输），但不占用过多的内存，防止发生Java内存溢出错误
                            ch.pipeline().addLast("http-chunked",new ChunkedWriteHandler(65536));

                            ch.pipeline().addLast("fileServerHandler",new HttpFileServerHandler(url));
                        }
                    });
            ChannelFuture f = serverBootstrap.bind(port).sync();
            f.channel().closeFuture().sync();
        }finally {
            boosGroup.shutdownGracefully();
            workerGroup.shutdownGracefully();
        }
    }

    public static void main(String[] args) throws Exception {
        new HttpFileServer().run(8080,DEFAULT_URL);
    }
}
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class HttpFileServerHandler extends SimpleChannelInboundHandler&lt;FullHttpRequest&gt;{
    private final String url;
    public HttpFileServerHandler(String url){
        this.url = url;
    }
    @Override
    public void mssageReceived(ChannelHandlerContext ctx,FullHttpRequest request) throws Exception{
        if(!request.getDecoderResult().isSuccess()){
            sendError(ctx,BAD_REQUEST);
            return;
        }
        if(request.getMethod() != GET){
            sendError(ctx,METHOD_NOT_ALLOWED);
            return;
        }
        final String uri = request.getUri();
        final String path = sanitizeUri(uri);
        if(path == null){
            sendError(ctx,FORBIDDEN);
            return;
        }
        File file = new File(path);
        if(file.isHidden() || !file.exists()){
            sendError(ctx,NOT_FOUND);
            return;
        }
        if(file.isDirectory()){
            if(uri.endsWith("/")){
                sendListing(ctx,file);
            }else{
                sendRedirect(ctx, uri + '/');
            }
            return;
        }
        if(!file.isFile()){
            sendError(ctx,FORBIDDEN);
            return;
        }
        RandomAccessFile randomAccessFile = null;
        try{
            randomAccessFile = new RandomAccessFile(file,"r");//以只读的方式打开文件
        }cath(FileNotFounException fnfe){
            sendError(ctx,NOT_FOUND);
            return;
        }
        long fileLength = randomAccessFile.length();
        HttpResponse response = new DefaultHttpResponse(HTTP_1_1,OK);
        setContentLength(response,fileLength);
        if(isKeepAlive(request)){
            reponse.headers().set(CONNECTION,HttpHeaders.Values.KEEP_ALIVE);
        }
        ctx.wirte(response);
        ChannelFuture sendFileFuture;
        sendFileFuture = ctx.write(new ChunkedFile(randomAccessFile,0,fileLength,8192),ctx.newProgressivePromise());
        sendFileFuture.addListenner(new ChannelProgressiveFutueListenner(){
            @Override
            public void operationProgressed(ChannelProgressiveFuture future,long progress,long total){
                if(total &lt;0){
                    System.out.println("Transfer progress :" + progress)
                }else {
                    System.out.println("Transfer progress :"+progress +"/" + total);
                }
            }
            @Override
            public void operationComplete(ChannelProgressiveFuture future)throws Exception{
                System.out.println("Transfer complete.");
            }
        });
        ChannelFuture lastContentFuture = ctx.wirteAndFlush(LasHttpContent.EMPTY_LAST_CONNENT);
        if(!isKeepAlive(request)){
            lastContentFutue.addListener(ChannelFutureListener.CLOSE);
        }
    }

    @Override
    public oid exceptionCaught(ChannelHandlerContext ctx,Throwable cause) throws Exception{
        cause.printStackTrace();
        if(ctx.channel().isActive()){
            sendError(ctx,INTERNAL_SERVER_ERROR);
        }
    }

    private static final Pattern INSECURE_URI = Pattern.compile(".*[&lt;&gt;&amp;\"].*");
    private String sanitizeUri(String uri){
        try{
            uri = URIDecoder.decode(uri,"UTF-8");
        }catch(UnsupportedEncodeingException e){
            try{
                uri = URLDecoder.decode(uri,"ISO-8859-1");
            }catch(UnsupporedEncodingException e1){
                throw new Error();
            }
        }
        if(!uri.startsWith(url)){
            return null;
        }
        if(!uri.startsWith("/")){
            return null;
        }
        uri = uri.replace('/',File.separatorChar);
        if(uri.contains(File.separator + '.') || uri.contains('.'+File.separator)||uri.startsWith(".")
        || uri.endsWith(".")|| INSECURE_URI.matcher(uri).matches()){
            return null;
        }
        return System.getProperty("user.dir") + File.separtor + uri;
    }
    private static void sendListing(ChannelHandlerContext ctx,File dir){
        FullHttpResponse response = new DefaultFullHttpResponse(HTTP_1_1，OK);
        response.headers().set(CONTENT_TYPE,"text/html;charset=UTF-8");
        StringBuilder buf = new StringBuilder();
        String dirPath = dir.getPath();
        buf.append("&lt;!DOCTYPE html&gt;\r\n");
        buf.append("&lt;html&gt;&lt;head&gt;&lt;title&gt;");
        buf.append(dirPath);
        buf.append("目录:");
        buf.append("&lt;/title&gt;&lt;/head&gt;&lt;body&gt;\r\n");
        buf.append("&lt;h3&gt;");
        buf.append(dirpatch).append("目录:");
        buf.append("&lt;/h3&gt;\r\n");
        buf.append("&lt;li&gt;链接:&lt;a href=\"../\"&gt;..&lt;/a&gt;&lt;/li&gt;\r\n");
        for(File f:dir.listFiles()){
            if(f.isHidden() || !f.canRead()){
                continue;
            }
            String name = f.getName();
            if(!ALLOWED_FILE_NAME.matcher(name).matches()){
                continue;
            }
            buf.append("&lt;li&gt;链接：&lt;a href-\"");
            buf.append(name);
            buf.append("\"&gt;");
            buf.append(name);
            buf.append("&lt;/a&gt;&lt;/li&gt;\r\n");
        }
        buf.append("&lt;/ul&gt;&lt;/body&gt;&lt;/html&gt;\r\n");
        ByteBuf buffer = Upooled.copiedBuffer(buf,CharsetUtil.UTF_8);
        response.content().writeBytes(buffer);
        buffer.release();
        ctx.writeAndFlush(response).addListener(ChannelFutureListener.CLOSE);
    }

    private static void sendRedirect(ChannelHandlerContext ctx,String new Uri){
        FullHttpResponse response = new DefaultFullHttpResponse(HTTP_1_1,FOUND);
        response.headers().set(LOCATION,newUri);
        ctx.writeAndFlush(response).addListener(ChannelFutureListener.CLOSE);
    }
    private staitc void sendError(ChannelHandlerContext ctx,HttpResponseStatus status){
        FullHttpResponse response = new DefaultFullHttpResponse(HTTP_1_1,status,Unpooled.copiedBuffer("Failure:" + status.toString() + "\r\n",CharsetUtil.UTF_8));
        response.headers().set(CONTENT_TYPE,"text/plain;charset=UTF-8");
        ctx.writeAndFlush(response).addListener(ChannelFutureListener.CLOSE);
    }
    private static void setContentTypeHeader(HttpResponse response,File file){
        MimetypesFileTypeMap mineTypesMap = new MimetypesFileTypeMap();
        response.headers().set(CONTENT_TYPE,mineTypesMap.getContetnType(file.getPath()));
    }
}
</code></pre></div><ul>
<li>Netty HTTP+XML协议栈开发
<ul>
<li>由于HTTP协议的通用性，很多易购系统间的通信交互采用HTTP协议，通过HTTP协议承载业务数据进行交互，例如HTTP+XML或者RESTFul+JSON</li>
<li>最常用的HTTP协议栈就是基于Servlet规范的Tomcat等Web容器，Jetty等轻量级Web容器。但是很多基于HTTP的应用都是后台应用，HTTP不仅是承载数据交换的一个通道，是一个载体而不是web容器，在这种场景下，一般不需要类似tomcat这样重量型的Web容器。由于其功能繁杂，会存在很多安全漏洞，会带来开发或维护成本的增加，在这种场景下，一个更加轻量级的HTTP协议栈是更好的选择</li>
</ul>
</li>
<li>高效的XML绑定框架jiBx
<ul>
<li>JiBX是一个非常优秀的XML数据绑定框架，提供灵活的绑定映射文件，实现数据对象与XML文件之间的转换，并不需要修改既有的Java类，转换效率是目前很多其他开源项目无法比拟的</li>
<li>JiBx优点包括：转换效率高，配置绑定文件简单、不需要操作xpath文件，不需要写属性的get/set方法、对象属性名与XML文件名可以不同等等</li>
<li>使用jiBX绑定XML文档与Java对象需要分两步：第一步是绑定XML文件，也就是映射XML文件与Java对象之间的对应关系；第二步是在运行时，实现XML文件与Java实例之间的相互转换。这时，它已经与绑定文件无关，可以说是完全脱耦了</li>
<li>在程序运行之前，需要先配置绑定文件并进行绑定，在绑定过程中它将会动态的修改程序中相应的class文件，主要是生成对应对象实例方法和添加被绑定标记的属性JiBx_bindingList等。它使用的技术是BCEL(Byte Code Engineering Library)，BCEL是目前java classworking最广泛使用的一种框架，他可以让你深入JVM汇编语言进行类操作。在JiBX运行时，使用了目前比较流行的一个技术XPP(Xml Pull Parsing)，这也正是JiBX如此高效的原因</li>
<li>JiBx有两个比较重要的概念: Unmarshal（数据分解）和Marshal（数据编排），Unmarshal是讲XML文件转换成Java对象，而Marshal则是讲Java对象编排成规范的XML文件。JiBX在Unmarshal/Marshal上如此高效，这要归功于使用了XXP技术，而不是使用了基于树型（tree-based）方式，将整个文档写入内存，然后进行操作的DOM(Document Object Model)，也不是使用基于事件流（event stream）的SAX(Simple API for Xml)。XPP使用的是不断增加的数据流处理方式，同时允许在解析XML文件时中断</li>
</ul>
</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class Order{
    private long orderNumber;
    private Customer customer;
    private Address billTo;
    private Shippiong shipping;
    private Address shipTo;
    private Float total;
    //set 、get
}
public class Customer{
    private long customerNumber;
    private String firstName;
    private String lastName;
    private List&lt;String&gt; middleNames;
    //定义set 、get
}
public class Address{
    private String street1;
    private String street2;
    private String city;
    private String state;
    private String postCode;
    private String country;
    //定义set、get方法
}
public enum Shipping{
    STANDARD_MAIL,PRIORITY_MAIL,INTERNATIONAL_MAIL,DOMESTC_EXPRESS,INTERNATIONAL_EXPRESS
}
public class TestOrder {
    private IBindingFactory factory = null;
    private StringWriter writer = null;
    private StringReader reader = null;
    private final static String CHARSET_NAME = "UTF-8";
    private String encode2Xml(Order order) throws JiBXException,IOException{
        factory = BindingDirectory.getFactory(Order.class);
        writer = new StringWriter();
        IMarShallingContext mctx = factory.createMarshallingContext();
        mctx.setIndent(2);
        mctx.marshalDocument(order,CHARSET_NAME,null,writer);
        String xmlStr = writer.toString();
        writer.close();
        System.out.println(xmlStr.toString());
        return xmlStr;
    }
    private Order decode2Order(String xmlBody) throws JiBXException{
        reader = new StringReader(xmlBody);
        IUnmarshallingContext uctx = factory.createUnmarshallingContext();
        Order order = (Order) uctx.unmarshalDocument(reader);
        return order;
    }
    public static void main(String[] args) throws JiBXExcpetion,IOExcpetion{
        TestOrder test = new TestOrder();
        Order order = OrderFactory.create(123);
        String body = test.encode2Xml(order);
        Order order2 = test.decode2Order(body);
        System.out.prinln(order2);
    }
}
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>HTTP+XML HTTP请求消息编码类
public class HttpXmlRequestEncoder extends AbstractHttpXmlEncoder&lt;HttpXmlRequest&gt;{
    @Override
    protected void encode(ChannelHandlerConetext ctx,HttpXmlRequest msg,List&lt;Object&gt; out) throws Exception{
        ByteBuf body = encode0(ctx,msg.getBody());
        FullHttpRequest request = msg.getRequest();
        if(request == null){
            request = new DefaultFullHttpRequest(HttpVersion.HTTP_1_1,HttpMethod.GET,"/do",body);
            HttpHeaders headers = request.headers();
            headers.set(HttpHeaders.Names.HOST,InetAddress.getLocalHost().getHostAddress());
            headers.set(HttpHeaders.Names.CONNECTION,HttpHeaders.Values.CLOSE);
            headers.set(HttpHeaders.Names.ACCEPT ENCODING,HttpHeaders.Values.GZIP.toString()+','+HttpHeaders.Values.DEFLATE.toString());
            headers.set(HttpHeaders.Names.USER_ACCEPT_CHARSET,"ISO-8859-1.utf-8;q=0.7*;q=0.7")
            headers.set(HttpHeaders.Names.ACCEPT_LANGUACGE,"zh");l
            headers.set(HttpHeaders.Names.USER_AGENT,"Netty xml Http Client side");
            headers.set(HttpHeaders.Names.ACCEPT,"text/html,application/xhtml+xml,application/xml;q=0.9*/*;q=0.8");
            HttpHeaders.setContentLength(request,body.readableBytes());
            out.add(request);
        }

    }
}
public abstract class AbstarctHttpXmlEncoder&lt;T&gt; extends MessageToMessageEncoder&lt;T&gt;{
    IBindingFactory factory = null;
    StringWriter writer = null;
    final static String CHARSET_NAME = "UTF-8";
    final static Charset UTF_8 = Charset.forName(CHARSET_NAME);
    protected ByteBuf encode0(ChannelHandlerContext ctx,Object body) throws Exception{
        factory = BindingDirectory.getFactory(body.getClass());
        writer = new StringWriter();
        IMarshallingContext mctx = factory.createMarshallingContext();
        mctx.setIndent(2);
        mctx.marshalDocument(body, CHARSET_NAME,null,writer);
        writer.close();
        writer = null;
        ByteBuf encodeBuf = Unpooled.copiedBuffer(xmlStr,UTF_8);
        return encodeBuf;
    }

    @Override
    public void exceptionCaught(ChannelHandlerContext ctx,Throwable cause) throws Exception{
        if(writer !=null){
            writer.close();
            writer = null;
        }
    }
}
HTTP+XML请求消息HttpXmlRequest 用于实现和协议栈之间的解耦
public class HttpXmlRequest{
    private FullHttpRequest request;
    private Object body;//编码对象
    public HttpXmlRequest(FullHttpRequest request ,Object body){
        this.request = request;
        this.body = body;
    }
    public final FullHttpRequest getRequest(){
        return request;
    }
    public final void setRequest(FullHttpRequest request){
        this.request = request;
    }
    public final Object getBody(){
        return body;
    }
    public final void setBody(Obejct body){
        this.body = body;
    }
}
HTTP+XML请求消息解码类
public class HttpXmlRequestDecoder extends AbstractHttpXmlDecoder&lt;FullHttpRequest&gt;{
    public HttpXmlRequestDecoder(Class&lt;?&gt; clazz){
        this(clazz,false);
    }
    public HttpXmlRequestDecoder(Class&lt;?&gt; clazz,boolean isPrint){
        super(clazz,isPrint);//是否打印Http码流的开关
    }
    @Override
    protected void decode(ChannelHandlerContext arg0,FullHttpRequest arg1,List&lt;Object&gt; arg2) throws Exception{
        if(!arg1.getDecoderResult().isSuccess()){
            sendError(arg0,BAD_REQUEST);
            return;
        }
        HttpXmlRequest request = new HttpXmlRequest(arg1,decode0(arg0,arg1.content()));
        arg2.add(request);
    }

    private staitc void sendError(ChannelHandlerContext ctx,HttpResponseStatus status){
        FullHttpResponse response = new DefaultFullHttpResponse(HTTP_1_1,status,Unpooled.copiedBuffer("Failure:" + status.toString() + "\r\n",CharsetUtil.UTF_8));
        response.headers().set(CONTENT_TYPE,"text/plain;charset=UTF-8");
        ctx.writeAndFlush(response).addListener(ChannelFutureListener.CLOSE);
    }
}

public abstract class AbstractHttpXmlDecoder&lt;T&gt; extends MessageToMessageDecoder&lt;T&gt;{
    private IBindingFactory factory;
    private StringReader reader;
    private Class&lt;?&gt; clazz;
    private boolean isPrint;
    private final static String CHARSET_NAME = "UTF-8";
    private final static Charset UTF_8 = Charset.forName(CHARSET_NAME);

    protected AbstractHttpXmlDecoder(Class&lt;?&gt; clazz){
        this(clazz,false);
    }
    
    protected AbstractHttpXmlDecoder(Class&lt;?&gt; clazz,boolean isPrint){
        this.clazz = clazz;
        this.isPrint = isPrint;
    }

    protected Object decode0(ChannelHandlerContext arg0,ByteBuf body) throws Exception{
        factory = BinddingDirectory.getFactory(clazz);
        String content = body.toString(UTF_8);
        if(isPrint) Sytem.out.print("The body is :"+content);
        reader = new StringReader(content);
        IUnmarshallingContext uctx = factory.createUnmarshallingContext();
        Object result = uctx.unmarshalDocument(reader);
        reader.close();
        reader = null;
        return result;
    }

    @Ovrride
    public void exceptionCaught(ChannelHandlerContext ctx,Throwable cause) throws Exception{
        if(reader !=null){
            reader.close();
            reader = null;
        }
    }
}
Http + XML 响应消息编码类
public class HttpXmlResponse{
    private FullHttpResponse httpResponse;
    private Object result;
    public HttpXmlResponse(FullHttpResponse httpResponse,Object result){
        this.httpResponse = httpResponse;
        this.result = result;
    }
    public final FullHttpResponse getHttpResponse(){
        return httpResponse;
    }
    public final void setHttpResponse(FullHttpResponse httpResponse){
        this.httpResponse = httpResponse;
    }
    public final Object getResult(){
        return result;
    }
    public final void setResult(Object result){
        this.result = result;
    }
}

public class HttpXmlResponseEncode extends AbstractHttpXmlEncoder&lt;HttpXmlResponse&gt;{
    protected void encode(ChannelHandlerContext ctx,HttpXmlResponse msg,List&lt;Object&gt; out) throws Exception{
        ByteBuf body = encode0(ctx,msg.getResult());
        FullHttpResponse response = msg.getHttpResponse();
        i(response == null){
            response = newDefaultFullHttpResponse(HTTP_1_1,OK,body);
        }else{//无法重用业务侧自定义HTTP应答消息的主要原因是netty的DefaultFullHttpResponse没有提供动态设置消息体的content接口，只能在第一次构造的时候设置内容
            reponse = new DefaultFullHttpResponse(msg.getHttpResponse().getProtocolVersion(),msg.getHttpResponse.getStatus(),body);
        }
        response.headers().set(CONTENT_TYPE,"text/xml");
        setContentLength(response,body.readableBytes());
        out.add(response);
    }
}
public class HttpXmlResponseDecoder extends AbstractHttpXmlDecoder&lt;DefaultFullHttpResponse&gt;{
    public httpXmlResponseDecoder(Class&lt;?&gt; clazz){
        this(clazz,false);
    }
    public HttpXmlResponseDecoder(Class&lt;?&gt; clazz,boolean isPrintlog){
        super(clazz,isPrintlog);
    }
    @Override
    protect void decode(ChannelHandlerContent ctx,DefaultFullHttpResponse msg,List&lt;Object&gt; out) throws Exception {
        HttpXmlResponse resHttpXmlResponse = new HttpXmlResponse(msg,decode0(ctx,msg.content()));
        out.add(resHttpXmlResponse);
    }
}
HTTP+XML客户端
public class HttpXmlClient{
    public void connet(int port) throws Exception{
        EventLoopGroup group = new NioEventLoopGroup();
        try {
            ServerBootstrap b = new ServerBootstrap();
            b.group(group)
                    .channel(NioSocketChannel.class)
                    .option(ChannelOption.TCP_NODELAY,true)
                    .handler(new ChannelInitalizer&lt;SocketChannel&gt;(){
                        @Override
                        public void initChannel(SocketChannel ch) throws Exception{
                            
                            ch.pipeline().addLast("http-decoder",new HttpResponseDecoder());
                            //负责将1个Http请求消息的多个部分合并成一个完整的HTTP消息
                            ch.pipeline().addLast("http-aggregator",new HttpObjectAggregator(65536));
                            //XML解码器
                            ch.pipeline().addLast("xml-decoder",new HttpXmlResponseDecoder(Oder.class,true));
                            ch.pipeline().addLast("http-encoder",new HttpXmlRequestEncoder());

                            ch.pipeline().addLast("xmlClientHandler",new HttpXmlClienHandle());
                        }
                    });
            ChannelFuture f = b.bind(port).sync();
            f.channel().closeFuture().sync();
        }finally {
            group.shutdownGracefully();
        }
    }

    public static void main(String[] args) throws Exception {
        new HttpXmlClient().run(8080);
    }
}
public class HttpXmlClientHandle extends SimpleChannelInboundHandle&lt;HttpXmlResponse&gt;{
    @Override
    public void ChannelActive(ChannelHandlerContext ctx){
        HttpXmlRequest request = new HttpXmlRequest(null,OderFactory.create(123));
        ctx.writeAndFlush(request);
    }
    @Override
    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause){
        cause.printStackTrace();
        ctx.close();
    }

    @Override
    protected void messageReceived(ChannelHandlerContext ctx,HttpXmlResponse msg) throws Exception{
        System.out.println("The client receive response of http header is:" + msg.getHttpResponse().headers().names());
        System.out.println("Thre client receive of http body is " + msg.getResult());
    }
}
public class OrderFactory{
    public static Order create(long orderID){
        Oder order = new Order();
        order.setOrderNumber(orderID);
        Address address = new Address();
        address.setCity("广州");
        address.setCounty("中国");
        order.setBillTo(address);
        Customer customer = new Customer();
        customer.setCustomerNumber(orderID);
        order.setCustomer(customer);
        return order;
    }
}

Http+XML服务端开发
public class HttpXmlServer{

    public void bind(final int portl) throws Exception{
        EventLoopGroup boosGroup = new NioEventLoopGroup();
        EventLoopGroup workerGroup = new NioEventLoopGroup();
        try {
            ServerBootstrap serverBootstrap = new ServerBootstrap();
            serverBootstrap.group(boosGroup,workerGroup)
                    .channel(NioServerSocketChannel.class)
                    .handler(new ChannelInitalizer&lt;SocketChannel&gt;(){
                        @Override
                        public void initChannel(SocketChannel ch) throws Exception{
                            
                            ch.pipeline().addLast("http-decoder",new HttpRequestDecoder());
                            ch.pipeline().addLast("http-aggregator",new HttpObjectAggregator(65536));
                            
                            ch.pipeline().addLast("xml-decoder",new HttpXmlRequestDecoder(Oder.class,true));
                            ch.pipeline().addLast("http-encoder",new HttpXmlResponseEncoder());

                            ch.pipeline().addLast("fileServerHandler",new HttpXmlServerHandler());
                        }
                    });
            ChannelFuture f = serverBootstrap.bind(port).sync();
            f.channel().closeFuture().sync();
        }finally {
            boosGroup.shutdownGracefully();
            workerGroup.shutdownGracefully();
        }
    }

    public static void main(String[] args) throws Exception {
        new HttpXmlServer().run(8080);
    }
}
public class HttpXmlServerHandler extends SimpleChannelInboundHandler&lt;HttpXmlRequest&gt;{
    @Override
    public void messagReceived(final ChannelHandlerContext ctx,HttpXmlRequest xmlRequest) throws Exception{
        HttpRequest request = xmlRequest.getRequest();
        Order order = (Order) xmlRequest.getBody();
        System.out.println("Http server receive request:" + order);
        dobusiness(order);
        if(!isKeeypAlive(request)){
            future.addListener(new GenericFutureListener&lt;Futrue&lt;? super Void&gt;&gt;{
                public void operationComplete(Future future) throws Exception{
                    ctx.close();
                }
            })
        }
    }
    private void dobusiness(Order oder){
        order.getCustomer().setFirstName("xxx");
    }
    public void exceptionCaught(ChannelHandlerContext ctx,Throwable cause) throws Exception{
        cause.printStackTrace();
        if(ctx.channel().isActive()){
            sendError(ctx,INTERNAL_SERVER_ERROR);
        }
    }
    private staitc void sendError(ChannelHandlerContext ctx,HttpResponseStatus status){
        FullHttpResponse response = new DefaultFullHttpResponse(HTTP_1_1,status,Unpooled.copiedBuffer("Failure:" + status.toString() + "\r\n",CharsetUtil.UTF_8));
        response.headers().set(CONTENT_TYPE,"text/plain;charset=UTF-8");
        ctx.writeAndFlush(response).addListener(ChannelFutureListener.CLOSE);
    }
}
</code></pre></div><ul>
<li>webSocket协议开发
<ul>
<li>WebSocket将网络套接字引入到了客户端和服务端，浏览器和服务器之间可以通过套接字建立持久的连接，双方可以随时互发数据给对方，而不是之前由客户端控制的一请求一应答模式。</li>
<li>HTTP协议为半数双工协议。半双工协议指数据可以在客户端和服务端两个方向上传输，但是不能同时传输。意味着在同一个时刻，只有同一个方向上的数据传送</li>
<li>HTTP消息冗长而繁琐。HTTP消息包含消息头、消息体、换行符等，通常情况下采用文本方式传输、相比于其他的二进制通信协议，冗长而繁琐</li>
<li>针对服务器推送的黑客工具，例如长时间轮询</li>
<li>轮询：在特定时间间隔如1秒，由浏览器对服务器发送HTTPRequest，然后由服务器返回的最新的数据给客户端浏览器。浏览器需要不断向服务器发出请求，然而HTTP request的header是非常冗长的，里面包含的可用数据比例可能非常低，会占用很多带宽和服务器资源</li>
<li>比较新的一种轮询技术是Comet，使用了Ajax，这种技术可以达到双向通信，但仍然需要发出请求，在Comet中，普遍采用长连接，会大量消耗服务器带宽和资源</li>
<li>在WebsocketAPI中，浏览器和服务器只需要做一个握手动作，然后浏览器和服务器之间形成了一条快速通道，两者就可以直接相互传送数据了。WebSocket基于TCP双向全双工进行消息传递，在同一时刻，既可以发送消息，又可以接受消息，性能有较大提升。</li>
<li>WebSocket特点
<ul>
<li>单一的TCP连接，采用全双工模式通信</li>
<li>对代理、防火墙和路由器透明</li>
<li>无头部消息’Cookie和身份验证</li>
<li>无安全开销</li>
<li>通过"ping/pong"帧保持链路激活</li>
<li>服务器可以主动推送消息给客户端，不需要客户端轮询</li>
</ul>
</li>
</ul>
</li>
<li>WebSocket生命周期
<ul>
<li>握手成功之后，服务端和客户端就可以通过"message"的方式进行通信了，一个消息由一个或者多个帧组成，WebSocket的消息并不一定对应一个特定网络层的真，他可以被分隔成多个帧或者被合并</li>
<li>帧都有自己对应的类型，属于同一个消息的多个帧具有相同类型的数据。从广义上将，数据类型可以使文本数据，二进制数据和控制帧（协议级信令，如信号）</li>
<li>WebSocket连接关闭
<ul>
<li>为关闭WebSocket连接，客户端和服务端需要通过一个安全的方法关闭底层TCP连接以及TLS会话，如果合适，丢弃任何可能已经接收的字节；必要时（比如收到工具），可以通过任何可用的手段关闭连接</li>
<li>底层的TCP连接，在正常情况下，应该首先有服务器关闭，在异常情况下（例如在一个合理的时间周期后没有收到TCP Close），客户端可以发起TCP Close。因此，当服务器被只是关闭WebSocket连接时，他应该立即发起一个TCP Close操作，客户端应该等待服务器的TCP Close</li>
<li>Websocket的握手关闭消息带有一个状态码和一个可选的关闭原因，它必须按照协议要求发送一个Close控制帧，当对端接收到关闭控制帧指令时，需要主动关闭WebSocket连接</li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class WebSocketServer{

    public void bind(final int portl) throws Exception{
        EventLoopGroup boosGroup = new NioEventLoopGroup();
        EventLoopGroup workerGroup = new NioEventLoopGroup();
        try {
            ServerBootstrap serverBootstrap = new ServerBootstrap();
            serverBootstrap.group(boosGroup,workerGroup)
                    .channel(NioServerSocketChannel.class)
                    .handler(new ChannelInitalizer&lt;SocketChannel&gt;(){
                        @Override
                        public void initChannel(SocketChannel ch) throws Exception{
                            
                            ch.pipeline().addLast("http-codec",new HttpServerCodec());
                            ch.pipeline().addLast("aggregator",new HttpObjectAggregator(65536));
                            //支持浏览器和服务器进行WebSocket通信
                            ch.pipeline().addLast("http-chunked",new ChunkedWriteHandler());
                            ch.pipeline().addLast("http-encoder",new HttpXmlResponseEncoder());

                            ch.pipeline().addLast("handler",new WebSocketHandler());
                        }
                    });
            ChannelFuture f = serverBootstrap.bind(port).sync();
            f.channel().closeFuture().sync();
        }finally {
            boosGroup.shutdownGracefully();
            workerGroup.shutdownGracefully();
        }
    }

    public static void main(String[] args) throws Exception {
        new WebSocketServer().run(8080);
    }
}
public class WebSocketServerHandler extends SimpleChannelInboundHandler&lt;Object&gt;{
    private WebSocketServerHandshaker handshaker;
    @Override
    public void messageReceived(ChannelHandlerContext ctx,Object msg) throws Exception{
        if(msg instanceof FullHttpRequest){
            handleHttpRequest(ctx,(FullHttpRequest) msg);
        }
        else if(msg instanceof WebSocketFrame){
            handleWebSocketFrame(ctx,(WebSocketFrame) msg);
        }
    }
    @Ovrride
    public void channelReadCompelte(ChannelHandlerContext ctx) throws Exception{
        ctx.flush();
    }
    private void handleHttpRequest(ChannelHandlerContext ctx,FullHttpRequest req) throws Exception{
        if(!reql.getDecoderResult().isSuccess()|| (!"websocket".equals(req.headers().get("upgrade")))){
            sendHttpResponse(ctx,req,new DefauleFullHttpResponse(HTTP_1_1,BAD_REQUEST);
            return;
        }
    }
    WebSocketServerHandshakerFactory wsFactory = new WebSoketServerHandshakerFactory("ws://localhost:8080/webscoket",null,false);
    handshaker = wsFactory.newHandshaker(req);
    if(handshaker == null){
        WebSocketServerHandShakerFactory.sendUnsupportedWebSocketVersionResponse(ctx.channel());
    }else{
        handshaker.handshake(ctx.channel(),req);
    }
    private void handleWebSocketFrame(ChannelHandlerContext ctx，WebSocketFrame frame){
        if(frame instanceof CloseWebSocketFrame){
            handshaker.close(ctx.channel(),(CloseWebSocketFrame) frame.retain());
            return;
        }
        if(frame instanceof PingWebSocketFrame){
            ctx.channel().write(new PongWebSocketFrame(frame.content.retain()));
            return;
        }
        if(!(frame instanceof TextWebSocketFrame)){
            throw new UnsupportOperationException(String.format("% frame types not supported",frame.getClass().getName()))
        }
        String request = ((TextWebSocketFrame) frame).text();
        System.out.println(String.format("%s received %s"),ctx.channel(),request);
        ctx.channel().write(
            new TextWebSocketFrame(request + ", 欢迎使用Nettty Websocket服务，现在时刻：" +new java.util.Date().toString());

        )
    }
    private static void sendHttpResponse(ChannelHandlerContext ctx,FullHtppRequest req,FullHttpResponse res){
        if(res.getStatus().code()!=200){
            ByteBuf buf = Unpooled.copiedBuffer(res.getStatus().toString(),CharsettUtil.UTF_8);
            res.content().writeBytes(buf);
            buf.release();
            setContentLength(res,res.content().readableBytes());
        }
        ChannelFuture f = ctx.channel().writeAndFlush(res);
        if(!isKeepAlive(req) || res.getStatus().code()!=200){
            f.addListener(ChannelFutureListener.CLOSE);
        }
    }
    @Ovrride
    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception{
        cause.printStatckTrace();
        ctx.close();
    }
}
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>&lt;html&gt;
&lt;head&gt;
&lt;meta charset="UTF-8"&gt;
Netty WebSocket 时间服务器
&lt;/head&gt;
&lt;br&gt;
&lt;body&gt;
&lt;br
&lt;script type="text/javascipt"&gt;
var socket;
if(!window.WebSocket){
    window.WebSocket = windows.MozWebSocket;

}
if(window.WebSocket){
    socket = new WebSocket("ws://localhost:8080/websocket");
    socket.onmessage = function(event){
        var ta = document.getElementById('responseText');
        ta.valeu = '';
        ta.value = event.data;
    };
    socket.onopen = function(event){
        var ta = document.getElementById('reseponseText');
        ta.value = "打开Websocket服务正常，浏览器支持Websocket";
    }
    socket.onclose = function(event){
        vat ta = document.getElementById(responseText');
        ta.value = ''';
        ta.value = 'webScoket关闭';
    }
    }
    else {
        alert(“error");
    }
function send(message){
    if(!window.WebSocket){return;}
    if(socket.readState == WebSokcet.OPNE){
        socket.send(message);
    }else{
        alert("WebSocket连接没有建立成功");
    }
}
&lt;/script&gt;
&lt;form onsubmit= "return false;"&gt;
&lt;input type ="text" name="message" value ="Netty最佳实践"&gt;
&lt;br&gt;&lt;br&gt;
&lt;input type = "button" value ="发送 Websocket请求消息" onclick ="send(this.form.message.value)"&gt;
&lt;hr color"blue"&gt;
&lt;h3&gt;服务端返回应答消息&lt;/h3&gt;
&lt;textarea id="responseText" style="width:500px;height:300px;"&gt;&lt;/textarea&gt;
&lt;/form&gt;
&lt;/body&gt;
&lt;/html&gt;
</code></pre></div><ul>
<li>UDP协议开发
<ul>
<li>UDP用户数据包协议(User Datagram Protocol,UDP)的简称，其主要作用是讲网络数据流量压缩成数据报形式，提供面向事务的简单信息传送服务。与TCP协议不同，UDP协议直接利用IP协议进行UDP数据报的传输，UDP提供的是面向无连接的，不可靠的数据报投递服务。当使用UDP协议传输信息时，用户应用程序必须负责解决数据报丢失，重复，排序，差错确认等问题</li>
<li>由于UDP具有资源消耗小，处理速度快的有点，所以通常视频，音频等可靠性要求不高的数据传输一般会使用UDP，即便有一定的丢包率，也不会对功能造成严重的影响</li>
<li>UDP是无连接的，通信双方不需要建立物理链路连接。在网络中它用于处理数据包，在OSI模型中，它处于第四传输层，位于IP协议的上一层，它不对数据报分组，组装，校验和排序，因此是不可靠的。报文的发送者不知道报文是否被对方正确接收</li>
<li>UDP数据报格式有首部和数据两个部分，首部8个字节
<ul>
<li>源端口：源端口号，2个字节，最大值为65535；</li>
<li>目的端口：目的端口号，2个字节，最大值为65535；</li>
<li>长度：2个字节，UDP用户数据报的总长度</li>
<li>校验和：2字节，用于校验UDP数据报的数字段和包含UDP数据报首部的“伪首部”。校验方法类似IP分组首部校验和</li>
<li>伪首部，又称为伪包头，是指在TCP的分段或UDP的数据报格式中，在数据报首部前面增加源IP地址，目的IP地址，IP分组的协议字段，TCP或UDP数据报的总长度等，共12字节，所构成的扩展首部结构，此伪首部是一个临时结构，既不向上也不向下传递，仅仅为了保证可以校验套接字的正确性</li>
</ul>
</li>
<li>UDP协议的特点
<ul>
<li>UDP传送数据前并不与对方建立连接，UDP是无连接的，在传输数据前，发送方和接收方相互交换信息是双方同步</li>
<li>UDP对接收到的数据包不发送确认信号，发送端不知道数据是否被正确接收，也不会重发数据</li>
<li>UDP传送数据比TCP快速，系统开销少，UDP比较简单，UDP头包含了源端口，目的端口，消息长度和校验和等很少的字节。由于UDP比TCP简单，灵活，常用于可靠性要求不高的数据传输，如视频，图片以及简单文件传输系统（TFTP）等，TCP适用于可靠性要求很高的但实时性要求不高的应用，如文件传输协议FTP，超文本传输协议HTTP，简单邮件传输协议SMTP等。</li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class ChineseProverbServer{

    public void run(final int portl) throws Exception{
        EventLoopGroup group = new NioEventLoopGroup();
        try {
            ServerBootstrap serverBootstrap = new ServerBootstrap();
            serverBootstrap.group(group)
                    .channel(NioDatagramChannel.class)
                    .option(ChannelOption.SO_BROADCAST,true)
                    .handler(new ChineseProverbServerHandler());
            ChannelFuture f = serverBootstrap.bind(port).sync();
            f.channel().closeFuture().sync();
        }finally {
            boosGroup.shutdownGracefully();
            workerGroup.shutdownGracefully();
        }
    }

    public static void main(String[] args) throws Exception {
        new ChineseProverbServer().run(8080);
    }
}
public class ChineseProverbServerHandler extends SipmleChannelInbounHandler&lt;DataramPacket&gt;{
    private static final String[] DICTIONARY={"只要功夫深，铁柱磨成针"};
    private String nextQuote(){
        int quoted = ThreadLocalRandom.current().nextInf(DICTIONARY.length);
        return DICTIONARY(quotedId);
    }
    public void messageReceived(ChannelHandlerContext ctx,DatagramPacket packet)throws Exception{
        String req = packet.content().toString(CharsetUitl.UTF_8);
        System.out.println(req);
        if("谚语字典查询?".equals(req)){
            ctx.writeAndFlush(new DatagramPacket(Unpooled.copiedBuffer("谚语查询结果：" +newQuote(),CharsetUtil.UTF_8),packet.sender()));
        }
    }
    public void exceptionCaught(ChannelHandlerContext ctx,Throwable cause){
        ctx.close();
        cause.printStatckTrace();
    }
}
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class ChineseProverbClient{

    public void run(final int portl) throws Exception{
        EventLoopGroup group = new NioEventLoopGroup();
        try {
            Bootstrap b = new Bootstrap();
            b .group(group)
                    .channel(NioDatagramChannel.class)
                    .option(ChannelOption.SO_BROADCAST,true)
                    .handler(new ChineseProverbClientHandler());
            Channel ch = b.bind(0).sync().channel();
            ch.writeAndFlush(
                new DatagramPacket(Unpooled.copiedBuffer("谚语字典查询?",CharsetUtil.UTF_9),new InetSocketAddress("255.255.255.255",port)).sync();//向本网段内所有主机广播请求消息
            );
            if(!ch.closeFuture().await(15000)){
                System.out.println("查询超时!")
            }
        }finally {
            group.shutdownGracefully();
        }
    }

    public static void main(String[] args) throws Exception {
        new ChineseProverbClient().run(8080);
    }
}
public class ChineseProverbClientHandler extends SimpleChannelInboundHandler&lt;DatagramPacket&gt;{
    public void messageReceived(channelHandlerContext ctx,DatagramPacket msg) throws Exception{
        String response = msg.content().toString(CharsetUtil.UTF_8);
        if(response.startsWitch("谚语查询结果:")){
            System.out.println(response);
            ctx.close();
        }
    }

    public void exceptionCaught(ChannelHandlerContext ctx,Throwable cause){
        cause.prinStackTrace();
        ctx.close();
    }
}
</code></pre></div><ul>
<li>文件传输
<ul>
<li>文件是计算机中一种基本的数据存储形式，在实际存储数据是，如果对于数据的读写速度要求不是很高，存储的数据量不是很大，使用文件作为一种持久数据存储的方式是比较好的选择。存储在文件内部的数据和内存中的数据不同，存储在文件中的数据是一种永久存储</li>
<li>在不同存储介质中，文件中的数据都是以一定的顺序依次存储起来的。在世界读取时由硬件以及操作系统完成对于数据的控制，保证程序读取到的数据与存储的顺序一致，每个文件以一个文件路径和文件名称进行表示，在需要访问该文件时，只需要知道改文件的路径以及文件的全名即可</li>
<li>绝对路径是指文件的完整路径，使用路径可以找到一个唯一的文件。使用绝对路径的最大缺点是不同操作系统的文件路径和表现形式不同，使用不当往往会导致文件读取失败，实际往往使用相对路径或者类路径</li>
<li>文件一般采用文件名.后缀名形式进行命名，文件名表示文件的作用，后缀名表示文件的类型</li>
</ul>
</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class FileServer{

    public void bind(final int portl) throws Exception{
        EventLoopGroup boosGroup = new NioEventLoopGroup();
        EventLoopGroup workerGroup = new NioEventLoopGroup();
        try {
            ServerBootstrap serverBootstrap = new ServerBootstrap();
            serverBootstrap.group(boosGroup,workerGroup)
                    .channel(NioServerSocketChannel.class)
                    .option(ChannelOption.SO_BAKCLOG,100)
                    .handler(new ChannelInitalizer&lt;SocketChannel&gt;(){
                        @Override
                        public void initChannel(SocketChannel ch) throws Exception{
                            
                            ch.pipeline().addLast(new StringEncoder(CharsetUtil.UTF_8),
                            new LineBasedFrameDecoder(1024)
                            new StringDecoder(CharsetUtil.UTF_8),
                            new FileServerHandler()
                            );
                        }
                    });
            ChannelFuture f = serverBootstrap.bind(port).sync();
            f.channel().closeFuture().sync();
        }finally {
            boosGroup.shutdownGracefully();
            workerGroup.shutdownGracefully();
        }
    }

    public static void main(String[] args) throws Exception {
        new FileServer().run(8080);
    }
}
public class FileServerHandler extends SimpleChannelInboundHandler&lt;String&gt;{
    private static String CR = System.getProperty("line.separtor");
    public void messageReceived(ChannelHandlerContext ctx,String msg) throws Exception{
        File file = new File(meg);
        if(file.exist()){
            if(!file.isFile()){
                ctx.writeAndFlush("Not a file:"+ file +CR);
                return;
            }
            ctx.write(file + " " file.length() + CR;
            RandomAccessFile randomAccessFile = new RandomAccessFile(msg,"r");
            FileRegion region = new DefaultFileRegion(
                //文件通道，用于对文件进行读写操作
                //文件操作位置，读取或写入的起始点
                //操作的总字节数
                randomAccessFile.getChannel(),0,randomAccessFile.length());
            )
            ctx.write(region);
            ctx.writeAndFlush(CR;
            randomAccessFile.close();
        }else{
            ctx.writeAndFlush("File not found: "+ file + CR);
        }
    }

    public void exceptionCaugtht(ChannelHandlerContext ctx,Throwable cause){
        cause.printStackrace();
        ctx.close();
    }
}

使用telnet localhost 8080进行调试
</code></pre></div><ul>
<li>私有协议开发
<ul>
<li>私有协议本质上是厂商内部发展和采用的标准，除非授权，其它厂商一般无权使用该协议。只要能够用于跨进程，跨主机数据交换的非标准协议，都可以成为私有协议，在传统的Java应用中，通常使用一下4种方式进行跨节点通信。
<ul>
<li>通过RMI进行远程服务调用</li>
<li>通过Java的Socket+Java序列化的范式进行跨节点调用</li>
<li>利用一些开源的RPC框架进行远程服务调用。如Facebooke的Thrift，Apache的Avro等</li>
<li>利用标准的共有协议进行跨节点服务调用：HTTP+XML，RESTful+JSON或者Webservice</li>
</ul>
</li>
</ul>
</li>
<li>私有协议栈功能描述
<ul>
<li>基于Netty的NIO通信框架，提供高性能的异步通信能力</li>
<li>提供消息的编解码框架，可以实现POJO的序列化和反序列化</li>
<li>提供基于IP地址的白名单接入认证机制</li>
<li>链路有效性校验机制</li>
<li>链路的断连重连机制</li>
</ul>
</li>
<li>通信模型
<ul>
<li>Netty协议栈客户端发送握手请求消息，携带节点ID等有效身份认证信息</li>
<li>Netty协议栈服务端对握手请求协议进行合法性校验，包括节点ID有效性校验，节点重复登录校验和IP地址合法新校验，校验通过后，返回登录成功的握手应答消息</li>
<li>链路建立成功之后，客户端发送业务消息</li>
<li>链路成功之后，服务端发送心跳消息</li>
<li>链路建立成功之后，客户端发送心跳消息</li>
<li>链路建立成功之后，服务端发送业务消息</li>
<li>服务端退出时，服务端关闭连接，客户端感知对方关闭连接后，被动关闭客户端连接</li>
<li>备注：Netty协议通信双方链路建立成功之后，双方可以进行全双工通信，无论客户端还是服务端，都可以主动发送请求消息给对安防，通信方式可以是TWOWAY或者ONEWAY。双方之间的心跳采用Ping-Pong机制，当链路处于空闲状态时，客户端主动发送Ping消息给服务端，服务端接收到Ping消息后发送应答消息Pong给客户端，如果客户端连续发送N条Ping消息欧没有接收到服务端返回的Pong消息，说明链路已经挂死或者对方处于异常状态，客户端主动关闭连接，间隔周期T后发起重连操作，直到重连成功</li>
<li>Netty协议栈消息定义
<ul>
<li>消息头
<ul>
<li>header：Header 变长 消息头定义
<ul>
<li>crcCode :整型int 32 Netty消息的校验码
<ul>
<li>0xABEF:固定值，表明该消息是Netty协议消息，2个字节</li>
<li>主版本号:1-255,1个字节</li>
<li>次版本号:1-255,1个字节</li>
</ul>
</li>
<li>length: 整型int 32 消息长度，整个消息，包括消息头和消息体</li>
<li>sessionID：长整型long 64 集群节点内全局唯一，由会话ID生成器生成</li>
<li>type Byte 8 0业务请求消息 1业务响应消息 2业务ONE WAY消息（既是请求又是响应消息）3我收请求消息 4 握手应答消息5 心跳请求消息 6心跳应答消息</li>
<li>priority Byte 8 消息优先级 0-255</li>
<li>attachment Map&lt;String,Object&gt; 变长 可选字段，用于扩展消息头</li>
</ul>
</li>
<li>body：Object 变长 对于请求消息，它是方法的参数，对于响应消息，它是返回值</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Netty协议支持的字段类型
<ul>
<li>boolean/Boolean</li>
<li>byte/Byte</li>
<li>int对应C/C++int32</li>
<li>char/Character</li>
<li>short对应C/C++int16</li>
<li>long对应C/C++int64</li>
<li>float/Float</li>
<li>double/Double</li>
<li>String 对应C/C++String</li>
<li>list支持各种List实现</li>
<li>array支持各种数组实现</li>
<li>map支持Map嵌套和泛型</li>
<li>set支持Set嵌套和泛型</li>
</ul>
</li>
<li>Netty协议的编解码规范
<ul>
<li>Neety协议NettyMessage的编码规范如下
<ul>
<li>crcCode:java.nio.ByteBuffer.putInt(int value),如果采用其他缓冲区实现，必须与其等价</li>
<li>length:java.nio.ByteBuffer.putInt(int value),如果采用其他缓冲区实现，必须与其等价</li>
<li>sessionID:java.nio.ByteBuffer.putLong(Long value),如果采用其他缓冲区实现，必须与其等价</li>
<li>type:java.nio.ByteBuffer.put(byte b),如果采用其他缓冲区实现，必须与其等价</li>
<li>priority:java.nio.ByteBuffer.put(byte b),如果采用其他缓冲区实现，必须与其等价</li>
<li>attachment:如果attachment长度为0，表示没有可选附件，则将长度编码设为0，java.nio.ByteBuffer.putInt(0);如果大于0，说明有附件编码，首先对附件个数进行编码，java.nio.ByteBuffer.putInt(attachment.size());然后对Key进行编码，先编码长度，再将它转成byte数组之后编码内容</li>
<li>body的编码: 通过JBossMarshalling将其序列化为byte数组，然后调用java.nio.ByteBuffer.put(byte[] src)将其写入ByteBuffer缓冲区中</li>
<li>由于整个消息的长度必须等全部字段都编码完成之后才能确认，所以最后需要更新消息头中的length字段，将其重新写入ByteBuffer中</li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>String key = null;
byte[] value = null;
for(Map.Entry&lt;String,Object&gt; param:attchment.entrySet()){
    key = param.getKey();
    buffer.writeString(key);
    value = marshallier.writeObject(parm.getValue());
    buffer.writeBinary(value);
    key = null;
    value = null;
}

</code></pre></div><pre><code>- Netty协议的解码
  -  crcCode:java.nio.ByteBuffer.getInt()获取校验码字段，其它缓冲区必须与其等价
  -  length:java.nio.ByteBuffer.getInt()获取Netty消息的长度，其它缓冲区必须与其等价
  -  sessionID:java.nio.ByteBuffer.getLong()获取会话ID，其它缓冲区必须与其等价
  -  type:java.nio.ByteBuffer.get()获取消息类型，其它缓冲区必须与其等价
  -  priority:java.nio.ByteBuffer.get()获取消息优先级，其它缓冲区必须与其等价
  -  attachment:首先创建一个新的attachment对象，调用java.nio.ByteBuffer.getInt()获取附件的长度，如果为0，说明附件为空，解码结束，继续解消息体，如果非空，则根据长度通过for循环解码
  -  body 通过JBoss的marshaller进行解码
</code></pre>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>String key = null;
Object value = null;
for(int i=0;i&lt;size;i++){
    key = buffer.readString();
    value = unmarshaller.readObject(buffer.readBinary());
    this.attachment.put(key,value)l;
}
key = null;
value = null;
</code></pre></div><ul>
<li>链路的建立
<ul>
<li>Netty协议栈对客户端的说明如下：如果A节点需要调用B节点的服务，但是A和B之间还没有建立物理链路，则由调用方主动发起连接，此时，调用方为客户端，被调用方为服务端</li>
<li>考虑到安全，链路建立需要通过基于IP地址或者号段的黑白名单安全认证机制。</li>
<li>客户端与服务端链路建立成功之后，由客户端发送握手请求消息，握手请求消息定义如下
<ul>
<li>消息头的type字段值为3</li>
<li>可选附件为个数为0</li>
<li>消息体为空</li>
<li>握手消息的长度为22个字节</li>
</ul>
</li>
<li>服务端收到客户端的握手请求消息之后，如果IP校验通过，返回握手成功应答消息给客户端，应用层链路建立成功。握手应答消息定义如下
<ul>
<li>消息头的type字段值为4</li>
<li>可选附件个数为0</li>
<li>消息体byte类型的结果 0 认证成功 - 认证失败</li>
</ul>
</li>
</ul>
</li>
<li>链路的关闭
<ul>
<li>由于采用长连接通信，在正常的业务运行期间，双方通过心跳和业务消息维持链路，任何一方都不需要主动关闭连接
<ul>
<li>当对方宕机或者重启时，会主动关闭链路，另一方读取到操作系统的通知信号，得知对方REST链路，需要关闭连接，释放自身句柄等资源。由于采用全双工通信，通信双方都需要关闭连接，释放资源</li>
<li>消息读写过程中，发生了I/O异常，需要主动关闭连接</li>
<li>信条消息读写过程中发生了I/O异常，需要主动关闭连接</li>
<li>心跳超时，需要主动关闭连接</li>
<li>发生编码异常等不可恢复错误时，需要主动关闭连接</li>
</ul>
</li>
</ul>
</li>
<li>可靠性设计
<ul>
<li>Netty协议栈可能会运行在非常恶劣的网络环境中，网络超时，闪断，对方进程僵死或者处理缓慢等情况都有可能发生。为了保证在这些极端的异常场景下Netty协议栈能够正常工作或者自动恢复，需要对它的可靠性进行统一规划和设计
<ul>
<li>心跳机制
<ul>
<li>在凌晨等业务低谷期时段，如果发生网络闪断，连接被Hang等网络问题时，由于没有业务消息，应用进程很难发现。到了白天业务高峰期时，会发生大量的网络通信失败。严重会导致一段时间进程无法处理业务消息。为了解决这个问题，在网络空闲时采用心跳机制来检测链路的互通性，一旦发生网络故障，立即关闭链路，主动重连
<ul>
<li>当网络处于空闲状态持续达到T（连续周期T没有读写消息）时，客户端主动发送Ping心跳消息给服务端</li>
<li>如果在下一个周期T到来市客户端没有收到对方发送的Pong心跳应答消息或者读到服务端发送的其它业务消息，则心跳失败计数器加1</li>
<li>每当客户端收到服务的业务消息或者Pong应答消息，将心跳失败计数器清零；当连续N次没有接收到服务端的Pong消息或者业务消息，则关闭链路，间隔INTERVAL时间后发起重连操作</li>
<li>服务端网络空闲状态持续时间达到T后，服务端将心跳失败计数器加1；只要接收到客户端发送的Ping消息或者其它业务消息，计数器清零</li>
<li>服务端连续N次没有接收到客户端的Ping消息或者其它业务消息，则关闭链路，释放资源，等待客户端重连</li>
<li>通过Ping-Pong双向心跳机制，可以保证无论通信哪一方出现网络故障，都能被几时地检测出来，为了防止由于对方短时间内繁忙而没有及时返回应答造成的误判，只有连续N次心跳检测失败才认定链路已经损害，需要关闭链路并重建链路</li>
<li>当读或者写信条消息发生I/O异常的时候，说明链路已经中断，此时需要立即关闭链路，如果是客户端，需要重新发起连接，如果是服务端，需要清空缓存的半包信息，等待客户端重连</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>重连机制
<ul>
<li>如果链路中断，等待INTERVAL时间后，由客户端发起重连操作，如果重连失败，间隔周期INTERVAL后再次发起重连，直到重连成功</li>
<li>为了保证服务端能够有充足的时间释放句柄资源，在首次断连时客户端需要等待INTERVAL时间之后再发起重连，而不是失败就立即重连</li>
<li>为了保证句柄资源几时释放，无论什么场景下的重连失败，客户端都必须保证自身资源被及时释放，包括但不限于SocketChannel。Socket等</li>
<li>重连失败后，需要打印异常堆栈信息，方便后续的问题定位</li>
</ul>
</li>
<li>重复登录保护
<ul>
<li>当客户端握手成功之后，在链路处于正常状态下，不允许客户端重复登录，以防止客户端在异常状态下反复重连导致句柄资源被耗尽</li>
<li>服务端接收到客户端握手请求消息之后，首先对IP地址进行合法性校验，如果校验成功，在缓存的地址表中查看客户端是否已经登录，如果已经登录，则拒绝重复登录，返回错误码-1，同时关闭TCP链路，并在服务端的日志中打印握手失败的原因</li>
<li>客户端收到握手失败的应答消息之后，关闭客户端的TCP连接，等待INTERVAL时间之后，再次发起TCP连接，直到认证成功</li>
<li>为了防止由服务端和客户端对链路状态理解不一致导致的客户端无法握手成功的问题，当服务端连续N次心跳超时之后需要主动关闭链路，清空改客户端的地址缓存信息，为了保证后续该客户端可以重连成功，防止被重复登录保护机制拒绝掉</li>
</ul>
</li>
<li>消息缓存重发
<ul>
<li>无论客户端还是服务端，当链路发生中断之后，在链路恢复之前，缓存在消息队列中待发送的消息不能丢失，等链路恢复之后，重新发送这些消息，保证链路中断期间消息不丢失</li>
<li>考虑到内存溢出的风险，建议消息缓存队列设置上限，当达到上限之后，应该拒绝继续向该队列添加消息</li>
</ul>
</li>
</ul>
</li>
<li>安全性设计
<ul>
<li>为了保证整个集群环境的安全，内部长连接采用基于IP地址的安全认证机制，服务端对握手请求消息的IP地址进行合法性校验，如果在白名单之内，则校验通过，否则，拒绝对方连接</li>
<li>如果将Netty协议栈放到公网中使用，需要采用更加严格的安全认证机制，例如基于秘钥和AES加密的用户名+密码认证机制，也可以采用SSL/TSL安全传输</li>
</ul>
</li>
<li>可扩展性设计
<ul>
<li>Netty协议需要具备一定的扩展能力，业务可以在消息头中自定义业务域字段，例如消息流水号，业务自定义消息头等，通过netty消息头中的可选附件attachment字段，业务可以方便地进行自定义扩展</li>
<li>Netty协议架构需要具备一定的扩展能力，如统一的消息拦截，接口日志，安全，加解密等可以被方便地添加和删除，不需要修改之前的逻辑代码，类似Servet的FilterChain和AOP，但考虑到性能因素，不推荐通过AOP实现功能的扩展</li>
</ul>
</li>
<li>Netty协议栈开发</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public final class NettyMessage{
    private Header header;
    private Object body;
    public final Header getHeader(){
        return header;
    }
    public final void setHeader(Header header){
        this.header = header;
    }
    public final Object getBody(){
        return body;
    }
    public final void setBody(Object body){
        this.body = body;
    }
    public String toString(){
        return "NettyMessage [ header=" + header + "]";
    }
}
public final class Header{
    private int crcCode = 0xabef0101;
    private int length;//消息长度
    private long sessionID;//会话ID
    private byte type;//消息类型
    private byte priority;//消息有衔接
    private Map&lt;String,Object&gt; attachment = new HashMap&lt;String,Object&gt;();//附件
    //set/get/toString();
}
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public final class NettyMessageEncoder extends MessageToMessageEncoder&lt;NettyMessage&gt;{
    MarshallingEncoder marshallingEncoder;
    public NettyMessageEncoder() throws IOException{
        this.marshallingEncoder = new MarshallingEncoder();
    }
    protected void encde(ChannelHandlerContext ctx,NettyMessage msg.List&lt;Object&gt; out) throws Exception{
        if(msg == null || msg.getHeader() == null){
            throw new Exception("The encode message is null");
        }
        ByteBuf sendBuf = Unpooled.buffer();
        sendBuf.writeInt((msg.getHeader().getCrcCode()));
        sendBuf.wirteInt((msg.getHeader().getLength()));
        sendBuf.wirteInt((msg.getHeader().getSessionID()));
        sendBuf.wirteInt((msg.getHeader().getType()));
        sendBuf.wirteInt((msg.getHeader().getPriority()));
        sendBuf.wirteInt((msg.getHeader().getAttachment().size()));
        String key = null;
        byte[] keyArray = null;
        Object value = null;
        for(Map.Entry&lt;String,Object&gt; param:msg.getHeader().getAttachment().entrySet()){
            key = parm.getKey();
            keyArray = key.getBytes("UTF-8");
            sendBuf.writeInt(keyArray.length);
            sendBuf.wirteBytes(keyArray);
            value = param.getValue();
            marshallingEncoder.encode(value,senBuf);
        } 
        key = null;
        keyArray = null;
        value = null;
        if(msg.getBody()!=null){
            marshallingEncoder.encode(msg.getBody(),sendBuf);
        }else{
            sendBuf.writeInt(0);
            sendBuf.setInt(4,sendBuf.readableBytes());
        }
    }
}
public class Marshalling Encoder{
    private static final byte[] LENGTH_PLACHOLDER = new byte[4];
    public MarshallingEncoder() throws IOException{
        marshaller = MarshallingCodeFactory.buildmarshalling();
    }
    protected void encode(Object msg.ByteBuf out) throws Exception{
        try{
            int lengthPos = out.writerIndex();
            out.writeBytes(LENGTH_PLACEHOLDER);
            ChannelBufferByteOutput output = new ChannleBufferByteOutput(out);
            marshaller.start(output);
            marshaller.writeObject(msg);
            marshaller.finish();
            out.setInt(lengthPos,out.writerIndex() - lengthPos - 4);
        }finally{
            marshaller.close();
        }
    }
}
public class NettyMessageDecoder extends LengthFieldBasedFrameDecoder{
    MarshallingDecoder marshallingDecoder;
    public NettyMessageDecoder(int max FrameLength,int lengthFieldOffset,int lengthFiedlLength) throws IOException{
        super(maxFrameLength,lengthFieldOffset,lengthFieldLength);
        marshallingDecode = new MarshallingDecoder();
    }
    protected Object decode(ChannelHandlerContext ctx,ByteBuf in) throws Exception{
        ByteBuf frame = (ByteBuf) super.decode(ctx,in);
        if(frame == null){//调用父类LengthFieldBasedFrameDecoder解码之后，返回的是整包消息或者为null，直接返回继续由I/O线程读取后面的码流
            return null;
        }
        NettyMessage message = new NettyMessage();
        Header header = new Header();
        header.setCrcCode(in.readInt());
        header.setLength(in.readInt());
        header.setSessionID(in.readLong());
        header.setType(in.readByte());
        header.setPriority(in.readByte());

        int size = in.readInt();
        if(size &gt; 0){
            Map&lt;String,Object&gt; attch = new HashMap&lt;String,Object&gt;(size);
            int keySize = 0;
            byte[] keyArray = null;
            String key = null;
            for(int i=0;i&lt;size;i++){
                keySize = in.readInt();
                keyArray = new byte[keySize];
                in.readBytes(keyArray);
                key = new String(keyArray,"UTF-8");
                attch.put(key,marshallingDecoder.decode(in));
            } 
            keyArray = null;
            key = null;
            header.setAttachment(attch);
        }
        if(in.readableBytes()&gt;4){
            message.setBody(marshallingDecoder.decode(in));
        }
        message.setHeader(header);
        return message;
    }
}
public class MarshallingDecoder{
    private final Unmarshaller unmarshaller;
    public MarshallingDecoder() throws IOException{
        unmarshaller = MarshallingCodecFactory.buildUnMarshalling();
    }

    protected Object decode(ByteBuf in) throws Exception{
        int objectSize = in.readInt();
        ByteBuf buf = in.slice(in.readerIndex(),objectSize);
        ByteInput input = new ChannelBufferByteInput(buf);
        try{
            unmarshaller.start(input);
            Object obj = unmarshaller.readObject();
            umarshaller.finish();
            in.readerIndex(in.readerIndex()+objectSize);
            return obj;
        }finally{
            unmarshaller.close();
        }
    }
}
public class LoginAuthReqHandler extends ChannelHandlerAdapter{
    public void channelActive(ChannelHandlerContext ctx) throws Exception{
        ctx.wirteAndFlush(buildLoginReq());
    }
    public void channelRead(ChannelHandlerContext ctx,Object msg)throws Exception{
        NettyMessage message = (NettyMessage) msg;
        if(message.getHeader()!=null &amp;&amp; message.getHeader().getType() == MessaagType.LOGIN_RESP.value()){
            byte loginResult = (byte) message.getBody();
            if(loginResult != (byte)0){
                ctx.close();
            }else{
                System.out.println("Login is ok：" + message);
                ctx.fireChannelRead(msg);
            }
        }else{
            ctx.fireChannelRead(msg);
        }
    }
    private NettyMessage buildLoginReq(){
        NettyMessage message = new NettyMessage();
        Header header = new Header();
        header.setType(MessageType.LOGIN_REQ.value());
        message.setHeader(header);
        return message;
    }

    public void exceptionCaught(ChannelHandlerContext ctx,Throwable cause){
        ctx.fireExceptionCaught(cause);
    }
}
public class LoginAuthRespHandler extends channelHandlerAdapter{
    private Map&lt;String,Boolean nodeCheck&gt; = new ConcurrentHashMap&lt;String,Boolean&gt;();
    private String[] whiteList = {"127.0.0.1","192.168.1.104"};
    public void channelRead(ChannelHandlerContext ctx,Object msg) throws Exception{
            NettyMessage  message = (NettyMessage) msg;
            if(message.getHeader!=null &amp;&amp; message.getHeader().getType()==MessageType.LOGIN_REQ.value()){
                String nodeIndex = ctx.channel().remoteAddress().toString();
                NettyMessagType  loginResp = null;
                //重复登录，拒绝
                if(nodeCheck.containsKey(nodeIndex)){
                    loginResp = buildResponse((byte)-1);
                }else{
                    InetSocketAddress address = (InetSocketAddress) ctx.channel().remoteAddress();
                    String ip = address.getAddress().getHostAddress();
                    boolean isOK = false;
                    for(String WIP:whiteList){
                        if(WIP.equals(ip)){
                            isOK = true;
                            break;
                        }
                    }
                }
                loginResp = isOK? bulidResponse((byte)0):buildResponse((byte)-1);
                if(isOK){
                    nodeCheck.put(nodeIndex,true);
                }
                System.out.println("The login response is:" + loginResp + "body [" + loginResp.getBody+"]");
                ctx.writeAdnFlush(loginResp);
            }else{
                ctx.fireChannelread(msg);
            }
    }
    private NettyMessag buildResponse(byte result){
        NettyMessage  message = new NettyMessage();
        Header header = new Header();
        header.setType(MessageType.LOGIN_RESP.value());
        message.setHeader(header);
        message.setBody(result);
        return message;
    }
    publuc void exceptionCaught(ChannelHandlerContext ctx,Throwable cause) throws Exception{
        nodeCheck.remove(ctx.channel().remoteAddress().toString());
        ctx.close();
        ctx.fireExceptionCaught(cause);
    }
}
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>public class HeartBeatReqHandler extends ChannelHandlerAdapter{
    private volatile SchduledFuture&lt;?&gt; heartBeat;

    public void channelRead(ChannelHandlerContext ctx,Object msg)throws Exception{
        NettyMessage message = (NettyMessage) msg;
        if(message.getHeader()!=null &amp;&amp; message.getHeader().getType == MessageType.LOGIN_RESP.value()){
            hearBeat = ctx.executor().scheduleAtFixedRate(new HeartBeatReqHandler.HearBeatTask(ctx,0,5000,TimeUnit.MILLISECONDS));

        }else if(message.getHeader()!=null &amp;&amp; message.getHeader().getType == MessageType.HEARTBEAT_RESP.value()){
            Sytem.out.println("Client receive server heart beat message:--&gt;" + message);
           
        }else{
             ctx.fireChannelRead(msg);
        }
        
    }
    private class HearBeatTask implements Runnable{
        private final ChannelHandlerContext ctx;
        public HearBeatTask(final ChannelHanderContext ctx){
            this.ctx = ctx;
        }
        @Override
        public void run(){
            NettyMessag heatBeat = buildHeatBeat();
            System.out.println("client send heart beat message to server :</code></pre></div>]]></content:encoded>
    </item>
    <item>
      <title>Dubbo</title>
      <link>https://javaguide.cn/backend/serviceinvocation/dubbo.html</link>
      <guid>https://javaguide.cn/backend/serviceinvocation/dubbo.html</guid>
      <source url="https://javaguide.cn/rss.xml">Dubbo</source>
      <description>1. 如何实现远程调用? 1、Webservice：效率不高基于soap协议。项目中不推荐使用。 2、使用restful形式的服务：http+json。很多项目中应用。如果服务太多，服务之间调用关系混乱，需要治疗服务。（不同语言不同公司使用） 3、使用dubbo。使用rpc协议进行远程调用，直接使用socket通信。传输效率高，并且可以统计出系统之间的...</description>
      <category>后端</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[
<ul>
<li>1、Webservice：效率不高基于soap协议。项目中不推荐使用。</li>
<li>2、使用restful形式的服务：http+json。很多项目中应用。如果服务太多，服务之间调用关系混乱，需要治疗服务。（不同语言不同公司使用）</li>
<li>3、使用dubbo。使用rpc协议进行远程调用，直接使用socket通信。传输效率高，并且可以统计出系统之间的调用关系、调用次数。（同语言使用）</li>
</ul>
<h1>2. Dubbo使用</h1>
<ul>
<li>
<p>Dubbo采用全Spring配置方式，透明化接入应用，对应用没有任何API侵入，只需用Spring加载Dubbo的配置即可，Dubbo基于Spring的Schema扩展进行加载。</p>
</li>
<li>
<p>远程服务中spring的配置，在本地服务的基础上，只需做简单配置，即可完成远程化：</p>
</li>
<li>
<p>将上面的local.xml配置拆分成两份，将服务定义部分放在服务提供方remote-provider.xml，将服务引用部分放在服务消费方remote-consumer.xml。并在提供方增加暴露服务配置<a href="dubbo:service">dubbo:service</a>，在消费方增加引用服务配置<a href="dubbo:reference">dubbo:reference</a></p>
</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>	xmlns:dubbo="http://code.alibabatech.com/schema/dubbo" 
	http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd
	以上两句配置在xml中
	&lt;!-- 使用dubbo发布服务 --&gt;
	&lt;!-- 提供方应用信息，用于计算依赖关系 --&gt;
	&lt;dubbo:application name="e3-manager" /&gt;
	&lt;!-- 配置注册中心集群 --&gt;
	&lt;dubbo:registry protocol="zookeeper"address="192.168.25.154:2181,192.168.25.154:2182,192.168.25.154:2183" /&gt;
	&lt;!-- 用dubbo协议在20880端口暴露服务 --&gt;
	&lt;dubbo:protocol name="dubbo" port="20880" /&gt;
	
	&lt;bean id="xxx" class="itemServiceImpl实现类"&gt;
	&lt;!-- 声明需要暴露的服务接口 --&gt;
	&lt;dubbo:service interface="cn.e3mall.service.ItemService接口" ref="xxx" /&gt;


	xmlns:dubbo="http://code.alibabatech.com/schema/dubbo" 
	http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd
	以上两句配置在xml中
	&lt;!-- 引用dubbo服务 --&gt;
	&lt;dubbo:application name="e3-manager-web"/&gt;
	&lt;!-- 配置注册中心集群 --&gt;
	&lt;dubbo:registry protocol="zookeeper" address="192.168.25.154:2181,192.168.25.154:2182,192.168.25.154:2183"/&gt;
	
	&lt;dubbo:reference interface="cn.e3mall.service.ItemService接口" id="itemService起一个名字，相当于bean的name" /&gt;

	在controller层
	@Autowired
	private ItemService itemservice使用即可
</code></pre></div><h1>3. 注册中心Zookeeper</h1>
<ul>
<li>官方推荐使用zookeeper注册中心。注册中心负责服务地址的注册与查找，相当于目录服务，服务提供者和消费者只在启动时与注册中心交互，注册中心不转发请求，压力较小。</li>
<li>使用dubbo-2.3.3以上版本，建议使用zookeeper注册中心。</li>
<li>Zookeeper是Apacahe Hadoop的子项目，是一个树型的目录服务，支持变更推送，</li>
<li>适合作为Dubbo服务的注册中心，工业强度较高，可用于生产环境，并推荐使用</li>
<li>Zookeeper优点：
<ul>
<li>1、可以作为集群的管理工具使用。</li>
<li>2、可以集中管理配置文件。</li>
</ul>
</li>
</ul>
<h1>4. Dubbo的安装</h1>
<ul>
<li>
<p>第一步：安装jdk</p>
</li>
<li>
<p>第二步：把zookeeper的压缩包上传到linux系统（目录随意）</p>
</li>
<li>
<p>第三步：解压缩压缩包tar -zxvf zookeeper-3.4.6.tar.gz</p>
</li>
<li>
<p>第四步：进入zookeeper-3.4.6目录，创建data文件夹。</p>
</li>
<li>
<p>第五步：把zookeeper-3.4.6目录下的conf目录将zoo_sample.cfg改名为zoo.cfg ：mv zoo_sample.cfg zoo.cfg</p>
</li>
<li>
<p>第六步：修改zoo.cfg的data属性设置为data所在的目录：vim zoo.cfg然后输入i编辑 dataDir=/usr/zookeeper-3.4.6/data 然后Esc，然后:wq保存并退出</p>
</li>
<li>
<p>第七步：进入bin目录启动zookeeper</p>
<ul>
<li>./zkServer.sh start 关闭：./zkServer.sh stop 查看状态：./zkServer.sh status</li>
<li>注意：需要关闭防火墙。service iptables stop 永久关闭修改配置开机不启动防火墙：chkconfig iptables off</li>
<li>如果不能成功启动zookeeper，需要删除data目录下的zookeeper_server.pid文件。</li>
</ul>
</li>
<li>
<p>第八步：Dubbo监控中心的安装</p>
<ul>
<li>cp dubbo-admin-2.5.4.war apache-tomcat-7.0.47/webapps/dubbo-admin.war</li>
<li>进入tomcat的bin目录下启动tomcat</li>
</ul>
</li>
<li>
<p>第九步：访问<a href="http://192.168.25.167:8080/dubbo-admin/" target="_blank" rel="noopener noreferrer">http://192.168.25.167:8080/dubbo-admin/</a> 用户名：root密码：root</p>
</li>
<li>
<p>如果监控中心和注册中心在同一台服务器上，可以不需要任何配置。</p>
</li>
<li>
<p>如果不在同一台服务器，需要修改配置文件dubbo.properties：</p>
</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>/root/apache-tomcat-7.0.47/webapps/dubbo-admin/WEB-INF/dubbo.properties
dubbo.registry.address=zookeeper://127.0.0.1:2181注册中心地址
dubbo.admin.root.password=root root用户的密码
dubbo.admin.guest.password=guest
</code></pre></div>]]></content:encoded>
    </item>
    <item>
      <title>架构设计</title>
      <link>https://javaguide.cn/backend/systemdesign/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1.html</link>
      <guid>https://javaguide.cn/backend/systemdesign/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1.html</guid>
      <source url="https://javaguide.cn/rss.xml">架构设计</source>
      <description>架构设计 软件的开发流程（瀑布模型） 需求调研分析----需求规格说明书 设计阶段（概要设计、详细设计）----页面原型、数据库设计、设计文档 编码阶段 测试阶段 上线和运维 架构总览 5.png5.png 传统架构(单一应用架构) 当网站流量很小时，只需一个应用，将所有功能都部署在一起，以减少部署节点和成本。此时，用于简化增删改查工作量的 数据访问框...</description>
      <category>架构设计</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>架构设计</p>
<!--more-->
<h1>软件的开发流程（瀑布模型）</h1>
<ul>
<li>需求调研分析</li>
</ul>
]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/e392fe8bea5afd6941e5d.png" type="image/png"/>
    </item>
    <item>
      <title>秒杀项目</title>
      <link>https://javaguide.cn/backend/systemdesign/%E7%A7%92%E6%9D%80%E9%A1%B9%E7%9B%AE.html</link>
      <guid>https://javaguide.cn/backend/systemdesign/%E7%A7%92%E6%9D%80%E9%A1%B9%E7%9B%AE.html</guid>
      <source url="https://javaguide.cn/rss.xml">秒杀项目</source>
      <description>电商秒杀系统-核心高性能解决方案 分层设计 接入层模型 View Object 与前端对接的模型，隐藏内部实现，仅展示的聚合模型 业务层模型 Domain Object 领域模型，业务核心模型，拥有生命周期贫血以及服务输出能力 （贫血模型，只有数据库对应字段，不提供其他功能，其他功能由sevice提供，比如用户模型只有username password...</description>
      <category>架构设计</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[
<h2>分层设计</h2>
<ul>
<li>接入层模型 View Object 与前端对接的模型，隐藏内部实现，仅展示的聚合模型</li>
<li>业务层模型 Domain Object 领域模型，业务核心模型，拥有生命周期贫血以及服务输出能力 （贫血模型，只有数据库对应字段，不提供其他功能，其他功能由sevice提供，比如用户模型只有username password 不会有注册等功能，充血模型则表示用户模型包括username password之外还能提供注册功能）可以处理用户生命周期，例如从注册登录到退出，包含多个数据模型，例如用户包括用户基础信息数据模型和用户密码信息数据模型</li>
<li>数据层 Data Object数据模型，同数据库映射，用以ORM方式操作数据库的能力模型<br>
-- 用户密码会与用户信息分开存储，用户密码会放在加密数据库中，而平时只用到用户的基础信息</li>
</ul>
<h2>环境部署</h2>
<h3>jdk安装</h3>
<ul>
<li>下载jdk的rpm文件</li>
<li>授权最高权限 chmod 777 rpm文件</li>
<li>安装rpm文件 rpm -ivh rpm文件 （默认安装到/usr/java）</li>
<li>添加环境变量vim ~/.bash_profile
<ul>
<li>添加JAVA_HOME=/usr/java/jdk1.8.0_65 PATH=JAVA_HOME/bin</li>
<li>保存并退出:wq</li>
<li>刷新配置文件source ~/.bash_profile</li>
</ul>
</li>
</ul>
<h3>mysql安装</h3>
<ul>
<li>安装mysql相关依赖yum install mysql*</li>
<li>rpm方式不需要镜像就能更新，但需要解决依赖</li>
<li>yum方式不需要解决依赖</li>
<li>yum install mariadb-server</li>
<li>启动mysql systemctl start mariadb.service</li>
<li>初始化root账户密码mysqladmin -u root password root</li>
</ul>
<h3>jar上传</h3>
<ul>
<li>打包成springboot应用</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>    &lt;plugins&gt;
      &lt;plugin&gt;
        &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
        &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;
        &lt;configuration&gt;
          &lt;source&gt;1.8&lt;/source&gt;
          &lt;target&gt;1.8&lt;/target&gt;
        &lt;/configuration&gt;
      &lt;/plugin&gt;
      &lt;plugin&gt;
        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
        &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;
      &lt;/plugin&gt;
    &lt;/plugins&gt;
</code></pre></div><ul>
<li>maven clean package</li>
<li>上传将文件传送到服务器 scp *.sql root@ip://tmp/  -&gt; -r 复制文件夹</li>
<li>chmod 777 jar包</li>
<li><a href="http://deploy.sh" target="_blank" rel="noopener noreferrer">deploy.sh</a> 文件 nohup java -Xms400m -Xmx400m -XX:NewSize=200m -XX:MaxNewSize=200m -jar miaosha.jar --spring.config.addition-location=/var/www/miaosha/application.properties</li>
<li>chmod 777 <a href="http://deploy.sh" target="_blank" rel="noopener noreferrer">deploy.sh</a></li>
</ul>
<h3>安装nginx</h3>
<ul>
<li>下载openresty-1.13.6.2.tar.gz</li>
<li>chomd -R 777 openresty-1.13.6.2.tar.gz</li>
<li>tar -xvzf openresty-1.13.6.2.tar.gz</li>
<li>cd openresty-1.13.6.2</li>
<li>yum install pcre-devel openssl-devel gcc curl</li>
<li>编译 ./configure</li>
<li>make 编译</li>
<li>make install 安装</li>
<li>cd /usr/local/openresty
<ul>
<li>bin</li>
<li>luajit</li>
<li>nginx /sbin/nginx(这个文件替换掉就能替换了nginx)</li>
</ul>
</li>
<li>启动nginx nginx/sbin/nginx -c nginx/conf/nginx.conf</li>
<li>修改配置后直接sbin/nginx -s reload 无缝重启 不影响客户连接</li>
</ul>
<h2>分布式</h2>
<h3>单台应用</h3>
<ul>
<li>pstree -p 端口号 | wc -l 查看java线程数</li>
<li>top -H查看性能数量
<ul>
<li>%Cpu  1、us 用户态下CPU的耗时  2、sy 内核空间对CPU的耗时（socket send read） 两个加起来不能超100%</li>
<li>load average 最近 1 分钟 5 分钟 15分钟的 cpu load数量，越低越好 控制在CPU数内 高表示CPU很忙（死循环us高，但load average很低）</li>
</ul>
</li>
<li>sever端的并发线程数上不去（spring-configuration-metadata.json文件）</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>server.tomcat.accept-count:等待队列长度(超过就拒绝)，默认100-&gt;1000
server.tomcat.max-connections:最大可被连接数，默认10000
server.tomcat.max-threads:最大工作线程数，默认200-&gt;800 4核8G
server.tomcat.min-space-threads:最小工作线程数，默认10-&gt;100

默认配置下，连接超过10000后出现拒绝链接情况
默认配置下，触发的请求超过200+100后拒绝处理
</code></pre></div><p>keep-alive减少连接消耗<br>
keepAliveTimeOut:多少毫秒后不响应的断开keepalive<br>
maxKeepAliveRequests:多少次请求后keepalive断开失效</p>
<ul>
<li>定制化内嵌tomcat配置</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>//当spring容器内没有TomcatEmbeddedServletContainerFactory这个bean时，会把此bean加载进spring容器中
@Component
public class WebServerConfiguration implements WebServerFactoryCustomizer&lt;ConfigurableWebServerFactory&gt; {
    @Override
    public void customize(ConfigurableWebServerFactory factory) {
        ((TomcatServletWebServerFactory)factory).addConnectorCustomizers(new TomcatConnectorCustomizer() {
            @Override
            public void customize(Connector connector) {
                Http11NioProtocol http11NioProtocol = (Http11NioProtocol) connector.getProtocolHandler();

                //定制化keepalivetimeout 设置30秒内没有请求则服务器自动断开keepalive连接
                http11NioProtocol.setKeepAliveTimeout(30000);
                //当客户端发送超过10000个请求则自动断开keepalive连接
                http11NioProtocol.setMaxKeepAliveRequests(1000);
            }
        });
    }
}
</code></pre></div><ul>
<li>
<p>单机容量问题（响应时间变长 TPS上不去），</p>
<ul>
<li>线程数量：4核CPU 8G内存单进程调度线程数800-1000以上后即花费巨大时间在CPU调度上</li>
<li>等待队列长度：队列做缓冲池用，但也不能无限长，消耗内存，出队入队也耗CPU（1000-2000）</li>
<li>表象:单机CPU使用率增高，memory占用增加，网络带宽使用增加</li>
<li>cpu us ：用户空间的cpu使用情况（用户层代码）</li>
<li>cpu sy：内核空间的cpu使用情况（系统调用）</li>
<li>load average：1,5,15分钟load平均值，跟着核数系数，0代表正常1代表打满1+表示等待阻塞</li>
<li>memory fee空闲内存，used使用内存</li>
</ul>
</li>
<li>
<p>MySql QPS容量问题</p>
<ul>
<li>主键查询:千万级别数据 = 1-10毫秒</li>
<li>唯一索引查询:千万级别数据 = 10-100毫秒</li>
<li>非唯一索引查询:千万级别数据 = 100-1000毫秒 -&gt;分库分表，扩容热点数据</li>
<li>无索引:百万条数据 1000毫秒+ -&gt;分库分表，扩容热点数据</li>
</ul>
</li>
<li>
<p>Mysql TPS容量问题</p>
<ul>
<li>非插入更新删除操作:同查询 -&gt;where条件</li>
<li>插入操作:1w-10w tps（依赖配置优化）</li>
</ul>
</li>
</ul>
<h3>nginx反向代理(水平扩展)</h3>
<ul>
<li>水平扩展-&gt;使用nginx反向代理（1个nginx，2个jar，1个mysql共4个虚拟机）</li>
<li>nginx作为web服务器（静态）</li>
<li>nginx作为动静分离服务器</li>
<li>nginx作为反向代理服务器</li>
<li>nginx生产环境使用nas（无限容量）代替本地磁盘</li>
<li>OpenResty框架-&gt;nginx开发和调优OpenResty是一款基于 NGINX 和 LuaJIT 的 Web 平台。redis lua nginx配置都有</li>
</ul>
<ol>
<li>nginx静态资源访问配置（访问/resources/都是访问静态资源）</li>
</ol>
<ul>
<li>location节点path:指定url映射key</li>
<li>location节点内容:root指定location path后对应的根路径，index指定默认的访问页 alias 指替换调路径</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>worker_processes 1工作进程
events{
	worker_connections 1024;可以接受的工作连接
}
mine.types-&gt;content-type设置

location /resources/ { -&gt;/resource/xxxx 替换为 /usr/local/openresty/nginx/html/resources/
	alias /usr/local/openresty/nginx/html/resources/;
	index index.html index.html;
}
</code></pre></div><p>2.反向代理配置（默认与后端没有长连接keep alive）数据库连接池和h5与nginx有keepalive，长连接<br>
2.1设置upstream server</p>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>server{
	upstream back_server {
		server ip:port weight=1;
		server ip:port weight=1;
		keepalive 30;//设置nginx与后端长连接30s，30内没操作断开 与 http1.1配合使用
	}
}
</code></pre></div><p>2.2设置动态请求location为proxy pass 路径</p>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>	location  /{
		proxy_pass http://back_server;
		proxy_set_header Host $http_host:$proxy_port;
		proxy_set_header X-Real-IP $remote_addr;
		proxy_set_header : X-Forwared-For $proxy_add_x_forwarded_for;//代表nginx转发请求
		proxy_http_version 1.1;//使用keepalive
		proxy_set_header Connection "";//使用keepalive
		
	}
</code></pre></div><p>2.3开启tomcat access log验证<br>
在application.properties配置<br>
server.tomcat.accesslog.enabled=true<br>
server.tomcat.accesslog.directory=/var/www/miaosha/tomcat //先创建<br>
server.tomcat.accesslog.pattern=%h %l %u %t "%r" %s %b %D<br>
%h-&gt;远端ip<br>
%l-&gt; -<br>
%u-&gt;远端用户<br>
%t-&gt;耗时<br>
%r-&gt;请求信息方法和url<br>
%s-&gt;返回状态码<br>
%b-&gt;byte send响应大小<br>
%D-&gt;处理请求时长<br>
设置长连接优化 proxy_http_version 1.1;//使用keepalive proxy_ser_header Connection "";//使用keepalive<br>
keepalive 30;//设置nginx与后端长连接30s，30内没操作断开 与 http1.1配合使用</p>
<ul>
<li>
<p>nginx高性能原因</p>
</li>
<li>
<p>epoll多路复用机制完成非阻塞IO操作</p>
<ul>
<li>bio模型。阻塞式进程模型，write过程阻塞，等到网络完成才能继续执行、</li>
<li>linux select模型 变更触发轮询查找， 有1024数量上限 首先阻塞自己，监听100个客户连接是否有变化，若有变化则唤醒自己，循环遍历100连接，找到发生变化的一个或者多个执行read操作。遍历效率低，连接数量有上限</li>
<li>epoll模型，变更触发回调直接读取，理论上无上限，不会断开客户连接，监听100个客户端连接是否有变化，设置回调函数，若有变化则唤醒自己，并执行回调函数</li>
</ul>
</li>
<li>
<p>java nio-》自动选择select或者epoll模型。linux内核2.6以上才有epoll模型</p>
</li>
<li>
<p>master worker 进程模型平滑加载和重启,不会断开与客户端连接<br>
master worker父子进程-&gt;master可以管理worker进程内存空间（两者共享内存，根据worker_processes配置worker进程数），worker进程可以竞争处理客户端连接accept请求，用内存锁保证多个worker进程能有序负责某个连接，一旦accept之后，就由当时处理的worker进程一直处理下去。reload配置文件只会切换worker进程，master进程不会修改，客户端也不会断开socket连接，是因为重启的时候将所有worker进程句柄交给master进程，重启时，master进程又交回给新的worker进程去处理，每个worker进程都是单线程的，没有阻塞的话，单线程比多线程快，只做了内核空间转向外部空间的拷贝。并没有阻塞什么，所以高性能</p>
</li>
<li>
<p>协程机制 非阻塞编程 单进程单线程<br>
依附于线程的内存模型，切换开销小（内存切换）而线程是CPU切换开销<br>
遇到阻塞及归还执行权，代码同步，可以处理大量的异步回调函数（大量异步函数嵌套，本身不好做顺序控制），协程可以作顺序控制，写代码可以直接return<br>
无需加锁，串行执行</p>
</li>
</ul>
<h3>分布式会话管理</h3>
<ul>
<li>基于cookie传输sessionid（jsessionid）：tomcat实现session（转移到redis）(移动端不行，禁cookie)<br>
@Autowired<br>
private HttpServletRequest httpServletRequest;</li>
</ul>
<p>httpServletRequest.getSession.setAttribute("xx",xx);</p>
<ul>
<li>基于token(令牌)实现sessionid：java实现session（uuid）（转移到redis）<br>
请求带上？token =<br>
后端 String token2 = this.httpServletRequest.getParameterMap().get("token")[0];//拿到</li>
</ul>
<p>@Autowired<br>
private RedisTemplate redisTemplate;</p>
<p>String uuidToken = UUID.randomUUID().toString();<br>
redisTemplate.opsForValue().set(uuidToken,userModel);<br>
redisTemplate.expire(token,1, TimeUnit.HOURS);</p>
<p>redisTemplate.opsForValue().get(uuidToken,userModel);</p>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>下载redis
chmod -R 777 redis-5.0.4.tag.gz
tar -zxvf redis-5.0.4.tag.gz
cd redis-5.0.4
./configure
make
make install
cd src
./redis-server

    &lt;dependency&gt;
      &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
      &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
      &lt;groupId&gt;org.springframework.session&lt;/groupId&gt;
      &lt;artifactId&gt;spring-session-data-redis&lt;/artifactId&gt;
      &lt;version&gt;2.0.5.RELEASE&lt;/version&gt;
    &lt;/dependency&gt;
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>spring.redis.host=127.0.0.1
spring.redis.port=6379
spring.redis.password=xxx
#默认16个数据库
spring.redis.database=0
#连接池
spring.redis.jedis.pool.max-active=50
spring.redis.jedis.pool.max-idle=20

@Component
@EnableRedisHttpSession(maxInactiveIntervalInSeconds = 3600)
public class RedisConfig {
    //将java序列化转成json序列化
    @Bean
    public RedisTemplate restTemplate(RedisConnectionFactory redisConnectionFactory) {
        RedisTemplate redisTemplate = new RedisTemplate();
        redisTemplate.setConnectionFactory(redisConnectionFactory);

        //设置key序列化方式-&gt;不设置则表示一定要实现序列化接口
        StringRedisSerializer stringRedisSerializer = new StringRedisSerializer();
        redisTemplate.setKeySerializer(stringRedisSerializer);

        //解决value的序列化方式-&gt;不设置则表示一定要实现序列化接口
        Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class);
        ObjectMapper objectMapper = new ObjectMapper();
        SimpleModule simpleModule = new SimpleModule();
        simpleModule.addDeserializer(DateTime.class, new JodaDateTimeJsonDeserializer());
        simpleModule.addSerializer(DateTime.class, new JodaDateTimeJsonSerializer());

        //各个属性都能有对应的解析说明，加了列的类型说明
        objectMapper.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL);

        objectMapper.registerModule(simpleModule);
        jackson2JsonRedisSerializer.setObjectMapper(objectMapper);
        redisTemplate.setValueSerializer(jackson2JsonRedisSerializer);

        return redisTemplate;
    }
}

public class JodaDateTimeJsonDeserializer extends JsonDeserializer&lt;DateTime&gt; {
    @Override
    public DateTime deserialize(JsonParser jsonParser, DeserializationContext deserializationContext) throws IOException, JsonProcessingException {
        String dateString = jsonParser.readValueAs(String.class);
        DateTimeFormatter formatter = DateTimeFormat.forPattern("yyyy-MM-dd HH:ss");

        return DateTime.parse(dateString,formatter);
    }
}
public class JodaDateTimeJsonSerializer extends JsonSerializer&lt;DateTime&gt; {
    @Override
    public void serialize(DateTime dateTime, JsonGenerator jsonGenerator, SerializerProvider serializerProvider) throws IOException {
        jsonGenerator.writeString(dateTime.toString("yyyy-MM-dd HH:mm:ss"));

    }
}
</code></pre></div><h2>查询多级缓存（丢失）</h2>
<ul>
<li>缓存设计
<ul>
<li>用内存做缓存</li>
<li>将缓存推到离用户最近的地方，性能越高，但是更新越难</li>
<li>脏缓存清理-&gt;数据更新了缓存没更新的情况（牺牲内存，并且有脏读问题）</li>
</ul>
</li>
<li>nginx proxy cache缓存</li>
<li>nginx lua缓存</li>
</ul>
<h3>redis缓存</h3>
<ul>
<li>redis缓存（网络，集中式负载均衡瓶颈）-&gt;一般把model放入到redis中缓存起来，并且记得设置超时时间，记得实现序列化接口(默认)<br>
redis nosql数据库可以持久化，集中式缓存，可以丢失<br>
单机，容量，故障瓶颈，所有业务炸掉<br>
sentinal哨兵模式 redis1对应一个slave redis2，则redis1会将数据同步到redis2，redis1挂了使用redis2，两者主从关系。redis sentinel与多个redis建立长连接，通过心跳机制，而后台访问redis sentinel决定redis主从问题，最后后台直接访问该redis<br>
容量问题明显，master不好扩容，难以复制数据</li>
</ul>
<p>cluster集群模式<br>
redis都在互连，使用算法保证高可用，后端只要访问其中一个redis就行</p>
<p>//配合RedisConfig<br>
redisTemplate.opsForValue().set(uuidToken,userModel);<br>
redisTemplate.expire(token,1, TimeUnit.HOURS);</p>
<p>redisTemplate.opsForValue().get(uuidToken,userModel);</p>
<h3>本地缓存</h3>
<ul>
<li>存放热点数据，较少redis访问，减少io，在每秒上万情况下</li>
<li>脏读非常不敏感，分散，数据难同步（可以用mq解决，但没必要）</li>
<li>内存可控</li>
<li>生命周期短，比redis短</li>
<li>内存jvm本地缓存</li>
<li>方案使用Guava cache有淘汰机制，能支持并发读写（线程安全）
<ul>
<li>可控制的大小和超时时间</li>
<li>可配置的lru策略(最近最少访问优先淘汰)</li>
<li>线程安全</li>
</ul>
</li>
</ul>
<p>先去取本地缓存-&gt;redis-&gt;mysql<br>
<br>
@Service<br>
public class CacheServiceImpl implements CacheService {</p>
<pre><code>private Cache&lt;String,Object&gt; commonCache = null;

@PostConstruct
public void init(){
    this.commonCache = CacheBuilder.newBuilder()
            //设置缓存容器初始容量为10
            .initialCapacity(10)
            //设置缓存中最大可以存储100个KEY,超过100个之后会按照LRU的策略移除缓存项
            .maximumSize(100)
            //设置写缓存后多少秒过期
            .expireAfterWrite(30, TimeUnit.SECONDS).build();
}

@Override
public void setCommonCache(String key, Object value) {
    commonCache.put(key,value);
}

@Override
public Object getCommonCache(String key) {
    return commonCache.getIfPresent(key);
}
</code></pre>
<p>}</p>
<h3>nginx proxy 缓存（少用，因为还是访问文件）</h3>
<ul>
<li>nginx proxy cache缓存（不好用，因为读文件，反而比其他内存缓存慢）</li>
<li>必须是nginx反向代理前置才能生效</li>
<li>依靠文件系统存索引级文件（把请求当做文件，去本地找是否有对应文件，有则缓存生效）</li>
<li>依靠内存缓存文件地址</li>
</ul>
<p>在nginx.conf中声明<br>
http{<br>
#声明一个cache缓存节点内容，生成二级目录，在url生成hash值时取最后一位当第一级目录，倒数第二位当二级目录 inactive=7d保存7天<br>
proxy_cache_path /usr/local/openresty/nginx/tmp_cache levels=1:2 keys_zone=tmp_cache:100m inactive=7d<br>
max_size=10g;<br>
location /{<br>
proxy_cache tmp_cache;<br>
proxy_cache_key $uri;<br>
# 返回状态码200 206 304 302<br>
proxy_cache_valid 200 206 304 302 7d;<br>
}<br>
}</p>
<h3>nginx lua缓存（放nginx内存，推荐）</h3>
<p>nginx 内存缓存(最好热点数据)</p>
<ul>
<li>
<p>lua协程机制，线程空间栈的执行单元，串行执行，用户态模拟出来的内存空间，以同步方式编写代码</p>
</li>
<li>
<p>nginx协程机制</p>
</li>
<li>
<p>nginx lua插载点</p>
</li>
<li>
<p>OpenResty</p>
</li>
<li>
<p>协程机制</p>
</li>
<li>
<p>依附于线程的内存模型，切换开销小</p>
</li>
<li>
<p>遇阻塞即归还执行权，代码同步</p>
</li>
<li>
<p>无需加锁</p>
</li>
<li>
<p>nginx协程</p>
</li>
<li>
<p>nginx的每一个worker进程都是在epoll或kqueue这种事件模型之上，封装成协程</p>
</li>
<li>
<p>每一个请求都有一个协程进行处理</p>
</li>
<li>
<p>即使ngx_lua须运行Lua，相对C有一定开销，但依旧能保证高并发能力</p>
</li>
<li>
<p>nginx每个worker进程都创建一个lua虚拟机</p>
</li>
<li>
<p>worker进程内所有协程共享同一个lua虚拟机</p>
</li>
<li>
<p>每个外部请求由一个lua协程处理，协程间数据隔离</p>
</li>
<li>
<p>lua代码 调用io等异步接口时，协程被挂起，上下文数据自动保存，不阻塞worker进程，io异步操作完成后还原协程上下文，代码继续执行</p>
</li>
</ul>
<p>nginx处理阶段<br>
NGX_HTTP_POST_READ_PHASE=0;//读取请求头<br>
NGX_HTTP_SERVER_REWRITE_PHASE;//执行rewrite -&gt;rewrite_handler定制开发<br>
NGX_HTTP_FIND_CONFIG_PHASE;//根据uri替换location<br>
NGX_HTTP_REWRITE_PHASE;//根据替换结果继续执行rewrite-&gt; reweite_handler定制开发<br>
NGX_HTTP_POST_REWRITE_PHASE;//执行rewrite后处理<br>
NGX_HTTP_PREACCESS_PHASE;//认证预处理，请求限制，连接限制 -&gt; limit_conn_hander_limit_req_handler定制开发<br>
NGX_HTTP_ACCESS_PHASE;//认证处理-&gt;auth_basic_handler_access_handler定制开发<br>
NGX_HTTP_POST_ACCESS_PHASE;//认证后处理，认证不通过，丢包<br>
NGX_HTTP_TRY_FILES_PHASE;//尝试try标签<br>
NGX_HTTP_CONTENT_PHASE;//内容处理-&gt;static_handler 定制开发<br>
NGX_HTTP_LOG_PHASE;//日志处理-&gt;log_handler</p>
<p>nginx lua插载点<br>
init_by_lua:系统启动时调用<br>
init_worker_by_lua:worker进程启动时调用<br>
set_by_lua:NGINX变量用复杂lua return<br>
rewrite_by_lua:重写url规则<br>
access_by_lua:权限认证阶段<br>
content_by_lua:内容输出节点</p>
<ul>
<li>使用lua<br>
init.lua文件<br>
ngx.lua(ngx.ERR,"init lua success");</li>
</ul>
<p>content.lua文件<br>
ngx.say("hello");<br>
ngx.exec("url");//nginx代理请求</p>
<p>在http模块下<br>
http{<br>
init_by_lua_file /usr/local/init.lua;<br>
location /xxx/ {<br>
default_type "text/html";<br>
content_by_lua_file	/usr/local/content.lua;<br>
}<br>
}</p>
<ul>
<li>开发OpenResty与nginx的lua(放入nginx的内存里面)</li>
<li>OpenResty由Nginx核心加很多第三方模块组成，默认集成了Lua开发环境，使得Nginx可以作为一个web server使用</li>
<li>借助于nginx的时间驱动模型和非阻塞IO,可以实现高性能的web应用程序</li>
<li>openResty提供了大量组件如mysql，redis，memcached等等，使在nginx上开发web应用方便简单</li>
<li>shared dic共享内存字典，所有worker进程可见，lru淘汰<br>
在nginx 文件中<br>
http{<br>
lua_shared_dict my_cache 128m<br>
location /xxx/ {<br>
default_type "application/json";<br>
content_by_lua_file	/usr/local/sharedic.lua;<br>
}<br>
}</li>
</ul>
<p>sharedic.lua文件</p>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>function get_from_cache(key)
	local cache_ngx = ngx.shared.my_cache
	local value = cache_ngx:get(key)
return value
end

function set_to_cache(key,value,exptime)
	if not exptime then 
		exptime = 0
	end
	local cache_ngx = ngx.shared.my_cache
	local succ,err,forcible = cache_ngx:set(key,value,exptime)
	return succ
end

local args = ngx.req.get_uri.args()
local id = agrs["id"]
local item_model = get_from_cache("item"..id)
if item_model == nill then
	local resp = ngx.location.capture("/item/get?id="..id)
	item_model = resp.body
	set_to_cache("item_"..id,item_model,1*60)
end
ngx.say(item_model)
</code></pre></div><p>openresty redis支持（减少访问jar消耗，减少数据更新问题）推荐</p>
<p>在nginx 文件中<br>
http{<br>
lua_shared_dict my_cache 128m<br>
location /xxx/ {<br>
default_type "application/json";<br>
content_by_lua_file	/usr/local/redis.lua;<br>
}<br>
}</p>
<p>redis.lua<br>
local args = ngx.req.get_uri.args()<br>
local id = agrs["id"]<br>
local cache = redis:new()<br>
local ok,err = cache:connect("127.0.0.1",6379)<br>
local item_model = cache:get(""item_"..id)<br>
if item_model == ngx.null or item_model == nil then<br>
local resp = ngx.location.capture("/item/get?id="..id);<br>
item_model =resp.body<br>
end</p>
<p>ngx.say(item_model)</p>
<h3>动态缓存cdn(访问静态资源html)</h3>
<ul>
<li>
<p>静态请求CDN（使用阿里云CDN加速和配置CNAME）<br>
DNS用CNAME解析到源站，域名解析分成A解析和CNAME解析等A解析就是域名-&gt;ip,而CNAME就是将请求发送到CNAME指定的服务器，然后由CNAME的服务器处理，此时CNAME的服务器会指向一个最近的服务器ip，该服务器会判断是否有缓存，没有则请求源站（回源）</p>
</li>
<li>
<p>回源缓冲设置</p>
</li>
<li>
<p>cache control响应头</p>
</li>
<li>
<p>private 客户端可以缓存（默认）</p>
</li>
<li>
<p>public：客户端和代理服务器都可以缓存</p>
</li>
<li>
<p>max-age=xxx:缓存的内容将在xxx秒后失效</p>
</li>
<li>
<p>no-cache：强制向服务端再验证一次</p>
<ul>
<li>有效性判断：ETag资源唯一标识，</li>
<li>Etag一致则 if-None-Match 客户端发送的匹配Etag标识符-&gt;一致则304</li>
<li>Etag不致则 -&gt;Last-modified: 资源最后被修改时间 if-Modified-Since:客户端发送的匹配资源最后修改时间的标识符 -&gt;一致则304</li>
</ul>
</li>
<li>
<p>no-store:不缓存请求的任何返回内容</p>
</li>
<li>
<p>浏览器的三种刷新方式</p>
</li>
<li>
<p>回车或a链接：cache-control对应的max-age是否仍然有效，有效则直接from cache，若cache-control中为no-cache，则进入缓存协商逻辑</p>
</li>
<li>
<p>F5刷新或command+R刷新：去掉cache-control中的max-age或直接设置max-age为0，然后进入缓存协商逻辑</p>
</li>
<li>
<p>ctrl+F5或commond+shift+R刷新：去掉cache-control和协商头，强制刷新</p>
</li>
<li>
<p>协商机制，比较Last-modified和Etag到服务端，若服务端判断没变化则304不返回数据否则200返回数据</p>
</li>
<li>
<p>CDN自定义缓存策略</p>
</li>
<li>
<p>可自定义目录过期时间</p>
</li>
<li>
<p>可自定义后缀名过期时间</p>
</li>
<li>
<p>可自定义对应权重</p>
</li>
<li>
<p>可通过界面或api强制刷新cdn对应目录刷新（非保成功，有通信限制）</p>
</li>
<li>
<p>静态资源cdn深入讲解--CDN自定义缓存策略04:16</p>
</li>
<li>
<p>静态资源部署策略</p>
</li>
<li>
<p>html必定no-cache或者max-age很短,便于更新。html文件或者设置较长的max age。依靠动态的获取版本号请求（对比版本号）发送到后端，异步下载最新的版本号的html后展示渲染在前端</p>
</li>
<li>
<p>css,js,img等元素使用带版本号部署，a.js?v=1.0，不便利，维护困难</p>
</li>
<li>
<p>css,js,img等元素使用带摘要部署，例如a.js?v=45edw存在先部署html还是先部署资源的覆盖问题，因为所有html与资源都要更新</p>
</li>
<li>
<p>（推荐）css,js,img等元素使用摘要做文件名，例如45edw.js,新老版本并存且可回滚，资源部署后再部署html-&gt;css,js,img对应静态资源保持生命周期内不会变，max-age可设置的很长，无视失效更新周期</p>
</li>
<li>
<p>动态请求也可以静态化成json资源推送到cdn上（获取商品）</p>
</li>
<li>
<p>前端先显示旧版本，因为cdn推送不一定成功，所以可以再依靠异步请求获取后端节点比对版本号，不一致则可以对对应资源状态做紧急下架处理（覆盖）</p>
</li>
<li>
<p>可通过跑批紧急推送cdn内容以使其下架等操作</p>
</li>
</ul>
<p>强推失效</p>
<ul>
<li>
<p>全页面静态化</p>
</li>
<li>
<p>html，css，js静态资源cdn化+js ajax 动态请求cdn化=全页面静态化</p>
</li>
<li>
<p>在服务端完成html，css，甚至js的load渲染成html文件后直接以静态资源的方式部署到cdn上（已渲染好的页面）</p>
</li>
<li>
<p>使用phantomjs（本质爬虫）</p>
</li>
<li>
<p>无头浏览器，可以借助器模拟webkit js的执行<br>
修改需要全页面静态化的实现，采用initView和hasInit方式防止多次初始化(写程序保证只加载一次)<br>
编写对应轮询生成内容方式<br>
将全静态话页面生成后推送到cdn</p>
</li>
</ul>
<p>xxx.js<br>
var page = require("webpage").create();<br>
var fs = require("fs");<br>
page.open("<a href="http://xxxx" target="_blank" rel="noopener noreferrer">http://xxxx</a>",function(status){<br>
console.log("status = " + status);<br>
setTimeout(function(){<br>
<a href="//page.evaluate" target="_blank" rel="noopener noreferrer">//page.evaluate</a>(function(){<br>
//调用拿到的请求的html里面的函数		<br>
//});<br>
fs.write("xxxx.html",page.content,"w");<br>
phantom.exit();<br>
},1000);</p>
<p>})</p>
<p>bin/phantomjs js/genitem.js</p>
<h3>动态请求缓存</h3>
<h3>页面静态化</h3>
<h2>交易泄压</h2>
<h3>缓存库存</h3>
<p>交易性能瓶颈<br>
交易验证完全依赖数据库(判断商品和用户，活动信息)<br>
数据库行锁；某个id（扣减库存）<br>
后置处理逻辑（保存订单，增加销量）</p>
<p>交易验证优化<br>
用户风控策略优化：策略缓存模型优化（放redis并设置超时时间）<br>
活动校验策略优化（放redis并设置超时时间）：引入活动发布流程，模型缓存化，紧急下线能力（异常商品去掉redis缓存即可）</p>
<p>库存行锁优化<br>
update的时候如果没有指定索引的话会锁表，有索引的话有行锁，行锁保证某条数据的更新操作串行化</p>
<p>扣减缓存异步化-&gt;1.活动发布同步库存进缓存-&gt;2.下单交易减库存缓存<br>
异步同步数据库-&gt;3.异步事务型消息扣减数据库内库存（异步消息队列rocketmq）高性能，高并发，分布式消息中间件<br>
应用，分布式事务，异步解耦（producer，name server consumer（注册中心），consumer group（consumer），broker（queue））-&gt;引入库存操作流水（库存数量，商品id，操作流水号，订单状态，操作前insert初始状态，操作完update为已扣减库存状态，操作中select查看操作状态，若为已扣减，则提交事务，否则回滚事务）-&gt;库存数据库最终一致性保证<br>
redis不能用时如何处理？扣减流水错误如何处理？</p>
<p>库存设计原则：<br>
宁可少卖，不能超卖<br>
redis可以比实际数据库中少，订单长时间没处理时，需要超时释放库存，把库存加回去</p>
<p>分布式事务<br>
CAP理论，最终一致性BASE<br>
安装rocketmq<br>
下载rocketmq<br>
chomd -R 777<br>
yum install unzip<br>
unzip rocketmq-all-4.4.0-release.zip<br>
cd rocketmq-all-4.4.0-release<br>
nohup sh bin/mqnamesrv(9876端口)<br>
nohup sh bin/mqbroker -n localhost:9876</p>
<p>mq.nameserver=xxxx:port<br>
mq.topicname=xx</p>
<pre><code>&lt;dependency&gt;
  &lt;groupId&gt;org.apache.rocketmq&lt;/groupId&gt;
  &lt;artifactId&gt;rocketmq-client&lt;/artifactId&gt;
  &lt;version&gt;4.3.0&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>//异步修改库存，要保证数据库插入订单和redis扣减库存成功后才异步把数据库扣减
TransactionSynchronizationManager.registerSynchronization(new TransactionSynchronizationAdapter() {
    @Override
    public void afterCommit() {

        super.afterCommit();
    }
});

确保最近的事务提交完成后会触发
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>@Component
public class MqProducer {

    @Autowired
    private DefaultMQProducer producer;

    @Autowired
    private TransactionMQProducer transactionMQProducer;

    @Value("${mq.nameserver.addr}")
    private String nameAddr;

    @Value("${mq.topicname}")
    private String topicName;

    @PostConstruct
    public void init() throws MQClientException {
        producer = new DefaultMQProducer("producer_group");
        producer.setNamesrvAddr(nameAddr);
        producer.start();

        transactionMQProducer = new TransactionMQProducer("transaction_producer_group");
        transactionMQProducer.setNamesrvAddr(nameAddr);
        transactionMQProducer.start();
        transactionMQProducer.setTransactionListener(new TransactionListener() {
            @Override
            public LocalTransactionState executeLocalTransaction(Message message, Object o) {
                 //真正要做的事  创建订单
                Integer itemId = (Integer) ((Map)arg).get("itemId");
                Integer promoId = (Integer) ((Map)arg).get("promoId");
                Integer userId = (Integer) ((Map)arg).get("userId");
                Integer amount = (Integer) ((Map)arg).get("amount");
                String stockLogId = (String) ((Map)arg).get("stockLogId");
                try {
                    orderService.createOrder(userId,itemId,promoId,amount,stockLogId);
                } catch (BusinessException e) {
                    e.printStackTrace();
                    //设置对应的stockLog为回滚状态
                    StockLogDO stockLogDO = stockLogDOMapper.selectByPrimaryKey(stockLogId);
                    stockLogDO.setStatus(3);
                    stockLogDOMapper.updateByPrimaryKeySelective(stockLogDO);
                    return LocalTransactionState.ROLLBACK_MESSAGE;
                }
                return LocalTransactionState.COMMIT_MESSAGE;
            }

            @Override
            //事务执行时间太长的时候rocketmq要回调这个方法，这里应该检查redis库存
            public LocalTransactionState checkLocalTransaction(MessageExt messageExt) {
		        //查询操作流水中操作的状态，用数据库并传入流水号
                //如果订单状态为已扣减，则成功，否则unknown
                return null;
            }
        });
    }
    //事务性扣减库存
    //事务型同步库存扣减消息
    public boolean transactionAsyncReduceStock(Integer userId,Integer itemId,Integer promoId,Integer amount,String stockLogId){
        Map&lt;String,Object&gt; bodyMap = new HashMap&lt;&gt;();
        bodyMap.put("itemId",itemId);
        bodyMap.put("amount",amount);
        bodyMap.put("stockLogId",stockLogId);

        Map&lt;String,Object&gt; argsMap = new HashMap&lt;&gt;();
        argsMap.put("itemId",itemId);
        argsMap.put("amount",amount);
        argsMap.put("userId",userId);
        argsMap.put("promoId",promoId);
        argsMap.put("stockLogId",stockLogId);

        Message message = new Message(topicName,"increase",
                JSON.toJSON(bodyMap).toString().getBytes(Charset.forName("UTF-8")));
        TransactionSendResult sendResult = null;
        try {

            sendResult = transactionMQProducer.sendMessageInTransaction(message,argsMap);
        } catch (MQClientException e) {
            e.printStackTrace();
            return false;
        }
        if(sendResult.getLocalTransactionState() == LocalTransactionState.ROLLBACK_MESSAGE){
            return false;
        }else if(sendResult.getLocalTransactionState() == LocalTransactionState.COMMIT_MESSAGE){
            return true;
        }else{
            return false;
        }

    }
    //无事务发送
    public boolean send(String itemId,Integer amount) {
        Map&lt;String,Object&gt; bodyMap = new HashMap&lt;&gt;();
        bodyMap.put("itemId",itemId);
        bodyMap.put("amount",amount);
        Message message = new Message(topicName,"increse",
                JSON.toJSON(bodyMap).toString().getBytes(Charset.forName("UTF-8")));
        try {
            producer.send(message);
        } catch (MQClientException e) {
            e.printStackTrace();
            return false;
        } catch (RemotingException e) {
            e.printStackTrace();
            return false;
        } catch (MQBrokerException e) {
            e.printStackTrace();
            return false;
        } catch (InterruptedException e) {
            e.printStackTrace();
            return false;
        }
        return true;
    }
}
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>@Component
public class MqConsumer {

    @Autowired
    private DefaultMQPushConsumer consumer;

    @Value("${mq.nameserver.addr}")
    private String nameAddr;

    @Value("${mq.topicname}")
    private String topicName;

    @PostConstruct
    public void init() throws MQClientException {
        consumer = new DefaultMQPushConsumer("stock_consumer_group");
        consumer.setNamesrvAddr(nameAddr);
        consumer.subscribe(topicName,"*");
        consumer.registerMessageListener(new MessageListenerConcurrently() {
            @Override
            public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; list, ConsumeConcurrentlyContext consumeConcurrentlyContext) {
                Message msg = list.get(0);
                String body = new String(msg.getBody());
                return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;
            }
        });
    }
}
</code></pre></div><h3>交易异步化</h3>
<h3>异步化事务</h3>
<p>操作流水<br>
数据类型<br>
主业务数据master data<br>
操作性数据log data</p>
<p>库存售罄<br>
库存售罄标识，放到redis<br>
出售前判断是否售罄，售罄后不去操作后续流程<br>
售罄后通知各系统售罄<br>
回补上新</p>
<p>后置流程<br>
销量逻辑异步化<br>
交易单逻辑异步化（生成交易单sequence后直接异步返回，前端轮询异步单状态）</p>
<h2>流量错峰</h2>
<p>流量削峰技术<br>
秒杀下单接口会被脚本不停的刷<br>
秒杀验证逻辑和秒杀下单接口强关联，代码冗余度高-&gt;引入秒杀令牌<br>
秒杀验证逻辑复杂，对交易系统产生无关联负载-&gt;引入秒杀令牌</p>
<h3>秒杀令牌</h3>
<p>秒杀令牌原理（少流量）<br>
秒杀接口需要依靠令牌才能进入（uid+商品id+秒杀id）<br>
秒杀的令牌由秒杀模块生成<br>
秒杀活动模块对秒杀令牌生成全权处理（将验证用户，商品，活动迁移到令牌生成，没有令牌不能下单，放redis，前端需要单独获取秒杀令牌，后端单独写秒杀令牌），逻辑收口（没有令牌不往下走）<br>
秒杀下单前需要获得秒杀令牌，没有令牌则不能下单</p>
<h3>秒杀大闸</h3>
<p>秒杀令牌只要活动一开始就无限制生成，影响系统性能<br>
解决方案：依靠秒杀令牌的授权原理定制化发牌逻辑，做到大闸功能，<br>
根据秒杀商品初始库存颁发对应数量的令牌，控制大闸流量，在redis保存库存数乘以系数个数量，然后放到redis中，每次生成秒杀令牌减掉1然后为0则不再发牌<br>
用户风控策略前置到秒杀令牌发放中<br>
库存售罄判断前置到秒杀令牌发放中</p>
<h3>队列泄洪</h3>
<p>浪涌流量涌入后系统无法应对（超大流量）<br>
多库存，多商品等令牌限制能力弱<br>
解决方案-&gt;队列泄洪原理<br>
排队有时候比并发更高效（redis单线程模型 innodb mutex key等）<br>
依靠排队去限制并发流量<br>
依靠排队和下游拥塞窗口程度调整队列释放流量大小-&gt;支付宝银行网关队列举例,支付宝做拥塞窗口处理，保证下游银行的tps</p>
<p>实现 本地：将队列维护在本地内存中（生产环境，推荐）<br>
分布式：将队列设置到外部redis内，性能太差，负载大<br>
企业一般是集中式异常，超时后转本地<br>
private ExecutorService executorService;</p>
<pre><code>@PostConstruct
public void init(){
    executorService = Executors.newFixedThreadPool(20);

}

    Future&lt;Object&gt; submit = executorService.submit(new Callable&lt;Object&gt;() {
        @Override
        public Object call() throws Exception {

            return null;

        }
    });
    try {
        submit.get();
    } catch (InterruptedException e) {
        e.printStackTrace();
    } catch (ExecutionException e) {
        e.printStackTrace();
    }
    return;
</code></pre>
<h2>防刷限流</h2>
<h3>验证码</h3>
<p>包装秒杀令牌前置，需要验证码来错峰<br>
数学公式验证码生成器,生成验证码返回给前端，然后放入redis在生成秒杀令牌时校验一下，没有校验过的不发放秒杀令牌</p>
<h3>限流器</h3>
<p>系统宁愿只让少数人能用，不能让所有人不能用<br>
方案<br>
1.限制并发 tps 每秒处理请求数量（不用）<br>
2.令牌桶算法 令牌桶算法的原理是系统会以一个恒定的速度往桶里放入令牌，而如果请求需要被处理，则需要先从桶里获取一个令牌，当桶里没有令牌可取时，则拒绝服务。（常用）<br>
3.漏桶算法，水（请求）先进入到漏桶里，漏桶以一定的速度出水，当水流入速度过大会直接溢出，可以看出漏桶算法能强行限制数据的传输速率。</p>
<p>对于很多应用场景来说，除了要求能够限制数据的平均传输速率外，还要求允许某种程度的突发传输。这时候漏桶算法可能就不合适了，令牌桶算法更为适合。</p>
<p>限流力度<br>
接口维度（限制controller）<br>
总维度（计算机资源限制）</p>
<p>限流范围<br>
集群限流：依赖redis或其他中间件技术做统一计数器，往往会产生性能瓶颈<br>
单机限流：负载均衡的前提下单机平均限流效果更好</p>
<pre><code>&lt;dependency&gt;
  &lt;groupId&gt;com.google.guava&lt;/groupId&gt;
  &lt;artifactId&gt;guava&lt;/artifactId&gt;
  &lt;version&gt;18.0&lt;/version&gt;
&lt;/dependency&gt;
private RateLimiter rateLimiter;

@PostConstruct
public  void init(){
    rateLimiter = RateLimiter.create(300);
}

    if(!rateLimiter.tryAcquire()){
        throw new RuntimeException("xxx");
    }
</code></pre>
<h3>防黄牛</h3>
<p>排队，限流，令牌均只能控制总流量，无法控制黄牛流量<br>
传统防刷<br>
限制一个会话(session_id,token)同一秒钟/分钟接口调用多少次-&gt;多会话接口绕开无效<br>
限制一个ip同一秒钟/分钟 接口调用多少次，数量不好控制-&gt;容易误伤</p>
<p>使用设备指纹防刷<br>
采集终端设备各项参数，启动应用时生成唯一设备指纹<br>
根据对应设备指纹的参数猜测出模拟器等可疑设备概率</p>
<p>凭证系统<br>
根据设备指纹下发凭证<br>
关键业务链路上带上凭证并由业务系统到凭证服务器上验证<br>
凭证服务器根据对应凭证所等价的设备指纹参数并根据实时行为风控系统判定对应凭证的可疑分数<br>
若分数低于某个数值则业务系统返回固定错误码，拉起前端验证码验身，验身成功后加入凭证服务器对应分数</p>
<p>H5最难防</p>
<h2>性能测试</h2>
<h3>jemeter压测</h3>
<ul>
<li>线程组 高并发压测 -&gt;发送http请求 -&gt;查看结果树 -&gt;聚合报告 tps qps :</li>
<li>新建测试计划
<ul>
<li>添加线程组-&gt;线程数-&gt;Ramp-up时间（多少秒内启动所有线程）-&gt;循环次数(每个线程调用接口几次)
<ul>
<li>添加http请求-&gt;名称-&gt;协议-&gt;服务器名称ip-&gt;请求方法-&gt;路径,同时选择keep-alive，因为要测的是返回时间而不是连接断开或者连接的时间
<ul>
<li>高级-&gt;客户端实现一定要选java</li>
</ul>
</li>
<li>添加察看结果树</li>
<li>添加聚合报表
<ul>
<li>Throughput (tps)每秒能接受多少流量</li>
<li>Average平均响应时间</li>
<li>Median中位线响应时间</li>
<li>90%Line 90%响应时间小于多少毫秒</li>
<li>Min最小返回时间</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3>压测优化</h3>
<h3>分布式会话管理</h3>
<p>分布式会话持久性管理-&gt;放redis，一定要redis高可用（redis cluster）<br>
会话有效期时间，tomcat默认30分钟，不与服务器发生交互的呆滞时间<br>
会话续命管理，触发操作延长生命周期，延长到30min，不是加30min<br>
安全性问题，用安全传输的https，但也会被浏览器捕获，最安全使用自定义协议并使用app提高安全性</p>
<p>强登录态与弱登录态<br>
强登录态：&gt;需要登录才能操作<br>
无需登录<br>
弱登录态: &gt;千人千面的智能推荐，电商，续命能力弱<br>
弱登录续命：&gt;1.请求续命，2.页面使用定时器请求续命（keepalive续命）</p>
<p>sso单点登录<br>
只要域名不一样时，cookie就不一样</p>
<ul>
<li>同域名：&gt;cookie一样，<a href="http://wwww.xxx.com/a/" target="_blank" rel="noopener noreferrer">wwww.xxx.com/a/</a> <a href="http://wwww.xxx.com/b/" target="_blank" rel="noopener noreferrer">wwww.xxx.com/b/</a></li>
<li>根域名相同，子域名不同 <a href="http://wap.a.com" target="_blank" rel="noopener noreferrer">wap.a.com</a> <a href="http://www.a.com" target="_blank" rel="noopener noreferrer">www.a.com</a>
<ul>
<li>httpOnly = false/true(除了浏览器自身，js无法访问cookieid)</li>
<li>domain =/  只要访问同一个一级域名时cookie域名就一样</li>
</ul>
</li>
<li>域名都不相同 <a href="http://a.com" target="_blank" rel="noopener noreferrer">a.com</a> <a href="http://b.com" target="_blank" rel="noopener noreferrer">b.com</a> 通过sso服务配合redirect，颁发cookie，然后返回需要请求的服务，服务缓存起来，后再去sso校验，成功后就继续服务，cookie颁发后一定要有有效期，或者强制更改手段，手动删除</li>
</ul>
<p>mysql应用性能优化拓展:&gt;缓存，异步，批处理<br>
写操作：批量insert 批量update 批量写，sql编译N次和1次的时间与空间复杂度，网络消耗的时间复杂度 磁盘寻址的复杂度<br>
读操作：索引<br>
mysql单机配置性能优化拓展 执行sql前先写undo/redo日志顺序写，写数据则是随机读写<br>
max_connection=1000默认100<br>
innodb_file_per_table=1,每个table一个文件<br>
innodb_buffer_pool_size=1G 写数据缓冲区大小，越大越容易命中buffer缓存，内存60%-80%</p>
<p>innodb_log_file_size=256M redo/undo日志大小<br>
innodb_log_buffer_size=16M 日志满了切换的时候添加buffer缓冲</p>
<p>innodb_flush_log_at_trx_commit=2需要放在【mysqlId_safe】节点下，默认1，事务提交立马刷盘</p>
<p>innodb_data_file_path=ibdata1:1G;ibdata2:1G;ibdata3:1G;autoextend,数据量大时分区</p>
<p>秒杀系统扣减库存</p>
<div class="language-c" data-ext="c" data-title="c"><pre class="language-c"><code><span class="token operator">--</span> 库存未预热
<span class="token keyword">if</span> <span class="token punctuation">(</span>redis<span class="token punctuation">.</span><span class="token function">call</span><span class="token punctuation">(</span><span class="token char">'exists'</span><span class="token punctuation">,</span> KEYS<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">)</span> then
    <span class="token keyword">return</span> <span class="token operator">-</span><span class="token number">9</span><span class="token punctuation">;</span>
end<span class="token punctuation">;</span>
<span class="token operator">--</span> 秒杀商品库存存在
<span class="token keyword">if</span> <span class="token punctuation">(</span>redis<span class="token punctuation">.</span><span class="token function">call</span><span class="token punctuation">(</span><span class="token char">'exists'</span><span class="token punctuation">,</span> KEYS<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">)</span> then
    local stock <span class="token operator">=</span> <span class="token function">tonumber</span><span class="token punctuation">(</span>redis<span class="token punctuation">.</span><span class="token function">call</span><span class="token punctuation">(</span><span class="token char">'get'</span><span class="token punctuation">,</span> KEYS<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    local num <span class="token operator">=</span> <span class="token function">tonumber</span><span class="token punctuation">(</span>ARGV<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token operator">--</span> 剩余库存少于请求数量
    <span class="token keyword">if</span> <span class="token punctuation">(</span>stock <span class="token operator">&lt;</span> num<span class="token punctuation">)</span> then
        <span class="token keyword">return</span> <span class="token operator">-</span><span class="token number">3</span>
    end<span class="token punctuation">;</span>
    <span class="token operator">--</span> 扣减库存
    <span class="token keyword">if</span> <span class="token punctuation">(</span>stock <span class="token operator">&gt;=</span> num<span class="token punctuation">)</span> then
        redis<span class="token punctuation">.</span><span class="token function">call</span><span class="token punctuation">(</span><span class="token char">'incrby'</span><span class="token punctuation">,</span> KEYS<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">0</span> <span class="token operator">-</span> num<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token operator">--</span> 扣减成功
        <span class="token keyword">return</span> <span class="token number">1</span>
    end<span class="token punctuation">;</span>
    <span class="token keyword">return</span> <span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">;</span>
end<span class="token punctuation">;</span>
<span class="token operator">--</span> 秒杀商品库存不存在
<span class="token keyword">return</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">;</span>
</code></pre></div>]]></content:encoded>
    </item>
    <item>
      <title>错误解决</title>
      <link>https://javaguide.cn/backend/systemdesign/%E9%94%99%E8%AF%AF%E8%A7%A3%E5%86%B3.html</link>
      <guid>https://javaguide.cn/backend/systemdesign/%E9%94%99%E8%AF%AF%E8%A7%A3%E5%86%B3.html</guid>
      <source url="https://javaguide.cn/rss.xml">错误解决</source>
      <description>常见错误解决 常见报错解决 Spring 整合Junit4测试： Junit4 js使用时一定要注意每句后面加分号 maven错误 Maven项目启动的时候一定要设置好tomcat7的版本，注意端口占用问题 Maven错误 maven报错1.PNGmaven报错1.PNG 永久去除jsp报错 spring报错 struts2 Hibernate:Nam...</description>
      <category>后端</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>常见错误解决</p>
<!--more-->
<h1>常见报错解决</h1>
<h2>Spring 整合Junit4测试：</h2>
<pre><code>log4j:WARN No appenders could be found for logger 
	(org.springframework.test.context.junit4.SpringJUnit4ClassRunner).
	log4j:WARN Please initialize the log4j system properly.
	解决办法：在src下建新的file名为log4j.properties
	然后其内如下
	log4j.rootLogger=WARN, stdout
	log4j.appender.stdout=org.apache.log4j.ConsoleAppender
	log4j.appender.stdout.layout=org.apache.log4j.PatternLayout
	log4j.appender.stdout.layout.ConversionPattern=%d %p [%c] - %m%n
</code></pre>
<h2>Junit4</h2>
<pre><code>initilizationError[Runner:JUnit4](0.00)表示可能该方法没加@Test
</code></pre>
<h2>js使用时一定要注意每句后面加分号</h2>
<pre><code>jsp页面数据传递①hidden②？参数名=值
</code></pre>
<h2>maven错误</h2>
<pre><code>Batch update returned unexpected row count from update [0]; actual row count: 0;
	Batch update returned unexpected row count from update [0]; actual row count: 0; 
	expected: 1
	这个异常是由于主键设置为自增长/uuid，而在我们插入记录的时候设置了ID的值导致的
</code></pre>
<h2>Maven项目启动的时候一定要设置好tomcat7的版本，注意端口占用问题</h2>
<pre><code>&lt;plugin&gt;
	&lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt;
	&lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt;
	&lt;version&gt;2.2&lt;/version&gt;
	&lt;configuration&gt;
	&lt;!-- 可以灵活配置工程路径 --&gt;
	&lt;path&gt;/ssh&lt;/path&gt;
	&lt;!-- 可以灵活配置端口号 --&gt;
	&lt;port&gt;8080&lt;/port&gt;
	&lt;/configuration&gt;
	&lt;/plugin&gt;
</code></pre>
<h2>Maven错误</h2>
<pre><code>[ERROR] No compiler is provided in this environment. 
	Perhaps you are running on a JRE rather than a JDK?
	对于Java开发者来说, Installed JREs中使用jdk目录
	而不适用jre目录也是最好的选择. 按下图配置
</code></pre>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/0bf9fbde3ee68241766f7.png" alt="maven报错1.PNG" tabindex="0"><figcaption>maven报错1.PNG</figcaption></figure>
<h2>永久去除jsp报错</h2>
<pre><code>https://jingyan.baidu.com/article/7f766dafbb5cf34101e1d0d8.html
</code></pre>
<h2>spring报错</h2>
<pre><code>注意单独配置后springmvc改了url后面重新启动项目不会更新配置，
	一定要clean
	Springmvc的 service经过扫描后无法xml配解注入dao接口实现类，
	需要用@Resource（name=”xxx”）来注入，是因为springmvc配置为子容器，
	而spring本身是父容器，且子能访问父，父不能访问子，
	故由于springmvc在请求到来的时候扫描了controller作为bean，即使没注解dao属性，
	但是已经将整个该类注册成bean，故之后的spring
	父容器再注册也不能再注入dao进去了

	是因为，系统首先加载spring父容器（application。Xml文件）
	第一次注册了service整个注解（包括依赖的dao接口），然而跟springmvc无关，
	相当于没注册进去springmvc容器。
	然后再加载springmvc文件，当加载到dao接口属性的时候，
	由于springmvc的扫描扫描bean的时候该接口属性没配置注解，导致没注入dao接口，报空指针错误。
	①如果在springmvc里面再用xml注解补充dao的注入的话，会报
	There is already handler of type [class com.junye.service.ItemsServiceImpl] 
	mapped.错误，
	②即使注解和xml配置调转了都不行，仍然报同样的错误
	（解释：是因为系统优先加载xml配置，然后再加载注解配置）
	③单独xml配置（去掉包扫描）完全没问题，说明springmvc不能同时用注解配置和xml配置
	④而对于spring本身来说却可以重复配置一样的bean进去容器，但以xml的配置为准

	补充，子容器能访问父容器的内容，但是父容器不能访问子容器的内容
	结论：springmvc开启扫描包扫描bean的时候。里面必须都注解注入，
	不要部分属性xml配置、部分注解，springmvc不允许用注解配置和xml注册同一个bean，
	而spring本身却可以，以xml为准

	applicationContext里面已经声明了 service的对象bean，
	又扫描service类的上面注解@Component声明为bean，
	重复导致spring容器不能判断Service的成员装配哪个对象。

	Xml配置优先于注解配置，加载顺序listener》filter》servlet，
	而spring配置文件先加载，后加载springmvc的配置文件。

	Springmvc使用必须用自己的springmvc扫描到controller注解的bean，
	若是spring扫的话没用，404
</code></pre>
<h2>struts2</h2>
<pre><code>注意struts整合spring时action必须设置scope=”prototype”
	判断是不是为true，直接&lt;s:if test="#parameters.select"&gt;，
	不要&lt;s:if test="#parameters.select==true"&gt;
</code></pre>
<h2>Hibernate:Named query not known异常的一种解决方案</h2>
<pre><code>请注意标签&lt;query&gt;要定义在&lt;class&gt;之外&lt;hibernate-mapping&gt;之内
	如果定义在&lt;class&gt;之内，就有可能报这个错误
	&lt;/class&gt;
	********************************************
	******************注意&lt;query&gt;标签位置*******
	**********************************************
	&lt;query name="getTeacherNotInClasses"&gt;SQL语句&lt;/query&gt;
	&lt;query name="getClassesByTitle"&gt;sql语句&lt;/query&gt;
	&lt;/hibernate-mapping&gt;
</code></pre>
<p>1、存储json用blob类型<br>
活动介绍[{"type":"image","content":"<a href="https://bzstatic.udinovo.com/tmp_34a994ba8130b1cec3431b941a6af9f5.jpg%22%7D,%7B%22type%22:%22image%22,%22content%22:%22https://bzstatic.udinovo.com/tmp_bbd3892eba215a1d247aadef19a0f764.jpg%22%7D,%7B%22type%22:%22image%22,%22content%22:%22https://bzstatic.udinovo.com/tmp_5c72371caeb39b1ae705527c49fbeacb.gif" target="_blank" rel="noopener noreferrer">https://bzstatic.udinovo.com/tmp_34a994ba8130b1cec3431b941a6af9f5.jpg"},{"type":"image","content":"https://bzstatic.udinovo.com/tmp_bbd3892eba215a1d247aadef19a0f764.jpg"},{"type":"image","content":"https://bzstatic.udinovo.com/tmp_5c72371caeb39b1ae705527c49fbeacb.gif</a>"}]<br>
2、只要用户登入系统，一般就记录一个游客记录到user表，以ctype 客户身份. 0:游客;1:授权用户;2:品牌用户标志一下<br>
3.、存储自定义列表可以用,;,;<br>
4、获取长度判断char_length(an.comment)&lt;=?<br>
5、服务器不重用tcp解决方案<a href="https://www.cnblogs.com/aoxueshou/p/13546814.html" target="_blank" rel="noopener noreferrer">https://www.cnblogs.com/aoxueshou/p/13546814.html</a><br>
7、join on可以加and or条件<br>
8、esxist用于判断有人报名的显示<br>
9、min（delete）判断是否报过名banzhu_action_bao<br>
10\gradlew build --refresh-dependencies<br>
11、<br>
12、order by xxx!=xxx<br>
13、group by 巧用max和min筛选匹配项max(if xxxx= xx,1,0)<br>
14、数据库中计算2点的距离,ifnull(st_distance(point(c.lat,c.lng),point(#{pagination.lat},#{pagination.lng})) * 111195,0) as pointdistance单位m  <a href="https://blog.csdn.net/worilb/article/details/124976921" target="_blank" rel="noopener noreferrer">https://blog.csdn.net/worilb/article/details/124976921</a><br>
lat是纬度lng是经度<br>
this AnnotationConfigServletWebServerApplicationContext<br>
spring refresh(){<br>
prepareRefresh-&gt;<br>
{<br>
initPropertySourcesStandardServletEnvironment<br>
earlyApplicationListeners<br>
earlyApplicationEvents<br>
}<br>
}<br>
15.排序不包括同名<br>
rank() over (order by)<br>
Creating sort index</p>
<p>Your authorization verification fails, you can still continue to use the system for 5 minutes, and the system will automatically stop after 5 minutes</p>
<p>17 一个字段是否为null业务可以判断是否已经坐过什么，如果字段为更新时间，那么就可以一个字段同时满足是否更新和什么时候更新两个业务</p>
<p>雪狼框架的分配分布式唯一id可能会因为已经存在类似的id而导致堆栈溢出</p>
<p>七牛云测试视频<a href="https://bzstatic.udinovo.com/2313.mp4" target="_blank" rel="noopener noreferrer">https://bzstatic.udinovo.com/2313.mp4</a></p>
<p>18 自定义费用<br>
xxx:xx;xxx,xx;</p>
<p>SELECT s.*,u.nick,u.gender,u.avatar,t.mode<br>
FROM banzhu_sport s inner join banzhu_user u on u.uid = s.uid</p>
<pre><code>    WHERE s.uid IN (select fs.uid from banzhu_user_focus fs
    inner join banzhu_user u on fs.uid = u.uid where fs.focusUid = #{pagination.uid} and fs.uid in (select focusUid from banzhu_user_focus where uid = #{pagination.uid})
    and fs.uid != #{pagination.uid}
    &lt;if test="pagination.keywords"&gt;
        and u.nick like "%"#{pagination.keywords}"%"
    &lt;/if&gt;
    and u.uid != #{pagination.uid} )
    AND s.typeId = #{pagination.map.typeId} AND s.seconds = #{pagination.map.seconds}
    AND NOT EXISTS (SELECT 1 FROM banzhu_sport WHERE uid = s.uid AND typeId = s.typeId AND seconds = s.seconds AND sportCnt &gt; s.sportCnt)
    group by s.uid
</code></pre>
<p>select abc.*,IFNULL(max(s.sportCnt),0) as sportCnt,<a href="http://s.id" target="_blank" rel="noopener noreferrer">s.id</a>,st.mode,s.round,s.createTime,t.mode<br>
from<br>
(select fs.uid,u.nick,u.gender,u.avatar from banzhu_user_focus fs<br>
inner join banzhu_user u on fs.uid = u.uid where fs.focusUid = #{pagination.uid} and fs.uid in (select focusUid from banzhu_user_focus where uid = #{pagination.uid})<br>
and fs.uid != #{pagination.uid}<br>
and u.uid != #{pagination.uid} ) abc left join banzhu_sport s on s.uid = abc.uid and s.seconds = #{pagination.map.seconds} and s.typeId = #{pagination.map.typeId}<br>
left join banzhu_sport_team st on <a href="http://st.id" target="_blank" rel="noopener noreferrer">st.id</a> = s.teamId<br>
group by abc.uid<br>
mysqlsysdate()不走索引</p>
<p>sse客户端解析代码<br>
怎么接收http请求response 的content-type=text/event-stream<br>
boolean processNextEvent() throws IOException {<br>
String id = this.lastId;<br>
String type = null;<br>
Buffer data = new Buffer();</p>
<pre><code>    while(true) {
        long lineEnd = this.source.indexOfElement(CRLF);
        if (lineEnd == -1L) {
            return false;
        }

        switch(this.source.getBuffer().getByte(0L)) {
        case 10:
        case 13:
            this.completeEvent(id, type, data);
            return true;
        case 100:
            if (this.isKey(DATA)) {
                this.parseData(data, lineEnd);
                continue;
            }
            break;
        case 101:
            if (this.isKey(EVENT)) {
                type = this.parseEvent(lineEnd);
                continue;
            }
            break;
        case 105:
            if (this.isKey(ID)) {
                id = this.parseId(lineEnd);
                continue;
            }
            break;
        case 114:
            if (this.isKey(RETRY)) {
                this.parseRetry(lineEnd);
                continue;
            }
        }

        this.source.skip(lineEnd);
        this.skipCrAndOrLf();
    }
}
</code></pre>
<p>update xxx set xxx-1 where xxx&gt;0 and id = ?</p>
<p>表设计可以使用action_xxx来即可用到action前缀索引，又能用到action_xxx索引，还能分action类和action_xxx小类</p>
<p>docker日志收集<br>
<a href="https://www.coder4.com/homs_online/ch01-architecture/micro-service-intro.html" target="_blank" rel="noopener noreferrer">https://www.coder4.com/homs_online/ch01-architecture/micro-service-intro.html</a></p>
<p>redis集群持久化<br>
<a href="https://help.aliyun.com/document_detail/90529.html?spm=a2c4g.11186623.6.569.1408519e9VE04k" target="_blank" rel="noopener noreferrer">https://help.aliyun.com/document_detail/90529.html?spm=a2c4g.11186623.6.569.1408519e9VE04k</a></p>
<p>目前要么elk efk 或者fk-elk</p>
<p>ps -ef |grep java |grep -w testbanzhu.jar|grep -v 'grep'|awk '{print $2}'| xargs -i{} kill -9 {}<br>
sleep 1 &amp;&amp; nohup java -server -jar testbanzhu.jar --server.port=8888 &amp;</p>
]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/0bf9fbde3ee68241766f7.png" type="image/png"/>
    </item>
    <item>
      <title>springmvc</title>
      <link>https://javaguide.cn/backend/webframework/springmvc.html</link>
      <guid>https://javaguide.cn/backend/webframework/springmvc.html</guid>
      <source url="https://javaguide.cn/rss.xml">springmvc</source>
      <description>springmvc 2. Springmvc概述 3. springmvc与struts2不同 5. springmvc入门 6. springmvc 配置 7. Handler配置 8. 异常处理器 9. ssm整合思路 10. 上传图片 11. RESTful支持 12. 拦截器 2. Springmvc概述 Spring web mvc和Stru...</description>
      <category>后端</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>springmvc</p>
<!--more-->
<!-- TOC -->
<ul>
<li><a href="#2-springmvc%E6%A6%82%E8%BF%B0">2. Springmvc概述</a></li>
<li><a href="#3-springmvc%E4%B8%8Estruts2%E4%B8%8D%E5%90%8C">3. springmvc与struts2不同</a></li>
<li><a href="#5-springmvc%E5%85%A5%E9%97%A8">5. springmvc入门</a></li>
<li><a href="#6-springmvc-%E9%85%8D%E7%BD%AE">6. springmvc 配置</a></li>
<li><a href="#7-handler%E9%85%8D%E7%BD%AE">7. Handler配置</a></li>
<li><a href="#8-%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86%E5%99%A8">8. 异常处理器</a></li>
<li><a href="#9-ssm%E6%95%B4%E5%90%88%E6%80%9D%E8%B7%AF">9. ssm整合思路</a></li>
<li><a href="#10-%E4%B8%8A%E4%BC%A0%E5%9B%BE%E7%89%87">10. 上传图片</a></li>
<li><a href="#11-restful%E6%94%AF%E6%8C%81">11. RESTful支持</a></li>
<li><a href="#12-%E6%8B%A6%E6%88%AA%E5%99%A8">12. 拦截器</a></li>
</ul>
<!-- /TOC -->
<h1>2. Springmvc概述</h1>
<ul>
<li>Spring web mvc和Struts2都属于表现层的框架,它是Spring框架的一部分<br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/be7cbdbe994b2221f35c0.png" alt="springmvc.png"></li>
</ul>
<h1>3. springmvc与struts2不同</h1>
<ul>
<li>springmvc的入口是一个servlet即前端控制器，而struts2入口是一个filter过滤器。</li>
<li>springmvc是基于方法开发(一个url对应一个方法)，请求参数传递到方法的形参，struts2是基于类开发，传递参数是通过类的属性</li>
<li>Struts采用值栈存储请求和响应的数据，通过OGNL存取数据， springmvc通过参数解析器是将request请求内容解析，并给方法形参赋值，</li>
</ul>
<h1>5. springmvc入门</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>	创建动态web工程(2.5)
	导入jar包
	commons-logging-1.1.1.jar
	jstl-1.2.jar
	spring-aop-4.1.3.RELEASE.jar
	spring-aspects-4.1.3.RELEASE.jar
	spring-beans-4.1.3.RELEASE.jar
	spring-context-4.1.3.RELEASE.jar
	spring-context-support-4.1.3.RELEASE.jar
	spring-core-4.1.3.RELEASE.jar
	spring-expression-4.1.3.RELEASE.jar
	spring-jdbc-4.1.3.RELEASE.jar
	spring-jms-4.1.3.RELEASE.jar
	spring-messaging-4.1.3.RELEASE.jar
	spring-tx-4.1.3.RELEASE.jar
	spring-web-4.1.3.RELEASE.jar
	spring-webmvc-4.1.3.RELEASE.jar

	在src下创建springmvc.xml
	导入所有约束文件aop、beans、context、mvc、tool、tx、util
	&lt;?xml version="1.0" encoding="UTF-8"?&gt;
	&lt;beans xmlns="http://www.springframework.org/schema/beans"
	xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
	xmlns:p="http://www.springframework.org/schema/p"
	xmlns:context="http://www.springframework.org/schema/context"
	xmlns:mvc="http://www.springframework.org/schema/mvc"
	xsi:schemaLocation="http://www.springframework.org/schema/beans 
	http://www.springframework.org/schema/beans/spring-beans-4.0.xsd
	http://www.springframework.org/schema/mvc 
	http://www.springframework.org/schema/mvc/spring-mvc-4.0.xsd
	http://www.springframework.org/schema/context 
	http://www.springframework.org/schema/context/spring-context-4.0.xsd"&gt;
		&lt;!--配置扫描注解 配置controller扫描包 --&gt;
		&lt;context:component-scan base-package="cn.itcast.springmvc.controller"/&gt;
	&lt;/beans&gt;
		
	在web.xml中配置SpringMVC的前端控制器DispatcherServlet
	&lt;?xml version="1.0" encoding="UTF-8"?&gt;
		&lt;web-app xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
		xmlns="http://java.sun.com/xml/ns/javaee"
		xsi:schemaLocation="http://java.sun.com/xml/ns/javaee 
		http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd"
		id="WebApp_ID" version="2.5"&gt;
		&lt;display-name&gt;springmvc-first&lt;/display-name&gt;
		&lt;welcome-file-list&gt;
			&lt;welcome-file&gt;index.html&lt;/welcome-file&gt;
		&lt;/welcome-file-list&gt;

		&lt;!-- 配置SpringMVC前端控制器 --&gt;
		&lt;servlet&gt;
			&lt;servlet-name&gt;springmvc-first&lt;/servlet-name&gt;
			&lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet
		&lt;/servlet-class&gt;
			&lt;!-- 指定SpringMVC配置文件 --&gt;
			&lt;!-- SpringMVC的配置文件的默认路径是
			/WEB-INF/${servlet-name}-servlet.xml --&gt;
			&lt;init-param&gt;
				&lt;param-name&gt;contextConfigLocation&lt;/param-name&gt;
				&lt;param-value&gt;classpath:springmvc.xml&lt;/param-value&gt;
			&lt;/init-param&gt;
		&lt;/servlet&gt;

		&lt;servlet-mapping&gt;
			&lt;servlet-name&gt;springmvc-first&lt;/servlet-name&gt;
				&lt;!-- 设置所有以action结尾的请求进入SpringMVC --&gt;
				&lt;url-pattern&gt;*.action&lt;/url-pattern&gt;
			&lt;/servlet-mapping&gt;
		&lt;/web-app&gt;
		在web.Xml中用dispathcherservlet然后Alt+/提示然后配置一下就行
	
	加入jsp页面
	把itemList.jsp放到/WEB-INF/jsp目录
	&lt;c:forEach items="${itemList }" var="item"&gt;
		&lt;tr&gt;
			&lt;td&gt;${item.name }&lt;/td&gt;
			&lt;td&gt;${item.price }&lt;/td&gt;
			&lt;td&gt;&lt;fmt:formatDate value="${item.createtime}" pattern="yyyy-MM-dd HH:mm:ss"/&gt;&lt;/td&gt;
			&lt;td&gt;${item.detail }&lt;/td&gt;
			&lt;td&gt;
				&lt;a href="${pageContext.request.contextPath}/itemEdit.action?id=${item.id}"&gt;修改&lt;/a&gt;
			&lt;/td&gt;
		&lt;/tr&gt;
	&lt;/c:forEach&gt;

	创建pojo
	public class Item {
		private int id;
		private String name;
		private double price;
		private Date createtime;
		private String detail;
		创建带参数的构造器
		set/get。。。
		}

	创建ItemController类，不需要实现任何接口。
	在类上添加@Controller注解，把Controller交由Spring管理
		在方法上面添加@RequestMapping注解，里面指定请求的url。
		其中“.action”可以加也可以不加。
		@Controller
		public class ItemController {
			@RequestMapping("/itemList.action")
			public ModelAndView queryItemList() {
				List&lt;Item&gt; list = new ArrayList&lt;&gt;();
				list.add(new Item(1, "1华为 荣耀8", 2399, new Date(), "质量好！1"));
				list.add(new Item(2, "2华为 荣耀8", 2399, new Date(), "质量好！2"));
				list.add(new Item(3, "3华为 荣耀8", 2399, new Date(), "质量好！3"));
				list.add(new Item(4, "4华为 荣耀8", 2399, new Date(), "质量好！4"));
				list.add(new Item(5, "5华为 荣耀8", 2399, new Date(), "质量好！5"));
				list.add(new Item(6, "6华为 荣耀8", 2399, new Date(), "质量好！6"));

				ModelAndView modelAndView = new ModelAndView();
				modelAndView.addObject("list", list);
				modelAndView.setViewName("/WEB-INF/jsp/itemList.jsp");

				//或者像下面这么写
				// 创建ModelAndView，用来存放数据和视图
				//ModelAndView modelAndView = new ModelAndView();
				// 设置数据到模型中
				//modelAndView.addObject("itemList", list);
				// 设置视图jsp，需要设置视图的物理地址
				// modelAndView.setViewName("/WEB-INF/jsp/itemList.jsp");
				// 配置好视图解析器前缀和后缀，这里只需要设置逻辑视图就可以了。
				// 视图解析器根据前缀+逻辑视图名+后缀拼接出来物理路径
				//modelAndView.setViewName("itemList");
				//return modelAndView;

				return modelAndView;
			}
		}
	启动项目测试
	浏览器访问地址http://127.0.0.1:8080/springmvc-first/itemList.action
</code></pre></div><h1>6. springmvc 配置</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>	组件扫描器(省去在spring容器配置每个Controller类的繁琐)
	使用&lt;context:component-scan&gt;自动扫描标记@Controller的控制器类，
	在springmvc.xml配置文件中配置如下：
	&lt;!-- 配置controller扫描包，多个包之间用,分隔 --&gt;
	&lt;context:component-scan base-package="cn.test.springmvc" /&gt;
	
	注解驱动（省去直接配置处理器映射器和处理器适配器的麻烦）
	SpringMVC使用&lt;mvc:annotation-driven&gt;
	自动加载RequestMappingHandlerMapping和RequestMappingHandlerAdapter
	&lt;!-- 注解驱动 --&gt;
	&lt;mvc:annotation-driven /&gt;
	
	视图解析器
	视图解析器使用SpringMVC框架默认的InternalResourceViewResolver（）
	这个视图解析器支持JSP视图解析
	在springmvc.xml配置文件中配置如下：
	&lt;!-- Example: prefix="/WEB-INF/jsp/",suffix=".jsp",viewname="test" -&gt; 
	"/WEB-INF/jsp/test.jsp" --&gt;
	&lt;!-- 配置视图解析器 --&gt;
	&lt;bean class="org.springframework.web.servlet.view.InternalResourceViewResolver"&gt;
		&lt;!-- 配置逻辑视图的前缀 --&gt;
		&lt;property name="prefix" value="/WEB-INF/jsp/" /&gt;
		&lt;!-- 配置逻辑视图的后缀 --&gt;
		&lt;property name="suffix" value=".jsp" /&gt;
	&lt;/bean&gt;
	逻辑视图名需要在controller中返回ModelAndView指定，
	比如逻辑视图名为ItemList，则最终返回的jsp视图地址:
	“WEB-INF/jsp/itemList.jsp”
	最终jsp物理地址：前缀+逻辑视图名+后缀
</code></pre></div><h1>7. Handler配置</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>参数绑定（接受请求参数的方法）
处理器形参中添加如下类型的参数处理适配器会默认识别并进行赋值。
HttpServletRequest:通过request对象获取请求信息public String editItem(HttpServletRequest request)
HttpServletResponse:通过response处理响应信息public String editItem(HttpServletResponse response)
HttpSession:通过session对象得到session中存放的对象public String editItem(HttpSession session)
简单数据类型(基本数据类型，基本类型包装类)参数类型推荐使用包装数据类型，因为基础数据类型不可以为null
public String editItem(Model model,Integer id,Boolean status) 请求url：http://localhost:8080/xxx.action?id=2&amp;status=false

@RequestParam:常用于处理简单类型的绑定。
value：请求参数名字，required：是否必须，默认是true、defaultValue：默认值，表示如果请求中没有同名参数时的默认值
public String queryItemById(@RequestParam(value = "itemId", required = true, defaultValue = "1") Integer id)

使用pojo对象接收表单数据（提交内容很多的时候）
要求：pojo对象中的属性名和表单中input的name属性一致
前端：name="pojo对象的属性名" value="${pojo.属性名}"
后端：test(pojo){}
pojo定义对应的属性并生成set/get方法
请求的参数名称和pojo的属性名称一致，会自动将请求参数赋值给pojo的属性。
注意：提交的表单中不要有日期类型的数据，否则会报400错误。
如果想提交日期类型的数据需要用到后面的自定义参数绑定的内容。

使用绑定包装pojo（内部类）
前端：name="内部类.内部属性名" value="外部类.内部类.内部属性名"
后端：定义pojo内部类
定义参数接收
@RequestMapping("/queryItem")
	public String queryItem(QueryVo queryVo) {
	System.out.println(queryVo.getItem().getId());
	System.out.println(queryVo.getItem().getName());
	return "success";
}

自定义参数绑定（自定义日期格式）
	可以在springmvc处理器适配器上自定义转换器Converter进行参数绑定。
	一般使用&lt;mvc:annotation-driven/&gt;注解驱动加载处理器适配器，可以在此标签上进行配置。
	前端
	&lt;input type="text" name="items.createtime" value="&lt;fmt:formatDate value="${item.createtime}" pattern="yyyy-MM-dd HH:mm:ss"/&gt;" /&gt;
	后端自定义Converter，
	//Converter&lt;S, T&gt;
	//S:source,需要转换的源的类型
	//T:target,需要转换的目标类型
	public class DateConverter implements Converter&lt;String, Date&gt; {
		@Override
		public Date convert(String source) {
			try {
				// 把字符串转换为日期类型
				SimpleDateFormat simpleDateFormat = 
				new SimpleDateFormat("yyy-MM-dd HH:mm:ss");
				Date date = simpleDateFormat.parse(source);
				return date;
			} catch (ParseException e) {
				e.printStackTrace();
			}
			// 如果转换异常则返回空
			return null;
		}
	}
	springmvc.xml配置Converter 同时可以配置多个的转换器。
	&lt;!-- 配置注解驱动 --&gt;
	&lt;!-- 如果配置此标签,可以不用配置... --&gt;
	&lt;mvc:annotation-driven conversion-service="conversionService" /&gt;

	&lt;!-- 转换器配置 --&gt;
	&lt;bean id="conversionService" class="org.springframework.format.support.FormattingConversionServiceFactoryBean"&gt;
		&lt;property name="converters"&gt;
		&lt;set&gt;
			&lt;bean class="cn.itcast.springmvc.converter.DateConverter" /&gt;
		&lt;/set&gt;
		&lt;/property&gt;
	&lt;/bean&gt;
绑定数组
	前端 &lt;c:forEach item="${itemList}" var="item"&gt;
			&lt;input type="checkbox" name="ids" value="${item.id}"/&gt;
			&lt;input type="checkbox" name="ids" value="${item.id}"/&gt;
		&lt;/c:forEach&gt;
	后端：pojo中定义private integer[] ids;生成set/get方法
	包装类型 绑定数组类型，可以使用两种方式，pojo的属性接收和直接接收
	@RequestMapping("queryItem")
	public String queryItem(QueryVo queryVo, Integer[] ids) {
		System.out.println(queryVo.getItem().getId());
		System.out.println(queryVo.getIds().length);
		System.out.println(ids.length);
		return "success";
	}
绑定List
	后端：在pojo中定义private List&lt;Item&gt; itemList;生成set/get方法
	前端页面：name属性必须是list属性名+下标+元素属性。
	&lt;c:forEach items="${itemList }" var="item" varStatus="s"&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;input type="checkbox" name="ids" value="${item.id}"/&gt;&lt;/td&gt;
		&lt;td&gt;
			&lt;input type="hidden" name="itemList[${s.index}].id" value="${item.id }"/&gt;
			&lt;input type="text" name="itemList[${s.index}].name" value="${item.name }"/&gt;
		&lt;/td&gt;
		&lt;/tr&gt;
	&lt;/c:forEach&gt;
	${current}	当前这次迭代的（集合中的）项
	${status.first}	判断当前项是否为集合中的第一项，返回值为true或false
	${status.last}	判断当前项是否为集合中的最
	varStatus属性常用参数总结下：
	${status.index}	输出行号，从0开始。
	${status.count}	输出行号，从1开始。
	${status.后一项，返回值为true或false
	begin、end、step分别表示：起始序号，结束序号，跳跃步伐。
	接收List类型的数据必须是pojo的属性，如果方法的形参为ArrayList类型无法正确接收到数据
我们需要从url上获取商品id，步骤如下：
	1.@RequestMapping("item/{id}")声明请求的url
	{xxx}叫做占位符，请求的URL可以是“item /1”或“item/2”
	2.使用(@PathVariable() Integer id)获取url上的数据	
	* 使用RESTful风格开发接口，实现根据id查询商品
	@RequestMapping("item/{id}")
	@ResponseBody
	public Item queryItemById(@PathVariable() Integer id) {
		Item item = this.itemService.queryItemById(id);
		return item;
	}
	如果@RequestMapping中表示为"item/{id}"，id和形参名称一致，
	@PathVariable不用指定名称。如果不一致，例如"item/{ItemId}"
	则需要指定名称@PathVariable("itemId")。

	http://127.0.0.1/item/123?id=1
	注意两个区别
	1.@PathVariable是获取url上数据的。@RequestParam获取请求参数的（包括post表单提交）
	2.如果加上@ResponseBody注解，就不会走视图解析器，
	不会返回页面，目前返回的json数据。如果不加，就走视图解析器，返回页面
	@RequestMapping("/hello")//接收所有hello路径的请求
		public String index(参数名与接收的参数名一致) {
		return "Hello World";
		}
### 指定前端url请求参数名称与方法名一致
### 通过HttpServletRequest来获取前端页面参数
### 创建一个JavaBean对象来封装表单参数或者是请求url路径中的参数
### 通过PathVariable注解来绑定请求路径的参数
### 通过RequestParam注解来获取
## springboot返回参数

### 返回jsp页面（undertow不支持jsp）
	值得注意的是，当我们使用Spring Boot 2.0 想要返回页面而不是提供json或者xml数据接口的时候，
		切记不能再使用@RestController了,只能使用@Controller.

@RequestMapping：定义不同的处理器映射规则，URL路径映射
	添加在方法上面
	@RequestMapping("/item"）
	value的值是数组，可以将多个url映射到同一个方法
	@RequestMapping(value = { "/itemList", "/itemListAll" })
	public ModelAndView queryItemList() {
		List&lt;Item&gt; list = this.itemService.queryItemList();
		ModelAndView mv = new ModelAndView("itemList");
		mv.addObject("itemList", list);
		return mv;
	}

	添加在类上面 在class上添加@RequestMapping(url)指定通用请求前缀， 
	限制此类下的所有方法请求url必须以请求前缀开头，可以使用此方法对url进行分类管理
	@controller
	@RequestMapping("item")
	public class ItemController{
		@RequestMapping(value = { "itemList", "itemListAll" })
		public ModelAndView queryItemList() {
		}
	}
	此时需要进入queryItemList()方法的请求url为：
	http://127.0.0.1:8080/springmvc-web2/item/itemList.action
	或者
	http://127.0.0.1:8080/springmvc-web2/item/itemListAll.action

请求方法限定 
	限定GET方法
	@RequestMapping(method = RequestMethod.GET)如果通过POST访问则报错：
	HTTP Status 405 - Request method 'POST' not supported
	@RequestMapping(value = "itemList",method = RequestMethod.POST)
	限定POST方法
	@RequestMapping(method = RequestMethod.POST)
	如果通过GET访问则报错：HTTP Status 405 - Request method 'GET' not supported
	
	GET和POST都可以@RequestMapping(method = {RequestMethod.GET,RequestMethod.POST})

Controller方法返回值
	返回ModelAndView
	controller方法中定义ModelAndView对象并返回，可添加model数据、指定view
	
	返回void
	request转发
	request.getRequestDispatcher("页面路径").forward(request, response);
	request.getRequestDispatcher("/WEB-INF/jsp/success.jsp").forward(request, response);
	response重定向
	response.sendRedirect("url")
	response.sendRedirect("/springmvc-web2/itemEdit.action");
	response指定响应结果，例如响应json数据
	response.getWriter().print("{\"abc\":123}");
	
	返回字符串
	逻辑视图名
	controller方法返回字符串可以指定逻辑视图名，通过视图解析器解析为物理视图地址。
	/WEB-INF/jsp/itemList.jsp
	return "itemList";
	Redirect重定向
	Contrller方法返回字符串可以重定向到一个url地址,重定向后浏览器地址栏变更为重定向的地址，
	重定向相当于执行了新的request和response，所以之前的请求参数都会丢失
	如果要指定请求参数，需要在重定向的url后面添加 ?itemId=1 这样的请求参数
	return "redirect:/itemEdit.action?itemId=" + item.getId();
	forward转发
	Controller方法执行后继续执行另一个Controller方法
	修改商品成功后，继续执行另一个方法,使用转发的方式实现。转发后浏览器地址栏还是原来的请求地址，
	转发并没有执行新的request和response，所以之前的请求参数都存在
	return "forward:/itemEdit.action";

	Model/ModelMap（返回处理结果给页面的方法）
	Model
	除了ModelAndView以外，还可以使用Model来向页面传递数据
	Model是一个接口，在参数里直接声明model即可
	如果使用Model则可以不使用ModelAndView对象，
	Model对象可以向页面传递数据，View对象则可以使用String返回值替代。
	不管是Model还是ModelAndView，其本质都是使用Request对象向jsp传递数据。
	@RequestMapping("/itemEdit")
	public String queryItemById(HttpServletRequest request, Model model) {
		// ModelAndView modelAndView = new ModelAndView();
		// modelAndView.addObject("item", item);
		// 设置逻辑视图
		// modelAndView.setViewName("itemEdit");

		model.addAttribute("item", item);
		return "itemEdit";
	}
	ModelMap
	ModelMap是Model接口的实现类，也可以通过ModelMap向页面传递数据
	使用Model和ModelMap的效果一样，如果直接使用Model，
	springmvc会实例化ModelMap。
	@RequestMapping("/itemEdit")
	public String queryItemById(HttpServletRequest request, ModelMap model) {
		model.addAttribute("item", item);
		return "itemEdit";
	}
</code></pre></div><h1>8. 异常处理器</h1>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/3687ac6947ed3a8f15d51.png" alt="异常.png" tabindex="0"><figcaption>异常.png</figcaption></figure>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>	系统的dao、service、controller出现都通过throws Exception向上抛出，最后由springmvc前端控制器交由异常处理器进行异常处理，

	自定义异常类
	如果controller、service、dao抛出此类异常说明是系统预期处理的异常信息。
	public class MyException extends Exception {
		private String message;
		public MyException() {
			super();
		}
		public MyException(String message) {
			super();
			this.message = message;
		}
		public String getMessage() {
			return message;
		}
		public void setMessage(String message) {
			this.message = message;
		}
	}
	自定义异常处理器
	public class CustomHandleException implements HandlerExceptionResolver {
		@Override
		public ModelAndView resolveException(HttpServletRequest request, HttpServletResponse response, Object handler,Exception exception) {
			String msg;
			if (exception instanceof MyException) {
				// 如果是自定义异常，读取异常信息
				msg = exception.getMessage();
			} else {
				// 如果是运行时异常，则取错误堆栈，从堆栈中获取异常信息
				Writer out = new StringWriter();
				PrintWriter s = new PrintWriter(out);
				exception.printStackTrace(s);
				msg = out.toString();
			}
			// 把错误信息发给相关人员,邮件,短信等方式
			// 返回错误页面，给用户友好页面显示错误信息
			ModelAndView modelAndView = new ModelAndView();
			modelAndView.addObject("msg", msg);
			modelAndView.setViewName("error");
			return modelAndView;
		}
	}
	
	在springmvc.xml中添加：
	&lt;!-- 配置全局异常处理器 --&gt;
	&lt;bean id="customHandleException" class="cn.itcast.ssm.exception.CustomHandleException"/&gt;

	错误页面
	&lt;%@ page language="java" contentType="text/html; charset=UTF-8"
		pageEncoding="UTF-8"%&gt;
		&lt;!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "
		http://www.w3.org/TR/html4/loose.dtd"&gt;
		&lt;html&gt;
	&lt;head&gt;
		&lt;meta http-equiv="Content-Type" content="text/html; charset=UTF-8"&gt;
		&lt;title&gt;Insert title here&lt;/title&gt;
	&lt;/head&gt;
	&lt;body&gt;
		&lt;h1&gt;异常信息&lt;/h1&gt;&lt;br /&gt;
		&lt;h2&gt;${msg }&lt;/h2&gt;
	&lt;/body&gt;
	&lt;/html&gt;
	异常测试
	修改ItemController方法“queryItemList”，抛出异常：
	@RequestMapping(value = { "itemList", "itemListAll" })
	public ModelAndView queryItemList() throws Exception {
		// 自定义异常
		if (true) {
			throw new MyException("自定义异常出现了~");
		}
		// 运行时异常
		int a = 1 / 0;
		// 查询商品数据
		List&lt;Item&gt; list = this.itemService.queryItemList();
		// 创建ModelAndView,设置逻辑视图名
		ModelAndView mv = new ModelAndView("itemList");
		// 把商品数据放到模型中
		mv.addObject("itemList", list);
		return mv;
	}
</code></pre></div><h1>9. ssm整合思路</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>创建数据库和表
导入的jar包
aopalliance-1.0.jar
asm-3.3.1.jar
aspectjweaver-1.6.11.jar
cglib-2.2.2.jar
commons-dbcp-1.2.2.jar
commons-logging-1.1.1.jar
commons-pool-1.3.jar
javassist-3.17.1-GA.jar
jstl-1.2.jar
junit-4.9.jar
log4j-1.2.17.jar
log4j-api-2.0-rc1.jar
log4j-core-2.0-rc1.jar
mybatis-3.2.7.jar
mybatis-spring-1.2.2.jar
mysql-connector-java-5.1.7-bin.jar
slf4j-api-1.7.5.jar
slf4j-log4j12-1.7.5.jar
spring-aop-4.1.3.RELEASE.jar
spring-aspects-4.1.3.RELEASE.jar
spring-beans-4.1.3.RELEASE.jar
spring-context-4.1.3.RELEASE.jar
spring-context-support-4.1.3.RELEASE.jar
spring-core-4.1.3.RELEASE.jar
spring-expression-4.1.3.RELEASE.jar
spring-jdbc-4.1.3.RELEASE.jar
spring-jms-4.1.3.RELEASE.jar
spring-messaging-4.1.3.RELEASE.jar
spring-tx-4.1.3.RELEASE.jar
spring-web-4.1.3.RELEASE.jar
spring-webmvc-4.1.3.RELEASE.jar

创建动态web工程springmvc-web(2.5)

加入sqlMapConfig.xml配置文件

在src下创建SqlMapConfig.xml
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;!DOCTYPE configuration
PUBLIC "-//mybatis.org//DTD Config 3.0//EN"
"http://mybatis.org/dtd/mybatis-3-config.dtd"&gt;
&lt;configuration&gt;
&lt;/configuration&gt;
加入UserMapper.xml配置文件
applicationContext-dao.xml
配置数据源、配置SqlSessionFactory、mapper扫描器。
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;beans xmlns="http://www.springframework.org/schema/beans"
xmlns:context="http://www.springframework.org/schema/context" xmlns:p="
http://www.springframework.org/schema/p"
xmlns:aop="http://www.springframework.org/schema/aop" xmlns:tx="
http://www.springframework.org/schema/tx"
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
xsi:schemaLocation="http://www.springframework.org/schema/beans 
http://www.springframework.org/schema/beans/spring-beans-4.0.xsd
http://www.springframework.org/schema/context 
http://www.springframework.org/schema/context/spring-context-4.0.xsd
http://www.springframework.org/schema/aop 
http://www.springframework.org/schema/aop/spring-aop-4.0.xsd 
http://www.springframework.org/schema/tx 
http://www.springframework.org/schema/tx/spring-tx-4.0.xsd
http://www.springframework.org/schema/util 
http://www.springframework.org/schema/util/spring-util-4.0.xsd"&gt;
&lt;!-- 加载配置文件 --&gt;
	&lt;context:property-placeholder location="classpath:db.properties" /&gt;
	&lt;bean id="dataSource" class="org.apache.commons.dbcp.BasicDataSource" destroy-method="close"&gt;
		&lt;property name="driverClassName" value="${jdbc.driver}" /&gt;
		&lt;property name="url" value="${jdbc.url}" /&gt;
		&lt;property name="username" value="${jdbc.username}" /&gt;
		&lt;property name="password" value="${jdbc.password}" /&gt;
		&lt;property name="maxActive" value="10" /&gt;
		&lt;property name="maxIdle" value="5" /&gt;
	&lt;/bean&gt;
	&lt;!-- 配置SqlSessionFactory --&gt;
	&lt;bean id="sqlSessionFactory" class="org.mybatis.spring.SqlSessionFactoryBean"&gt;
		&lt;property name="dataSource" ref="dataSource" /&gt;
		&lt;property name="configLocation" value="classpath:mybatis/SqlMapConfig.xml" /&gt;
	&lt;/bean&gt;
	&lt;!-- 配置Mapper扫描 --&gt;
	&lt;bean class="org.mybatis.spring.mapper.MapperScannerConfigurer"&gt;
		&lt;!-- 配置Mapper的接口所在的扫描包，
		同时默认扫描了同包下的同类名的Mapper.xml文件 mapper接口方式开发，
		整合后的spring默认加载与接口同包下与接口同名的Mapper文件，
		而dao开发就要手动配置mapper的位置，如果没找到就报错，
		可以在sqlMapperConfig.xml配置mapper resourc解决--&gt;
		&lt;property name="basePackage" value="cn.itcast.ssm.mapper" /&gt;
	&lt;/bean&gt;
&lt;/beans&gt;

db.properties
applicationContext-service.xml
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;beans xmlns="http://www.springframework.org/schema/beans"
	xmlns:context="http://www.springframework.org/schema/context" 
	xmlns:p="http://www.springframework.org/schema/p"
	xmlns:aop="http://www.springframework.org/schema/aop" xmlns:tx="
	http://www.springframework.org/schema/tx"
	xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
	xsi:schemaLocation="http://www.springframework.org/schema/beans 
	http://www.springframework.org/schema/beans/spring-beans-4.0.xsd
	http://www.springframework.org/schema/context 
	http://www.springframework.org/schema/context/spring-context-4.0.xsd
	http://www.springframework.org/schema/aop 
	http://www.springframework.org/schema/aop/spring-aop-4.0.xsd 
	http://www.springframework.org/schema/tx 
	http://www.springframework.org/schema/tx/spring-tx-4.0.xsd
	http://www.springframework.org/schema/util 
	http://www.springframework.org/schema/util/spring-util-4.0.xsd"&gt;
&lt;!-- 配置service扫描 --&gt;
	&lt;context:component-scan base-package="cn.itcast.ssm.service" /&gt;
&lt;/beans&gt;

applicationContext-trans.xml
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;beans xmlns="http://www.springframework.org/schema/beans"
	xmlns:context="http://www.springframework.org/schema/context" xmlns:p="
	http://www.springframework.org/schema/p"
	xmlns:aop="http://www.springframework.org/schema/aop" xmlns:tx="
	http://www.springframework.org/schema/tx"
	xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
	xsi:schemaLocation="http://www.springframework.org/schema/beans 
	http://www.springframework.org/schema/beans/spring-beans-4.0.xsd
	http://www.springframework.org/schema/context 
	http://www.springframework.org/schema/context/spring-context-4.0.xsd
	http://www.springframework.org/schema/aop 
	http://www.springframework.org/schema/aop/spring-aop-4.0.xsd 
	http://www.springframework.org/schema/tx 
	http://www.springframework.org/schema/tx/spring-tx-4.0.xsd
	http://www.springframework.org/schema/util 
	http://www.springframework.org/schema/util/spring-util-4.0.xsd"&gt;
	&lt;!-- 事务管理器 --&gt;
	&lt;bean id="transactionManager"class="org.springframework.jdbc.datasource.DataSourceTransactionManager"&gt;
		&lt;!-- 数据源 --&gt;
		&lt;property name="dataSource" ref="dataSource" /&gt;
	&lt;/bean&gt;
	&lt;!-- 通知 --&gt;
	&lt;tx:advice id="txAdvice" transaction-manager="transactionManager"&gt;
		&lt;tx:attributes&gt;
			&lt;tx:method name="find*" propagation="SUPPORTS" read-only="true" /&gt;
		&lt;/tx:attributes&gt;
	&lt;/tx:advice&gt;
	&lt;aop:config&gt;
		&lt;aop:advisor advice-ref="txAdvice" pointcut="execution(* cn.itcast.ssm.service.*.*(..))" /&gt;
	&lt;/aop:config&gt;
&lt;/beans&gt;
springmvc.xml
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;beans xmlns="http://www.springframework.org/schema/beans"
	xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:p="
	http://www.springframework.org/schema/p"
	xmlns:context="http://www.springframework.org/schema/context"
	xmlns:mvc="http://www.springframework.org/schema/mvc"
	xsi:schemaLocation="http://www.springframework.org/schema/beans 
	http://www.springframework.org/schema/beans/spring-beans-4.0.xsd
	http://www.springframework.org/schema/mvc
	http://www.springframework.org/schema/mvc/spring-mvc-4.0.xsd
	http://www.springframework.org/schema/context
	http://www.springframework.org/schema/context/spring-context-4.0.xsd"&gt;
	&lt;!-- 配置controller扫描包 --&gt;
	&lt;context:component-scan base-package="cn.itcast.ssm.controller" /&gt;
	&lt;!-- 注解驱动 --&gt;
	&lt;mvc:annotation-driven /&gt;
	&lt;!-- Example: prefix="/WEB-INF/jsp/", suffix=".jsp", viewname="test"-&gt; 
	"/WEB-INF/jsp/test.jsp" --&gt;
	&lt;!-- 配置视图解析器 --&gt;
	&lt;bean class="org.springframework.web.servlet.view.InternalResourceViewResolver"&gt;
		&lt;!-- 配置逻辑视图的前缀 --&gt;
		&lt;property name="prefix" value="/WEB-INF/jsp/" /&gt;
		&lt;!-- 配置逻辑视图的后缀 --&gt;
		&lt;property name="suffix" value=".jsp" /&gt;
	&lt;/bean&gt;
&lt;/beans&gt;

web.xml
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;web-app xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
xmlns="http://java.sun.com/xml/ns/javaee"
xsi:schemaLocation="http://java.sun.com/xml/ns/javaee 
http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd"
id="WebApp_ID" version="2.5"&gt;
&lt;display-name&gt;springmvc-web&lt;/display-name&gt;
&lt;welcome-file-list&gt;
	&lt;welcome-file&gt;index.html&lt;/welcome-file&gt;
&lt;/welcome-file-list&gt;

&lt;context-param&gt;
	&lt;param-name&gt;contextConfigLocation&lt;/param-name&gt;
	&lt;param-value&gt;classpath:spring/applicationContext*.xml&lt;/param-value&gt;
&lt;/context-param&gt;

&lt;listener&gt;
	&lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt;
&lt;/listener&gt;

&lt;servlet&gt;
	&lt;servlet-name&gt;springmvc-web&lt;/servlet-name&gt;
	&lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt;
	&lt;init-param&gt;
		&lt;param-name&gt;contextConfigLocation&lt;/param-name&gt;
		&lt;param-value&gt;classpath:spring/springmvc.xml&lt;/param-value&gt;
	&lt;/init-param&gt;
&lt;/servlet&gt;
&lt;servlet-mapping&gt;
	&lt;servlet-name&gt;springmvc-web&lt;/servlet-name&gt;
	&lt;url-pattern&gt;*.action&lt;/url-pattern&gt;
&lt;/servlet-mapping&gt;
&lt;/web-app&gt;

加入jsp页面
itemList.jsp和itemEdit.jsp到工程中

DAO开发
mapper.xml配置文件
使用逆向工程，生成配置文件，将生成的包复制粘贴到工程下面

ItemService接口
public interface ItemService {
	List&lt;Item&gt; queryItemList();
}

ItemServiceImpl实现类
@Service
public class ItemServiceImpl implements ItemService {
	@Autowired
	private ItemMapper itemMapper;
	@Override
	public List&lt;Item&gt; queryItemList() {
		List&lt;Item&gt; list = this.itemMapper.selectByExample(null);
		return list;
	}
}
ItemController
@Controller
public class ItemController {
	@Autowired
	private ItemService itemService;
	@RequestMapping("/itemList")
	public ModelAndView queryItemList() {
		// 获取商品数据
		List&lt;Item&gt; list = this.itemService.queryItemList();
		ModelAndView modelAndView = new ModelAndView();
		modelAndView.addObject("itemList", list);
		modelAndView.setViewName("itemList");
		return modelAndView;
	}

}
测试访问url：http://127.0.0.1:8080/springmvc-web/itemList.action
</code></pre></div><h1>10. 上传图片</h1>
<ul>
<li>配置虚拟目录
<ul>
<li>在tomcat上配置图片虚拟目录，在tomcat下conf/server.xml中添加：</li>
<li>
</li>
<li>访问<a href="http://localhost:8080/pic%E5%8D%B3%E5%8F%AF%E8%AE%BF%E9%97%AED:%5Cdevelop%5Cupload%5Ctemp%E4%B8%8B%E7%9A%84%E5%9B%BE%E7%89%87%E3%80%82" target="_blank" rel="noopener noreferrer">http://localhost:8080/pic即可访问D:\develop\upload\temp下的图片。</a></li>
<li>也可以通过eclipse配置，如下图：</li>
<li>复制一张图片到存放图片的文件夹，使用浏览器访问</li>
<li>测试效果，并复制一张图片到存放图片的文件夹</li>
</ul>
</li>
</ul>
<p><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/124e400cb9fbe7a173728.png" alt="上传1.png"><br>
<img src="https://290ff162.telegraph-image-eg9.pages.dev/file/9e2725e89c87cb0d490f1.png" alt="上传2.png"></p>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>加入jar包
实现图片上传需要加入的jar包，fileupload和io包、放到工程的lib文件夹中
在springmvc.xml中配置文件上传解析器
&lt;!-- 文件上传,id必须设置为multipartResolver --&gt;
&lt;bean id="multipartResolver"class="org.springframework.web.multipart.commons.CommonsMultipartResolver"&gt;
	!-- 设置文件上传大小 --&gt;
	&lt;property name="maxUploadSize" value="5000000" /&gt;
&lt;/bean&gt;

jsp页面修改
在商品修改页面，打开图片上传功能
&lt;tr&gt;
&lt;td&gt;商品图片&lt;/td&gt;
&lt;td&gt;
&lt;!-- 上传图片是需要指定属性 enctype="multipart/form-data" --&gt;
&lt;form id="itemForm" action="" method="post" enctype="multipart/form-data"&gt;
	&lt;c:if test="${item.pic !=null}"&gt;
		&lt;img src="/pic/${item.pic}" width=100 height=100/&gt;&lt;br/&gt;
	&lt;/c:if&gt;
	&lt;input type="file"  name="pictureFile"/&gt; 
&lt;/form&gt;
&lt;/td&gt;
&lt;/tr&gt;

图片上传方法
@RequestMapping("updateItem")
public String updateItemById(Item item, MultipartFile pictureFile) throws Exception {
	// 图片上传
	// 设置图片名称，不能重复，可以使用uuid
	String picName = UUID.randomUUID().toString();

	// 获取文件名
	String oriName = pictureFile.getOriginalFilename();
	// 获取图片后缀
	String extName = oriName.substring(oriName.lastIndexOf("."));

	// 开始上传
	pictureFile.transferTo(new File("C:/upload/image/" + picName + extName));

	// 设置图片名到商品中
	item.setPic(picName + extName);
	// </code></pre></div>]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/be7cbdbe994b2221f35c0.png" type="image/png"/>
    </item>
    <item>
      <title>struts2</title>
      <link>https://javaguide.cn/backend/webframework/struts2.html</link>
      <guid>https://javaguide.cn/backend/webframework/struts2.html</guid>
      <source url="https://javaguide.cn/rss.xml">struts2</source>
      <description>struts2 1. struts2访问流程&amp;架构&amp;介绍 2. 搭建struts2框架 3. strust.xml配置详解 4. Action生命周期 5. ActionContext内容 6. 访问servletAPI方式 7. jsp获得 8. Action接收参数 9. struts、hibernate的javassist-3.18.1-GA.j...</description>
      <category>后端</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>struts2</p>
<!--more-->
<!-- TOC -->
<ul>
<li><a href="#1-struts2%E8%AE%BF%E9%97%AE%E6%B5%81%E7%A8%8B%E6%9E%B6%E6%9E%84%E4%BB%8B%E7%BB%8D">1. struts2访问流程&amp;架构&amp;介绍</a></li>
<li><a href="#2-%E6%90%AD%E5%BB%BAstruts2%E6%A1%86%E6%9E%B6">2. 搭建struts2框架</a></li>
<li><a href="#3-strustxml%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3">3. strust.xml配置详解</a></li>
<li><a href="#4-action%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F">4. Action生命周期</a></li>
<li><a href="#5-actioncontext%E5%86%85%E5%AE%B9">5. ActionContext内容</a></li>
<li><a href="#6-%E8%AE%BF%E9%97%AEservletapi%E6%96%B9%E5%BC%8F">6. 访问servletAPI方式</a></li>
<li><a href="#7-jsp%E8%8E%B7%E5%BE%97">7. jsp获得</a></li>
<li><a href="#8-action%E6%8E%A5%E6%94%B6%E5%8F%82%E6%95%B0">8. Action接收参数</a></li>
<li><a href="#9-strutshibernate%E7%9A%84javassist-3181-gajar%E5%8C%85%E9%87%8D%E5%A4%8D%E5%88%A0%E9%99%A4%E7%89%88%E6%9C%AC%E4%BD%8E%E7%9A%84">9. struts、hibernate的javassist-3.18.1-GA.jar包重复,删除版本低的.</a></li>
<li><a href="#10-ognl%E8%A1%A8%E8%BE%BE%E5%BC%8F">10. OGNL表达式</a>
<ul>
<li><a href="#101-ognl%E4%B8%8Estruts2%E7%9A%84%E7%BB%93%E5%90%88%E5%8E%9F%E7%90%86">10.1. OGNL与Struts2的结合原理</a></li>
<li><a href="#102-struts2%E4%B8%8Eognl%E7%BB%93%E5%90%88%E4%BD%93%E7%8E%B0">10.2. struts2与ognl结合体现</a></li>
</ul>
</li>
<li><a href="#11-%E8%87%AA%E5%AE%9A%E4%B9%89%E6%8B%A6%E6%88%AA%E5%99%A8">11. 自定义拦截器</a></li>
<li><a href="#12-struts2%E6%A0%87%E7%AD%BE%E4%BA%86%E8%A7%A3">12. struts2标签(了解)</a></li>
<li><a href="#13-%E8%A1%A8%E7%8E%B0%E5%B1%82%E6%8A%BD%E5%8F%96">13. 表现层抽取</a></li>
<li><a href="#14-%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0">14. 文件上传</a></li>
<li><a href="#15-%E5%A4%84%E7%90%86ajax%E8%AF%B7%E6%B1%82">15. 处理Ajax请求</a></li>
</ul>
<!-- /TOC -->
<!--more-->
<h1>1. struts2访问流程&amp;架构&amp;介绍</h1>
<ul>
<li>自动封装参数、参数校验、结果的处理(转发|重定向)、国际化、显示等待页面、表单的防止重复提交</li>
<li>struts2前身：webwork框架(基于filter)与struts1(基于Servlet)两者无关.</li>
</ul>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/61bb9c3bcf7d5ee3f1d3a.png" alt="struts2.png" tabindex="0"><figcaption>struts2.png</figcaption></figure>
<h1>2. 搭建struts2框架</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>导包:web-content --&gt;web-INF--&gt;lib
asm-3.3.jar
asm-commons-3.3.jar
asm-tree-3.3.jar
commons-fileupload-1.3.1.jar
commons-io-2.2.jar
commons-lang3-3.2.jar
freemarker-2.3.22.jar
javassist-3.11.0.GA.jar
log4j-api-2.2.jar
log4j-core-2.2.jar
ognl-3.0.6.jar
struts2-core-2.3.24.jar
xwork-core-2.3.24.jar

在src下面创建*Action.java
	方法一：创建一个类.不继承任何父类.不实现任何接口.使struts2框架的代码侵入性更低.
	public class DemoAction {
		public String hello(){
			return "success";
		}
	}
	方法二：实现一个接口Action
	import com.opensymphony.xwork2.Action;
	// 里面有execute方法,提供action方法的规范.
	// Action接口预置了一些字符串.可以在返回结果时使用.为了方便
	public class DemoAction implements Action {
		@Override
		public String execute() throws Exception {
			return null;
		}
	}
	方法三：继承ActionSupport
	// 帮我们实现了 Validateable, ValidationAware, TextProvider, LocaleProvider .
	//如果我们需要用到这些接口的实现时,不需要自己来实现了.
	public class Demo5Action  extends ActionSupport{}

创建struts主配置文件在src下创建struts.xml
导入约束window菜单--&gt; preference--&gt;cata 在web App Libraries--struts2-core-2.3.24.jar--struts-2.3.dtd
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;!DOCTYPE struts PUBLIC
"-//Apache Software Foundation//DTD Struts Configuration 2.3//EN"
"http://struts.apache.org/dtds/struts-2.3.dtd"&gt;
&lt;struts&gt;
		&lt;!-- package:将Action配置封装.就是可以在Package中配置很多action.
			name属性: 给包起个名字,起到标识作用.随便起.不能其他包名重复.
			namespace属性:给action的访问路径中定义一个命名空间
			extends属性: 继承一个 指定包
			abstract属性:包是否为抽象的; 标识性属性.标识该包不能独立运行.专门被继承 --&gt;
	&lt;package name="hello" namespace="/hello" extends="struts-default"&gt;
			&lt;!-- action元素:配置action类
				name属性: 决定了Action访问资源名.
				class属性: action的完整类名
				method属性: 指定调用Action中的哪个方法来处理请求 --&gt;
		&lt;action name="TestAction" class="com.junye.test.HelloAction" method="fun"&gt;
			&lt;!-- result元素:结果配置 
				name属性: 标识结果处理的名称.与action方法的返回值对应.
				type属性: 指定调用哪一个result类来处理结果,默认使用转发.
				标签体:填写页面的相对路径--&gt;
			&lt;result name="success"&gt;/hello.jsp&lt;/result&gt;
		&lt;/action&gt;
	&lt;/package&gt;
	&lt;!-- 引入其他struts配置文件 --&gt;
	&lt;include file="cn/junye/b_dynamic/struts.xml"&gt;&lt;/include&gt;
&lt;/struts&gt;

将struts2核心过滤器配置到web.xml,配置在欢迎页前面
	&lt;filter&gt;
		&lt;filter-name&gt;struts2&lt;/filter-name&gt;
		&lt;filter-class&gt;org.apache.struts2.dispatcher.ng.filter.StrutsPrepareAndExecuteFilter&lt;/filter-class&gt;
	&lt;/filter&gt;
	&lt;filter-mapping&gt;
		&lt;filter-name&gt;struts2&lt;/filter-name&gt;
		&lt;url-pattern&gt;/*&lt;/url-pattern&gt;
	&lt;/filter-mapping&gt;
	
测试:访问http://localhost:8080/mystruts/hello/TestAction
</code></pre></div><h1>3. strust.xml配置详解</h1>
<ul>
<li>struts2常量配置方式(先后也是加载顺序)后加载覆盖</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>方式1:src/struts.xml（只用这个）
	&lt;constant name="struts.i18n.encoding" value="UTF8"&gt;&lt;/constant&gt;
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>方式2:在src下创建struts.properties：
struts.i18n.encoding=UTF8
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>方式3:在项目的web.xml中
&lt;context-param&gt;
	&lt;param-name&gt;struts.i18n.encoding&lt;/param-name&gt;
	&lt;param-value&gt;UTF-8&lt;/param-value&gt;
&lt;/context-param&gt;
</code></pre></div><ul>
<li>struts2常量配置位置App Libraries--struts2-core-2.3.24.jar--org.apache.struts2-default.properties;</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>&lt;!--常量配置struts.xml--&gt;
&lt;!-- i18n:国际化. 解决post提交乱码 get提交，按以前的方式--&gt;
&lt;constant name="struts.i18n.encoding" value="UTF-8"&gt;&lt;/constant&gt;
&lt;!-- 指定访问action时的后缀名 
http://localhost:8080/struts2_day01/hello/HelloAction.？默认.action 和 “空”--&gt;
&lt;constant name="struts.action.extension" value="？"&gt;&lt;/constant&gt;
&lt;!-- 指定struts2是否以开发模式运行1.热加载主配置.(不需要重启即可生效)2.提供更多错误信息输出,方便开发时的调试--&gt;
&lt;constant name="struts.devMode" value="true"&gt;&lt;/constant&gt;
</code></pre></div><ul>
<li>struts2动态方法调用(struts.xml)</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>通配符方式  使用{1} 取出第一个星号通配的内容
&lt;package name="dynamic" namespace="/dynamic" extends="struts-default" &gt;
	&lt;action name="Demo1Action_*" class="cn.b.Demo1Action" method="{1}" &gt;
		&lt;result name="success" &gt;/{1}.jsp&lt;/result&gt;
	&lt;/action&gt;
&lt;/package&gt;	
访问http://localhost:8080/struts2_day01/dynamic/Demo1Action_find.action跳转到find.jsp
</code></pre></div><ul>
<li>struts2中的默认配置</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>&lt;package name="default" namespace="/default" extends="struts-default" &gt;
	&lt;!--不声明则默认访问,不管整合没整合--&gt;
	&lt;!--&lt;default-class-ref class="com.opensymphony.xwork2.ActionSupport" /&gt;--&gt;
	&lt;!-- 声明后找不到包下的action,会使用Demo2Action作为默认action处理请求 --&gt;
	&lt;default-action-ref name="Demo2Action"&gt;&lt;/default-action-ref&gt;
	&lt;!-- method属性:execute result的name属性:success   result的type属性:dispatcher转发  --&gt;
	&lt;!-- class属性:com.opensymphony.xwork2.ActionSupport --&gt;
	&lt;action name="Demo2Action"   &gt;
		&lt;result  &gt;/hello.jsp&lt;/result&gt;
	&lt;/action&gt;
&lt;/package&gt;
http://localhost:8080/struts2_day01/default/xxxx.action,默认访问Demo2Action
</code></pre></div><ul>
<li>结果跳转方式struts.xml中（result的type属性）用于post/get提交</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>	转发
	&lt;action name="Demo1Action" class="cn.a_result.Demo1Action" method="execute" &gt;
		&lt;result name="success" type="dispatcher" &gt;/hello.jsp&lt;/result&gt;
	&lt;/action&gt;

	重定向地址栏发生变化
	&lt;action name="Demo2Action" class="cn.a_result.Demo2Action" method="execute" &gt;
		&lt;result name="success" type="redirect" &gt;/hello.jsp&lt;/result&gt;
	&lt;/action&gt;

	转发到Action
	&lt;action name="Demo3Action" class="cn.a_result.Demo3Action" method="execute" &gt;
		&lt;result name="success" type="chain"&gt;
			&lt;param name="actionName"&gt;Demo1Action&lt;/param&gt;
			&lt;param name="namespace"&gt;/&lt;/param&gt;//转发的命名空间
		&lt;/result&gt;
	&lt;/action&gt;

	重定向到Action
	&lt;action name="Demo4Action" class="cn.a_result.Demo4Action" method="execute" &gt;
		&lt;result  name="success"  type="redirectAction"&gt;
			&lt;param name="actionName"&gt;Demo1Action&lt;/param&gt;
			&lt;param name="namespace"&gt;/&lt;/param&gt;//转发的命名空间
		&lt;/result&gt;
	&lt;/action&gt;
</code></pre></div><ul>
<li>全局结果集</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>&lt;global-result&gt;
	&lt;result name="" type="redirect"&gt;/login.jsp&lt;/result&gt;
&lt;/global-result&gt;
&lt;global-exception-mappings&gt;
	&lt;exception-mapping result="error" exception="java.lang.RuntimeException"&gt;
&lt;/exception-mapping&gt;
&lt;/global-exception-mappings&gt;
</code></pre></div><h1>4. Action生命周期</h1>
<ul>
<li>1.每次请求到来时,都会创建一个新的Action实例、</li>
<li>2.Action是线程安全的.可以使用成员变量接收参数,servlet线程不安全</li>
</ul>
<h1>5. ActionContext内容</h1>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/01a9aa1dcc1e771d064fe.png" alt="ActionContext.png" tabindex="0"><figcaption>ActionContext.png</figcaption></figure>
<ul>
<li>attr域以最小的域的map的键为准、request域就是request中的一个map</li>
</ul>
<h1>6. 访问servletAPI方式</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>通过ActionContext,通过Map原来的方法键值对获得,或者通过封装好的方法获得
//request域=&gt; map (不推荐,ActionContext生命周期和request一样，推荐ActionContext)
//不推荐Map&lt;String, Object&gt; requestScope = (Map&lt;String, Object&gt;) ActionContext.getContext().get("request");
ActionContext.getContext().put("name", "requestTom");//推荐

//session域 =&gt; map
Map&lt;String, Object&gt; sessionScope = ActionContext.getContext().getSession();
sessionScope.put("name", "sessionTom");
销毁session：ActionContext.getContext().getSession().invalidate();

//application域=&gt;map
Map&lt;String, Object&gt;applicationScope =ActionContext.getContext().getApplication(); 
操作map put("name","Tom")、remove("name", "Tom")、get("","");

//获得原生response的方法(推荐)
HttpServletResponse response = ServletActionContext.getResponse();
	
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>通过ServletActionContext（不推荐）获得各种原生域
HttpServletRequest request = ServletActionContext.getRequest();
HttpSession session = request.getSession();
HttpServletResponse response = ServletActionContext.getResponse();
ServletContext servletContext = ServletActionContext.getServletContext();
PageContext pageContext = ServletActionContext.getPageContext();
操作各种域：setAttribute、addAttribute、getAttribute、removeAttribute
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>通过实现接口方式（用拦截器完成的）
public class Demo7Action extends ActionSupport implements ServletRequestAware {
	private HttpServletRequest request;
	public String execute() throws Exception { 	
		System.out.println("原生request:"+request);
		return SUCCESS;
	}
	@Override
	public void setServletRequest(HttpServletRequest request) {
		this.request = request;
	}	
}
</code></pre></div><h1>7. jsp获得</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>page：${pageScope.name};
request: ${requestScope.name}
session:${sessionScope.name}
application:${applicationScope.name}
${name}按顺序取
</code></pre></div><h1>8. Action接收参数</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>表单
&lt;form action="${pageContext.request.contextPath}/Demo8Action"&gt;
	用户名:&lt;input type="text" name="name" /&gt;&lt;br&gt;
	年龄:&lt;input type="text" name="age" /&gt;&lt;br&gt;
	生日:&lt;input type="text" name="birthday" /&gt;&lt;br&gt;
		&lt;input type="submit" value="提交" /&gt;
&lt;/form&gt;
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>单个类型：能获得radio和chekbox的值
属性驱动获得参数：set/get方法
public class Demo8Action extends ActionSupport  {
	//准备与参数键名称相同的属性
	private String name;
	//自动类型转换 只能转换8大基本数据类型以及对应包装类
	private Integer age;
	//支持特定类型字符串转换为Date ,例如 yyyy-MM-dd，一定要有set/get方法
	private Date   birthday;
	public String execute() throws Exception { 
		System.out.println("name参数值:"+name+",age参数值:"+age+",生日:"+birthday);
		return SUCCESS;
	}
}
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>对象驱动获得参数
public class Demo9Action extends ActionSupport  {
	private User user;//生成set/get方法
	public String execute() throws Exception { 	
		System.out.println(user);
		return SUCCESS;
	}
}
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>模型驱动获得参数实现接口（只能返回一个对象）
public class Demo10Action extends ActionSupport implements ModelDriven&lt;User&gt; {
	private User user =new User();
	public String execute() throws Exception { 
		System.out.println(user);
		return SUCCESS;
	}
	@Override
	public User getModel() {
		return user;
	}
}
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>	④radio或checkbox的获取
	只要将属性名字设置成对应的radio或checkbox的值即可获得提交的参数，
	radio是单个值，而checkbox是一行value，空格value的结构，拆分即可
	String[] split = hobby.split(", ");
	for(String s:split) {
		System.err.println(s);
	}
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>	⑤集合类型参数封装
	list:&lt;input type="text" name="list" /&gt;&lt;br&gt;//不指定索引则一个一个塞
	list:&lt;input type="text" name="list[3]" /&gt;&lt;br&gt;//指定就放到规定的地方，不指定就null
	private List&lt;String&gt; list;set、get方法
	map:&lt;input type="text" name="map['haha']" /&gt;&lt;br&gt;//值封装到键值haha上
	private Map&lt;String,String&gt; map;set/get方法
</code></pre></div><h1>9. struts、hibernate的javassist-3.18.1-GA.jar包重复,删除版本低的.</h1>
<h1>10. OGNL表达式</h1>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/ade13c1a8726195fa2700.png" alt="Ognl.png" tabindex="0"><figcaption>Ognl.png</figcaption></figure>
<ul>
<li>OGNL:对象视图导航语言.  ${<a href="http://user.addr.name" target="_blank" rel="noopener noreferrer">user.addr.name</a>} 这种写法就叫对象视图导航.</li>
<li>OGNL不仅仅可以视图导航.支持比EL表达式（11内置对象）更加丰富的功能.</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>	使用OGNL准备工作：struts2 的包中已经包含了ognl-3.0.6.jar.不需要导入额外的jar包
	保存
	root和context可以放多个对象或者map，查找时只输入key或者属性名即可。从栈顶一直查到栈低，重复的查不到两个
	User rootUser = new User("tom",18);
	Map&lt;String,User&gt; context = new HashMap&lt;String,User&gt;();
	context.put("user1", new User("jack",18));
	context.put("user2", new User("rose",22));
	OgnlContext oc = new OgnlContext();
	oc.setRoot(rootUser);//将rootUser作为root部分
	oc.setValues(context);//将context这个Map作为Context部分

	基本取值
	//取出root中user对象的name属性
	String name = (String) Ognl.getValue("name", oc, oc.getRoot());
	Integer age = (Integer) Ognl.getValue("age", oc, oc.getRoot());
	//取出context中键为user1对象的name属性#代表context
	String name = (String) Ognl.getValue("#user1.name", oc, oc.getRoot());
	String name2 = (String) Ognl.getValue("#user2.name", oc, oc.getRoot());
	Integer age = (Integer) Ognl.getValue("#user2.age", oc, oc.getRoot());

	赋值
	//将root中的user对象的name属性赋值
	Ognl.getValue("name='jerry'", oc, oc.getRoot());
	String name2 = (String) Ognl.getValue("#user1.name='a',#user1.name", oc, oc.getRoot());

	调用方法（赋值和取值）
	//调用root中user对象的setName方法
	Ognl.getValue("setName('lilei')", oc, oc.getRoot());
	String name = (String) Ognl.getValue("getName()", oc, oc.getRoot());
	String name2 = (String)Ognl.getValue("#user1.setName('lucy'),#user1.getName()", oc, oc.getRoot());

	调用静态方法（static）
	String name = (String) Ognl.getValue("@cn.a_ognl.HahaUtils@echo('hello 强勇!')", oc, oc.getRoot());//@完整类名
	//Double pi = (Double) Ognl.getValue("@java.lang.Math@PI", oc, oc.getRoot());
	Double pi = (Double) Ognl.getValue("@@PI", oc, oc.getRoot())

	创建对象(List,Map)
	Integer size = (Integer) Ognl.getValue("{'tom','jerry','jack','rose'}.size()", oc, oc.getRoot());
	String name = (String) Ognl.getValue("{'tom','jerry','jack','rose'}[0]", oc, oc.getRoot());//tom
	String name2 = (String) Ognl.getValue("{'tom','jerry','jack','rose'}.get(1)", oc, oc.getRoot());//jerry
	Integer size2 = (Integer) Ognl.getValue("#{'name':'tom','age':18}.size()", oc, oc.getRoot());
	String name3  = (String) Ognl.getValue("#{'name':'tom','age':18}['name']", oc, oc.getRoot());
	Integer age  = (Integer) Ognl.getValue("#{'name':'tom','age':18}.get('age')", oc, oc.getRoot());
</code></pre></div><h2>10.1. OGNL与Struts2的结合原理</h2>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/dee2b3721039564887ecb.png" alt="Struts2与Ognl结合原理.png" tabindex="0"><figcaption>Struts2与Ognl结合原理.png</figcaption></figure>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>	接口ValueStack实现类OgnlValueStack包括root和context两部分
	public class OgnlValueStack implements ValueStack{
		CompoundRoot root;//栈结构
		transient Map&lt;String,Object&gt; context;//map结构
	}

</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>	//root是栈，是由ArrayList和栈方法模拟的，访问栈中属性的特点.由上到下
	//默认情况下，root放置的是被访问的当前Aciton,请求参数被封装到Action中
	public class CompoundRoot extends ArrayList{
		//栈方法：弹栈
		public Object pop(){
			return remove(0);
		}
		//栈方法：压栈
		public Object push(Object o){
			add(0,o);
		}
	}
</code></pre></div><div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>	查看值栈中两部分内容
	(使用DEBUG标签)&lt;s:debug&gt;&lt;/s:debug&gt;
</code></pre></div><h2>10.2. struts2与ognl结合体现</h2>
<ul>
<li>参数接收</li>
</ul>
<figure><img src="https://290ff162.telegraph-image-eg9.pages.dev/file/01fe1aa30249f33864027.jpg" alt="ognl与struts2结合.JPG" tabindex="0"><figcaption>ognl与struts2结合.JPG</figcaption></figure>
<ul>
<li>
<p>获得ValueStack和ActionContext的方法</p>
<ul>
<li>获得ActionContext数据中心:  ActionContext.getContext();</li>
<li>获得值栈：ActionContext.getContext().getValueStack();</li>
</ul>
</li>
<li>
<p>ValueStack的API（少用）常用来接收表单数据，很少往这root放数据</p>
<ul>
<li>将数据obj放入值栈ValueStack中的Root：ActionContext.getContext().getValueStack().push(obj);</li>
<li>从值栈ValueStack中的Root将数据obj取出：ActionContext.getContext().getValueStack().pop();</li>
<li>从值栈ValueStack中的Root将查询数据Object findValue = ActionContext.getContext().getValueStack().findValue("name");</li>
<li>从值栈ValueStack中的Root将修改数据ActionContext.getContext().getValueStack().setParameter("name", "name");</li>
<li>通过键值对key和value将数据放入值栈ValueStack中的Context：ActionContext.getContext().put(key, value);</li>
<li>通过键名找到值栈ValueStack中的对象Object object = ActionContext.getContext().get("name");</li>
<li>可以通过EL表达式${}从值栈中的Context取数据</li>
</ul>
</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>&lt;action name="Demo4Action" class="cn.a_result.Demo4Action" method="execute" &gt;
	&lt;result  name="success"  type="redirectAction"&gt;
		&lt;param name="actionName"&gt;Demo1Action&lt;/param&gt;
		&lt;param name="namespace"&gt;/&lt;/param&gt;//转发的命名空间
		&lt;param name="name"&gt;{{name}}&lt;/param&gt;//转发的命名空间
	&lt;/result&gt;
&lt;/action&gt;
语法:${ognl表达式}，将数据传递到结果那边，不过一般都是在域中传递，不常用
可以通过EL表达式${}从值栈中的Context取数据

扩展:request对象的getAttribute方法
同时也是ognl表达式获得参数的方法（查找顺序）
request.getAttribute()
原生request域
查找valueStack的Root部分（栈）
查找valueStack的context部分（ActionContext）
</code></pre></div><h1>11. 自定义拦截器</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>//拦截器生命周期:随项目的启动而创建,随项目关闭而销毁
①拦截器创建
方法一：实现Interceptor接口并实现其三个方法
public class MyInterceptor implements Intercepter{}

方法二：继承AbstractInterceptor
空实现了init 和 destory方法. 我们如果不需要实现这两个方法,就可以只实现intercept方法
public class MyInterceptor2 extends AbstractInterceptor {}

方法三：继承MethodFilterInterceptor 方法过滤拦截器并复写doIntercept方法
//功能: 定制拦截器拦截的方法.  定制哪些方法需要拦截、哪些方法不需要拦截
public class MyInterceptor3 extends MethodFilterInterceptor{
	doIntercept(ActionInvocation invocation){
		放行+前后处理:
		//前处理
		invocation.invoke();
		//后处理
		//不处理直接放行
		return invocation.invoke();
		不放行,直接跳转到一个结果页面
		return "success";//不执行后续的拦截器以及Action,直接交给Result处理结果.进行页面跳转
	}
}

②配置struts.xml，在default.properties中可以找到相应的默认配置
注册拦截器&lt;interceptor name="" class=""&gt;&lt;/interceptor&gt;

定制拦截方法并配置拦截器栈
&lt;interceptor-stack name="myStack"&gt;
	&lt;!-- 自定义拦截器引入(建议放在20个拦截器之前) --&gt;
	&lt;interceptor-ref name="myInter3"&gt;
		&lt;!-- 指定哪些方法不拦截
		&lt;param name="excludeMethods"&gt;add,delete&lt;/param&gt; --&gt;
		&lt;!-- 指定哪些方法需要拦截 --&gt;
		&lt;param name="includeMethods"&gt;add,delete&lt;/param&gt;
	&lt;/interceptor-ref&gt;
	&lt;!-- 引用默认的拦截器栈(20个) --&gt;
	&lt;interceptor-ref name="defaultStack"&gt;&lt;/interceptor-ref&gt;
&lt;/interceptor-stack&gt;

指定包中默认拦截器栈&lt;default-interceptor-ref name="myStack"&gt;&lt;/default-interceptor-ref&gt;

Action指定拦截器
&lt;action name="Demo1Action_*" class="cn.interceptor.Demo1Action" method="{1}" &gt;
	&lt;!-- 为Action单独指定走哪个拦截器(栈) 
	&lt;interceptor-ref name="myStack"&gt;&lt;/interceptor-ref&gt;--&gt;
	&lt;result name="success" type="dispatcher" &gt;/index.jsp&lt;/result&gt;
&lt;/action&gt;
</code></pre></div><h1>12. struts2标签(了解)</h1>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>	控制标签
	遍历标签 iterator 
	&lt;s:iterator value="#list" &gt;
		&lt;s:property /&gt;&lt;br&gt;
	&lt;/s:iterator&gt;

	&lt;s:iterator value="#list" var="name" &gt;
		&lt;s:property value="#name" /&gt;&lt;br&gt;
	&lt;/s:iterator&gt;

	&lt;s:iterator begin="1" end="100" step="1"  &gt;
		&lt;s:property /&gt;
	&lt;/s:iterator&gt;

	if标签
	&lt;s:if test="#list.size()==4"&gt;
		list长度为4!
	&lt;/s:if&gt;
	&lt;s:elseif test="#list.size()==3"&gt;
		list长度为3!
	&lt;/s:elseif&gt;
	&lt;s:else&gt;
		list不3不4!
	&lt;/s:else&gt;
	判断boolean值不要自己用==true判断

	数据标签
	&lt;!--property 配合ognl表达式页面取值,Action没有返回数据时没有值--&gt;
	&lt;s:property value="#list.size()" /&gt;
	&lt;!--获得session中的值，常用于表达登录用户信息--&gt;
	&lt;s:property value="#session.user.name" /&gt;

	表单标签
	&lt;!-- 好处1: 内置了一套样式.  - 好处2: 自动回显,根据栈中的属性  --&gt;
	&lt;!-- theme:指定表单的主题，就是表单的style，xhtml:默认，simple:没有主题--&gt;
	&lt;s:form action="Demo3Action" namespace="/" theme="xhtml" &gt;
		&lt;s:textfield name="name" label="用户名"  &gt;&lt;/s:textfield&gt;
		&lt;s:password name="password" label="密码" &gt;&lt;/s:password&gt;
		&lt;s:radio list="{'男','女'}" name="gender" label="性别" &gt;&lt;/s:radio&gt;
		&lt;s:radio list="#{1:'男',0:'女'}" name="gender" label="性别" &gt;&lt;/s:radio&gt;
		&lt;s:checkboxlist list="#{2:'抽烟',1:'喝酒',0:'烫头'}" name="habits" label="爱好" &gt;&lt;/s:checkboxlist&gt;
		&lt;s:select list="#{2:'大专',1:'本科',0:'硕士'}" headerKey="" headerValue="</code></pre></div>]]></content:encoded>
      <enclosure url="https://290ff162.telegraph-image-eg9.pages.dev/file/61bb9c3bcf7d5ee3f1d3a.png" type="image/png"/>
    </item>
    <item>
      <title>APISIX</title>
      <link>https://javaguide.cn/backend/apigateway/apisix.html</link>
      <guid>https://javaguide.cn/backend/apigateway/apisix.html</guid>
      <source url="https://javaguide.cn/rss.xml">APISIX</source>
      <category>后端</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Kong</title>
      <link>https://javaguide.cn/backend/apigateway/kong.html</link>
      <guid>https://javaguide.cn/backend/apigateway/kong.html</guid>
      <source url="https://javaguide.cn/rss.xml">Kong</source>
      <category>后端</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Soul</title>
      <link>https://javaguide.cn/backend/apigateway/soul.html</link>
      <guid>https://javaguide.cn/backend/apigateway/soul.html</guid>
      <source url="https://javaguide.cn/rss.xml">Soul</source>
      <category>后端</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Spring Cloud Gateway</title>
      <link>https://javaguide.cn/backend/apigateway/springcloudgateway.html</link>
      <guid>https://javaguide.cn/backend/apigateway/springcloudgateway.html</guid>
      <source url="https://javaguide.cn/rss.xml">Spring Cloud Gateway</source>
      <category>后端</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Zuul</title>
      <link>https://javaguide.cn/backend/apigateway/zuul.html</link>
      <guid>https://javaguide.cn/backend/apigateway/zuul.html</guid>
      <source url="https://javaguide.cn/rss.xml">Zuul</source>
      <category>后端</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Apollo</title>
      <link>https://javaguide.cn/backend/configcenter/apollo.html</link>
      <guid>https://javaguide.cn/backend/configcenter/apollo.html</guid>
      <source url="https://javaguide.cn/rss.xml">Apollo</source>
      <category>后端</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Disconf</title>
      <link>https://javaguide.cn/backend/configcenter/disconf.html</link>
      <guid>https://javaguide.cn/backend/configcenter/disconf.html</guid>
      <source url="https://javaguide.cn/rss.xml">Disconf</source>
      <category>后端</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Nacos</title>
      <link>https://javaguide.cn/backend/configcenter/nacos.html</link>
      <guid>https://javaguide.cn/backend/configcenter/nacos.html</guid>
      <source url="https://javaguide.cn/rss.xml">Nacos</source>
      <category>后端</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Spring Cloud Config</title>
      <link>https://javaguide.cn/backend/configcenter/springcloudconfig.html</link>
      <guid>https://javaguide.cn/backend/configcenter/springcloudconfig.html</guid>
      <source url="https://javaguide.cn/rss.xml">Spring Cloud Config</source>
      <category>后端</category>
      <pubDate>Sun, 01 Jan 2023 00:00:00 GMT</pubDate>
    </item>
  </channel>
</rss>